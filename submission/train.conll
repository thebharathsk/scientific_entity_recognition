FERMAT -X- _ B-MethodName
: -X- _ O
An -X- _ O
Alternative -X- _ O
to -X- _ O
Accuracy -X- _ O
for -X- _ O
Numerical -X- _ B-TaskName
Reasoning -X- _ I-TaskName

While -X- _ O
pre -X- _ O
- -X- _ O
trained -X- _ O
language -X- _ O
models -X- _ O
achieve -X- _ O
impressive -X- _ O
performance -X- _ O
on -X- _ O
various -X- _ O
NLP -X- _ O
benchmarks -X- _ O
, -X- _ O
they -X- _ O
still -X- _ O
struggle -X- _ O
with -X- _ O
tasks -X- _ O
that -X- _ O
require -X- _ O
numerical -X- _ B-TaskName
reasoning -X- _ I-TaskName
. -X- _ O
Recent -X- _ O
advances -X- _ O
in -X- _ O
improving -X- _ O
numerical -X- _ O
reasoning -X- _ O
are -X- _ O
mostly -X- _ O
achieved -X- _ O
using -X- _ O
very -X- _ O
large -X- _ O
language -X- _ O
models -X- _ O
that -X- _ O
contain -X- _ O
billions -X- _ O
of -X- _ O
parameters -X- _ O
and -X- _ O
are -X- _ O
not -X- _ O
accessible -X- _ O
to -X- _ O
everyone -X- _ O
. -X- _ O
In -X- _ O
addition -X- _ O
, -X- _ O
numerical -X- _ B-TaskName
reasoning -X- _ I-TaskName
is -X- _ O
measured -X- _ O
using -X- _ O
a -X- _ O
single -X- _ O
score -X- _ O
on -X- _ O
existing -X- _ O
datasets -X- _ O
. -X- _ O
As -X- _ O
a -X- _ O
result -X- _ O
, -X- _ O
we -X- _ O
do -X- _ O
not -X- _ O
have -X- _ O
a -X- _ O
clear -X- _ O
understanding -X- _ O
of -X- _ O
the -X- _ O
strengths -X- _ O
and -X- _ O
shortcomings -X- _ O
of -X- _ O
existing -X- _ O
models -X- _ O
on -X- _ O
different -X- _ O
numerical -X- _ O
reasoning -X- _ O
aspects -X- _ O
and -X- _ O
therefore -X- _ O
, -X- _ O
potential -X- _ O
ways -X- _ O
to -X- _ O
improve -X- _ O
them -X- _ O
apart -X- _ O
from -X- _ O
scaling -X- _ O
them -X- _ O
up -X- _ O
. -X- _ O
Inspired -X- _ O
by -X- _ O
CheckList -X- _ O
( -X- _ O
Ribeiro -X- _ O
et -X- _ O
al -X- _ O
. -X- _ O
, -X- _ O
2020 -X- _ O
) -X- _ O
, -X- _ O
we -X- _ O
introduce -X- _ O
a -X- _ O
multi -X- _ O
- -X- _ O
view -X- _ O
evaluation -X- _ O
set -X- _ O
for -X- _ O
numerical -X- _ O
reasoning -X- _ O
in -X- _ O
English -X- _ O
, -X- _ O
called -X- _ O
FERMAT -X- _ B-MethodName
. -X- _ O
Instead -X- _ O
of -X- _ O
reporting -X- _ O
a -X- _ O
single -X- _ O
score -X- _ O
on -X- _ O
a -X- _ O
whole -X- _ O
dataset -X- _ O
, -X- _ O
FERMAT -X- _ B-MethodName
evaluates -X- _ O
models -X- _ O
on -X- _ O
various -X- _ O
key -X- _ O
numerical -X- _ O
reasoning -X- _ O
aspects -X- _ O
such -X- _ O
as -X- _ O
number -X- _ B-TaskName
understanding -X- _ I-TaskName
, -X- _ I-TaskName
mathematical -X- _ I-TaskName
operations -X- _ I-TaskName
, -X- _ I-TaskName
and -X- _ I-TaskName
training -X- _ I-TaskName
dependency -X- _ I-TaskName
. -X- _ O
Apart -X- _ O
from -X- _ O
providing -X- _ O
a -X- _ O
comprehensive -X- _ O
evaluation -X- _ O
of -X- _ O
models -X- _ O
on -X- _ O
different -X- _ O
numerical -X- _ O
reasoning -X- _ O
aspects -X- _ O
, -X- _ O
FERMAT -X- _ B-MethodName
enables -X- _ O
a -X- _ O
systematic -X- _ O
and -X- _ O
automated -X- _ O
generation -X- _ O
of -X- _ O
an -X- _ O
arbitrarily -X- _ O
large -X- _ O
training -X- _ O
or -X- _ O
evaluation -X- _ O
set -X- _ O
for -X- _ O
each -X- _ O
aspect -X- _ O
. -X- _ O
The -X- _ O
datasets -X- _ O
and -X- _ O
codes -X- _ O
are -X- _ O
publicly -X- _ O
available -X- _ O
to -X- _ O
generate -X- _ O
further -X- _ O
multi -X- _ O
- -X- _ O
view -X- _ O
data -X- _ O
for -X- _ O
ulterior -X- _ O
tasks -X- _ O
and -X- _ O
languages -X- _ O
. -X- _ O
1 -X- _ O

Numerical -X- _ B-TaskName
reasoning -X- _ I-TaskName
is -X- _ O
an -X- _ O
aspect -X- _ O
that -X- _ O
is -X- _ O
often -X- _ O
forgotten -X- _ O
despite -X- _ O
being -X- _ O
an -X- _ O
integral -X- _ O
part -X- _ O
of -X- _ O
natural -X- _ O
language -X- _ O
. -X- _ O
It -X- _ O
is -X- _ O
the -X- _ O
ability -X- _ O
to -X- _ O
interact -X- _ O
with -X- _ O
numbers -X- _ O
using -X- _ O
the -X- _ O
fundamental -X- _ O
mathematical -X- _ O
properties -X- _ O
and -X- _ O
thus -X- _ O
model -X- _ O
an -X- _ O
area -X- _ O
of -X- _ O
human -X- _ O
cognitive -X- _ O
thinking -X- _ O
( -X- _ O
Saxton -X- _ O
et -X- _ O
al -X- _ O
. -X- _ O
, -X- _ O
2019 -X- _ O
) -X- _ O
. -X- _ O
Better -X- _ O
understanding -X- _ O
of -X- _ O
numbers -X- _ O
in -X- _ O
language -X- _ O
models -X- _ O
would -X- _ O
benefit -X- _ O
various -X- _ O
tasks -X- _ O
like -X- _ O
fact -X- _ B-TaskName
- -X- _ I-TaskName
checking -X- _ I-TaskName
( -X- _ O
Vlachos -X- _ O
and -X- _ O
Riedel -X- _ O
, -X- _ O
2015 -X- _ O
) -X- _ O
, -X- _ O
text -X- _ B-TaskName
generation -X- _ I-TaskName
( -X- _ O
Moosavi -X- _ O
et -X- _ O
al -X- _ O
. -X- _ O
, -X- _ O
2021 -X- _ O
; -X- _ O
Suadaa -X- _ O
et -X- _ O
al -X- _ O
. -X- _ O
, -X- _ O
2021 -X- _ O
) -X- _ O
, -X- _ O
and -X- _ O
educational -X- _ O
tools -X- _ O
1 -X- _ O
https -X- _ O
: -X- _ O
/ -X- _ O
/ -X- _ O
github.com -X- _ O
/ -X- _ O
jasivan -X- _ O
/ -X- _ O
FERMAT -X- _ O
( -X- _ O
Mandal -X- _ O
et -X- _ O
al -X- _ O
. -X- _ O
, -X- _ O
2022 -X- _ O
) -X- _ O
. -X- _ O
Current -X- _ O
models -X- _ O
' -X- _ O
performance -X- _ O
are -X- _ O
still -X- _ O
too -X- _ O
weak -X- _ O
with -X- _ O
respect -X- _ O
to -X- _ O
numerical -X- _ O
accuracy -X- _ O
to -X- _ O
then -X- _ O
be -X- _ O
used -X- _ O
in -X- _ O
downstream -X- _ O
tasks -X- _ O
like -X- _ O
Infotabs -X- _ O
which -X- _ O
requires -X- _ O
identifying -X- _ O
numbers -X- _ O
in -X- _ O
tables -X- _ O
and -X- _ O
then -X- _ O
performing -X- _ O
operations -X- _ O
to -X- _ O
correctly -X- _ O
label -X- _ O
statements -X- _ O
causing -X- _ O
factuality -X- _ O
errors -X- _ O
in -X- _ O
such -X- _ O
tasks -X- _ O
. -X- _ O

Recently -X- _ O
, -X- _ O
we -X- _ O
have -X- _ O
observed -X- _ O
improved -X- _ O
performances -X- _ O
on -X- _ O
relevant -X- _ O
datasets -X- _ O
about -X- _ O
numerical -X- _ O
reasoning -X- _ O
using -X- _ O
very -X- _ O
large -X- _ O
language -X- _ O
models -X- _ O
( -X- _ O
Wei -X- _ O
et -X- _ O
al -X- _ O
. -X- _ O
, -X- _ O
2022b -X- _ O
; -X- _ O
Lewkowycz -X- _ O
et -X- _ O
al -X- _ O
. -X- _ O
, -X- _ O
2022 -X- _ O
; -X- _ O
Kojima -X- _ O
et -X- _ O
al -X- _ O
. -X- _ O
, -X- _ O
2022 -X- _ O
) -X- _ O
. -X- _ O
However -X- _ O
, -X- _ O
there -X- _ O
are -X- _ O
two -X- _ O
main -X- _ O
limitations -X- _ O
to -X- _ O
this -X- _ O
recent -X- _ O
trend -X- _ O
. -X- _ O
First -X- _ O
, -X- _ O
as -X- _ O
models -X- _ O
become -X- _ O
larger -X- _ O
their -X- _ O
access -X- _ O
becomes -X- _ O
restricted -X- _ O
to -X- _ O
fewer -X- _ O
users -X- _ O
, -X- _ O
i.e. -X- _ O
, -X- _ O
users -X- _ O
with -X- _ O
the -X- _ O
computational -X- _ O
resources -X- _ O
of -X- _ O
large -X- _ O
companies -X- _ O
. -X- _ O
For -X- _ O
example -X- _ O
, -X- _ O
using -X- _ O
one -X- _ O
of -X- _ O
the -X- _ O
best -X- _ O
mathematical -X- _ O
models -X- _ O
, -X- _ O
the -X- _ O
540B -X- _ O
parameter -X- _ O
model -X- _ O
Minerva -X- _ B-MethodName
( -X- _ O
Lewkowycz -X- _ O
et -X- _ O
al -X- _ O
. -X- _ O
, -X- _ O
2022 -X- _ O
) -X- _ O
, -X- _ O
would -X- _ O
require -X- _ O
over -X- _ O
2212 -X- _ O
G -X- _ O
of -X- _ O
memory -X- _ O
for -X- _ O
inference -X- _ O
only -X- _ O
. -X- _ O
Second -X- _ O
, -X- _ O
the -X- _ O
numerical -X- _ O
reasoning -X- _ O
capabilities -X- _ O
of -X- _ O
existing -X- _ O
models -X- _ O
are -X- _ O
measured -X- _ O
using -X- _ O
a -X- _ O
single -X- _ O
score -X- _ O
, -X- _ O
i.e. -X- _ O
, -X- _ O
mostly -X- _ O
accuracy -X- _ O
on -X- _ O
common -X- _ O
benchmarks -X- _ O
like -X- _ O
GSM8 -X- _ B-DatasetName
K -X- _ I-DatasetName
( -X- _ O
Cobbe -X- _ O
et -X- _ O
al -X- _ O
. -X- _ O
, -X- _ O
2021 -X- _ O
) -X- _ O
. -X- _ O
Therefore -X- _ O
, -X- _ O
their -X- _ O
strengths -X- _ O
and -X- _ O
shortcomings -X- _ O
in -X- _ O
different -X- _ O
aspects -X- _ O
of -X- _ O
numerical -X- _ O
reasoning -X- _ O
compared -X- _ O
to -X- _ O
other -X- _ O
models -X- _ O
are -X- _ O
not -X- _ O
clear -X- _ O
. -X- _ O
As -X- _ O
a -X- _ O
result -X- _ O
, -X- _ O
it -X- _ O
is -X- _ O
unclear -X- _ O
what -X- _ O
numerical -X- _ O
reasoning -X- _ O
aspects -X- _ O
should -X- _ O
be -X- _ O
improved -X- _ O
to -X- _ O
improve -X- _ O
their -X- _ O
performance -X- _ O
on -X- _ O
datasets -X- _ O
requiring -X- _ O
numerical -X- _ O
reasoning -X- _ O
. -X- _ O

Motivated -X- _ O
by -X- _ O
CheckList -X- _ B-DatasetName
( -X- _ O
Ribeiro -X- _ O
et -X- _ O
al -X- _ O
. -X- _ O
, -X- _ O
2020 -X- _ O
) -X- _ O
, -X- _ O
which -X- _ O
is -X- _ O
a -X- _ O
behavioral -X- _ O
test -X- _ O
set -X- _ O
concerning -X- _ O
various -X- _ O
linguistic -X- _ O
aspects -X- _ O
of -X- _ O
the -X- _ O
input -X- _ O
language -X- _ O
, -X- _ O
we -X- _ O
propose -X- _ O
a -X- _ O
unique -X- _ O
and -X- _ O
open -X- _ O
Flexible -X- _ O
Evaluation -X- _ O
set -X- _ O
for -X- _ O
Representating -X- _ O
Multiviews -X- _ O
of -X- _ O
Arithmetic -X- _ O
Types -X- _ O
, -X- _ O
2 -X- _ O
FERMAT -X- _ O
, -X- _ O
for -X- _ O
evaluating -X- _ O
the -X- _ O
numerical -X- _ O
reasoning -X- _ O
capabilities -X- _ O
of -X- _ O
models -X- _ O
based -X- _ O
on -X- _ O
multiple -X- _ O
key -X- _ O
aspects -X- _ O
. -X- _ O
It -X- _ O
evaluates -X- _ O
models -X- _ O
according -X- _ O
to -X- _ O
( -X- _ O
a -X- _ O
) -X- _ O
different -X- _ O
ranges -X- _ O
and -X- _ O
representations -X- _ O
of -X- _ O
numbers -X- _ O
, -X- _ O
( -X- _ O
b -X- _ O
) -X- _ O
different -X- _ O
mathematical -X- _ O
operations -X- _ O
, -X- _ O
and -X- _ O
( -X- _ O
c -X- _ O
) -X- _ O
the -X- _ O
dependence -X- _ O
of -X- _ O
models -X- _ O
on -X- _ O
the -X- _ O
fine -X- _ O
- -X- _ O
tuning -X- _ O
data -X- _ O
. -X- _ O
In -X- _ O
addition -X- _ O
, -X- _ O
it -X- _ O
contains -X- _ O
a -X- _ O
tool -X- _ O
to -X- _ O
automatically -X- _ O
generate -X- _ O
new -X- _ O
instances -X- _ O
for -X- _ O
each -X- _ O
of -X- _ O
its -X- _ O
aspects -X- _ O
. -X- _ O
FERMAT -X- _ O
enables -X- _ O
( -X- _ O
a -X- _ O
) -X- _ O
the -X- _ O
identification -X- _ O
of -X- _ O
the -X- _ O
strength -X- _ O
and -X- _ O
shortcomings -X- _ O
of -X- _ O
models -X- _ O
according -X- _ O
to -X- _ O
its -X- _ O
aspects -X- _ O
, -X- _ O
and -X- _ O
( -X- _ O
b -X- _ O
) -X- _ O
the -X- _ O
automatic -X- _ O
creation -X- _ O
of -X- _ O
additional -X- _ O
training -X- _ O
and -X- _ O
evaluation -X- _ O
instances -X- _ O
using -X- _ O
expert -X- _ O
written -X- _ O
templates -X- _ O
that -X- _ O
reflect -X- _ O
FERMAT -X- _ O
's -X- _ O
categories -X- _ O
. -X- _ O

FERMAT -X- _ O
complements -X- _ O
the -X- _ O
recently -X- _ O
proposed -X- _ O
LĪLA -X- _ B-MethodName
benchmark -X- _ I-MethodName
( -X- _ O
Mishra -X- _ O
et -X- _ O
al -X- _ O
. -X- _ O
, -X- _ O
2022a -X- _ O
) -X- _ O
for -X- _ O
mathematical -X- _ O
reasoning -X- _ O
. -X- _ O
LĪLA -X- _ O
evaluates -X- _ O
high -X- _ O
- -X- _ O
level -X- _ O
aspects -X- _ O
, -X- _ O
e.g. -X- _ O
whether -X- _ O
performing -X- _ O
mathematical -X- _ O
reasoning -X- _ O
also -X- _ O
depends -X- _ O
on -X- _ O
commonsense -X- _ O
knowledge -X- _ O
or -X- _ O
how -X- _ O
the -X- _ O
performance -X- _ O
changes -X- _ O
depending -X- _ O
on -X- _ O
the -X- _ O
difficulty -X- _ O
of -X- _ O
the -X- _ O
input -X- _ O
language -X- _ O
. -X- _ O
However -X- _ O
, -X- _ O
even -X- _ O
the -X- _ O
best -X- _ O
- -X- _ O
performing -X- _ O
model -X- _ O
on -X- _ O
the -X- _ O
LĪLA -X- _ O
benchmark -X- _ O
, -X- _ O
i.e. -X- _ O
, -X- _ O
a -X- _ O
2.7B -X- _ O
parameter -X- _ O
model -X- _ O
that -X- _ O
is -X- _ O
fine -X- _ O
- -X- _ O
tuned -X- _ O
on -X- _ O
mathematical -X- _ O
datasets -X- _ O
, -X- _ O
only -X- _ O
achieves -X- _ O
an -X- _ O
accuracy -X- _ B-MetricName
of -X- _ O
around -X- _ O
20 -X- _ B-MetricValue
- -X- _ I-MetricValue
30 -X- _ I-MetricValue
points -X- _ I-MetricValue
when -X- _ O
the -X- _ O
input -X- _ O
is -X- _ O
formulated -X- _ O
using -X- _ O
a -X- _ O
simple -X- _ O
language -X- _ O
and -X- _ O
the -X- _ O
test -X- _ O
data -X- _ O
is -X- _ O
from -X- _ O
a -X- _ O
different -X- _ O
distribution -X- _ O
than -X- _ O
that -X- _ O
of -X- _ O
the -X- _ O
training -X- _ O
, -X- _ O
and -X- _ O
it -X- _ O
is -X- _ O
not -X- _ O
clear -X- _ O
how -X- _ O
to -X- _ O
further -X- _ O
improve -X- _ O
this -X- _ O
performance -X- _ O
. -X- _ O

Number -X- _ B-TaskName
Understanding -X- _ I-TaskName

The -X- _ O
operations -X- _ O
sought -X- _ O
by -X- _ O
the -X- _ O
model -X- _ O
plays -X- _ O
a -X- _ O
vital -X- _ O
role -X- _ O
in -X- _ O
numerical -X- _ B-TaskName
reasoning -X- _ I-TaskName
. -X- _ O
A -X- _ O
one -X- _ O
- -X- _ O
hop -X- _ O
problem -X- _ O
which -X- _ O
requires -X- _ O
a -X- _ O
single -X- _ O
operation -X- _ O
, -X- _ O
to -X- _ O
a -X- _ O
human -X- _ O
, -X- _ O
would -X- _ O
seem -X- _ O
much -X- _ O
easier -X- _ O
than -X- _ O
a -X- _ O
two -X- _ O
- -X- _ O
hop -X- _ O
problem -X- _ O
where -X- _ O
an -X- _ O
intermediate -X- _ O
calculation -X- _ O
would -X- _ O
need -X- _ O
to -X- _ O
be -X- _ O
computed -X- _ O
first -X- _ O
. -X- _ O
With -X- _ O
regards -X- _ O
to -X- _ O
this -X- _ O
, -X- _ O
we -X- _ O
consider -X- _ O
9 -X- _ O
operation -X- _ O
sets -X- _ O
generated -X- _ O
using -X- _ O
basic -X- _ O
operations -X- _ O
( -X- _ O
addition -X- _ O
, -X- _ O
subtraction -X- _ O
, -X- _ O
multiplication -X- _ O
and -X- _ O
division -X- _ O
) -X- _ O
. -X- _ O
Their -X- _ O
distribution -X- _ O
is -X- _ O
given -X- _ O
in -X- _ O
Appendix -X- _ O
A -X- _ O
. -X- _ O

Training -X- _ O
Dependency -X- _ B-TaskName
Classification -X- _ I-TaskName

For -X- _ O
zero -X- _ O
- -X- _ O
shot -X- _ O
performance -X- _ O
, -X- _ O
we -X- _ O
evaluate -X- _ O
the -X- _ O
following -X- _ O
models -X- _ O
on -X- _ O
FERMAT -X- _ O
without -X- _ O
any -X- _ O
training -X- _ O
: -X- _ B-MethodName
11 -X- _ I-MethodName
T0 -X- _ I-MethodName
( -X- _ O
3B -X- _ B-HyperparameterValue
) -X- _ O
( -X- _ O
Sanh -X- _ O
et -X- _ O
al -X- _ O
. -X- _ O
, -X- _ O
2022 -X- _ O
) -X- _ O
, -X- _ O
FLAN -X- _ B-MethodName
- -X- _ I-MethodName
XL -X- _ I-MethodName
( -X- _ I-MethodName
3B -X- _ B-HyperparameterValue
) -X- _ O
( -X- _ O
Wei -X- _ O
et -X- _ O
al -X- _ O
. -X- _ O
, -X- _ O
2022a -X- _ O
) -X- _ O
, -X- _ O
BHĀSKARA -X- _ B-MethodName
( -X- _ O
2.7B -X- _ B-HyperparameterValue
) -X- _ O
( -X- _ O
Mishra -X- _ O
et -X- _ O
al -X- _ O
. -X- _ O
, -X- _ O
2022a -X- _ O
) -X- _ O
, -X- _ O
FLAN -X- _ B-MethodName
- -X- _ I-MethodName
large -X- _ I-MethodName
( -X- _ O
770 -X- _ B-HyperparameterValue
M -X- _ I-HyperparameterValue
) -X- _ O
, -X- _ O
FLAN -X- _ B-MethodName
- -X- _ I-MethodName
base -X- _ I-MethodName
( -X- _ O
220 -X- _ B-HyperparameterValue
M -X- _ I-HyperparameterValue
) -X- _ O
, -X- _ O
T5 -X- _ B-MethodName
- -X- _ I-MethodName
base -X- _ I-MethodName
( -X- _ O
220 -X- _ B-HyperparameterValue
M -X- _ I-HyperparameterValue
) -X- _ O
( -X- _ O
Raffel -X- _ O
et -X- _ O
al -X- _ O
. -X- _ O
, -X- _ O
2020 -X- _ O
) -X- _ O
, -X- _ O
BARTbase -X- _ B-MethodName
( -X- _ O
140 -X- _ B-HyperparameterValue
M -X- _ I-HyperparameterValue
) -X- _ O
( -X- _ O
Lewis -X- _ O
et -X- _ O
al -X- _ O
. -X- _ O
, -X- _ O
2020 -X- _ O
) -X- _ O
, -X- _ O
and -X- _ O
NT5 -X- _ B-MethodName
( -X- _ O
3 -X- _ B-HyperparameterValue
M -X- _ I-HyperparameterValue
) -X- _ O
, -X- _ O
where -X- _ O
the -X- _ O
size -X- _ O
of -X- _ O
the -X- _ O
models -X- _ O
is -X- _ O
given -X- _ O
in -X- _ O
brackets -X- _ O
. -X- _ O
A -X- _ O
zero -X- _ O
- -X- _ O
shot -X- _ O
evaluation -X- _ O
is -X- _ O
appropriate -X- _ O
because -X- _ O
these -X- _ O
models -X- _ O
are -X- _ O
intended -X- _ O
to -X- _ O
be -X- _ O
used -X- _ O
as -X- _ O
off -X- _ O
- -X- _ O
the -X- _ O
- -X- _ O
shelf -X- _ O
multi -X- _ O
- -X- _ O
purpose -X- _ O
models -X- _ O
. -X- _ O
T0 -X- _ B-MethodName
, -X- _ I-MethodName
FLAN -X- _ I-MethodName
, -X- _ I-MethodName
BHĀSKARA -X- _ I-MethodName
and -X- _ I-MethodName
NT5 -X- _ I-MethodName
have -X- _ O
been -X- _ O
trained -X- _ O
using -X- _ O
prompts -X- _ O
, -X- _ O
so -X- _ O
we -X- _ O
also -X- _ O
test -X- _ O
them -X- _ O
with -X- _ O
and -X- _ O
without -X- _ O
prompts -X- _ O
. -X- _ O
We -X- _ O
select -X- _ O
the -X- _ O
prompts -X- _ O
by -X- _ O
consulting -X- _ O
the -X- _ O
original -X- _ O
papers -X- _ O
and -X- _ O
judge -X- _ O
which -X- _ O
fit -X- _ O
closest -X- _ O
with -X- _ O
our -X- _ O
question -X- _ B-TaskName
answering -X- _ I-TaskName
task -X- _ O
( -X- _ O
see -X- _ O
Appendix -X- _ O
C -X- _ O
for -X- _ O
the -X- _ O
exact -X- _ O
prompts -X- _ O
used -X- _ O
) -X- _ O
. -X- _ O
From -X- _ O
the -X- _ O
models -X- _ O
we -X- _ O
considered -X- _ O
, -X- _ O
BHĀSKARA -X- _ O
, -X- _ O
FLAN -X- _ O
and -X- _ O
NT5 -X- _ O
are -X- _ O
the -X- _ O
ones -X- _ O
that -X- _ O
have -X- _ O
also -X- _ O
been -X- _ O
trained -X- _ O
for -X- _ O
maths -X- _ O
related -X- _ O
datasets -X- _ O
. -X- _ O
BHĀSKARA -X- _ O
is -X- _ O
trained -X- _ O
on -X- _ O
LĪLA -X- _ O
and -X- _ O
reaches -X- _ O
near -X- _ O
state -X- _ O
of -X- _ O
the -X- _ O
art -X- _ O
performance -X- _ O
, -X- _ O
thus -X- _ O
is -X- _ O
a -X- _ O
reliable -X- _ O
model -X- _ O
to -X- _ O
compare -X- _ O
numerical -X- _ O
reasoning -X- _ O
capabilities -X- _ O
. -X- _ O
However -X- _ O
, -X- _ O
since -X- _ O
LĪLA -X- _ O
contains -X- _ O
lots -X- _ O
of -X- _ O
existing -X- _ O
data -X- _ O
, -X- _ O
BHĀSKARA -X- _ O
has -X- _ O
seen -X- _ O
46.89 -X- _ O
% -X- _ O
of -X- _ O
the -X- _ O
Original -X- _ O
test -X- _ O
set -X- _ O
( -X- _ O
Mishra -X- _ O
et -X- _ O
al -X- _ O
. -X- _ O
, -X- _ O
2022a -X- _ O
) -X- _ O
at -X- _ O
training -X- _ O
time -X- _ O
. -X- _ O
It -X- _ O
also -X- _ O
includes -X- _ O
DeepMind -X- _ O
Mathematics -X- _ O
( -X- _ O
Saxton -X- _ O
et -X- _ O
al -X- _ O
. -X- _ O
, -X- _ O
2019 -X- _ O
) -X- _ O
in -X- _ O
its -X- _ O
pre -X- _ O
- -X- _ O
training -X- _ O
data -X- _ O
. -X- _ O
FLAN -X- _ O
has -X- _ O
also -X- _ O
seen -X- _ O
DeepMind -X- _ O
Mathematics -X- _ O
in -X- _ O
training -X- _ O
. -X- _ O
NT5 -X- _ O
is -X- _ O
pre -X- _ O
- -X- _ O
trained -X- _ O
on -X- _ O
synthetic -X- _ O
numerical -X- _ O
tasks -X- _ O
involving -X- _ O
non -X- _ O
- -X- _ O
worded -X- _ O
problems -X- _ O
with -X- _ O
integers -X- _ O
up -X- _ O
to -X- _ O
20000 -X- _ O
, -X- _ O
decimals -X- _ O
, -X- _ O
negatives -X- _ O
and -X- _ O
percentages -X- _ O
and -X- _ O
textual -X- _ O
tasks -X- _ O
as -X- _ O
described -X- _ O
by -X- _ O
Geva -X- _ O
et -X- _ O
al -X- _ O
. -X- _ O
( -X- _ O
2020 -X- _ O
) -X- _ O
, -X- _ O
and -X- _ O
then -X- _ O
fine -X- _ O
- -X- _ O
tuned -X- _ O
on -X- _ O
DROP -X- _ O
. -X- _ O

For -X- _ O
this -X- _ O
setting -X- _ O
, -X- _ O
we -X- _ O
create -X- _ O
a -X- _ O
training -X- _ O
data -X- _ O
called -X- _ O
Base -X- _ B-DatasetName
( -X- _ O
see -X- _ O
Section -X- _ O
4.2.1 -X- _ O
) -X- _ O
on -X- _ O
which -X- _ O
we -X- _ O
fine -X- _ O
- -X- _ O
tune -X- _ O
the -X- _ O
following -X- _ O
models -X- _ O
: -X- _ O
FLAN -X- _ B-MethodName
- -X- _ I-MethodName
large -X- _ I-MethodName
, -X- _ O
FLAN -X- _ B-MethodName
- -X- _ I-MethodName
base -X- _ I-MethodName
, -X- _ O
T5 -X- _ B-MethodName
- -X- _ I-MethodName
base -X- _ I-MethodName
, -X- _ O
BART -X- _ B-MethodName
- -X- _ I-MethodName
base -X- _ I-MethodName
and -X- _ O
NT5 -X- _ B-MethodName
accessed -X- _ O
from -X- _ O
Huggingface -X- _ O
( -X- _ O
Wolf -X- _ O
et -X- _ O
al -X- _ O
. -X- _ O
, -X- _ O
2020 -X- _ O
) -X- _ O
. -X- _ O
We -X- _ O
also -X- _ O
use -X- _ O
a -X- _ O
digit -X- _ O
tokeniser -X- _ O
as -X- _ O
implemented -X- _ O
by -X- _ O
Petrak -X- _ O
et -X- _ O
al -X- _ O
. -X- _ O
( -X- _ O
2022 -X- _ O
) -X- _ O
which -X- _ O
gives -X- _ O
more -X- _ O
promising -X- _ O
results -X- _ O
in -X- _ O
finetuning -X- _ O
experiments -X- _ O
compared -X- _ O
to -X- _ O
using -X- _ O
the -X- _ O
default -X- _ O
tokeniser -X- _ O
for -X- _ O
numbers -X- _ O
. -X- _ O
12 -X- _ O
Due -X- _ O
to -X- _ O
limitations -X- _ O
in -X- _ O
computational -X- _ O
resources -X- _ O
, -X- _ O
we -X- _ O
are -X- _ O
unable -X- _ O
to -X- _ O
use -X- _ O
the -X- _ O
3B -X- _ O
parameter -X- _ O
models -X- _ O
for -X- _ O
fine -X- _ O
- -X- _ O
tuning -X- _ O
. -X- _ O
Moreover -X- _ O
, -X- _ O
despite -X- _ O
BHĀSKARA -X- _ B-MethodName
being -X- _ O
advertised -X- _ O
as -X- _ O
a -X- _ O
good -X- _ O
starting -X- _ O
point -X- _ O
for -X- _ O
maths -X- _ O
related -X- _ O
data -X- _ O
, -X- _ O
it -X- _ O
is -X- _ O
still -X- _ O
too -X- _ O
big -X- _ O
for -X- _ O
us -X- _ O
to -X- _ O
train -X- _ O
. -X- _ O
13 -X- _ O

Table -X- _ O
2 -X- _ O
illustrates -X- _ O
the -X- _ O
zero -X- _ O
- -X- _ O
shot -X- _ O
and -X- _ O
fine -X- _ O
- -X- _ O
tuning -X- _ O
performance -X- _ O
of -X- _ O
eight -X- _ O
models -X- _ O
on -X- _ O
FERMAT -X- _ O
with -X- _ O
green -X- _ O
highlighting -X- _ O
the -X- _ O
stronger -X- _ O
performances -X- _ O
for -X- _ O
a -X- _ O
given -X- _ O
arithmetic -X- _ O
type -X- _ O
and -X- _ O
red -X- _ O
the -X- _ O
poorer -X- _ O
ones -X- _ O
. -X- _ O
For -X- _ O
models -X- _ O
that -X- _ O
use -X- _ O
prompts -X- _ O
( -X- _ O
T0 -X- _ B-MethodName
, -X- _ O
BHĀSKARA -X- _ B-MethodName
, -X- _ O
FLAN -X- _ B-MethodName
and -X- _ O
NT5 -X- _ B-MethodName
) -X- _ O
, -X- _ O
for -X- _ O
each -X- _ O
type -X- _ O
, -X- _ O
we -X- _ O
report -X- _ O
their -X- _ O
mean -X- _ O
accuracy -X- _ B-MetricName
using -X- _ O
all -X- _ O
the -X- _ O
prompts -X- _ O
and -X- _ O
no -X- _ O
- -X- _ O
prompt -X- _ O
settings -X- _ O
. -X- _ O
For -X- _ O
these -X- _ O
models -X- _ O
, -X- _ O
the -X- _ O
standard -X- _ B-MetricName
deviation -X- _ I-MetricName
between -X- _ O
the -X- _ O
prompted -X- _ O
and -X- _ O
non -X- _ O
- -X- _ O
prompted -X- _ O
results -X- _ O
is -X- _ O
below -X- _ O
1.5 -X- _ B-MetricValue
% -X- _ I-MetricValue
, -X- _ O
therefore -X- _ O
the -X- _ O
reported -X- _ O
results -X- _ O
are -X- _ O
representative -X- _ O
( -X- _ O
see -X- _ O
Appendix -X- _ O
E -X- _ O
for -X- _ O
the -X- _ O
full -X- _ O
results -X- _ O
) -X- _ O
. -X- _ O

Secondly -X- _ O
, -X- _ O
the -X- _ O
accuracy -X- _ B-MetricName
level -X- _ O
for -X- _ O
Original -X- _ O
is -X- _ O
always -X- _ O
part -X- _ O
of -X- _ O
the -X- _ O
highest -X- _ O
values -X- _ O
, -X- _ O
expect -X- _ O
for -X- _ O
NT5 -X- _ O
, -X- _ O
so -X- _ O
it -X- _ O
is -X- _ O
not -X- _ O
a -X- _ O
representative -X- _ O
test -X- _ O
set -X- _ O
for -X- _ O
numerical -X- _ O
reasoning -X- _ O
despite -X- _ O
being -X- _ O
derived -X- _ O
from -X- _ O
existing -X- _ O
benchmarks -X- _ O
. -X- _ O
This -X- _ O
could -X- _ O
also -X- _ O
be -X- _ O
due -X- _ O
to -X- _ O
the -X- _ O
poor -X- _ O
diversity -X- _ O
of -X- _ O
the -X- _ O
Original -X- _ O
set -X- _ O
as -X- _ O
stressed -X- _ O
in -X- _ O
Section -X- _ O
3.1.2 -X- _ O
. -X- _ O
Contrastingly -X- _ O
, -X- _ O
NT5 -X- _ O
has -X- _ O
its -X- _ O
highest -X- _ O
accuracy -X- _ B-MetricName
for -X- _ O
addition -X- _ O
and -X- _ O
subtraction -X- _ O
meaning -X- _ O
that -X- _ O
it -X- _ O
is -X- _ O
generally -X- _ O
learning -X- _ O
operations -X- _ O
over -X- _ O
specific -X- _ O
number -X- _ O
types -X- _ O
. -X- _ O

The -X- _ O
bars -X- _ O
' -X- _ O
monotonic -X- _ O
trend -X- _ O
suggests -X- _ O
that -X- _ O
if -X- _ O
more -X- _ O
of -X- _ O
a -X- _ O
test -X- _ O
expression -X- _ O
is -X- _ O
seen -X- _ O
at -X- _ O
training -X- _ O
, -X- _ O
the -X- _ O
model -X- _ O
is -X- _ O
more -X- _ O
likely -X- _ O
to -X- _ O
answer -X- _ O
it -X- _ O
correctly -X- _ O
. -X- _ O
However -X- _ O
, -X- _ O
even -X- _ O
for -X- _ O
the -X- _ O
exact -X- _ O
match -X- _ O
category -X- _ O
, -X- _ O
the -X- _ O
performance -X- _ B-MetricName
is -X- _ O
only -X- _ O
46 -X- _ B-MetricValue
% -X- _ I-MetricValue
. -X- _ O
This -X- _ O
is -X- _ O
because -X- _ O
the -X- _ O
language -X- _ O
that -X- _ O
is -X- _ O
used -X- _ O
to -X- _ O
describe -X- _ O
the -X- _ O
targeted -X- _ O
equation -X- _ O
may -X- _ O
be -X- _ O
different -X- _ O
in -X- _ O
different -X- _ O
instances -X- _ O
, -X- _ O
e.g. -X- _ O
the -X- _ O
words -X- _ O
" -X- _ O
another -X- _ O
" -X- _ O
and -X- _ O
" -X- _ O
increases -X- _ O
" -X- _ O
are -X- _ O
only -X- _ O
two -X- _ O
possible -X- _ O
terms -X- _ O
suggesting -X- _ O
an -X- _ O
addition -X- _ O
( -X- _ O
see -X- _ O
Appendix -X- _ O
B -X- _ O
for -X- _ O
their -X- _ O
use -X- _ O
in -X- _ O
context -X- _ O
) -X- _ O
, -X- _ O
indicating -X- _ O
that -X- _ O
the -X- _ O
model -X- _ O
needs -X- _ O
exposure -X- _ O
to -X- _ O
a -X- _ O
variety -X- _ O
of -X- _ O
different -X- _ O
ways -X- _ O
maths -X- _ O
is -X- _ O
expressed -X- _ O
and -X- _ O
that -X- _ O
enriching -X- _ O
the -X- _ O
training -X- _ O
data -X- _ O
with -X- _ O
higher -X- _ O
language -X- _ O
diversity -X- _ O
can -X- _ O
be -X- _ O
beneficial -X- _ O
. -X- _ O

In -X- _ O
addition -X- _ O
, -X- _ O
the -X- _ O
accuracy -X- _ B-MetricName
for -X- _ O
Exact -X- _ O
and -X- _ O
All -X- _ O
Numbers -X- _ O
classes -X- _ O
are -X- _ O
similar -X- _ O
for -X- _ O
both -X- _ O
models -X- _ O
highlighting -X- _ O
that -X- _ O
seeing -X- _ O
numbers -X- _ O
during -X- _ O
training -X- _ O
, -X- _ O
and -X- _ O
therefore -X- _ O
having -X- _ O
a -X- _ O
correct -X- _ O
encoding -X- _ O
for -X- _ O
them -X- _ O
, -X- _ O
plays -X- _ O
an -X- _ O
important -X- _ O
role -X- _ O
in -X- _ O
solving -X- _ O
their -X- _ O
corresponding -X- _ O
maths -X- _ O
operations -X- _ O
, -X- _ O
e.g. -X- _ O
89 -X- _ O
and -X- _ O
30 -X- _ O
appear -X- _ O
both -X- _ O
in -X- _ O
the -X- _ O
training -X- _ O
set -X- _ O
, -X- _ O
" -X- _ O
Stacey -X- _ O
prints -X- _ O
30 -X- _ O
letters -X- _ O
to -X- _ O
post -X- _ O
. -X- _ O
The -X- _ O
printer -X- _ O
was -X- _ O
filled -X- _ O
with -X- _ O
89 -X- _ O
sheets -X- _ O
of -X- _ O
paper -X- _ O
. -X- _ O
How -X- _ O
many -X- _ O
more -X- _ O
letters -X- _ O
could -X- _ O
she -X- _ O
print -X- _ O
? -X- _ O
" -X- _ O
, -X- _ O
and -X- _ O
in -X- _ O
the -X- _ O
2 -X- _ O
digit -X- _ O
test -X- _ O
set -X- _ O
, -X- _ O
" -X- _ O
89 -X- _ O
beavers -X- _ O
were -X- _ O
working -X- _ O
on -X- _ O
their -X- _ O
home -X- _ O
. -X- _ O
30 -X- _ O
went -X- _ O
for -X- _ O
a -X- _ O
swim -X- _ O
. -X- _ O
How -X- _ O
many -X- _ O
beavers -X- _ O
are -X- _ O
still -X- _ O
working -X- _ O
on -X- _ O
their -X- _ O
home -X- _ O
? -X- _ O
" -X- _ O
. -X- _ O
This -X- _ O
could -X- _ O
be -X- _ O
seconded -X- _ O
by -X- _ O
FLANlarge -X- _ B-MethodName
having -X- _ O
higher -X- _ O
accuracy -X- _ B-MetricName
than -X- _ O
T5 -X- _ B-MethodName
- -X- _ I-MethodName
base -X- _ I-MethodName
for -X- _ O
each -X- _ O
class -X- _ O
as -X- _ O
is -X- _ O
has -X- _ O
seen -X- _ O
more -X- _ O
maths -X- _ O
at -X- _ O
pre -X- _ O
- -X- _ O
training -X- _ O
. -X- _ O

To -X- _ O
make -X- _ O
a -X- _ O
fair -X- _ O
comparison -X- _ O
with -X- _ O
the -X- _ O
next -X- _ O
training -X- _ O
set -X- _ O
, -X- _ O
the -X- _ O
language -X- _ O
and -X- _ O
mathematics -X- _ O
is -X- _ O
fixed -X- _ O
as -X- _ O
it -X- _ O
only -X- _ O
uses -X- _ O
the -X- _ O
expert -X- _ O
templates -X- _ O
, -X- _ O
( -X- _ O
3 -X- _ O
) -X- _ O
Base -X- _ O
Diversified -X- _ O
starts -X- _ O
with -X- _ O
Base -X- _ O
and -X- _ O
also -X- _ O
adds -X- _ O
100 -X- _ O
K -X- _ O
instances -X- _ O
from -X- _ O
the -X- _ O
same -X- _ O
distribution -X- _ O
of -X- _ O
aspects -X- _ O
. -X- _ O
However -X- _ O
, -X- _ O
unlike -X- _ O
all -X- _ O
the -X- _ O
other -X- _ O
training -X- _ O
sets -X- _ O
which -X- _ O
purely -X- _ O
use -X- _ O
the -X- _ O
expert -X- _ O
templates -X- _ O
, -X- _ O
this -X- _ O
augments -X- _ O
the -X- _ O
initial -X- _ O
set -X- _ O
using -X- _ O
templates -X- _ O
recovered -X- _ O
from -X- _ O
GSM8 -X- _ O
K -X- _ O
and -X- _ O
AQUA -X- _ O
( -X- _ O
see -X- _ O
Section -X- _ O
3.4 -X- _ O
) -X- _ O
which -X- _ O
enhances -X- _ O
the -X- _ O
language -X- _ O
and -X- _ O
mathematics -X- _ O
seen -X- _ O
. -X- _ O
We -X- _ O
compare -X- _ O
FLAN -X- _ O
- -X- _ O
base -X- _ O
fine -X- _ O
- -X- _ O
tuned -X- _ O
on -X- _ O
the -X- _ O
above -X- _ O
training -X- _ O
set -X- _ O
along -X- _ O
with -X- _ O
the -X- _ O
model -X- _ O
's -X- _ O
zero -X- _ O
- -X- _ O
shot -X- _ O
baseline -X- _ O
performance -X- _ O
. -X- _ O
Figure -X- _ O
2 -X- _ O
illustrates -X- _ O
the -X- _ O
results -X- _ O
of -X- _ O
these -X- _ O
experiments -X- _ O
. -X- _ O
First -X- _ O
, -X- _ O
as -X- _ O
already -X- _ O
established -X- _ O
, -X- _ O
training -X- _ O
on -X- _ O
diverse -X- _ O
templates -X- _ O
over -X- _ O
a -X- _ O
variety -X- _ O
of -X- _ O
aspects -X- _ O
is -X- _ O
beneficial -X- _ O
by -X- _ O
the -X- _ O
shear -X- _ O
difference -X- _ O
illustrated -X- _ O
by -X- _ O
Figure -X- _ O
2 -X- _ O
between -X- _ O
Zero -X- _ O
- -X- _ O
shot -X- _ O
( -X- _ O
black -X- _ O
) -X- _ O
and -X- _ O
the -X- _ O
fine -X- _ O
- -X- _ O
tuned -X- _ O
performance -X- _ O
( -X- _ O
blue -X- _ O
, -X- _ O
orange -X- _ O
, -X- _ O
green -X- _ O
) -X- _ O
. -X- _ O
In -X- _ O
contrast -X- _ O
, -X- _ O
when -X- _ O
comparing -X- _ O
Base -X- _ O
( -X- _ O
blue -X- _ O
) -X- _ O
and -X- _ O
Base -X- _ O
Scaled -X- _ O
Up -X- _ O
( -X- _ O
orange -X- _ O
) -X- _ O
, -X- _ O
we -X- _ O
remark -X- _ O
that -X- _ O
despite -X- _ O
seeing -X- _ O
100 -X- _ O
K -X- _ O
more -X- _ O
combinations -X- _ O
of -X- _ O
numbers -X- _ O
and -X- _ O
operations -X- _ O
, -X- _ O
the -X- _ O
learning -X- _ O
stagnates -X- _ O
when -X- _ O
using -X- _ O
the -X- _ O
same -X- _ O
templates -X- _ O
meaning -X- _ O
that -X- _ O
the -X- _ O
model -X- _ O
has -X- _ O
learnt -X- _ O
as -X- _ O
much -X- _ O
as -X- _ O
it -X- _ O
could -X- _ O
from -X- _ O
the -X- _ O
breadth -X- _ O
of -X- _ O
the -X- _ O
available -X- _ O
templates -X- _ O
. -X- _ O
Consequently -X- _ O
, -X- _ O
either -X- _ O
linguistic -X- _ O
or -X- _ O
mathematical -X- _ O
diversity -X- _ O
is -X- _ O
required -X- _ O
to -X- _ O
make -X- _ O
a -X- _ O
sufficient -X- _ O
contribution -X- _ O
. -X- _ O
This -X- _ O
phenomenon -X- _ O
is -X- _ O
, -X- _ O
in -X- _ O
fact -X- _ O
, -X- _ O
displayed -X- _ O
by -X- _ O
the -X- _ O
improvement -X- _ B-MetricName
generated -X- _ O
by -X- _ O
Base -X- _ O
Diversified -X- _ O
( -X- _ O
green -X- _ O
) -X- _ O
, -X- _ O
in -X- _ O
certain -X- _ O
aspect -X- _ O
by -X- _ O
over -X- _ O
21 -X- _ B-MetricValue
% -X- _ I-MetricValue
. -X- _ O
The -X- _ O
diversity -X- _ O
helps -X- _ O
the -X- _ O
model -X- _ O
map -X- _ O
the -X- _ O
language -X- _ O
used -X- _ O
to -X- _ O
describe -X- _ O
particular -X- _ O
mathematics -X- _ O
better -X- _ O
, -X- _ O
for -X- _ O
instance -X- _ O
" -X- _ O
share -X- _ O
" -X- _ O
to -X- _ O
mean -X- _ O
" -X- _ O
division -X- _ O
" -X- _ O
, -X- _ O
and -X- _ O
possibly -X- _ O
observing -X- _ O
more -X- _ O
variety -X- _ O
of -X- _ O
this -X- _ O
in -X- _ O
different -X- _ O
context -X- _ O
seems -X- _ O
to -X- _ O
improve -X- _ O
the -X- _ O
model -X- _ O
. -X- _ O
Therefore -X- _ O
, -X- _ O
a -X- _ O
diversity -X- _ O
in -X- _ O
the -X- _ O
templates -X- _ O
used -X- _ O
is -X- _ O
important -X- _ O
, -X- _ O
suggesting -X- _ O
that -X- _ O
a -X- _ O
large -X- _ O
variety -X- _ O
of -X- _ O
language -X- _ O
may -X- _ O
be -X- _ O
required -X- _ O
to -X- _ O
attempt -X- _ O
to -X- _ O
further -X- _ O
ameliorate -X- _ O
the -X- _ O
performance -X- _ O
. -X- _ O
Nevertheless -X- _ O
, -X- _ O
the -X- _ O
mathematical -X- _ O
diversity -X- _ O
seems -X- _ O
to -X- _ O
also -X- _ O
play -X- _ O
a -X- _ O
more -X- _ O
important -X- _ O
role -X- _ O
as -X- _ O
the -X- _ O
diverse -X- _ O
templates -X- _ O
from -X- _ O
GSM8 -X- _ O
K -X- _ O
and -X- _ O
AQUA -X- _ O
have -X- _ O
more -X- _ O
two -X- _ O
- -X- _ O
hop -X- _ O
operations -X- _ O
( -X- _ O
see -X- _ O
Appendix -X- _ O
B -X- _ O
) -X- _ O
. -X- _ O
Relatedly -X- _ O
, -X- _ O
the -X- _ O
mean -X- _ O
percentage -X- _ O
increase -X- _ O
of -X- _ O
one -X- _ O
- -X- _ O
hop -X- _ O
operations -X- _ O
from -X- _ O
Base -X- _ O
to -X- _ O
Base -X- _ O
Diversified -X- _ O
is -X- _ O
approximately -X- _ O
95 -X- _ O
% -X- _ O
which -X- _ O
is -X- _ O
about -X- _ O
half -X- _ O
the -X- _ O
mean -X- _ O
percentage -X- _ O
increase -X- _ O
for -X- _ O
two -X- _ O
- -X- _ O
hop -X- _ O
operations -X- _ O
, -X- _ O
i.e. -X- _ O
187 -X- _ O
% -X- _ O
. -X- _ O
This -X- _ O
suggests -X- _ O
that -X- _ O
mathematical -X- _ O
variation -X- _ O
may -X- _ O
be -X- _ O
more -X- _ O
central -X- _ O
than -X- _ O
language -X- _ O
diversity -X- _ O
. -X- _ O

Third -X- _ O
, -X- _ O
a -X- _ O
noteworthy -X- _ O
observation -X- _ O
is -X- _ O
that -X- _ O
Base -X- _ B-MethodName
Diversified -X- _ I-MethodName
( -X- _ O
green -X- _ O
) -X- _ O
performs -X- _ O
worse -X- _ O
than -X- _ O
Base -X- _ B-MethodName
( -X- _ O
blue -X- _ O
) -X- _ O
only -X- _ O
on -X- _ O
the -X- _ O
" -X- _ O
Original -X- _ O
2dp -X- _ O
no -X- _ O
0 -X- _ O
" -X- _ O
aspect -X- _ O
, -X- _ O
e.g. -X- _ O
, -X- _ O
using -X- _ O
" -X- _ O
.32 -X- _ O
" -X- _ O
instead -X- _ O
of -X- _ O
" -X- _ O
0.32 -X- _ O
" -X- _ O
. -X- _ O
When -X- _ O
further -X- _ O
analysing -X- _ O
the -X- _ O
model -X- _ O
's -X- _ O
output -X- _ O
of -X- _ O
this -X- _ O
aspect -X- _ O
for -X- _ O
Base -X- _ O
Diversified -X- _ O
, -X- _ O
we -X- _ O
note -X- _ O
that -X- _ O
the -X- _ O
model -X- _ O
, -X- _ O
on -X- _ O
top -X- _ O
of -X- _ O
the -X- _ O
19.8 -X- _ O
% -X- _ O
accuracy -X- _ O
, -X- _ O
produces -X- _ O
an -X- _ O
additional -X- _ O
19.7 -X- _ O
% -X- _ O
of -X- _ O
outputs -X- _ O
containing -X- _ O
correct -X- _ O
digits -X- _ O
but -X- _ O
an -X- _ O
incorrect -X- _ O
magnitude -X- _ O
, -X- _ O
e.g. -X- _ O
, -X- _ O
the -X- _ O
correct -X- _ O
answer -X- _ O
might -X- _ O
be -X- _ O
" -X- _ O
1.8 -X- _ O
" -X- _ O
, -X- _ O
but -X- _ O
the -X- _ O
model -X- _ O
predicts -X- _ O
" -X- _ O
0.18 -X- _ O
" -X- _ O
. -X- _ O
The -X- _ O
model -X- _ O
might -X- _ O
be -X- _ O
disturbed -X- _ O
by -X- _ O
the -X- _ O
decimal -X- _ O
place -X- _ O
or -X- _ O
the -X- _ O
absence -X- _ O
of -X- _ O
zero -X- _ O
, -X- _ O
implying -X- _ O
that -X- _ O
number -X- _ O
encoding -X- _ O
including -X- _ O
positioning -X- _ O
is -X- _ O
vital -X- _ O
, -X- _ O
and -X- _ O
thus -X- _ O
, -X- _ O
an -X- _ O
accurate -X- _ O
encoding -X- _ O
of -X- _ O
numbers -X- _ O
is -X- _ O
crucial -X- _ O
. -X- _ O

The -X- _ O
majority -X- _ O
of -X- _ O
existing -X- _ O
datasets -X- _ O
for -X- _ O
numerical -X- _ B-TaskName
reasoning -X- _ I-TaskName
evaluate -X- _ O
models -X- _ O
based -X- _ O
on -X- _ O
a -X- _ O
single -X- _ O
score -X- _ O
, -X- _ O
making -X- _ O
it -X- _ O
impossible -X- _ O
to -X- _ O
identify -X- _ O
their -X- _ O
strengths -X- _ O
and -X- _ O
shortcomings -X- _ O
to -X- _ O
further -X- _ O
improve -X- _ O
them -X- _ O
. -X- _ O
Multi -X- _ O
- -X- _ O
view -X- _ O
benchmarks -X- _ O
are -X- _ O
the -X- _ O
alternative -X- _ O
for -X- _ O
a -X- _ O
more -X- _ O
comprehensive -X- _ O
and -X- _ O
informative -X- _ O
evaluation -X- _ O
of -X- _ O
models -X- _ O
. -X- _ O
In -X- _ O
this -X- _ O
direction -X- _ O
, -X- _ O
we -X- _ O
introduce -X- _ O
FERMAT -X- _ B-MethodName
, -X- _ O
a -X- _ O
multi -X- _ B-TaskName
- -X- _ I-TaskName
view -X- _ I-TaskName
evaluation -X- _ I-TaskName
set -X- _ O
that -X- _ O
enables -X- _ O
a -X- _ O
fine -X- _ O
- -X- _ O
grained -X- _ O
analysis -X- _ O
of -X- _ O
models -X- _ O
based -X- _ O
on -X- _ O
three -X- _ O
key -X- _ O
aspects -X- _ O
including -X- _ O
number -X- _ O
understanding -X- _ O
, -X- _ O
mathematical -X- _ O
operations -X- _ O
, -X- _ O
and -X- _ O
training -X- _ O
dependency -X- _ O
. -X- _ O
FERMAT -X- _ B-MethodName
's -X- _ O
aspects -X- _ O
are -X- _ O
associated -X- _ O
with -X- _ O
separate -X- _ O
templates -X- _ O
for -X- _ O
generating -X- _ O
instances -X- _ O
for -X- _ O
both -X- _ O
evaluation -X- _ O
and -X- _ O
training -X- _ O
sets -X- _ O
, -X- _ O
which -X- _ O
are -X- _ O
collected -X- _ O
from -X- _ O
completely -X- _ O
independent -X- _ O
sources -X- _ O
and -X- _ O
domains -X- _ O
. -X- _ O

Our -X- _ O
results -X- _ O
confirm -X- _ O
that -X- _ O
comparing -X- _ O
a -X- _ O
single -X- _ O
accuracy -X- _ B-MetricName
score -X- _ O
, -X- _ O
as -X- _ O
with -X- _ O
all -X- _ O
existing -X- _ O
maths -X- _ O
datasets -X- _ O
, -X- _ O
is -X- _ O
not -X- _ O
representative -X- _ O
of -X- _ O
the -X- _ O
performance -X- _ O
on -X- _ O
various -X- _ O
numerical -X- _ O
reasoning -X- _ O
aspects -X- _ O
as -X- _ O
the -X- _ O
evaluation -X- _ O
dataset -X- _ O
may -X- _ O
be -X- _ O
skewed -X- _ O
towards -X- _ O
a -X- _ O
specific -X- _ O
data -X- _ O
distribution -X- _ O
. -X- _ O
Based -X- _ O
on -X- _ O
our -X- _ O
results -X- _ O
, -X- _ O
a -X- _ O
wider -X- _ O
language -X- _ O
and -X- _ O
mathematical -X- _ O
variation -X- _ O
can -X- _ O
improve -X- _ O
even -X- _ O
smaller -X- _ O
models -X- _ O
. -X- _ O
However -X- _ O
, -X- _ O
an -X- _ O
apparent -X- _ O
future -X- _ O
direction -X- _ O
is -X- _ O
to -X- _ O
focus -X- _ O
on -X- _ O
improving -X- _ O
number -X- _ O
encodings -X- _ O
in -X- _ O
existing -X- _ O
models -X- _ O
and -X- _ O
understanding -X- _ O
how -X- _ O
these -X- _ O
affect -X- _ O
performance -X- _ O
. -X- _ O

The -X- _ O
hyperparameters -X- _ O
were -X- _ O
tested -X- _ O
on -X- _ O
a -X- _ O
smaller -X- _ O
set -X- _ O
for -X- _ O
efficiency -X- _ O
. -X- _ O
During -X- _ O
fine -X- _ O
- -X- _ O
tuning -X- _ O
, -X- _ O
we -X- _ O
used -X- _ O
100 -X- _ B-HyperparameterValue
epochs -X- _ B-HyperparameterName
with -X- _ O
an -X- _ O
early -X- _ B-HyperparameterName
stopping -X- _ I-HyperparameterName
patience -X- _ I-HyperparameterName
of -X- _ O
10 -X- _ B-HyperparameterValue
and -X- _ O
threshold -X- _ B-HyperparameterName
of -X- _ O
1.0 -X- _ B-HyperparameterValue
. -X- _ O
The -X- _ O
best -X- _ O
model -X- _ O
was -X- _ O
based -X- _ O
on -X- _ O
accuracy -X- _ B-MetricName
of -X- _ O
the -X- _ O
evaluation -X- _ B-HyperparameterName
set -X- _ I-HyperparameterName
. -X- _ O
All -X- _ O
experiments -X- _ O
were -X- _ O
conducted -X- _ O
with -X- _ O
a -X- _ O
learning -X- _ B-HyperparameterName
rate -X- _ I-HyperparameterName
of -X- _ O
5e-5 -X- _ B-HyperparameterValue
, -X- _ O
weight -X- _ B-HyperparameterName
decay -X- _ I-HyperparameterName
of -X- _ O
0.005 -X- _ B-HyperparameterValue
, -X- _ O
warm -X- _ B-HyperparameterName
- -X- _ I-HyperparameterName
up -X- _ I-HyperparameterName
of -X- _ O
100 -X- _ B-HyperparameterValue
, -X- _ O
float32 -X- _ B-HyperparameterValue
and -X- _ O
3 -X- _ B-HyperparameterValue
generation -X- _ B-HyperparameterName
beams -X- _ I-HyperparameterName
. -X- _ O
The -X- _ O
rest -X- _ O
of -X- _ O
the -X- _ O
hyperparameters -X- _ O
were -X- _ O
as -X- _ O
the -X- _ O
default -X- _ O
setting -X- _ O
in -X- _ O
Huggingface -X- _ O
. -X- _ O
The -X- _ O
max -X- _ B-HyperparameterName
input -X- _ I-HyperparameterName
length -X- _ I-HyperparameterName
was -X- _ O
512 -X- _ B-HyperparameterValue
and -X- _ O
max -X- _ B-HyperparameterName
target -X- _ I-HyperparameterName
length -X- _ I-HyperparameterName
, -X- _ O
16 -X- _ B-HyperparameterValue
which -X- _ O
is -X- _ O
above -X- _ O
the -X- _ O
12 -X- _ O
digit -X- _ O
limit -X- _ O
we -X- _ O
restrained -X- _ O
ourselves -X- _ O
to -X- _ O
for -X- _ O
the -X- _ O
answers -X- _ O
when -X- _ O
generating -X- _ O
questions -X- _ O
. -X- _ O
The -X- _ O
resource -X- _ O
used -X- _ O
was -X- _ O
an -X- _ O
Nvidia -X- _ O
Tesla -X- _ O
V100 -X- _ O
with -X- _ O
32G -X- _ O
. -X- _ O

Table -X- _ O
8 -X- _ O
shows -X- _ O
the -X- _ O
results -X- _ O
of -X- _ O
FLAN -X- _ O
- -X- _ O
base -X- _ O
for -X- _ O
each -X- _ O
numerical -X- _ O
reasoning -X- _ O
aspects -X- _ O
as -X- _ O
a -X- _ O
zero -X- _ O
- -X- _ O
shot -X- _ O
performance -X- _ O
and -X- _ O
when -X- _ O
fine -X- _ O
- -X- _ O
tuned -X- _ O
on -X- _ O
different -X- _ O
. -X- _ O
Accuracy -X- _ B-MetricName
is -X- _ O
given -X- _ O
as -X- _ O
a -X- _ O
percentage -X- _ O
. -X- _ O
Green -X- _ O
cells -X- _ O
indicate -X- _ O
higher -X- _ O
accuracy -X- _ B-MetricName
and -X- _ O
red -X- _ O
poorer -X- _ O
performance -X- _ B-MetricName
. -X- _ O
We -X- _ O
do -X- _ O
not -X- _ O
believe -X- _ O
our -X- _ O
work -X- _ O
to -X- _ O
have -X- _ O
potential -X- _ O
risks -X- _ O
, -X- _ O
instead -X- _ O
we -X- _ O
aim -X- _ O
to -X- _ O
reduce -X- _ O
environmental -X- _ O
impact -X- _ O
by -X- _ O
looking -X- _ O
at -X- _ O
alternative -X- _ O
to -X- _ O
large -X- _ O
models -X- _ O
. -X- _ O
We -X- _ O
aim -X- _ O
to -X- _ O
provide -X- _ O
this -X- _ O
when -X- _ O
these -X- _ O
artifacts -X- _ O
are -X- _ O
made -X- _ O
available -X- _ O
in -X- _ O
an -X- _ O
open -X- _ O
repository -X- _ O
. -X- _ O

DEER -X- _ B-MethodName
: -X- _ I-MethodName
Descriptive -X- _ I-MethodName
Knowledge -X- _ I-MethodName
Graph -X- _ I-MethodName
for -X- _ I-MethodName
Explaining -X- _ I-MethodName
Entity -X- _ I-MethodName
Relationships -X- _ I-MethodName

We -X- _ O
propose -X- _ O
DEER -X- _ B-MethodName
( -X- _ I-MethodName
Descriptive -X- _ I-MethodName
Knowledge -X- _ I-MethodName
Graph -X- _ I-MethodName
for -X- _ I-MethodName
Explaining -X- _ I-MethodName
Entity -X- _ I-MethodName
Relationships -X- _ I-MethodName
) -X- _ I-MethodName
an -X- _ O
open -X- _ O
and -X- _ O
informative -X- _ O
form -X- _ O
of -X- _ O
modeling -X- _ O
entity -X- _ B-TaskName
relationships -X- _ I-TaskName
. -X- _ O
In -X- _ O
DEER -X- _ O
, -X- _ O
relationships -X- _ O
between -X- _ O
entities -X- _ O
are -X- _ O
represented -X- _ O
by -X- _ O
free -X- _ O
- -X- _ O
text -X- _ O
relation -X- _ O
descriptions -X- _ O
. -X- _ O
For -X- _ O
instance -X- _ O
, -X- _ O
the -X- _ O
relationship -X- _ O
between -X- _ O
entities -X- _ O
of -X- _ O
machine -X- _ O
learning -X- _ O
and -X- _ O
algorithm -X- _ O
can -X- _ O
be -X- _ O
represented -X- _ O
as -X- _ O
" -X- _ O
Machine -X- _ O
learning -X- _ O
explores -X- _ O
the -X- _ O
study -X- _ O
and -X- _ O
construction -X- _ O
of -X- _ O
algorithms -X- _ O
that -X- _ O
can -X- _ O
learn -X- _ O
from -X- _ O
and -X- _ O
make -X- _ O
predictions -X- _ O
on -X- _ O
data -X- _ O
. -X- _ O
" -X- _ O
To -X- _ O
construct -X- _ O
DEER -X- _ B-MethodName
, -X- _ O
we -X- _ O
propose -X- _ O
a -X- _ O
self -X- _ O
- -X- _ O
supervised -X- _ O
learning -X- _ O
method -X- _ O
to -X- _ O
extract -X- _ O
relation -X- _ O
descriptions -X- _ O
with -X- _ O
the -X- _ O
analysis -X- _ O
of -X- _ O
dependency -X- _ O
patterns -X- _ O
and -X- _ O
generate -X- _ O
relation -X- _ O
descriptions -X- _ O
with -X- _ O
a -X- _ O
transformer -X- _ O
- -X- _ O
based -X- _ O
relation -X- _ O
description -X- _ O
synthesizing -X- _ O
model -X- _ O
, -X- _ O
where -X- _ O
no -X- _ O
human -X- _ O
labeling -X- _ O
is -X- _ O
required -X- _ O
. -X- _ O
Experiments -X- _ O
demonstrate -X- _ O
that -X- _ O
our -X- _ O
system -X- _ O
can -X- _ O
extract -X- _ O
and -X- _ O
generate -X- _ O
highquality -X- _ O
relation -X- _ O
descriptions -X- _ O
for -X- _ O
explaining -X- _ O
entity -X- _ O
relationships -X- _ O
. -X- _ O
The -X- _ O
results -X- _ O
suggest -X- _ O
that -X- _ O
we -X- _ O
can -X- _ O
build -X- _ O
an -X- _ O
open -X- _ O
and -X- _ O
informative -X- _ O
knowledge -X- _ O
graph -X- _ O
without -X- _ O
human -X- _ O
annotation -X- _ O
. -X- _ O
1As -X- _ O
of -X- _ O
2020 -X- _ O
, -X- _ O
deep -X- _ O
learning -X- _ O
has -X- _ O
become -X- _ O
the -X- _ O
dominant -X- _ O
approach -X- _ O
for -X- _ O
much -X- _ O
ongoing -X- _ O
work -X- _ O
in -X- _ O
the -X- _ O
field -X- _ O
of -X- _ O
machine -X- _ O
learning -X- _ O
. -X- _ O
Machine -X- _ O
learning -X- _ O
explores -X- _ O
the -X- _ O
study -X- _ O
and -X- _ O
construction -X- _ O
of -X- _ O
algorithms -X- _ O
that -X- _ O
can -X- _ O
learn -X- _ O
from -X- _ O
and -X- _ O
make -X- _ O
predictions -X- _ O
on -X- _ O
data -X- _ O
. -X- _ O
Machine -X- _ O
learning -X- _ O
is -X- _ O
a -X- _ O
subfield -X- _ O
of -X- _ O
soft -X- _ O
computing -X- _ O
within -X- _ O
computer -X- _ O
science -X- _ O
that -X- _ O
evolved -X- _ O
from -X- _ O
the -X- _ O
study -X- _ O
of -X- _ O
pattern -X- _ O
recognition -X- _ O
and -X- _ O
computational -X- _ O
learning -X- _ O
theory -X- _ O
in -X- _ O
artificial -X- _ O
intelligence -X- _ O
. -X- _ O
As -X- _ O
a -X- _ O
scientific -X- _ O
endeavor -X- _ O
, -X- _ O
machine -X- _ O
learning -X- _ O
grew -X- _ O
out -X- _ O
of -X- _ O
the -X- _ O
quest -X- _ O
for -X- _ O
artificial -X- _ O
intelligence -X- _ O
. -X- _ O
Regularization -X- _ O
, -X- _ O
in -X- _ O
the -X- _ O
context -X- _ O
of -X- _ O
machine -X- _ O
learning -X- _ O
, -X- _ O
refers -X- _ O
to -X- _ O
the -X- _ O
process -X- _ O
of -X- _ O
modifying -X- _ O
a -X- _ O
learning -X- _ O
algorithm -X- _ O
so -X- _ O
as -X- _ O
to -X- _ O
prevent -X- _ O
overfitting -X- _ O
. -X- _ O
Data -X- _ O
mining -X- _ O
uses -X- _ O
many -X- _ O
machine -X- _ O
learning -X- _ O
methods -X- _ O
, -X- _ O
but -X- _ O
with -X- _ O
different -X- _ O
goals -X- _ O
… -X- _ O

Based -X- _ O
on -X- _ O
the -X- _ O
above -X- _ O
analysis -X- _ O
, -X- _ O
we -X- _ O
propose -X- _ O
a -X- _ O
new -X- _ O
form -X- _ O
of -X- _ O
modeling -X- _ O
relationships -X- _ O
between -X- _ O
entities -X- _ O
: -X- _ O
DEER -X- _ B-MethodName
( -X- _ I-MethodName
Descriptive -X- _ I-MethodName
Knowledge -X- _ I-MethodName
Graph -X- _ I-MethodName
for -X- _ I-MethodName
Explaining -X- _ I-MethodName
Entity -X- _ I-MethodName
Relationships -X- _ I-MethodName
) -X- _ I-MethodName
. -X- _ O
We -X- _ O
define -X- _ O
DEER -X- _ B-MethodName
as -X- _ O
a -X- _ O
graph -X- _ O
, -X- _ O
where -X- _ O
nodes -X- _ O
are -X- _ O
entities -X- _ O
and -X- _ O
edges -X- _ O
are -X- _ O
descriptive -X- _ O
statements -X- _ O
of -X- _ O
entity -X- _ O
relationships -X- _ O
( -X- _ O
refer -X- _ O
to -X- _ O
Figure -X- _ O
1 -X- _ O
for -X- _ O
an -X- _ O
example -X- _ O
) -X- _ O
. -X- _ O
DEER -X- _ O
is -X- _ O
open -X- _ O
since -X- _ O
it -X- _ O
does -X- _ O
not -X- _ O
require -X- _ O
a -X- _ O
pre -X- _ O
- -X- _ O
specified -X- _ O
set -X- _ O
of -X- _ O
relation -X- _ O
types -X- _ O
. -X- _ O
In -X- _ O
principle -X- _ O
, -X- _ O
all -X- _ O
entity -X- _ O
relationships -X- _ O
, -X- _ O
either -X- _ O
explicit -X- _ O
or -X- _ O
implicit -X- _ O
, -X- _ O
can -X- _ O
be -X- _ O
represented -X- _ O
by -X- _ O
DEER -X- _ B-MethodName
, -X- _ O
as -X- _ O
long -X- _ O
as -X- _ O
they -X- _ O
can -X- _ O
be -X- _ O
connected -X- _ O
in -X- _ O
a -X- _ O
sentence -X- _ O
-which -X- _ O
is -X- _ O
not -X- _ O
possible -X- _ O
for -X- _ O
KGs -X- _ O
. -X- _ O
It -X- _ O
is -X- _ O
in- -X- _ O

The -X- _ O
key -X- _ O
to -X- _ O
building -X- _ O
DEER -X- _ O
is -X- _ O
to -X- _ O
acquire -X- _ O
highquality -X- _ O
relation -X- _ O
descriptions -X- _ O
. -X- _ O
However -X- _ O
, -X- _ O
writing -X- _ O
or -X- _ O
collecting -X- _ O
relation -X- _ O
descriptions -X- _ O
manually -X- _ O
requires -X- _ O
enormous -X- _ O
human -X- _ B-DatasetName
efforts -X- _ I-DatasetName
and -X- _ O
expertise -X- _ O
( -X- _ O
in -X- _ O
our -X- _ O
human -X- _ O
evaluation -X- _ O
in -X- _ O
Section -X- _ O
6.1 -X- _ O
, -X- _ O
it -X- _ O
takes -X- _ O
∼3 -X- _ O
minutes -X- _ O
to -X- _ O
evaluate -X- _ O
whether -X- _ O
a -X- _ O
sentence -X- _ O
is -X- _ O
a -X- _ O
good -X- _ O
relation -X- _ O
description -X- _ O
) -X- _ O
. -X- _ O
Considering -X- _ O
this -X- _ O
, -X- _ O
we -X- _ O
propose -X- _ O
a -X- _ O
novel -X- _ O
two -X- _ O
- -X- _ O
step -X- _ O
approach -X- _ O
to -X- _ O
construct -X- _ O
DEER -X- _ O
with -X- _ O
Wikipedia -X- _ O
, -X- _ O
where -X- _ O
no -X- _ O
manual -X- _ O
annotation -X- _ O
is -X- _ O
required -X- _ O
. -X- _ O
Specifically -X- _ O
, -X- _ O
we -X- _ O
first -X- _ O
extract -X- _ O
relation -X- _ O
descriptions -X- _ O
from -X- _ O
corpus -X- _ O
in -X- _ O
a -X- _ O
self -X- _ O
- -X- _ O
supervised -X- _ O
manner -X- _ O
, -X- _ O
where -X- _ O
a -X- _ O
scoring -X- _ O
function -X- _ O
is -X- _ O
introduced -X- _ O
to -X- _ O
measure -X- _ O
the -X- _ O
explicitness -X- _ O
, -X- _ O
i.e. -X- _ O
, -X- _ O
how -X- _ O
explicit -X- _ O
is -X- _ O
the -X- _ O
relationship -X- _ O
represented -X- _ O
by -X- _ O
the -X- _ O
sentence -X- _ O
, -X- _ O
and -X- _ O
significance -X- _ O
, -X- _ O
i.e. -X- _ O
, -X- _ O
how -X- _ O
significant -X- _ O
is -X- _ O
the -X- _ O
relationship -X- _ O
represented -X- _ O
, -X- _ O
with -X- _ O
the -X- _ O
analysis -X- _ O
of -X- _ O
dependency -X- _ O
patterns -X- _ O
. -X- _ O
Second -X- _ O
, -X- _ O
based -X- _ O
on -X- _ O
the -X- _ O
extracted -X- _ O
graph -X- _ O
, -X- _ O
a -X- _ O
transformer -X- _ O
- -X- _ O
based -X- _ O
relation -X- _ O
description -X- _ O
synthesizing -X- _ O
model -X- _ O
is -X- _ O
introduced -X- _ O
to -X- _ O
generate -X- _ O
relation -X- _ O
descriptions -X- _ O
for -X- _ O
interesting -X- _ O
entity -X- _ O
pairs -X- _ O
whose -X- _ O
relation -X- _ O
descriptions -X- _ O
are -X- _ O
not -X- _ O
extracted -X- _ O
in -X- _ O
the -X- _ O
first -X- _ O
step -X- _ O
. -X- _ O
This -X- _ O
allows -X- _ O
DEER -X- _ O
to -X- _ O
handle -X- _ O
a -X- _ O
large -X- _ O
number -X- _ O
of -X- _ O
entity -X- _ O
pairs -X- _ O
, -X- _ O
including -X- _ O
those -X- _ O
that -X- _ O
do -X- _ O
not -X- _ O
co -X- _ O
- -X- _ O
occur -X- _ O
in -X- _ O
the -X- _ O
corpus -X- _ O
. -X- _ O

Both -X- _ O
quantitative -X- _ O
and -X- _ O
qualitative -X- _ O
experiments -X- _ O
demonstrate -X- _ O
the -X- _ O
effectiveness -X- _ O
of -X- _ O
our -X- _ O
proposed -X- _ O
methods -X- _ O
. -X- _ O
We -X- _ O
also -X- _ O
conduct -X- _ O
case -X- _ O
study -X- _ O
and -X- _ O
error -X- _ O
analysis -X- _ O
and -X- _ O
suggest -X- _ O
several -X- _ O
promising -X- _ O
directions -X- _ O
for -X- _ O
future -X- _ O
work -X- _ O
-DEER -X- _ O
not -X- _ O
only -X- _ O
serves -X- _ O
as -X- _ O
a -X- _ O
valuable -X- _ O
application -X- _ O
in -X- _ O
itself -X- _ O
to -X- _ O
help -X- _ O
understand -X- _ O
entity -X- _ B-TaskName
relationships -X- _ I-TaskName
, -X- _ O
but -X- _ O
also -X- _ O
has -X- _ O
the -X- _ O
potential -X- _ O
to -X- _ O
serve -X- _ O
as -X- _ O
a -X- _ O
knowledge -X- _ O
source -X- _ O
to -X- _ O
facilitate -X- _ O
various -X- _ O
tasks -X- _ O
on -X- _ O
entities -X- _ O
and -X- _ O
entity -X- _ O
relationships -X- _ O
. -X- _ O

In -X- _ O
this -X- _ O
section -X- _ O
, -X- _ O
we -X- _ O
design -X- _ O
a -X- _ O
scoring -X- _ B-MetricName
function -X- _ I-MetricName
to -X- _ O
measure -X- _ O
the -X- _ O
quality -X- _ O
of -X- _ O
relation -X- _ O
descriptions -X- _ O
. -X- _ O
Since -X- _ O
we -X- _ O
use -X- _ O
Wikipedia -X- _ O
as -X- _ O
the -X- _ O
source -X- _ O
corpus -X- _ O
, -X- _ O
the -X- _ O
correctness -X- _ B-MetricName
of -X- _ O
the -X- _ O
extracted -X- _ O
sentences -X- _ O
can -X- _ O
be -X- _ O
largely -X- _ O
guaranteed -X- _ O
; -X- _ O
thus -X- _ O
, -X- _ O
we -X- _ O
focus -X- _ O
on -X- _ O
measuring -X- _ O
explicitness -X- _ B-MetricName
and -X- _ O
significance -X- _ B-MetricName
of -X- _ O
candidate -X- _ O
relation -X- _ O
descriptions -X- _ O
. -X- _ O

Shortest -X- _ B-MetricName
Dependency -X- _ I-MetricName
Path -X- _ I-MetricName
as -X- _ I-MetricName
Relation -X- _ I-MetricName

Explicitness -X- _ B-MetricName

Given -X- _ O
two -X- _ O
entities -X- _ O
and -X- _ O
a -X- _ O
candidate -X- _ O
relation -X- _ O
description -X- _ O
s -X- _ O
, -X- _ O
we -X- _ O
measure -X- _ O
the -X- _ O
explicitness -X- _ B-MetricName
by -X- _ O
calculating -X- _ O
the -X- _ O
normalized -X- _ O
logarithmic -X- _ O
frequency -X- _ O
of -X- _ O
the -X- _ O
relation -X- _ O
pattern -X- _ O
of -X- _ O
the -X- _ O
corePath -X- _ O
: -X- _ O

Significance -X- _ B-MetricName

We -X- _ O
measure -X- _ O
the -X- _ O
significance -X- _ B-MetricName
as -X- _ O
the -X- _ O
proportion -X- _ O
of -X- _ O
information -X- _ O
that -X- _ O
is -X- _ O
relevant -X- _ O
to -X- _ O
the -X- _ O
entity -X- _ O
relationship -X- _ O
in -X- _ O
a -X- _ O
sentence -X- _ O
. -X- _ O
To -X- _ O
measure -X- _ O
the -X- _ O
relevance -X- _ O
of -X- _ O
each -X- _ O
token -X- _ O
in -X- _ O
the -X- _ O
sentence -X- _ O
to -X- _ O
the -X- _ O
entity -X- _ O
relationship -X- _ O
, -X- _ O
we -X- _ O
divide -X- _ O
tokens -X- _ O
into -X- _ O
three -X- _ O
categories -X- _ O
: -X- _ O
1 -X- _ O
) -X- _ O
core -X- _ O
token -X- _ O
if -X- _ O
the -X- _ O
token -X- _ O
is -X- _ O
in -X- _ O
the -X- _ O
corePath -X- _ O
; -X- _ O
2 -X- _ O
) -X- _ O
modifying -X- _ O
token -X- _ O
if -X- _ O
the -X- _ O
token -X- _ O
is -X- _ O
in -X- _ O
a -X- _ O
subPath -X- _ O
that -X- _ O
is -X- _ O
connected -X- _ O
to -X- _ O
the -X- _ O
corePath -X- _ O
through -X- _ O
a -X- _ O
modifying -X- _ O
dependency -X- _ O
; -X- _ O
and -X- _ O
3 -X- _ O
) -X- _ O
irrelevant -X- _ O
token -X- _ O
for -X- _ O
the -X- _ O
rest -X- _ O
tokens -X- _ O
. -X- _ O
The -X- _ O
intuition -X- _ O
here -X- _ O
is -X- _ O
that -X- _ O
a -X- _ O
sub -X- _ O
- -X- _ O
dependency -X- _ O
tree -X- _ O
connected -X- _ O
to -X- _ O
the -X- _ O
corePath -X- _ O
with -X- _ O
a -X- _ O
modifying -X- _ O
dependency -X- _ O
is -X- _ O
supposed -X- _ O
to -X- _ O
modify -X- _ O
the -X- _ O
relationship -X- _ O
. -X- _ O
We -X- _ O
predefined -X- _ O
a -X- _ O
set -X- _ O
of -X- _ O
modifying -X- _ O
dependencies -X- _ O
in -X- _ O
Table -X- _ O
7 -X- _ O
. -X- _ O

We -X- _ O
calculate -X- _ O
a -X- _ O
score -X- _ O
for -X- _ O
each -X- _ O
token -X- _ O
in -X- _ O
the -X- _ O
sentence -X- _ O
based -X- _ O
on -X- _ O
its -X- _ O
category -X- _ O
and -X- _ O
dependency -X- _ O
analysis -X- _ O
. -X- _ O
Then -X- _ O
, -X- _ O
the -X- _ O
significance -X- _ O
score -X- _ O
is -X- _ O
the -X- _ O
average -X- _ O
of -X- _ O
all -X- _ O
the -X- _ O
token -X- _ O
's -X- _ O
scores -X- _ O
. -X- _ O
Formally -X- _ O
, -X- _ O
for -X- _ O
a -X- _ O
candidate -X- _ B-MetricName
relation -X- _ I-MetricName
description -X- _ I-MetricName
s -X- _ I-MetricName
, -X- _ O
the -X- _ O
significance -X- _ B-MetricName
score -X- _ I-MetricName
is -X- _ O

Relation -X- _ B-MetricName
Descriptive -X- _ I-MetricName
Score -X- _ I-MetricName

To -X- _ O
calculate -X- _ O
the -X- _ O
explicitness -X- _ B-MetricName
and -X- _ O
significance -X- _ B-MetricName
, -X- _ O
we -X- _ O
need -X- _ O
to -X- _ O
build -X- _ O
a -X- _ O
database -X- _ O
of -X- _ O
relation -X- _ O
patterns -X- _ O
for -X- _ O
both -X- _ O
corePath -X- _ O
and -X- _ O
subPath -X- _ O
. -X- _ O
We -X- _ O
construct -X- _ O
both -X- _ O
databases -X- _ O
with -X- _ O
the -X- _ O
candidate -X- _ O
relation -X- _ O
descriptions -X- _ O
and -X- _ O
corresponding -X- _ O
entity -X- _ O
pairs -X- _ O
collected -X- _ O
from -X- _ O
Section -X- _ O
4.1 -X- _ O
with -X- _ O
spaCy -X- _ O
. -X- _ O
We -X- _ O
also -X- _ O
require -X- _ O
the -X- _ O
two -X- _ O
target -X- _ O
entities -X- _ O
in -X- _ O
the -X- _ O
sentence -X- _ O
are -X- _ O
related -X- _ O
to -X- _ O
a -X- _ O
certain -X- _ O
threshold -X- _ O
. -X- _ O
Intuitively -X- _ O
, -X- _ O
if -X- _ O
two -X- _ O
entities -X- _ O
are -X- _ O
more -X- _ O
related -X- _ O
, -X- _ O
the -X- _ O
sentences -X- _ O
containing -X- _ O
them -X- _ O
are -X- _ O
more -X- _ O
likely -X- _ O
to -X- _ O
be -X- _ O
relation -X- _ O
descriptions -X- _ O
; -X- _ O
therefore -X- _ O
, -X- _ O
the -X- _ O
extracted -X- _ O
corePath -X- _ O
relation -X- _ O
patterns -X- _ O
are -X- _ O
more -X- _ O
likely -X- _ O
to -X- _ O
indicate -X- _ O
entity -X- _ O
relationships -X- _ O
. -X- _ O
We -X- _ O
measure -X- _ O
the -X- _ O
relevance -X- _ O
of -X- _ O
two -X- _ O
entities -X- _ O
by -X- _ O
calculating -X- _ O
the -X- _ O
cosine -X- _ O
similarity -X- _ O
of -X- _ O
the -X- _ O
entity -X- _ O
embeddings -X- _ O
in -X- _ O
Wikipedia2Vec -X- _ O
. -X- _ O
We -X- _ O
filter -X- _ O
out -X- _ O
entity -X- _ O
pairs -X- _ O
( -X- _ O
and -X- _ O
the -X- _ O
associated -X- _ O
sentences -X- _ O
) -X- _ O
with -X- _ O
a -X- _ O
relevance -X- _ B-HyperparameterName
score -X- _ I-HyperparameterName
< -X- _ O
0.5 -X- _ B-HyperparameterValue
. -X- _ O
This -X- _ O
leads -X- _ O
to -X- _ O
a -X- _ O
collection -X- _ O
of -X- _ O
7,186,996 -X- _ O
corePaths -X- _ O
and -X- _ O
83,265,285 -X- _ O
subPaths -X- _ O
. -X- _ O

With -X- _ O
the -X- _ O
databases -X- _ O
of -X- _ O
relation -X- _ O
patterns -X- _ O
, -X- _ O
we -X- _ O
can -X- _ O
calculate -X- _ O
the -X- _ O
explicitness -X- _ O
and -X- _ O
significance -X- _ O
scores -X- _ O
for -X- _ O
a -X- _ O
candidate -X- _ O
relation -X- _ O
description -X- _ O
. -X- _ O
The -X- _ O
final -X- _ O
score -X- _ O
, -X- _ O
named -X- _ O
Relation -X- _ B-MetricName
Descriptive -X- _ I-MetricName
Score -X- _ I-MetricName
( -X- _ I-MetricName
RDScore -X- _ I-MetricName
) -X- _ I-MetricName
, -X- _ O
is -X- _ O
computed -X- _ O
as -X- _ O
the -X- _ O
harmonic -X- _ O
mean -X- _ O
: -X- _ O

Relation -X- _ B-TaskName
Description -X- _ I-TaskName
Generation -X- _ I-TaskName

In -X- _ O
the -X- _ O
previous -X- _ O
section -X- _ O
, -X- _ O
we -X- _ O
extract -X- _ O
relation -X- _ O
descriptions -X- _ O
for -X- _ O
entity -X- _ O
pairs -X- _ O
with -X- _ O
the -X- _ O
analysis -X- _ O
of -X- _ O
dependency -X- _ O
patterns -X- _ O
and -X- _ O
build -X- _ O
an -X- _ O
initial -X- _ O
DEER -X- _ O
with -X- _ O
Wikipedia -X- _ B-DatasetName
automatically -X- _ O
. -X- _ O
However -X- _ O
, -X- _ O
for -X- _ O
some -X- _ O
related -X- _ O
entity -X- _ O
pairs -X- _ O
, -X- _ O
there -X- _ O
may -X- _ O
not -X- _ O
exist -X- _ O
a -X- _ O
sentence -X- _ O
that -X- _ O
contains -X- _ O
both -X- _ O
entities -X- _ O
; -X- _ O
and -X- _ O
although -X- _ O
such -X- _ O
a -X- _ O
sentence -X- _ O
exists -X- _ O
, -X- _ O
it -X- _ O
may -X- _ O
not -X- _ O
be -X- _ O
extracted -X- _ O
by -X- _ O
the -X- _ O
system -X- _ O
. -X- _ O
To -X- _ O
solve -X- _ O
this -X- _ O
problem -X- _ O
, -X- _ O
in -X- _ O
this -X- _ O
section -X- _ O
, -X- _ O
we -X- _ O
introduce -X- _ O
Relation -X- _ B-TaskName
Description -X- _ I-TaskName
Generation -X- _ I-TaskName
-generating -X- _ O
relation -X- _ O
descriptions -X- _ O
for -X- _ O
interesting -X- _ O
entity -X- _ O
pairs -X- _ O
. -X- _ O

To -X- _ O
incorporate -X- _ O
G -X- _ O
0 -X- _ O
for -X- _ O
generation -X- _ O
, -X- _ O
we -X- _ O
propose -X- _ O
Relation -X- _ B-MethodName
Description -X- _ I-MethodName
Synthesizing -X- _ I-MethodName
( -X- _ I-MethodName
RelationSyn -X- _ I-MethodName
) -X- _ I-MethodName
. -X- _ O
RelationSyn -X- _ O
consists -X- _ O
of -X- _ O
two -X- _ O
processes -X- _ O
: -X- _ O
first -X- _ O
retrieving -X- _ O
relevant -X- _ O
relation -X- _ O
descriptions -X- _ O
( -X- _ O
reasoning -X- _ O
paths -X- _ O
) -X- _ O
from -X- _ O
the -X- _ O
graph -X- _ O
and -X- _ O
then -X- _ O
synthesizing -X- _ O
them -X- _ O
into -X- _ O
a -X- _ O
final -X- _ O
relation -X- _ O
description -X- _ O
( -X- _ O
Figure -X- _ O
4 -X- _ O
) -X- _ O
. -X- _ O

In -X- _ O
DEER -X- _ O
, -X- _ O
we -X- _ O
define -X- _ O
a -X- _ O
reasoning -X- _ O
path -X- _ O
q -X- _ O
as -X- _ O
a -X- _ O
path -X- _ O
connecting -X- _ O
the -X- _ O
target -X- _ O
entities -X- _ O
, -X- _ O
which -X- _ O
is -X- _ O
called -X- _ O
k -X- _ O
- -X- _ O
hop -X- _ O
if -X- _ O
it -X- _ O
is -X- _ O
connected -X- _ O
by -X- _ O
k -X- _ O
edges -X- _ O
. -X- _ O
For -X- _ O
instance -X- _ O
, -X- _ O
in -X- _ O
Figure -X- _ O
4 -X- _ O
, -X- _ O
there -X- _ O
are -X- _ O
two -X- _ O
2 -X- _ O
- -X- _ O
hop -X- _ O
reasoning -X- _ O
paths -X- _ O
between -X- _ O
x -X- _ O
and -X- _ O
y -X- _ O
: -X- _ O
( -X- _ O
x -X- _ O
, -X- _ O
s -X- _ O
11 -X- _ O
, -X- _ O
e -X- _ O
11 -X- _ O
, -X- _ O
s -X- _ O
12 -X- _ O
, -X- _ O
y -X- _ O
) -X- _ O
and -X- _ O
( -X- _ O
x -X- _ O
, -X- _ O
s -X- _ O
21 -X- _ O
, -X- _ O
e -X- _ O
21 -X- _ O
, -X- _ O
s -X- _ O
22 -X- _ O
, -X- _ O
y -X- _ O
) -X- _ O
, -X- _ O
and -X- _ O
two -X- _ O
3 -X- _ O
- -X- _ O
hop -X- _ O
reasoning -X- _ O
paths -X- _ O
: -X- _ O
( -X- _ O
x -X- _ O
, -X- _ O
s -X- _ O
21 -X- _ O
, -X- _ O
e -X- _ O
21 -X- _ O
, -X- _ O
s -X- _ O
23 -X- _ O
, -X- _ O
e -X- _ O
32 -X- _ O
, -X- _ O
s -X- _ O
33 -X- _ O
, -X- _ O
y -X- _ O
) -X- _ O
and -X- _ O
( -X- _ O
x -X- _ O
, -X- _ O
s -X- _ O
31 -X- _ O
, -X- _ O
e -X- _ O
31 -X- _ O
, -X- _ O
s -X- _ O
32 -X- _ O
, -X- _ O
e -X- _ O
32 -X- _ O
, -X- _ O
s -X- _ O
33 -X- _ O
, -X- _ O
y -X- _ O
) -X- _ O
in -X- _ O
the -X- _ O
graph -X- _ O
5 -X- _ O
. -X- _ O
To -X- _ O
measure -X- _ O
the -X- _ O
quality -X- _ O
of -X- _ O
reasoning -X- _ O
paths -X- _ O
, -X- _ O
we -X- _ O
define -X- _ O
Path -X- _ B-MetricName
- -X- _ I-MetricName
Score -X- _ I-MetricName
as -X- _ O
the -X- _ O
harmonic -X- _ O
mean -X- _ O
of -X- _ O
RDScore -X- _ B-MetricName
of -X- _ O
relation -X- _ O
descriptions -X- _ O
in -X- _ O
the -X- _ O
path -X- _ O
: -X- _ O

However -X- _ O
, -X- _ O
not -X- _ O
all -X- _ O
reasoning -X- _ O
paths -X- _ O
are -X- _ O
equally -X- _ O
useful -X- _ O
. -X- _ O
Longer -X- _ O
reasoning -X- _ O
paths -X- _ O
are -X- _ O
usually -X- _ O
more -X- _ O
difficult -X- _ O
to -X- _ O
reason -X- _ O
, -X- _ O
while -X- _ O
paths -X- _ O
with -X- _ O
higher -X- _ O
Path -X- _ B-MetricName
- -X- _ I-MetricName
Score -X- _ I-MetricName
usually -X- _ O
contain -X- _ O
more -X- _ O
explicit -X- _ O
and -X- _ O
significant -X- _ O
relation -X- _ O
descriptions -X- _ O
. -X- _ O
Therefore -X- _ O
, -X- _ O
when -X- _ O
retrieving -X- _ O
reasoning -X- _ O
paths -X- _ O
for -X- _ O
an -X- _ O
entity -X- _ O
pair -X- _ O
, -X- _ O
we -X- _ O
first -X- _ O
sort -X- _ O
the -X- _ O
paths -X- _ O
by -X- _ O
their -X- _ O
length -X- _ O
( -X- _ O
shorter -X- _ O
first -X- _ O
) -X- _ O
and -X- _ O
then -X- _ O
by -X- _ O
their -X- _ O
PathScore -X- _ B-MetricName
( -X- _ O
higher -X- _ O
first -X- _ O
) -X- _ O
. -X- _ O

Combining -X- _ O
retrieval -X- _ O
and -X- _ O
synthesizing -X- _ O
, -X- _ O
given -X- _ O
two -X- _ O
entities -X- _ O
, -X- _ O
we -X- _ O
first -X- _ O
retrieve -X- _ O
m -X- _ O
reasoning -X- _ O
paths -X- _ O
connecting -X- _ O
the -X- _ O
target -X- _ O
entities -X- _ O
according -X- _ O
to -X- _ O
their -X- _ O
length -X- _ O
and -X- _ O
PathScore -X- _ O
, -X- _ O
and -X- _ O
then -X- _ O
synthesize -X- _ O
them -X- _ O
to -X- _ O
produce -X- _ O
the -X- _ O
target -X- _ O
relation -X- _ O
description -X- _ O
. -X- _ O
We -X- _ O
refer -X- _ O
to -X- _ O
this -X- _ O
model -X- _ O
as -X- _ O
RelationSyn -X- _ B-MethodName
- -X- _ I-MethodName
m -X- _ I-MethodName
. -X- _ O

Since -X- _ O
previous -X- _ O
works -X- _ O
on -X- _ O
relation -X- _ O
description -X- _ O
extraction -X- _ O
are -X- _ O
supervised -X- _ O
and -X- _ O
only -X- _ O
limited -X- _ O
to -X- _ O
several -X- _ O
explicit -X- _ O
relation -X- _ O
types -X- _ O
, -X- _ O
e.g. -X- _ O
, -X- _ O
9 -X- _ O
in -X- _ O
Voskarides -X- _ O
et -X- _ O
al -X- _ O
. -X- _ O
( -X- _ O
2015 -X- _ O
) -X- _ O
, -X- _ O
it -X- _ O
is -X- _ O
impractical -X- _ O
and -X- _ O
meaningless -X- _ O
to -X- _ O
compare -X- _ O
with -X- _ O
them -X- _ O
. -X- _ O
For -X- _ O
instance -X- _ O
, -X- _ O
the -X- _ O
relationship -X- _ O
of -X- _ O
( -X- _ O
Arthur -X- _ O
Samuel -X- _ O
, -X- _ O
Machine -X- _ O
Learning -X- _ O
) -X- _ O
is -X- _ O
not -X- _ O
available -X- _ O
or -X- _ O
even -X- _ O
not -X- _ O
considered -X- _ O
by -X- _ O
the -X- _ O
previous -X- _ O
methods -X- _ O
. -X- _ O
Therefore -X- _ O
, -X- _ O
we -X- _ O
verify -X- _ O
the -X- _ O
effectiveness -X- _ O
of -X- _ O
our -X- _ O
model -X- _ O
by -X- _ O
comparing -X- _ O
different -X- _ O
variants -X- _ O
of -X- _ O
the -X- _ O
model -X- _ O
: -X- _ O
• -X- _ O
Random -X- _ B-MetricName
: -X- _ O
A -X- _ O
sentence -X- _ O
containing -X- _ O
the -X- _ O
target -X- _ O
entities -X- _ O
is -X- _ O
randomly -X- _ O
selected -X- _ O
as -X- _ O
the -X- _ O
relation -X- _ O
description -X- _ O
. -X- _ O
• -X- _ O
ExpScore -X- _ B-MetricName
: -X- _ O
The -X- _ O
sentence -X- _ O
with -X- _ O
the -X- _ O
highest -X- _ O
explicitness -X- _ O
is -X- _ O
selected -X- _ O
according -X- _ O
to -X- _ O
Eq -X- _ O
. -X- _ O
( -X- _ O
1 -X- _ O
) -X- _ O
. -X- _ O
• -X- _ O
SigScore -X- _ B-MetricName
: -X- _ O
The -X- _ O
sentence -X- _ O
with -X- _ O
the -X- _ O
highest -X- _ O
significance -X- _ O
is -X- _ O
selected -X- _ O
according -X- _ O
to -X- _ O
Eq -X- _ O
. -X- _ O
( -X- _ O
2 -X- _ O
) -X- _ O
. -X- _ O
• -X- _ O
RDScore -X- _ B-MetricName
: -X- _ O
The -X- _ O
sentence -X- _ O
with -X- _ O
the -X- _ O
highest -X- _ O
RD -X- _ O
- -X- _ O
Score -X- _ O
is -X- _ O
selected -X- _ O
according -X- _ O
to -X- _ O
Eq -X- _ O
. -X- _ O
( -X- _ O
4 -X- _ O
) -X- _ O
. -X- _ O
6 -X- _ O
More -X- _ O
specifically -X- _ O
, -X- _ O
for -X- _ O
better -X- _ O
comparison -X- _ O
with -X- _ O
generation -X- _ O
later -X- _ O
, -X- _ O
we -X- _ O
sample -X- _ O
100 -X- _ O
entity -X- _ O
pairs -X- _ O
from -X- _ O
the -X- _ O
test -X- _ O
set -X- _ O
in -X- _ O
Table -X- _ O
4 -X- _ O
. -X- _ O
Table -X- _ O
3 -X- _ O
shows -X- _ O
the -X- _ O
human -X- _ O
evaluation -X- _ O
results -X- _ O
for -X- _ O
relation -X- _ O
description -X- _ O
extraction -X- _ O
, -X- _ O
with -X- _ O
an -X- _ O
average -X- _ O
pairwise -X- _ O
Cohen -X- _ O
's -X- _ O
κ -X- _ O
of -X- _ O
0.66 -X- _ O
( -X- _ O
good -X- _ O
agreement -X- _ O
) -X- _ O
. -X- _ O
From -X- _ O
the -X- _ O
results -X- _ O
, -X- _ O
we -X- _ O
observe -X- _ O
that -X- _ O
both -X- _ O
our -X- _ O
explicitness -X- _ O
and -X- _ O
significance -X- _ O
measurements -X- _ O
are -X- _ O
important -X- _ O
to -X- _ O
ensure -X- _ O
a -X- _ O
good -X- _ O
relation -X- _ O
description -X- _ O
. -X- _ O
In -X- _ O
addition -X- _ O
, -X- _ O
RD -X- _ B-MetricName
- -X- _ I-MetricName
Score -X- _ I-MetricName
achieves -X- _ O
an -X- _ O
average -X- _ O
rating -X- _ O
of -X- _ O
4.18 -X- _ B-MetricValue
, -X- _ O
which -X- _ O
means -X- _ O
that -X- _ O
most -X- _ O
of -X- _ O
the -X- _ O
selected -X- _ O
sentences -X- _ O
are -X- _ O
highquality -X- _ O
relation -X- _ O
descriptions -X- _ O
, -X- _ O
further -X- _ O
indicating -X- _ O
that -X- _ O
the -X- _ O
quality -X- _ O
of -X- _ O
Wiki -X- _ B-DatasetName
- -X- _ I-DatasetName
DEER -X- _ I-DatasetName
0 -X- _ O
is -X- _ O
high -X- _ O
. -X- _ O

Data -X- _ O
construction -X- _ O
. -X- _ O
We -X- _ O
build -X- _ O
a -X- _ O
dataset -X- _ O
for -X- _ O
relation -X- _ O
description -X- _ O
generation -X- _ O
as -X- _ O
follows -X- _ O
: -X- _ O
for -X- _ O
an -X- _ O
entity -X- _ O
pair -X- _ O
with -X- _ O
a -X- _ O
relation -X- _ O
description -X- _ O
in -X- _ O
Wiki -X- _ B-DatasetName
- -X- _ I-DatasetName
DEER -X- _ I-DatasetName
0 -X- _ O
, -X- _ O
we -X- _ O
hide -X- _ O
the -X- _ O
relation -X- _ O
description -X- _ O
and -X- _ O
consider -X- _ O
it -X- _ O
as -X- _ O
the -X- _ O
target -X- _ O
for -X- _ O
generation -X- _ O
. -X- _ O
The -X- _ O
goal -X- _ O
is -X- _ O
to -X- _ O
recover -X- _ O
/ -X- _ O
generate -X- _ O
the -X- _ O
target -X- _ O
relation -X- _ O
description -X- _ O
with -X- _ O
the -X- _ O
rest -X- _ O
of -X- _ O
the -X- _ O
graph -X- _ O
7 -X- _ O
. -X- _ O
For -X- _ O
instance -X- _ O
, -X- _ O
in -X- _ O
Figure -X- _ O
4 -X- _ O
, -X- _ O
we -X- _ O
hide -X- _ O
the -X- _ O
edge -X- _ O
( -X- _ O
relation -X- _ O
description -X- _ O
s -X- _ O
) -X- _ O
between -X- _ O
x -X- _ O
and -X- _ O
y -X- _ O
and -X- _ O
use -X- _ O
the -X- _ O
remaining -X- _ O
reasoning -X- _ O
paths -X- _ O
to -X- _ O
recover -X- _ O
s. -X- _ O
We -X- _ O
train -X- _ O
and -X- _ O
test -X- _ O
on -X- _ O
entity -X- _ O
pairs -X- _ O
with -X- _ O
≥ -X- _ O
5 -X- _ O
reasoning -X- _ O
paths -X- _ O
connecting -X- _ O
them -X- _ O
. -X- _ O
The -X- _ O
statistics -X- _ O
of -X- _ O
the -X- _ O
data -X- _ O
are -X- _ O
reported -X- _ O
in -X- _ O
Table -X- _ O
4 -X- _ O
. -X- _ O
( -X- _ O
Huang -X- _ O
et -X- _ O
al -X- _ O
. -X- _ O
, -X- _ O
2022a -X- _ O
) -X- _ O
-a -X- _ O
recent -X- _ O
work -X- _ O
aimed -X- _ O
at -X- _ O
generating -X- _ O
sentences -X- _ O
capturing -X- _ O
general -X- _ O
relations -X- _ O
between -X- _ O
entities -X- _ O
conditioned -X- _ O
on -X- _ O
entity -X- _ O
pairs -X- _ O
. -X- _ O
To -X- _ O
the -X- _ O
best -X- _ O
of -X- _ O
our -X- _ O
knowledge -X- _ O
, -X- _ O
no -X- _ O
other -X- _ O
existing -X- _ O
work -X- _ O
can -X- _ O
generate -X- _ O
relation -X- _ O
descriptions -X- _ O
for -X- _ O
any -X- _ O
two -X- _ O
related -X- _ O
entities -X- _ O
( -X- _ O
since -X- _ O
open -X- _ O
relation -X- _ O
modeling -X- _ O
has -X- _ O
only -X- _ O
just -X- _ O
been -X- _ O
introduced -X- _ O
) -X- _ O
. -X- _ O
Therefore -X- _ O
, -X- _ O
we -X- _ O
mainly -X- _ O
compare -X- _ O
the -X- _ O
models -X- _ O
proposed -X- _ O
in -X- _ O
Huang -X- _ O
et -X- _ O
al -X- _ O
. -X- _ O
( -X- _ O
2022a -X- _ O
) -X- _ O
Metrics -X- _ O
. -X- _ O
We -X- _ O
perform -X- _ O
both -X- _ O
quantitative -X- _ O
and -X- _ O
qualitative -X- _ O
evaluation -X- _ O
. -X- _ O
Following -X- _ O
Huang -X- _ O
et -X- _ O
al -X- _ O
. -X- _ O
( -X- _ O
2022a -X- _ O
) -X- _ O
, -X- _ O
we -X- _ O
apply -X- _ O
several -X- _ O
automatic -X- _ O
metrics -X- _ O
, -X- _ O
including -X- _ O
BLEU -X- _ B-MetricName
( -X- _ O
Papineni -X- _ O
et -X- _ O
al -X- _ O
. -X- _ O
, -X- _ O
2002 -X- _ O
) -X- _ O
, -X- _ O
ROUGE -X- _ B-MetricName
- -X- _ I-MetricName
L -X- _ I-MetricName
( -X- _ O
Lin -X- _ O
, -X- _ O
2004 -X- _ O
) -X- _ O
, -X- _ O
METEOR -X- _ B-MetricName
( -X- _ O
Banerjee -X- _ O
and -X- _ O
Lavie -X- _ O
, -X- _ O
2005 -X- _ O
) -X- _ O
, -X- _ O
and -X- _ O
BERTScore -X- _ B-MetricName
( -X- _ O
Zhang -X- _ O
et -X- _ O
al -X- _ O
. -X- _ O
, -X- _ O
2019 -X- _ O

Models -X- _ O
. -X- _ O
The -X- _ O
task -X- _ O
of -X- _ O
relation -X- _ B-TaskName
description -X- _ I-TaskName
generation -X- _ I-TaskName
is -X- _ O
relevant -X- _ O
to -X- _ O
Open -X- _ B-TaskName
Relation -X- _ I-TaskName
Modeling -X- _ I-TaskName

Table -X- _ O
5 -X- _ O
reports -X- _ O
the -X- _ O
results -X- _ O
of -X- _ O
relation -X- _ O
description -X- _ O
generation -X- _ O
with -X- _ O
the -X- _ O
automatic -X- _ O
metrics -X- _ O
. -X- _ O
We -X- _ O
observe -X- _ O
that -X- _ O
our -X- _ O
best -X- _ O
model -X- _ O
RelationSyn-5 -X- _ B-MethodName
outperforms -X- _ O
the -X- _ O
state -X- _ O
- -X- _ O
of -X- _ O
- -X- _ O
the -X- _ O
- -X- _ O
art -X- _ O
model -X- _ O
for -X- _ O
open -X- _ O
relation -X- _ O
modeling -X- _ O
significantly -X- _ O
. -X- _ O
We -X- _ O
also -X- _ O
observe -X- _ O
that -X- _ O
RelationSyn-1 -X- _ B-MethodName
performs -X- _ O
better -X- _ O
than -X- _ O
RelationSyn-0 -X- _ B-MethodName
, -X- _ O
which -X- _ O
means -X- _ O
that -X- _ O
reasoning -X- _ O
paths -X- _ O
in -X- _ O
DEER -X- _ O
are -X- _ O
helpful -X- _ O
for -X- _ O
relation -X- _ O
description -X- _ O
generation -X- _ O
. -X- _ O
In -X- _ O
addition -X- _ O
, -X- _ O
as -X- _ O
the -X- _ O
number -X- _ O
of -X- _ O
reasoning -X- _ O
paths -X- _ O
, -X- _ O
i.e. -X- _ O
, -X- _ O
m -X- _ O
, -X- _ O
increases -X- _ O
, -X- _ O
the -X- _ O
performance -X- _ O
of -X- _ O
RelationSyn -X- _ B-MethodName
- -X- _ I-MethodName
m -X- _ I-MethodName
improves -X- _ O
. -X- _ O
This -X- _ O
demonstrates -X- _ O
that -X- _ O
the -X- _ O
proposed -X- _ O
model -X- _ O
can -X- _ O
synthesize -X- _ O
multiple -X- _ O
relation -X- _ O
descriptions -X- _ O
in -X- _ O
different -X- _ O
reasoning -X- _ O
paths -X- _ O
into -X- _ O
a -X- _ O
final -X- _ O
relation -X- _ O
description -X- _ O
. -X- _ O

For -X- _ O
a -X- _ O
better -X- _ O
comparison -X- _ O
with -X- _ O
extraction -X- _ O
, -X- _ O
we -X- _ O
sample -X- _ O
the -X- _ O
same -X- _ O
100 -X- _ O
entity -X- _ O
pairs -X- _ O
from -X- _ O
the -X- _ O
test -X- _ O
set -X- _ O
as -X- _ O
in -X- _ O
Sec -X- _ O
- -X- _ O
tion -X- _ O
6.1 -X- _ O
. -X- _ O
From -X- _ O
the -X- _ O
results -X- _ O
in -X- _ O
Table -X- _ O
6 -X- _ O
, -X- _ O
we -X- _ O
observe -X- _ O
that -X- _ O
the -X- _ O
quality -X- _ O
of -X- _ O
generated -X- _ O
relation -X- _ O
descriptions -X- _ O
is -X- _ O
higher -X- _ O
than -X- _ O
that -X- _ O
of -X- _ O
random -X- _ O
sentences -X- _ O
containing -X- _ O
the -X- _ O
target -X- _ O
entities -X- _ O
. -X- _ O
The -X- _ O
best -X- _ O
model -X- _ O
, -X- _ O
RelationSyn-5 -X- _ B-MethodName
, -X- _ O
achieves -X- _ O
a -X- _ O
rating -X- _ B-MetricName
of -X- _ O
3.47 -X- _ B-MetricValue
, -X- _ O
which -X- _ O
means -X- _ O
the -X- _ O
model -X- _ O
can -X- _ O
generate -X- _ O
reasonable -X- _ O
relation -X- _ O
descriptions -X- _ O
. -X- _ O
However -X- _ O
, -X- _ O
the -X- _ O
performance -X- _ O
is -X- _ O
still -X- _ O
much -X- _ O
worse -X- _ O
than -X- _ O
Oracle -X- _ O
, -X- _ O
i.e. -X- _ O
, -X- _ O
relation -X- _ O
descriptions -X- _ O
extracted -X- _ O
by -X- _ O
our -X- _ O
best -X- _ O
extraction -X- _ O
model -X- _ O
( -X- _ O
RDScore -X- _ O
) -X- _ O
. -X- _ O
This -X- _ O
indicates -X- _ O
that -X- _ O
generating -X- _ O
high -X- _ O
- -X- _ O
quality -X- _ O
relation -X- _ O
descriptions -X- _ O
is -X- _ O
still -X- _ O
a -X- _ O
challenging -X- _ O
task -X- _ O
. -X- _ O

In -X- _ O
Table -X- _ O
9 -X- _ O
of -X- _ O
Appendix -X- _ O
B -X- _ O
, -X- _ O
we -X- _ O
show -X- _ O
some -X- _ O
sample -X- _ O
outputs -X- _ O
in -X- _ O
the -X- _ O
test -X- _ O
set -X- _ O
of -X- _ O
relation -X- _ O
description -X- _ O
generation -X- _ O
of -X- _ O
three -X- _ O
extraction -X- _ O
models -X- _ O
: -X- _ O
ExpScore -X- _ B-MethodName
, -X- _ I-MethodName
SigScore -X- _ I-MethodName
, -X- _ I-MethodName
RDScore -X- _ I-MethodName
, -X- _ O
and -X- _ O
three -X- _ O
generation -X- _ O
models -X- _ O
: -X- _ O
RelationSyn-0 -X- _ B-MethodName
, -X- _ I-MethodName
RelationSyn-1 -X- _ I-MethodName
, -X- _ I-MethodName
RelationSyn-5 -X- _ I-MethodName
. -X- _ I-MethodName

From -X- _ O
the -X- _ O
human -X- _ O
evaluation -X- _ O
results -X- _ O
, -X- _ O
we -X- _ O
also -X- _ O
find -X- _ O
that -X- _ O
the -X- _ O
correctness -X- _ O
of -X- _ O
relation -X- _ O
descriptions -X- _ O
extracted -X- _ O
by -X- _ O
RDScore -X- _ O
is -X- _ O
largely -X- _ O
guaranteed -X- _ O
. -X- _ O
However -X- _ O
, -X- _ O
sometimes -X- _ O
, -X- _ O
the -X- _ O
extracted -X- _ O
sentences -X- _ O
are -X- _ O
still -X- _ O
a -X- _ O
bit -X- _ O
implicit -X- _ O
or -X- _ O
not -X- _ O
significant -X- _ O
. -X- _ O
In -X- _ O
contrast -X- _ O
to -X- _ O
this -X- _ O
, -X- _ O
the -X- _ O
relation -X- _ O
descriptions -X- _ O
generated -X- _ O
by -X- _ O
RelationSyn -X- _ O
are -X- _ O
usually -X- _ O
explicit -X- _ B-MetricName
and -X- _ O
significant -X- _ B-MetricName
( -X- _ O
the -X- _ O
average -X- _ O
RDScore -X- _ O
of -X- _ O
the -X- _ O
relation -X- _ O
descriptions -X- _ O
generated -X- _ O
by -X- _ O
RelationSyn-5 -X- _ O
is -X- _ O
0.886 -X- _ B-MetricValue
, -X- _ O
compared -X- _ O
to -X- _ O
0.853 -X- _ B-MetricValue
of -X- _ O
Oracle -X- _ O
) -X- _ O
, -X- _ O
but -X- _ O
contain -X- _ O
major -X- _ O
or -X- _ O
minor -X- _ O
errors -X- _ O
. -X- _ O
We -X- _ O
think -X- _ O
this -X- _ O
is -X- _ O
because -X- _ O
most -X- _ O
of -X- _ O
the -X- _ O
relation -X- _ O
descriptions -X- _ O
extracted -X- _ O
by -X- _ O
RDScore -X- _ O
are -X- _ O
explicit -X- _ O
and -X- _ O
significant -X- _ O
, -X- _ O
and -X- _ O
the -X- _ O
generation -X- _ O
model -X- _ O
can -X- _ O
mimic -X- _ O
the -X- _ O
dominant -X- _ O
style -X- _ O
of -X- _ O
relation -X- _ O
descriptions -X- _ O
in -X- _ O
the -X- _ O
training -X- _ O
set -X- _ O
. -X- _ O
However -X- _ O
, -X- _ O
it -X- _ O
is -X- _ O
still -X- _ O
challenging -X- _ O
to -X- _ O
generate -X- _ O
fully -X- _ O
correct -X- _ O
rela -X- _ O
- -X- _ O
tion -X- _ O
descriptions -X- _ O
by -X- _ O
synthesizing -X- _ O
existing -X- _ O
relation -X- _ O
descriptions -X- _ O
. -X- _ O

We -X- _ O
also -X- _ O
attempted -X- _ O
to -X- _ O
find -X- _ O
the -X- _ O
eight -X- _ O
entity -X- _ O
pairs -X- _ O
in -X- _ O
Table -X- _ O
9 -X- _ O
in -X- _ O
Wikidata -X- _ B-DatasetName
. -X- _ O
Among -X- _ O
them -X- _ O
, -X- _ O
only -X- _ O
( -X- _ O
Surfers -X- _ O
Paradise -X- _ O
, -X- _ O
Queensland -X- _ O
) -X- _ O
is -X- _ O
present -X- _ O
in -X- _ O
Wikidata -X- _ B-DatasetName
. -X- _ O
This -X- _ O
further -X- _ O
confirms -X- _ O
that -X- _ O
DEER -X- _ O
can -X- _ O
model -X- _ O
a -X- _ O
wider -X- _ O
range -X- _ O
of -X- _ O
entity -X- _ O
relationships -X- _ O
. -X- _ O

In -X- _ O
this -X- _ O
paper -X- _ O
, -X- _ O
we -X- _ O
propose -X- _ O
DEER -X- _ B-MethodName
-an -X- _ O
open -X- _ O
and -X- _ O
informative -X- _ O
form -X- _ O
of -X- _ O
modeling -X- _ O
relationships -X- _ O
between -X- _ O
entities -X- _ O
. -X- _ O
To -X- _ O
avoid -X- _ O
tremendous -X- _ O
human -X- _ O
efforts -X- _ O
, -X- _ O
we -X- _ O
design -X- _ O
a -X- _ O
novel -X- _ O
self -X- _ O
- -X- _ O
supervised -X- _ O
learning -X- _ O
approach -X- _ O
to -X- _ O
extract -X- _ O
relation -X- _ O
descriptions -X- _ O
from -X- _ O
Wikipedia -X- _ O
. -X- _ O
To -X- _ O
provide -X- _ O
relation -X- _ O
descriptions -X- _ O
for -X- _ O
related -X- _ O
entity -X- _ O
pairs -X- _ O
whose -X- _ O
relation -X- _ O
descriptions -X- _ O
are -X- _ O
not -X- _ O
extracted -X- _ O
in -X- _ O
the -X- _ O
previous -X- _ O
step -X- _ O
, -X- _ O
we -X- _ O
study -X- _ O
relation -X- _ B-TaskName
description -X- _ I-TaskName
generation -X- _ I-TaskName
by -X- _ O
synthesizing -X- _ O
relation -X- _ O
descriptions -X- _ O
in -X- _ O
the -X- _ O
retrieved -X- _ O
reasoning -X- _ O
paths -X- _ O
. -X- _ O
We -X- _ O
believe -X- _ O
that -X- _ O
DEER -X- _ O
can -X- _ O
not -X- _ O
only -X- _ O
serve -X- _ O
as -X- _ O
a -X- _ O
direct -X- _ O
application -X- _ O
to -X- _ O
help -X- _ O
understand -X- _ O
entity -X- _ O
relationships -X- _ O
but -X- _ O
also -X- _ O
be -X- _ O
utilized -X- _ O
as -X- _ O
a -X- _ O
knowledge -X- _ O
source -X- _ O
to -X- _ O
facilitate -X- _ O
related -X- _ O
tasks -X- _ O
such -X- _ O
as -X- _ O
relation -X- _ B-TaskName
extraction -X- _ I-TaskName
( -X- _ O
Bach -X- _ O
and -X- _ O
Badaskar -X- _ O
, -X- _ O
2007 -X- _ O
) -X- _ O
and -X- _ O
knowledge -X- _ B-TaskName
graph -X- _ I-TaskName
completion -X- _ I-TaskName
( -X- _ O
Lin -X- _ O
et -X- _ O
al -X- _ O
. -X- _ O
, -X- _ O
2015 -X- _ O
) -X- _ O
. -X- _ O

We -X- _ O
introduce -X- _ O
our -X- _ O
preprocessing -X- _ O
to -X- _ O
the -X- _ O
raw -X- _ O
Wikipedia -X- _ B-DatasetName
dump -X- _ O
10 -X- _ O
. -X- _ O
For -X- _ O
each -X- _ O
article -X- _ O
, -X- _ O
we -X- _ O
extract -X- _ O
the -X- _ O
plain -X- _ O
text -X- _ O
by -X- _ O
WikiExtractor -X- _ O
11 -X- _ O
. -X- _ O
We -X- _ O
split -X- _ O
the -X- _ O
Wikipedia -X- _ O
articles -X- _ O
into -X- _ O
sentences -X- _ O
with -X- _ O
the -X- _ O
NLTK -X- _ O
library -X- _ O
12 -X- _ O
and -X- _ O
map -X- _ O
entity -X- _ O
pairs -X- _ O
to -X- _ O
candidate -X- _ O
relation -X- _ O
descriptions -X- _ O
with -X- _ O
the -X- _ O
following -X- _ O
steps -X- _ O
: -X- _ O

Entity -X- _ O
collection -X- _ O
. -X- _ O
We -X- _ O
collect -X- _ O
Wikipedia -X- _ O
page -X- _ O
titles -X- _ O
( -X- _ O
surface -X- _ O
form -X- _ O
) -X- _ O
as -X- _ O
our -X- _ O
entities -X- _ O
. -X- _ O
To -X- _ O
acquire -X- _ O
knowledge -X- _ O
and -X- _ O
utilize -X- _ O
the -X- _ O
pre -X- _ O
- -X- _ O
trained -X- _ O
entity -X- _ O
embeddings -X- _ O
in -X- _ O
Wikipedia2Vec -X- _ O
( -X- _ O
Yamada -X- _ O
et -X- _ O
al -X- _ O
. -X- _ O
, -X- _ O
2020 -X- _ O
) -X- _ O
in -X- _ O
the -X- _ O
later -X- _ O
steps -X- _ O
, -X- _ O
we -X- _ O
only -X- _ O
keep -X- _ O
entities -X- _ O
that -X- _ O
can -X- _ O
be -X- _ O
recognized -X- _ O
by -X- _ O
Wikipedia2Vec -X- _ B-MethodName
. -X- _ O

What -X- _ O
social -X- _ O
attitudes -X- _ O
about -X- _ O
gender -X- _ O
does -X- _ O
BERT -X- _ B-MethodName
encode -X- _ O
? -X- _ O
Leveraging -X- _ O
insights -X- _ O
from -X- _ O
psycholinguistics -X- _ O

Much -X- _ O
research -X- _ O
has -X- _ O
sought -X- _ O
to -X- _ O
evaluate -X- _ O
the -X- _ O
degree -X- _ O
to -X- _ O
which -X- _ O
large -X- _ O
language -X- _ O
models -X- _ O
reflect -X- _ O
social -X- _ O
biases -X- _ O
. -X- _ O
We -X- _ O
complement -X- _ O
such -X- _ O
work -X- _ O
with -X- _ O
an -X- _ O
approach -X- _ O
to -X- _ O
elucidating -X- _ O
the -X- _ O
connections -X- _ O
between -X- _ O
language -X- _ O
model -X- _ O
predictions -X- _ O
and -X- _ O
people -X- _ O
's -X- _ O
social -X- _ O
attitudes -X- _ O
. -X- _ O
We -X- _ O
show -X- _ O
how -X- _ O
word -X- _ O
preferences -X- _ O
in -X- _ O
a -X- _ O
large -X- _ O
language -X- _ O
model -X- _ O
reflect -X- _ O
social -X- _ O
attitudes -X- _ O
about -X- _ O
gender -X- _ O
, -X- _ O
using -X- _ O
two -X- _ O
datasets -X- _ O
from -X- _ O
human -X- _ O
experiments -X- _ O
that -X- _ O
found -X- _ O
differences -X- _ O
in -X- _ O
gendered -X- _ O
or -X- _ O
gender -X- _ O
neutral -X- _ O
word -X- _ O
choices -X- _ O
by -X- _ O
participants -X- _ O
with -X- _ O
differing -X- _ O
views -X- _ O
on -X- _ O
gender -X- _ O
( -X- _ O
progressive -X- _ O
, -X- _ O
moderate -X- _ O
, -X- _ O
or -X- _ O
conservative -X- _ O
) -X- _ O
. -X- _ O
We -X- _ O
find -X- _ O
that -X- _ O
the -X- _ O
language -X- _ O
model -X- _ O
BERT -X- _ B-MethodName
takes -X- _ O
into -X- _ O
account -X- _ O
factors -X- _ O
that -X- _ O
shape -X- _ O
human -X- _ O
lexical -X- _ O
choice -X- _ O
of -X- _ O
such -X- _ O
language -X- _ O
, -X- _ O
but -X- _ O
may -X- _ O
not -X- _ O
weigh -X- _ O
those -X- _ O
factors -X- _ O
in -X- _ O
the -X- _ O
same -X- _ O
way -X- _ O
people -X- _ O
do -X- _ O
. -X- _ O
Moreover -X- _ O
, -X- _ O
we -X- _ O
show -X- _ O
that -X- _ O
BERT -X- _ O
's -X- _ O
predictions -X- _ O
most -X- _ O
resemble -X- _ O
responses -X- _ O
from -X- _ O
participants -X- _ O
with -X- _ O
moderate -X- _ O
to -X- _ O
conservative -X- _ O
views -X- _ O
on -X- _ O
gender -X- _ O
. -X- _ O
Such -X- _ O
findings -X- _ O
illuminate -X- _ O
how -X- _ O
a -X- _ O
language -X- _ O
model -X- _ O
: -X- _ O
( -X- _ O
1 -X- _ O
) -X- _ O
may -X- _ O
differ -X- _ O
from -X- _ O
people -X- _ O
in -X- _ O
how -X- _ O
it -X- _ O
deploys -X- _ O
words -X- _ O
that -X- _ O
signal -X- _ O
gender -X- _ O
, -X- _ O
and -X- _ O
( -X- _ O
2 -X- _ O
) -X- _ O
may -X- _ O
prioritize -X- _ O
some -X- _ O
social -X- _ O
attitudes -X- _ O
over -X- _ O
others -X- _ O
. -X- _ O

We -X- _ O
use -X- _ O
the -X- _ O
datasets -X- _ O
from -X- _ O
these -X- _ O
two -X- _ O
experiments -X- _ O
to -X- _ O
evaluate -X- _ O
the -X- _ O
large -X- _ O
language -X- _ O
model -X- _ O
BERT -X- _ B-MethodName
( -X- _ O
specifically -X- _ O
, -X- _ O
BERT -X- _ B-MethodName
- -X- _ I-MethodName
base -X- _ I-MethodName
- -X- _ I-MethodName
uncased -X- _ I-MethodName
, -X- _ O
Devlin -X- _ O
et -X- _ O
al -X- _ O
. -X- _ O
, -X- _ O
2019 -X- _ O
) -X- _ O
. -X- _ O
We -X- _ O
focused -X- _ O
on -X- _ O
a -X- _ O
masked -X- _ O
language -X- _ O
model -X- _ O
because -X- _ O
such -X- _ O
models -X- _ O
can -X- _ O
readily -X- _ O
mimic -X- _ O
the -X- _ O
linguistic -X- _ O
tasks -X- _ O
in -X- _ O
these -X- _ O
experiments -X- _ O
. -X- _ O
We -X- _ O
selected -X- _ O
BERT -X- _ O
specifically -X- _ O
because -X- _ O
it -X- _ O
has -X- _ O
been -X- _ O
widely -X- _ O
deployed -X- _ O
and -X- _ O
thoroughly -X- _ O
evaluated -X- _ O
in -X- _ O
the -X- _ O
computational -X- _ O
linguistics -X- _ O
literature -X- _ O
, -X- _ O
which -X- _ O
facilitates -X- _ O
comparison -X- _ O
with -X- _ O
past -X- _ O
studies -X- _ O
. -X- _ O
Additionally -X- _ O
, -X- _ O
our -X- _ O
focus -X- _ O
on -X- _ O
the -X- _ O
light -X- _ B-MethodName
- -X- _ I-MethodName
weight -X- _ I-MethodName
BERT -X- _ I-MethodName
- -X- _ I-MethodName
base -X- _ I-MethodName
- -X- _ I-MethodName
uncased -X- _ I-MethodName
allowed -X- _ O
for -X- _ O
more -X- _ O
experimentation -X- _ O
, -X- _ O
letting -X- _ O
us -X- _ O
carefully -X- _ O
evaluate -X- _ O
numerous -X- _ O
experimental -X- _ O
conditions -X- _ O
across -X- _ O
multiple -X- _ O
participant -X- _ O
groups -X- _ O
. -X- _ O
Although -X- _ O
we -X- _ O
focus -X- _ O
on -X- _ O
masked -X- _ O
language -X- _ O
modeling -X- _ O
and -X- _ O
BERT -X- _ O
, -X- _ O
1 -X- _ O
our -X- _ O
approach -X- _ O
for -X- _ O
relating -X- _ O
linguistic -X- _ O
behaviour -X- _ O
to -X- _ O
social -X- _ O
attitudes -X- _ O
is -X- _ O
generalizable -X- _ O
, -X- _ O
and -X- _ O
can -X- _ O
readily -X- _ O
be -X- _ O
extended -X- _ O
to -X- _ O
other -X- _ O
models -X- _ O
or -X- _ O
tasks -X- _ O
. -X- _ O

We -X- _ O
do -X- _ O
this -X- _ O
in -X- _ O
the -X- _ O
context -X- _ O
of -X- _ O
much -X- _ O
work -X- _ O
on -X- _ O
language -X- _ B-TaskName
and -X- _ I-TaskName
social -X- _ I-TaskName
attitudes -X- _ I-TaskName
. -X- _ O
Sociolinguists -X- _ O
have -X- _ O
studied -X- _ O
the -X- _ O
subtle -X- _ O
yet -X- _ O
pervasive -X- _ O
ways -X- _ O
that -X- _ O
language -X- _ O
communicates -X- _ O
social -X- _ O
meaning -X- _ O
around -X- _ O
gender -X- _ O
( -X- _ O
e.g. -X- _ O
, -X- _ O
Eckert -X- _ O
, -X- _ O
2012 -X- _ O
; -X- _ O
Meyerhoff -X- _ O
, -X- _ O
2014 -X- _ O
) -X- _ O
, -X- _ O
and -X- _ O
raised -X- _ O
concerns -X- _ O
about -X- _ O
how -X- _ O
this -X- _ O
is -X- _ O
handled -X- _ O
in -X- _ O
NLP -X- _ O
( -X- _ O
Nguyen -X- _ O
et -X- _ O
al -X- _ O
. -X- _ O
, -X- _ O
2021 -X- _ O
) -X- _ O
. -X- _ O
Discourse -X- _ B-TaskName
Analysis -X- _ I-TaskName
emphasizes -X- _ O
words -X- _ O
as -X- _ O
social -X- _ O
categories -X- _ O
( -X- _ O
e.g. -X- _ O
, -X- _ O
Stokoe -X- _ O
and -X- _ O
Attenborough -X- _ O
, -X- _ O
2014 -X- _ O
) -X- _ O
, -X- _ O
which -X- _ O
computational -X- _ O
work -X- _ O
has -X- _ O
operationalized -X- _ O
to -X- _ O
study -X- _ O
online -X- _ O
attitudes -X- _ O
about -X- _ O
gender -X- _ O
( -X- _ O
LaViolette -X- _ O
and -X- _ O
Hogan -X- _ O
, -X- _ O
2019 -X- _ O
; -X- _ O
Li -X- _ O
and -X- _ O
Mendelsohn -X- _ O
, -X- _ O
2019 -X- _ O
) -X- _ O
. -X- _ O
Past -X- _ O
computational -X- _ O
work -X- _ O
in -X- _ O
this -X- _ O
vein -X- _ O
has -X- _ O
studied -X- _ O
variation -X- _ O
in -X- _ O
use -X- _ O
of -X- _ O
gendered -X- _ O
vs. -X- _ O
gender -X- _ O
neutral -X- _ O
terms -X- _ O
across -X- _ O
online -X- _ O
communities -X- _ O
( -X- _ O
CH -X- _ O
- -X- _ O
Wang -X- _ O
and -X- _ O
Jurgens -X- _ O
, -X- _ O
2021 -X- _ O
) -X- _ O
. -X- _ O
Here -X- _ O
, -X- _ O
we -X- _ O
take -X- _ O
this -X- _ O
sociolinguistic -X- _ O
lens -X- _ O
to -X- _ O
evaluating -X- _ O
two -X- _ O
different -X- _ O
kinds -X- _ O
of -X- _ O
gendered -X- _ O
and -X- _ O
gender -X- _ O
- -X- _ O
neutral -X- _ O
language -X- _ O
choices -X- _ O
in -X- _ O
large -X- _ O
language -X- _ O
models -X- _ O
. -X- _ O

3 -X- _ B-HyperparameterName
- -X- _ I-HyperparameterName
way -X- _ I-HyperparameterName
split -X- _ I-HyperparameterName
: -X- _ O

2 -X- _ B-HyperparameterName
- -X- _ I-HyperparameterName
way -X- _ I-HyperparameterName
split -X- _ I-HyperparameterName
: -X- _ O

The -X- _ O
stimuli -X- _ O
included -X- _ O
20 -X- _ O
different -X- _ O
sets -X- _ O
of -X- _ O
role -X- _ O
nouns -X- _ O
: -X- _ O
14 -X- _ O
have -X- _ O
a -X- _ O
3 -X- _ B-HyperparameterName
- -X- _ I-HyperparameterName
way -X- _ I-HyperparameterName
split -X- _ I-HyperparameterName
between -X- _ O
feminine -X- _ O
[ -X- _ O
FEM -X- _ O
] -X- _ O
, -X- _ O
masculine -X- _ O
[ -X- _ O
MASC -X- _ O
] -X- _ O
, -X- _ O
and -X- _ O
gender -X- _ O
neutral -X- _ O
[ -X- _ O
G -X- _ O
- -X- _ O
NEUT -X- _ O
] -X- _ O
variants -X- _ O
, -X- _ O
and -X- _ O
6 -X- _ O
have -X- _ O
a -X- _ O
2 -X- _ O
- -X- _ B-HyperparameterName
way -X- _ I-HyperparameterName
split -X- _ I-HyperparameterName
between -X- _ O
a -X- _ O
FEM -X- _ O
variant -X- _ O
and -X- _ O
a -X- _ O
variant -X- _ O
that -X- _ O
can -X- _ O
be -X- _ O
MASC -X- _ O
and -X- _ O
/ -X- _ O
or -X- _ O
G -X- _ O
- -X- _ O
NEUT -X- _ O
. -X- _ O
( -X- _ O
Appendix -X- _ O
A.1 -X- _ O
lists -X- _ O
all -X- _ O
the -X- _ O
role -X- _ O
noun -X- _ O
sets -X- _ O
. -X- _ O
) -X- _ O
Because -X- _ O
of -X- _ O
this -X- _ O
difference -X- _ O
, -X- _ O
we -X- _ O
analyze -X- _ O
the -X- _ O
3 -X- _ O
- -X- _ O
way -X- _ O
and -X- _ O
2 -X- _ O
- -X- _ O
way -X- _ O
role -X- _ O
noun -X- _ O
sets -X- _ O
separately -X- _ O
. -X- _ O
Papineau -X- _ O
et -X- _ O
al -X- _ O
. -X- _ O
( -X- _ O
2022 -X- _ O
) -X- _ O
also -X- _ O
scored -X- _ O
each -X- _ O
participant -X- _ O
given -X- _ O
their -X- _ O
responses -X- _ O
on -X- _ O
the -X- _ O
Social -X- _ O
Roles -X- _ O
Questionnaire -X- _ O
of -X- _ O
Baber -X- _ O
and -X- _ O
Tucker -X- _ O
( -X- _ O
2006 -X- _ O
) -X- _ O
, -X- _ O
in -X- _ O
which -X- _ O
higher -X- _ O
scores -X- _ O
mean -X- _ O
more -X- _ O
rigid -X- _ O
views -X- _ O
about -X- _ O
the -X- _ O
social -X- _ O
roles -X- _ O
of -X- _ O
men -X- _ O
and -X- _ O
women -X- _ O
. -X- _ O
Following -X- _ O
Papineau -X- _ O
et -X- _ O
al -X- _ O
. -X- _ O
( -X- _ O
2022 -X- _ O
) -X- _ O
, -X- _ O
we -X- _ O
refer -X- _ O
to -X- _ O
participants -X- _ O
with -X- _ O
higher -X- _ O
scores -X- _ O
( -X- _ O
more -X- _ O
rigid -X- _ O
views -X- _ O
) -X- _ O
as -X- _ O
having -X- _ O
more -X- _ O
conservative -X- _ O
attitudes -X- _ O
about -X- _ O
gender -X- _ O
. -X- _ O
For -X- _ O
our -X- _ O
analyses -X- _ O
, -X- _ O
we -X- _ O
grouped -X- _ O
participants -X- _ O
into -X- _ O
three -X- _ O
bins -X- _ B-HyperparameterName
based -X- _ O
on -X- _ O
this -X- _ O
score -X- _ O
: -X- _ O
those -X- _ O
with -X- _ O
progressive -X- _ O
gender -X- _ O
attitudes -X- _ O
( -X- _ O
lowest -X- _ O
third -X- _ O
of -X- _ O
scores -X- _ O
; -X- _ O
n=90 -X- _ B-HyperparameterName
) -X- _ O
, -X- _ O
moderate -X- _ O
gender -X- _ O
attitudes -X- _ O
( -X- _ O
middle -X- _ O
third -X- _ O
; -X- _ O
n=90 -X- _ B-HyperparameterName
) -X- _ O
, -X- _ O
and -X- _ O
conservative -X- _ O
gender -X- _ O
attitudes -X- _ O
( -X- _ O
highest -X- _ O
third -X- _ O
; -X- _ O
n=91 -X- _ B-HyperparameterName
) -X- _ O
. -X- _ O
4 -X- _ O
Appendix -X- _ O
A.2 -X- _ O
provides -X- _ O
details -X- _ O
on -X- _ O
this -X- _ O
survey -X- _ O
, -X- _ O
and -X- _ O
how -X- _ O
we -X- _ O
grouped -X- _ O
participants -X- _ O
based -X- _ O
on -X- _ O
their -X- _ O
responses -X- _ O
. -X- _ O
Figure -X- _ O
1a -X- _ O
shows -X- _ O
, -X- _ O
for -X- _ O
each -X- _ O
of -X- _ O
the -X- _ O
participant -X- _ O
groups -X- _ O
, -X- _ O
the -X- _ O
average -X- _ O
proportion -X- _ O
of -X- _ O
responses -X- _ O
of -X- _ O
FEM -X- _ O
/ -X- _ O
MASC -X- _ O
/ -X- _ O
G -X- _ O
- -X- _ O
NEUT -X- _ O
variants -X- _ O
for -X- _ O
the -X- _ O
3 -X- _ O
- -X- _ O
way -X- _ O
role -X- _ O
nouns -X- _ O
, -X- _ O
given -X- _ O
a -X- _ O
woman -X- _ O
's -X- _ O
or -X- _ O
a -X- _ O
man -X- _ O
's -X- _ O
name -X- _ O
. -X- _ O

BERT -X- _ B-MethodName
can -X- _ O
be -X- _ O
used -X- _ O
as -X- _ O
a -X- _ O
masked -X- _ O
language -X- _ O
model -X- _ O
to -X- _ O
generate -X- _ O
such -X- _ O
probabilities -X- _ O
; -X- _ O
however -X- _ O
, -X- _ O
the -X- _ O
direct -X- _ O
method -X- _ O
of -X- _ O
masking -X- _ O
the -X- _ O
target -X- _ O
-e.g -X- _ O
. -X- _ O
, -X- _ O
giving -X- _ O
BERT -X- _ B-MethodName
" -X- _ O
Sally -X- _ O
is -X- _ O
a -X- _ O
[ -X- _ O
MASK -X- _ O
] -X- _ O
from -X- _ O
Utah -X- _ O
" -X- _ O
and -X- _ O
comparing -X- _ O
its -X- _ O
probabilities -X- _ O
of -X- _ O
firewoman -X- _ O
/ -X- _ O
fireman -X- _ O
/ -X- _ O
firefighter -X- _ O
for -X- _ O
the -X- _ O
mask -X- _ O
-is -X- _ O
not -X- _ O
appropriate -X- _ O
. -X- _ O
Some -X- _ O
role -X- _ O
noun -X- _ O
variants -X- _ O
differ -X- _ O
in -X- _ O
their -X- _ O
number -X- _ O
of -X- _ O
words -X- _ O
( -X- _ O
e.g. -X- _ O
, -X- _ O
police -X- _ O
officer -X- _ O
vs. -X- _ O
policeman -X- _ O
) -X- _ O
, -X- _ O
and -X- _ O
this -X- _ O
is -X- _ O
compounded -X- _ O
by -X- _ O
BERT -X- _ O
breaking -X- _ O
many -X- _ O
words -X- _ O
into -X- _ O
multiple -X- _ O
word -X- _ O
pieces -X- _ O
( -X- _ O
e.g. -X- _ O
, -X- _ O
firefighter -X- _ O
is -X- _ O
fire -X- _ O
plus -X- _ O
# -X- _ O
# -X- _ O
fighter -X- _ O
) -X- _ O
. -X- _ O
This -X- _ O
often -X- _ O
leads -X- _ O
to -X- _ O
an -X- _ O
unfair -X- _ O
comparison -X- _ O
of -X- _ O
P -X- _ O
( -X- _ O
V -X- _ O
|C -X- _ O
) -X- _ O
over -X- _ O
varying -X- _ O
numbers -X- _ O
of -X- _ O
masked -X- _ O
items -X- _ O
for -X- _ O
V -X- _ O
. -X- _ O

In -X- _ O
addition -X- _ O
, -X- _ O
we -X- _ O
compute -X- _ O
the -X- _ O
average -X- _ B-MetricName
log -X- _ I-MetricName
likelihood -X- _ I-MetricName
, -X- _ O
according -X- _ O
to -X- _ O
BERT -X- _ O
's -X- _ O
probabilities -X- _ O
, -X- _ O
of -X- _ O
responses -X- _ O
of -X- _ O
participants -X- _ O
in -X- _ O
each -X- _ O
gender -X- _ O
attitudes -X- _ O
group -X- _ O
-progressive -X- _ O
, -X- _ O
moderate -X- _ O
, -X- _ O
and -X- _ O
conservative -X- _ O
- -X- _ O
shown -X- _ O
in -X- _ O
Table -X- _ O
1 -X- _ O
. -X- _ O
7 -X- _ O
This -X- _ O
identifies -X- _ O
which -X- _ O
participant -X- _ O
group -X- _ O
's -X- _ O
responses -X- _ O
are -X- _ O
best -X- _ O
predicted -X- _ O
by -X- _ O
BERT -X- _ O
. -X- _ O

On -X- _ O
forms -X- _ O
with -X- _ O
a -X- _ O
2 -X- _ B-HyperparameterName
- -X- _ I-HyperparameterName
way -X- _ I-HyperparameterName
split -X- _ I-HyperparameterName
, -X- _ O
there -X- _ O
are -X- _ O
minimal -X- _ O
differences -X- _ O
between -X- _ O
the -X- _ O
participant -X- _ O
groups -X- _ O
, -X- _ O
and -X- _ O
BERT -X- _ O
performs -X- _ O
similarly -X- _ O
on -X- _ O
each -X- _ O
of -X- _ O
them -X- _ O
. -X- _ O

Overall -X- _ O
then -X- _ O
for -X- _ O
RQ2 -X- _ O
, -X- _ O
across -X- _ O
men -X- _ O
's -X- _ O
and -X- _ O
women -X- _ O
's -X- _ O
names -X- _ O
, -X- _ O
BERT -X- _ O
performs -X- _ O
most -X- _ O
like -X- _ O
participants -X- _ O
with -X- _ O
moderate -X- _ O
and -X- _ O
conservative -X- _ O
social -X- _ O
attitudes -X- _ O
on -X- _ O
gender -X- _ O
roles -X- _ O
( -X- _ O
Table -X- _ O
1 -X- _ O
, -X- _ O
column -X- _ O
4 -X- _ O
) -X- _ O
. -X- _ O
For -X- _ O
role -X- _ O
nouns -X- _ O
with -X- _ O
a -X- _ O
3 -X- _ B-HyperparameterName
- -X- _ I-HyperparameterName
way -X- _ I-HyperparameterName
FEM -X- _ I-HyperparameterName
/ -X- _ I-HyperparameterName
MASC -X- _ I-HyperparameterName
/ -X- _ I-HyperparameterName
G -X- _ I-HyperparameterName
- -X- _ I-HyperparameterName
NEUT -X- _ I-HyperparameterName
split -X- _ I-HyperparameterName
, -X- _ O
this -X- _ O
is -X- _ O
especially -X- _ O
due -X- _ O
to -X- _ O
its -X- _ O
high -X- _ O
probability -X- _ O
for -X- _ O
MASC -X- _ O
forms -X- _ O
for -X- _ O
both -X- _ O
women -X- _ O
's -X- _ O
and -X- _ O
men -X- _ O
's -X- _ O
names -X- _ O
. -X- _ O
This -X- _ O
means -X- _ O
that -X- _ O
BERT -X- _ O
is -X- _ O
at -X- _ O
risk -X- _ O
of -X- _ O
conveying -X- _ O
( -X- _ O
and -X- _ O
propagating -X- _ O
) -X- _ O
rigid -X- _ O
social -X- _ O
attitudes -X- _ O
on -X- _ O
gender -X- _ O
in -X- _ O
its -X- _ O
use -X- _ O
of -X- _ O
role -X- _ O
nouns -X- _ O
. -X- _ O

We -X- _ O
use -X- _ O
surprisal -X- _ B-MetricName
, -X- _ O
-log -X- _ O
P -X- _ O
( -X- _ O
they|context -X- _ O
) -X- _ O
, -X- _ O
as -X- _ O
BERT -X- _ O
's -X- _ O
assessment -X- _ O
of -X- _ O
they -X- _ O
in -X- _ O
context -X- _ O
. -X- _ O
Much -X- _ O
work -X- _ O
in -X- _ O
psycholinguistics -X- _ O
shows -X- _ O
that -X- _ O
surprisal -X- _ O
captures -X- _ O
human -X- _ O
expectations -X- _ O
for -X- _ O
words -X- _ O
in -X- _ O
processing -X- _ O
sentences -X- _ O
( -X- _ O
e.g. -X- _ O
, -X- _ O
Hale -X- _ O
, -X- _ O
2001 -X- _ O
; -X- _ O
Smith -X- _ O
and -X- _ O
Levy -X- _ O
, -X- _ O
2008 -X- _ O
) -X- _ O
, -X- _ O
so -X- _ O
it -X- _ O
works -X- _ O
well -X- _ O
for -X- _ O
comparing -X- _ O
BERT -X- _ O
to -X- _ O
human -X- _ O
ratings -X- _ O
of -X- _ O
naturalness -X- _ O
here -X- _ O
. -X- _ O
We -X- _ O
feed -X- _ O
into -X- _ O
BERT -X- _ O
the -X- _ O
335 -X- _ O
stimuli -X- _ O
from -X- _ O
Camilliere -X- _ O
et -X- _ O
al -X- _ O
. -X- _ O
( -X- _ O
2021 -X- _ O
) -X- _ O
, -X- _ O
masking -X- _ O
they -X- _ O
, -X- _ O
as -X- _ O
in -X- _ O
: -X- _ O

In -X- _ O
this -X- _ O
project -X- _ O
, -X- _ O
we -X- _ O
develop -X- _ O
an -X- _ O
approach -X- _ O
for -X- _ O
evaluating -X- _ B-TaskName
the -X- _ I-TaskName
social -X- _ I-TaskName
attitudes -X- _ I-TaskName
encoded -X- _ I-TaskName
in -X- _ I-TaskName
large -X- _ I-TaskName
language -X- _ I-TaskName
models -X- _ I-TaskName
. -X- _ O
To -X- _ O
do -X- _ O
this -X- _ O
, -X- _ O
we -X- _ O
leverage -X- _ O
experimental -X- _ B-DatasetName
data -X- _ I-DatasetName
from -X- _ I-DatasetName
psycholinguistics -X- _ I-DatasetName
, -X- _ O
and -X- _ O
compare -X- _ O
the -X- _ O
predictions -X- _ O
of -X- _ O
a -X- _ O
language -X- _ O
model -X- _ O
to -X- _ O
responses -X- _ O
from -X- _ O
partic- -X- _ O
11 -X- _ O
We -X- _ O
chose -X- _ O
this -X- _ O
measure -X- _ O
rather -X- _ O
than -X- _ O
nonbinary -X- _ O
familiarity -X- _ O
because -X- _ O
we -X- _ O
think -X- _ O
it -X- _ O
is -X- _ O
more -X- _ O
reflective -X- _ O
of -X- _ O
social -X- _ O
attitudes -X- _ O
. -X- _ O
ipants -X- _ O
with -X- _ O
different -X- _ O
social -X- _ O
attitudes -X- _ O
. -X- _ O
This -X- _ O
contrasts -X- _ O
with -X- _ O
much -X- _ O
past -X- _ O
work -X- _ O
on -X- _ O
bias -X- _ O
in -X- _ O
NLP -X- _ O
, -X- _ O
which -X- _ O
has -X- _ O
often -X- _ O
tested -X- _ O
whether -X- _ O
models -X- _ O
encode -X- _ O
stereotypical -X- _ O
associations -X- _ O
or -X- _ O
not -X- _ O
, -X- _ O
rather -X- _ O
than -X- _ O
taking -X- _ O
a -X- _ O
comparative -X- _ O
approach -X- _ O
to -X- _ O
learned -X- _ O
associations -X- _ O
, -X- _ O
and -X- _ O
considering -X- _ O
how -X- _ O
those -X- _ O
may -X- _ O
relate -X- _ O
to -X- _ O
social -X- _ O
attitudes -X- _ O
. -X- _ O

In -X- _ O
this -X- _ O
paper -X- _ O
, -X- _ O
we -X- _ O
developed -X- _ O
an -X- _ O
approach -X- _ O
for -X- _ O
evaluating -X- _ O
how -X- _ O
large -X- _ O
language -X- _ O
models -X- _ O
encode -X- _ O
social -X- _ O
attitudes -X- _ O
about -X- _ O
gender -X- _ O
, -X- _ O
and -X- _ O
we -X- _ O
applied -X- _ O
that -X- _ O
approach -X- _ O
to -X- _ O
evaluate -X- _ O
BERT -X- _ B-MethodName
- -X- _ I-MethodName
base -X- _ I-MethodName
- -X- _ I-MethodName
uncased -X- _ I-MethodName
. -X- _ O
Because -X- _ O
the -X- _ O
goal -X- _ O
of -X- _ O
this -X- _ O
paper -X- _ O
was -X- _ O
ethical -X- _ O
in -X- _ O
nature -X- _ O
, -X- _ O
limitations -X- _ O
on -X- _ O
the -X- _ O
generalizability -X- _ O
of -X- _ O
our -X- _ O
approach -X- _ O
and -X- _ O
findings -X- _ O
entail -X- _ O
ethical -X- _ O
risks -X- _ O
. -X- _ O
With -X- _ O
this -X- _ O
in -X- _ O
mind -X- _ O
, -X- _ O
we -X- _ O
discuss -X- _ O
both -X- _ O
limitations -X- _ O
and -X- _ O
risks -X- _ O
in -X- _ O
this -X- _ O
section -X- _ O
. -X- _ O
We -X- _ O
first -X- _ O
discuss -X- _ O
limitations -X- _ O
related -X- _ O
to -X- _ O
data -X- _ O
, -X- _ O
and -X- _ O
then -X- _ O
discuss -X- _ O
those -X- _ O
related -X- _ O
to -X- _ O
models -X- _ O
and -X- _ O
tasks -X- _ O
. -X- _ O
For -X- _ O
both -X- _ O
data -X- _ O
and -X- _ O
models -X- _ O
/ -X- _ O
tasks -X- _ O
, -X- _ O
we -X- _ O
consider -X- _ O
general -X- _ O
limitations -X- _ O
of -X- _ O
our -X- _ O
approach -X- _ O
, -X- _ O
as -X- _ O
well -X- _ O
as -X- _ O
more -X- _ O
specific -X- _ O
limitations -X- _ O
of -X- _ O
how -X- _ O
we -X- _ O
applied -X- _ O
the -X- _ O
approach -X- _ O
here -X- _ O
. -X- _ O

Just -X- _ O
as -X- _ O
it -X- _ O
is -X- _ O
not -X- _ O
possible -X- _ O
to -X- _ O
create -X- _ O
a -X- _ O
single -X- _ O
benchmark -X- _ O
for -X- _ O
all -X- _ O
language -X- _ O
understanding -X- _ O
( -X- _ O
Raji -X- _ O
et -X- _ O
al -X- _ O
. -X- _ O
, -X- _ O
2021 -X- _ O
) -X- _ O
, -X- _ O
it -X- _ O
is -X- _ O
not -X- _ O
possible -X- _ O
to -X- _ O
create -X- _ O
a -X- _ O
single -X- _ O
, -X- _ O
definitive -X- _ O
dataset -X- _ O
that -X- _ O
relates -X- _ O
language -X- _ O
choices -X- _ O
to -X- _ O
social -X- _ O
attitudes -X- _ O
. -X- _ O
Human -X- _ B-DatasetName
experimental -X- _ I-DatasetName
data -X- _ I-DatasetName
is -X- _ O
always -X- _ O
limited -X- _ O
by -X- _ O
practical -X- _ O
considerations -X- _ O
and -X- _ O
can -X- _ O
not -X- _ O
test -X- _ O
every -X- _ O
condition -X- _ O
of -X- _ O
theoretical -X- _ O
interest -X- _ O
; -X- _ O
e.g. -X- _ O
, -X- _ O
in -X- _ O
the -X- _ O
role -X- _ O
nouns -X- _ O
dataset -X- _ O
, -X- _ O
there -X- _ O
were -X- _ O
no -X- _ O
conditions -X- _ O
with -X- _ O
gender -X- _ O
neutral -X- _ O
names -X- _ O
, -X- _ O
while -X- _ O
in -X- _ O
the -X- _ O
singular -X- _ O
they -X- _ O
dataset -X- _ O
, -X- _ O
there -X- _ O
was -X- _ O
no -X- _ O
comparison -X- _ O
to -X- _ O
neopronouns -X- _ O
( -X- _ O
e.g. -X- _ O
, -X- _ O
xe -X- _ O
/ -X- _ O
xem -X- _ O
) -X- _ O
. -X- _ O
Additionally -X- _ O
, -X- _ O
because -X- _ O
past -X- _ O
work -X- _ O
has -X- _ O
found -X- _ O
that -X- _ O
model -X- _ O
preferences -X- _ O
may -X- _ O
vary -X- _ O
across -X- _ O
similar -X- _ O
linguistic -X- _ O
contexts -X- _ O
( -X- _ O
Delobelle -X- _ O
et -X- _ O
al -X- _ O
. -X- _ O
, -X- _ O
2022 -X- _ O
) -X- _ O
, -X- _ O
it -X- _ O
may -X- _ O
be -X- _ O
the -X- _ O
case -X- _ O
that -X- _ O
BERT -X- _ O
's -X- _ O
predictions -X- _ O
would -X- _ O
correlate -X- _ O
differently -X- _ O
with -X- _ O
human -X- _ O
responses -X- _ O
on -X- _ O
other -X- _ O
variations -X- _ O
on -X- _ O
the -X- _ O
stimuli -X- _ O
. -X- _ O
Relating -X- _ O
model -X- _ O
preferences -X- _ O
to -X- _ O
human -X- _ O
behaviour -X- _ O
will -X- _ O
always -X- _ O
be -X- _ O
limited -X- _ O
by -X- _ O
the -X- _ O
amount -X- _ O
of -X- _ O
human -X- _ O
data -X- _ O
that -X- _ O
can -X- _ O
be -X- _ O
obtained -X- _ O
. -X- _ O

There -X- _ O
are -X- _ O
also -X- _ O
several -X- _ O
limitations -X- _ O
related -X- _ O
to -X- _ O
the -X- _ O
models -X- _ O
and -X- _ O
tasks -X- _ O
considered -X- _ O
. -X- _ O
First -X- _ O
, -X- _ O
we -X- _ O
evaluated -X- _ O
only -X- _ O
one -X- _ O
model -X- _ O
( -X- _ O
BERT -X- _ B-MethodName
- -X- _ I-MethodName
base -X- _ I-MethodName
- -X- _ I-MethodName
uncased -X- _ I-MethodName
) -X- _ O
, -X- _ O
and -X- _ O
more -X- _ O
work -X- _ O
is -X- _ O
needed -X- _ O
to -X- _ O
understand -X- _ O
if -X- _ O
and -X- _ O
how -X- _ O
our -X- _ O
specific -X- _ O
results -X- _ O
generalize -X- _ O
to -X- _ O
other -X- _ O
masked -X- _ O
language -X- _ O
models -X- _ O
. -X- _ O
This -X- _ O
is -X- _ O
especially -X- _ O
important -X- _ O
given -X- _ O
that -X- _ O
past -X- _ O
findings -X- _ O
comparing -X- _ O
gender -X- _ O
bias -X- _ O
in -X- _ O
masked -X- _ O
language -X- _ O
models -X- _ O
with -X- _ O
different -X- _ O
architectures -X- _ O
and -X- _ O
model -X- _ O
sizes -X- _ O
are -X- _ O
mixed -X- _ O
( -X- _ O
e.g. -X- _ O
, -X- _ O
Sharma -X- _ O
et -X- _ O
al -X- _ O
. -X- _ O
, -X- _ O
2020 -X- _ O
; -X- _ O
Jentzsch -X- _ O
and -X- _ O
Turan -X- _ O
, -X- _ O
2022 -X- _ O
; -X- _ O
Tal -X- _ O
et -X- _ O
al -X- _ O
. -X- _ O
, -X- _ O
2022 -X- _ O
) -X- _ O
. -X- _ O

Additionally -X- _ O
, -X- _ O
we -X- _ O
only -X- _ O
considered -X- _ O
the -X- _ O
task -X- _ O
of -X- _ O
masked -X- _ B-TaskName
language -X- _ I-TaskName
modeling -X- _ I-TaskName
. -X- _ O
We -X- _ O
made -X- _ O
this -X- _ O
choice -X- _ O
because -X- _ O
psycholinguistic -X- _ O
datasets -X- _ O
that -X- _ O
pair -X- _ O
linguistic -X- _ O
choices -X- _ O
with -X- _ O
results -X- _ O
of -X- _ O
social -X- _ O
attitude -X- _ O
surveys -X- _ O
are -X- _ O
rare -X- _ O
, -X- _ O
and -X- _ O
those -X- _ O
available -X- _ O
to -X- _ O
us -X- _ O
used -X- _ O
language -X- _ O
tasks -X- _ O
that -X- _ O
were -X- _ O
most -X- _ O
appropriate -X- _ O
for -X- _ O
evaluation -X- _ O
on -X- _ O
the -X- _ O
task -X- _ O
of -X- _ O
masked -X- _ O
language -X- _ O
modeling -X- _ O
. -X- _ O
However -X- _ O
, -X- _ O
given -X- _ O
that -X- _ O
bias -X- _ O
on -X- _ O
the -X- _ O
intrinsic -X- _ O
task -X- _ O
of -X- _ O
masked -X- _ O
language -X- _ O
modeling -X- _ O
may -X- _ O
not -X- _ O
relate -X- _ O
to -X- _ O
( -X- _ O
extrinsic -X- _ O
) -X- _ O
bias -X- _ O
on -X- _ O
downstream -X- _ O
tasks -X- _ O
( -X- _ O
Delobelle -X- _ O
et -X- _ O
al -X- _ O
. -X- _ O
, -X- _ O
2022 -X- _ O
) -X- _ O
, -X- _ O
our -X- _ O
results -X- _ O
( -X- _ O
such -X- _ O
as -X- _ O
BERT -X- _ O
's -X- _ O
language -X- _ O
communicating -X- _ O
conservative -X- _ O
attitudes -X- _ O
) -X- _ O
may -X- _ O
or -X- _ O
may -X- _ O
not -X- _ O
carry -X- _ O
over -X- _ O
to -X- _ O
downstream -X- _ O
tasks -X- _ O
. -X- _ O
In -X- _ O
the -X- _ O
future -X- _ O
, -X- _ O
our -X- _ O
approach -X- _ O
for -X- _ O
relating -X- _ O
task -X- _ O
predictions -X- _ O
to -X- _ O
social -X- _ O
attitudes -X- _ O
could -X- _ O
be -X- _ O
used -X- _ O
to -X- _ O
evaluate -X- _ O
downstream -X- _ O
tasks -X- _ O
( -X- _ O
such -X- _ O
as -X- _ O
coreference -X- _ O
resolution -X- _ O
) -X- _ O
, -X- _ O
once -X- _ O
appropriate -X- _ O
human -X- _ O
data -X- _ O
is -X- _ O
available -X- _ O
. -X- _ O

We -X- _ O
aimed -X- _ O
to -X- _ O
validate -X- _ O
that -X- _ O
the -X- _ O
groupings -X- _ O
by -X- _ O
linguistic -X- _ O
stage -X- _ O
, -X- _ O
used -X- _ O
by -X- _ O
Camilliere -X- _ O
et -X- _ O
al -X- _ O
. -X- _ O
( -X- _ O
2021 -X- _ O
) -X- _ O
, -X- _ O
reflect -X- _ O
social -X- _ O
attitudes -X- _ O
. -X- _ O
To -X- _ O
do -X- _ O
so -X- _ O
, -X- _ O
we -X- _ O
conduct -X- _ O
one -X- _ O
- -X- _ O
tailed -X- _ O
Mann -X- _ O
- -X- _ O
Whitney -X- _ O
U -X- _ O
- -X- _ O
Tests -X- _ O
comparing -X- _ O
scores -X- _ O
on -X- _ O
the -X- _ O
nonbinary -X- _ O
acceptance -X- _ O
survey -X- _ O
and -X- _ O
nonbinary -X- _ O
famil- -X- _ O
iarity -X- _ O
survey -X- _ O
across -X- _ O
the -X- _ O
groups -X- _ O
. -X- _ O
( -X- _ O
Recall -X- _ O
, -X- _ O
these -X- _ O
are -X- _ O
the -X- _ O
two -X- _ O
surveys -X- _ O
Camilliere -X- _ O
et -X- _ O
al -X- _ O
. -X- _ O
( -X- _ O
2021 -X- _ O
) -X- _ O
found -X- _ O
to -X- _ O
predict -X- _ O
ratings -X- _ O
on -X- _ O
their -X- _ O
experimental -X- _ O
task -X- _ O
. -X- _ O
) -X- _ O
We -X- _ O
find -X- _ O
significantly -X- _ O
higher -X- _ O
( -X- _ O
greater -X- _ O
acceptance -X- _ B-MetricName
/ -X- _ O
greater -X- _ O
familiarity -X- _ B-MetricName
) -X- _ O
scores -X- _ O
for -X- _ O
the -X- _ O
super -X- _ O
- -X- _ O
innovative -X- _ O
cluster -X- _ O
than -X- _ O
the -X- _ O
innovative -X- _ O
cluster -X- _ O
for -X- _ O
both -X- _ O
the -X- _ O
nonbinary -X- _ O
acceptance -X- _ B-MetricName
scale -X- _ O
( -X- _ O
2.13 -X- _ B-MetricValue
for -X- _ O
super -X- _ O
- -X- _ O
innovators -X- _ O
vs. -X- _ O
1.27 -X- _ B-MetricValue
for -X- _ O
innovators -X- _ O
, -X- _ O
p -X- _ B-HyperparameterName
= -X- _ O
0.0083 -X- _ B-HyperparameterValue
) -X- _ O
and -X- _ O
the -X- _ O
nonbinary -X- _ O
familiarity -X- _ B-MetricName
scale -X- _ O
( -X- _ O
1.25 -X- _ B-MetricValue
for -X- _ O
super -X- _ O
- -X- _ O
innovators -X- _ O
vs. -X- _ O
0.49 -X- _ B-MetricValue
for -X- _ O
innovators -X- _ O
, -X- _ O
p -X- _ B-HyperparameterName
= -X- _ O
0.0241 -X- _ B-HyperparameterValue
) -X- _ O
. -X- _ O
We -X- _ O
find -X- _ O
no -X- _ O
significant -X- _ O
differences -X- _ O
in -X- _ O
survey -X- _ O
responses -X- _ O
between -X- _ O
the -X- _ O
innovative -X- _ O
and -X- _ O
non -X- _ O
- -X- _ O
innovative -X- _ O
clusters -X- _ O
on -X- _ O
either -X- _ O
the -X- _ O
nonbinary -X- _ O
acceptance -X- _ O
scale -X- _ O
( -X- _ O
1.27 -X- _ O
for -X- _ O
innovators -X- _ O
vs. -X- _ O
1.29 -X- _ O
for -X- _ O
non -X- _ O
- -X- _ O
innovators -X- _ O
, -X- _ O
p -X- _ O
= -X- _ O
0.5805 -X- _ O
) -X- _ O
or -X- _ O
the -X- _ O
nonbinary -X- _ O
familiarity -X- _ O
scale -X- _ O
( -X- _ O
0.49 -X- _ O
for -X- _ O
innovators -X- _ O
vs. -X- _ O
0.61 -X- _ O
for -X- _ O
non -X- _ O
- -X- _ O
innovators -X- _ O
, -X- _ O
p -X- _ O
= -X- _ O
0.8138 -X- _ O
) -X- _ O
. -X- _ O

We -X- _ O
use -X- _ O
data -X- _ B-DatasetName
from -X- _ I-DatasetName
Papineau -X- _ I-DatasetName
et -X- _ I-DatasetName
al -X- _ I-DatasetName
. -X- _ O
( -X- _ O
2022 -X- _ O
) -X- _ O
14 -X- _ O
, -X- _ O
which -X- _ O
is -X- _ O
made -X- _ O
available -X- _ O
under -X- _ O
an -X- _ O
MIT -X- _ O
license -X- _ O
. -X- _ O
We -X- _ O
also -X- _ O
use -X- _ O
data -X- _ B-DatasetName
from -X- _ I-DatasetName
Camilliere -X- _ I-DatasetName
et -X- _ I-DatasetName
al -X- _ I-DatasetName
. -X- _ O
( -X- _ O
2021 -X- _ O
) -X- _ O
, -X- _ O
which -X- _ O
was -X- _ O
shared -X- _ O
with -X- _ O
us -X- _ O
directly -X- _ O
by -X- _ O
the -X- _ O
authors -X- _ O
. -X- _ O
The -X- _ O
model -X- _ O
we -X- _ O
evaluated -X- _ O
was -X- _ O
BERT -X- _ O
( -X- _ O
Devlin -X- _ O
et -X- _ O
al -X- _ O
. -X- _ O
, -X- _ O
2019 -X- _ O
) -X- _ O
, -X- _ O
which -X- _ O
is -X- _ O
released -X- _ O
under -X- _ O
an -X- _ O
Apache -X- _ O
License -X- _ O
2.0 -X- _ O
. -X- _ O
The -X- _ O
specific -X- _ O
model -X- _ O
we -X- _ O
studied -X- _ O
is -X- _ O
bert-14 -X- _ B-MethodName
https -X- _ O
: -X- _ O
/ -X- _ O
/ -X- _ O
github.com -X- _ O
/ -X- _ O
BranPap -X- _ O
/ -X- _ O
gender_ideology -X- _ O
base -X- _ O
- -X- _ O
uncased -X- _ O
, -X- _ O
which -X- _ O
has -X- _ O
110 -X- _ O
million -X- _ O
parameters -X- _ O
. -X- _ O
We -X- _ O
use -X- _ O
the -X- _ O
PyTorch -X- _ O
implementation -X- _ O
made -X- _ O
available -X- _ O
through -X- _ O
the -X- _ O
HuggingFace -X- _ O
Transformers -X- _ O
library -X- _ O
15 -X- _ O
( -X- _ O
library -X- _ O
version -X- _ O
4.9.2 -X- _ O
) -X- _ O
. -X- _ O
All -X- _ O
analyses -X- _ O
were -X- _ O
run -X- _ O
on -X- _ O
a -X- _ O
2020 -X- _ O
M1 -X- _ O
MacBook -X- _ O
Air -X- _ O
; -X- _ O
the -X- _ O
combined -X- _ O
analyses -X- _ O
took -X- _ O
less -X- _ O
than -X- _ O
24 -X- _ O
hours -X- _ O
of -X- _ O
compute -X- _ O
time -X- _ O
. -X- _ O

Hierarchical -X- _ B-MethodName
Curriculum -X- _ I-MethodName
Learning -X- _ I-MethodName
for -X- _ O
AMR -X- _ B-TaskName
Parsing -X- _ I-TaskName

Meaning -X- _ O
Representation -X- _ O
( -X- _ O
AMR -X- _ O
) -X- _ O
parsing -X- _ O
aims -X- _ O
to -X- _ O
translate -X- _ O
sentences -X- _ O
to -X- _ O
semantic -X- _ O
representation -X- _ O
with -X- _ O
a -X- _ O
hierarchical -X- _ O
structure -X- _ O
, -X- _ O
and -X- _ O
is -X- _ O
recently -X- _ O
empowered -X- _ O
by -X- _ O
pretrained -X- _ O
sequenceto -X- _ O
- -X- _ O
sequence -X- _ O
models -X- _ O
. -X- _ O
However -X- _ O
, -X- _ O
there -X- _ O
exists -X- _ O
a -X- _ O
gap -X- _ O
between -X- _ O
their -X- _ O
flat -X- _ O
training -X- _ O
objective -X- _ O
( -X- _ O
i.e. -X- _ O
, -X- _ O
equally -X- _ O
treats -X- _ O
all -X- _ O
output -X- _ O
tokens -X- _ O
) -X- _ O
and -X- _ O
the -X- _ O
hierarchical -X- _ O
AMR -X- _ B-TaskName
structure -X- _ O
, -X- _ O
which -X- _ O
limits -X- _ O
the -X- _ O
model -X- _ O
generalization -X- _ O
. -X- _ O
To -X- _ O
bridge -X- _ O
this -X- _ O
gap -X- _ O
, -X- _ O
we -X- _ O
propose -X- _ O
a -X- _ O
Hierarchical -X- _ B-MethodName
Curriculum -X- _ I-MethodName
Learning -X- _ I-MethodName
( -X- _ I-MethodName
HCL -X- _ I-MethodName
) -X- _ I-MethodName
framework -X- _ O
with -X- _ O
Structure -X- _ O
- -X- _ O
level -X- _ O
( -X- _ O
SC -X- _ O
) -X- _ O
and -X- _ O
Instance -X- _ O
- -X- _ O
level -X- _ O
Curricula -X- _ O
( -X- _ O
IC -X- _ O
) -X- _ O
. -X- _ O
SC -X- _ O
switches -X- _ O
progressively -X- _ O
from -X- _ O
core -X- _ O
to -X- _ O
detail -X- _ O
AMR -X- _ O
semantic -X- _ O
elements -X- _ O
while -X- _ O
IC -X- _ O
transits -X- _ O
from -X- _ O
structuresimple -X- _ O
to -X- _ O
-complex -X- _ O
AMR -X- _ O
instances -X- _ O
during -X- _ O
training -X- _ O
. -X- _ O
Through -X- _ O
these -X- _ O
two -X- _ O
warming -X- _ O
- -X- _ O
up -X- _ O
processes -X- _ O
, -X- _ O
HCL -X- _ B-MethodName
reduces -X- _ O
the -X- _ O
difficulty -X- _ O
of -X- _ O
learning -X- _ O
complex -X- _ O
structures -X- _ O
, -X- _ O
thus -X- _ O
the -X- _ O
flat -X- _ O
model -X- _ O
can -X- _ O
better -X- _ O
adapt -X- _ O
to -X- _ O
the -X- _ O
AMR -X- _ O
hierarchy -X- _ O
. -X- _ O
Extensive -X- _ O
experiments -X- _ O
on -X- _ O
AMR2.0 -X- _ O
, -X- _ O
AMR3.0 -X- _ O
, -X- _ O
structurecomplex -X- _ O
and -X- _ O
out -X- _ O
- -X- _ O
of -X- _ O
- -X- _ O
distribution -X- _ O
situations -X- _ O
verify -X- _ O
the -X- _ O
effectiveness -X- _ O
of -X- _ O
HCL -X- _ B-MethodName
. -X- _ O

Abstract -X- _ B-TaskName
Meaning -X- _ I-TaskName
Representation -X- _ I-TaskName
( -X- _ I-TaskName
AMR -X- _ I-TaskName
) -X- _ I-TaskName
( -X- _ O
Banarescu -X- _ O
et -X- _ O
al -X- _ O
. -X- _ O
, -X- _ O
2013 -X- _ O
) -X- _ O
parsing -X- _ O
aims -X- _ O
to -X- _ O
translate -X- _ O
a -X- _ O
natural -X- _ O
sentence -X- _ O
into -X- _ O
a -X- _ O
directed -X- _ O
acyclic -X- _ O
graph -X- _ O
. -X- _ O
Figure -X- _ O
1 -X- _ O
( -X- _ O
a -X- _ O
) -X- _ O
illustrates -X- _ O
an -X- _ O
AMR -X- _ O
graph -X- _ O
where -X- _ O
nodes -X- _ O
represent -X- _ O
concepts -X- _ O
, -X- _ O
e.g. -X- _ O
, -X- _ O
' -X- _ O
die-01 -X- _ O
' -X- _ O
and -X- _ O
' -X- _ O
soldier -X- _ O
' -X- _ O
, -X- _ O
and -X- _ O
edges -X- _ O
represent -X- _ O
relations -X- _ O
, -X- _ O
e.g. -X- _ O
, -X- _ O
' -X- _ O
: -X- _ O
ARG1 -X- _ O
' -X- _ O
and -X- _ O
' -X- _ O
: -X- _ O
quant -X- _ O
' -X- _ O
. -X- _ O
AMR -X- _ O
has -X- _ O
been -X- _ O
exploited -X- _ O
in -X- _ O
the -X- _ O
downstream -X- _ O
NLP -X- _ O
tasks -X- _ O
, -X- _ O
including -X- _ O
information -X- _ O
extraction -X- _ O
( -X- _ O
Rao -X- _ O
et -X- _ O
al -X- _ O
. -X- _ O
, -X- _ O
2017 -X- _ O
; -X- _ O
Wang -X- _ O
et -X- _ O
al -X- _ O
. -X- _ O
, -X- _ O
2017 -X- _ O
; -X- _ O
Zhang -X- _ O
and -X- _ O
Ji -X- _ O
, -X- _ O
2021 -X- _ O
) -X- _ O
, -X- _ O
text -X- _ O
summarization -X- _ O
( -X- _ O
Liao -X- _ O
et -X- _ O
al -X- _ O
. -X- _ O
, -X- _ O
2018 -X- _ O
; -X- _ O
Hardy -X- _ O
and -X- _ O
Vlachos -X- _ O
, -X- _ O
2018 -X- _ O
) -X- _ O
and -X- _ O
question -X- _ O
answering -X- _ O
( -X- _ O
Mitra -X- _ O
and -X- _ O
Baral -X- _ O
, -X- _ O
2016 -X- _ O
; -X- _ O
Sachan -X- _ O
and -X- _ O
Xing -X- _ O
, -X- _ O
2016 -X- _ O
) -X- _ O
. -X- _ O

Motivated -X- _ O
by -X- _ O
learning -X- _ O
core -X- _ O
concepts -X- _ O
first -X- _ O
, -X- _ O
we -X- _ O
propose -X- _ O
Structure -X- _ O
- -X- _ O
level -X- _ O
Curriculum -X- _ O
( -X- _ O
SC -X- _ O
) -X- _ O
. -X- _ O
AMR -X- _ O
graphs -X- _ O
are -X- _ O
organized -X- _ O
in -X- _ O
a -X- _ O
hierarchy -X- _ O
where -X- _ O
the -X- _ O
core -X- _ O
semantics -X- _ O
stay -X- _ O
closely -X- _ O
to -X- _ O
the -X- _ O
root -X- _ O
( -X- _ O
Cai -X- _ O
and -X- _ O
Lam -X- _ O
, -X- _ O
2019 -X- _ O
) -X- _ O
, -X- _ O
thus -X- _ O
SC -X- _ O
divides -X- _ O
all -X- _ O
AMR -X- _ O
sub -X- _ O
- -X- _ O
graphs -X- _ O
into -X- _ O
N -X- _ B-HyperparameterName
buckets -X- _ I-HyperparameterName
according -X- _ O
to -X- _ O
their -X- _ O
depths -X- _ O
{ -X- _ O
S -X- _ O
i -X- _ O
: -X- _ O
i -X- _ O
= -X- _ O
1 -X- _ O
, -X- _ O
2 -X- _ O
, -X- _ O
... -X- _ O
, -X- _ O
N -X- _ O
} -X- _ O
, -X- _ O
where -X- _ O
S -X- _ O
i -X- _ O
contains -X- _ O
AMR -X- _ O
sub -X- _ O
- -X- _ O
graphs -X- _ O
with -X- _ O
the -X- _ O
depth -X- _ O
i. -X- _ O
As -X- _ O
shown -X- _ O
in -X- _ O
Figure -X- _ O
2 -X- _ O
a -X- _ O
sentence -X- _ O
into -X- _ O
a -X- _ O
sub -X- _ O
- -X- _ O
graph -X- _ O
with -X- _ O
the -X- _ O
depth -X- _ B-HyperparameterName
d -X- _ I-HyperparameterName
, -X- _ O
we -X- _ O
append -X- _ O
a -X- _ O
special -X- _ O
string -X- _ O
" -X- _ O
parse -X- _ O
to -X- _ O
d -X- _ O
layers -X- _ O
" -X- _ O
to -X- _ O
the -X- _ O
input -X- _ O
sentence -X- _ O
, -X- _ O
and -X- _ O
replace -X- _ O
the -X- _ O
start -X- _ O
token -X- _ O
of -X- _ O
the -X- _ O
decoder -X- _ O
with -X- _ O
an -X- _ O
artificial -X- _ O
token -X- _ O
< -X- _ O
d -X- _ O
> -X- _ O
, -X- _ O
so -X- _ O
the -X- _ O
model -X- _ O
can -X- _ O
perceive -X- _ O
layers -X- _ O
that -X- _ O
need -X- _ O
to -X- _ O
be -X- _ O
parsed -X- _ O
. -X- _ O

Experiment -X- _ O
Setups -X- _ O
Our -X- _ O
implementation -X- _ O
is -X- _ O
based -X- _ O
on -X- _ O
Huggingface -X- _ O
's -X- _ O
transformers -X- _ O
library -X- _ O
( -X- _ O
Wolf -X- _ O
et -X- _ O
al -X- _ O
. -X- _ O
, -X- _ O
2020 -X- _ O
) -X- _ O
and -X- _ O
the -X- _ O
open -X- _ O
codebase -X- _ O
of -X- _ O
Bevilacqua -X- _ O
et -X- _ O
al -X- _ O
. -X- _ O
( -X- _ O
2021 -X- _ O
) -X- _ O
3 -X- _ O
. -X- _ O
We -X- _ O
use -X- _ O
BART -X- _ B-MethodName
- -X- _ I-MethodName
large -X- _ I-MethodName
as -X- _ O
our -X- _ O
sequence -X- _ O
- -X- _ O
to -X- _ O
- -X- _ O
sequence -X- _ O
model -X- _ O
the -X- _ O
same -X- _ O
as -X- _ O
Bevilacqua -X- _ O
et -X- _ O
al -X- _ O
. -X- _ O
( -X- _ O
2021 -X- _ O
) -X- _ O
. -X- _ O
We -X- _ O
utilizes -X- _ O
RAdam -X- _ O
as -X- _ O
our -X- _ O
optimizer -X- _ O
with -X- _ O
the -X- _ O
learning -X- _ B-HyperparameterName
rate -X- _ I-HyperparameterName
3e-5 -X- _ B-HyperparameterValue
. -X- _ O
The -X- _ O
batch -X- _ B-HyperparameterName
size -X- _ I-HyperparameterName
is -X- _ O
2048 -X- _ B-HyperparameterValue
graph -X- _ O
linearization -X- _ O
tokens -X- _ O
with -X- _ O
the -X- _ O
gradient -X- _ B-HyperparameterName
accumulation -X- _ I-HyperparameterName
10 -X- _ B-HyperparameterValue
. -X- _ O
Dropout -X- _ B-HyperparameterName
is -X- _ O
set -X- _ O
to -X- _ O
0.25 -X- _ B-HyperparameterValue
and -X- _ O
beam -X- _ B-HyperparameterName
size -X- _ I-HyperparameterName
is -X- _ O
5 -X- _ B-HyperparameterValue
. -X- _ O
The -X- _ O
training -X- _ O
steps -X- _ O
T -X- _ B-HyperparameterName
sc -X- _ I-HyperparameterName
is -X- _ O
1000 -X- _ B-HyperparameterValue
and -X- _ O
T -X- _ B-HyperparameterName
ic -X- _ I-HyperparameterName
is -X- _ O
500 -X- _ B-HyperparameterValue
. -X- _ O
After -X- _ O
the -X- _ O
curriculum -X- _ O
training -X- _ O
, -X- _ O
the -X- _ O
model -X- _ O
is -X- _ O
trained -X- _ O
for -X- _ O
30 -X- _ B-HyperparameterValue
epochs -X- _ B-HyperparameterName
on -X- _ O
the -X- _ O
training -X- _ O
set -X- _ O
. -X- _ O
We -X- _ O
use -X- _ O
cross -X- _ B-MetricName
- -X- _ I-MetricName
entropy -X- _ I-MetricName
as -X- _ O
our -X- _ O
loss -X- _ O
function -X- _ O
. -X- _ O
We -X- _ O
train -X- _ O
our -X- _ O
model -X- _ O
on -X- _ O
a -X- _ O
single -X- _ O
NVIDIA -X- _ O
TESLA -X- _ O
V100 -X- _ O
GPU -X- _ O
with -X- _ O
32 -X- _ O
GB -X- _ O
memory -X- _ O
. -X- _ O
We -X- _ O
adopt -X- _ O
the -X- _ O
same -X- _ O
post -X- _ O
- -X- _ O
processing -X- _ O
process -X- _ O
as -X- _ O
Bevilacqua -X- _ O
et -X- _ O
al -X- _ O
. -X- _ O
( -X- _ O
2021 -X- _ O
) -X- _ O
. -X- _ O
Our -X- _ O
code -X- _ O
and -X- _ O
model -X- _ O
are -X- _ O
available -X- _ O
at -X- _ O
https -X- _ O
: -X- _ O
/ -X- _ O
/ -X- _ O
github.com -X- _ O
/ -X- _ O
Wangpeiyi9979 -X- _ O
/ -X- _ O
HCL -X- _ O
- -X- _ O
Text2AMR -X- _ O
. -X- _ O

We -X- _ O
compare -X- _ O
our -X- _ O
method -X- _ O
with -X- _ O
previous -X- _ O
approaches -X- _ O
in -X- _ O
ness -X- _ O
of -X- _ O
our -X- _ O
method -X- _ O
. -X- _ O
Although -X- _ O
Cai -X- _ O
and -X- _ O
Lam -X- _ O
( -X- _ O
2020 -X- _ O
) -X- _ O
outperforms -X- _ O
our -X- _ O
model -X- _ O
in -X- _ O
Neg -X- _ O
. -X- _ O
and -X- _ O
Wiki -X- _ O
. -X- _ O
on -X- _ O
AMR2.0 -X- _ B-DatasetName
, -X- _ I-DatasetName
they -X- _ O
adopt -X- _ O
a -X- _ O
complex -X- _ O
process -X- _ O
, -X- _ O
which -X- _ O
may -X- _ O
hurt -X- _ O
the -X- _ O
model -X- _ O
generalization -X- _ O
ability -X- _ O
. -X- _ O
Bevilacqua -X- _ O
et -X- _ O
al -X- _ O
. -X- _ O
( -X- _ O
2021 -X- _ O
) -X- _ O
outperforms -X- _ O
slightly -X- _ O
our -X- _ O
model -X- _ O
in -X- _ O
Conc -X- _ O
. -X- _ O
and -X- _ O
Wiki -X- _ O
. -X- _ O
on -X- _ O
AMR3.0 -X- _ B-DatasetName
. -X- _ O
However -X- _ O
, -X- _ O
these -X- _ O
metrics -X- _ O
are -X- _ O
unrelated -X- _ O
to -X- _ O
the -X- _ O
AMR -X- _ O
structure -X- _ O
that -X- _ O
our -X- _ O
HCL -X- _ O
focuses -X- _ O
on -X- _ O
. -X- _ O

As -X- _ O
shown -X- _ O
in -X- _ O
Table -X- _ O
1 -X- _ O
, -X- _ O
compared -X- _ O
with -X- _ O
Bevilacqua -X- _ O
et -X- _ O
al -X- _ O
. -X- _ O
( -X- _ O
2021 -X- _ O
) -X- _ O
( -X- _ O
also -X- _ O
a -X- _ O
sequence -X- _ O
- -X- _ O
to -X- _ O
- -X- _ O
sequence -X- _ O
model -X- _ O
based -X- _ O
on -X- _ O
BART -X- _ B-MethodName
- -X- _ I-MethodName
large -X- _ I-MethodName
) -X- _ O
, -X- _ O
our -X- _ O
method -X- _ O
achieves -X- _ O
2.97 -X- _ B-MetricValue
and -X- _ O
2.83 -X- _ B-MetricValue
average -X- _ O
F1 -X- _ B-MetricName
scores -X- _ O
improvement -X- _ O
on -X- _ O
3 -X- _ O
structure -X- _ O
- -X- _ O
dependent -X- _ O
metrics -X- _ O
on -X- _ O
AMR2.0 -X- _ B-DatasetName
and -X- _ O
AMR3.0 -X- _ B-DatasetName
, -X- _ O
respectively -X- _ O
, -X- _ O
which -X- _ O
proves -X- _ O
HCL -X- _ O
helps -X- _ O
the -X- _ O
flat -X- _ O
sequence -X- _ O
- -X- _ O
to -X- _ O
- -X- _ O
sequence -X- _ O
model -X- _ O
better -X- _ O
adapt -X- _ O
to -X- _ O
AMR -X- _ B-TaskName
with -X- _ O
the -X- _ O
hierarchical -X- _ O
and -X- _ O
complex -X- _ O
structure -X- _ O
. -X- _ O

To -X- _ O
illustrate -X- _ O
the -X- _ O
effect -X- _ O
of -X- _ O
our -X- _ O
proposed -X- _ O
curricula -X- _ O
. -X- _ O
We -X- _ O
conduct -X- _ O
ablation -X- _ O
studies -X- _ O
by -X- _ O
removing -X- _ O
one -X- _ O
curriculum -X- _ O
at -X- _ O
a -X- _ O
time -X- _ O
. -X- _ O
Table -X- _ O
2 -X- _ O
shows -X- _ O
the -X- _ O
SMATCH -X- _ B-MetricName
scores -X- _ I-MetricName
on -X- _ O
both -X- _ O
AMR2.0 -X- _ B-DatasetName
and -X- _ O
AMR3.0 -X- _ B-DatasetName
. -X- _ O

There -X- _ O
are -X- _ O
8 -X- _ O
fine -X- _ O
- -X- _ O
grained -X- _ O
AMR -X- _ O
metrics -X- _ O
: -X- _ O
( -X- _ O
1 -X- _ O
) -X- _ O
Unlabeled -X- _ B-MetricName
: -X- _ O
Smatch -X- _ O
score -X- _ O
computed -X- _ O
on -X- _ O
the -X- _ O
predicted -X- _ O
graphs -X- _ O
after -X- _ O
removing -X- _ O
all -X- _ O
edge -X- _ O
labels -X- _ O
. -X- _ O
( -X- _ O
2 -X- _ O
) -X- _ O
No -X- _ B-MetricName
WSD -X- _ I-MetricName
. -X- _ O
: -X- _ O
Smatch -X- _ O
score -X- _ O
while -X- _ O
ignoring -X- _ O
Propbank -X- _ O
senses -X- _ O
( -X- _ O
e.g. -X- _ O
, -X- _ O
duck-01 -X- _ O
vs -X- _ O
duck-02 -X- _ O
) -X- _ O
. -X- _ O
( -X- _ O
3 -X- _ O
) -X- _ O
Named -X- _ B-MetricName
Ent -X- _ I-MetricName
. -X- _ O
: -X- _ O
F -X- _ O
- -X- _ O
score -X- _ O
on -X- _ O
the -X- _ O
named -X- _ O
entity -X- _ O
recognition -X- _ O
( -X- _ O
: -X- _ O
name -X- _ O
roles -X- _ O
) -X- _ O
. -X- _ O
( -X- _ O
4 -X- _ O
) -X- _ O
Wikification -X- _ B-MetricName
: -X- _ O
F -X- _ O
- -X- _ O
score -X- _ O
on -X- _ O
the -X- _ O
wikification -X- _ O
( -X- _ O
: -X- _ O
wiki -X- _ O
roles -X- _ O
) -X- _ O
. -X- _ O
( -X- _ O
5 -X- _ O
) -X- _ O
Negation -X- _ B-MetricName
: -X- _ O
F -X- _ O
- -X- _ O
score -X- _ O
on -X- _ O
the -X- _ O
negation -X- _ O
detection -X- _ O
( -X- _ O
: -X- _ O
polarity -X- _ O
roles -X- _ O
) -X- _ O
. -X- _ O
( -X- _ O
6 -X- _ O
) -X- _ O
Concepts -X- _ B-MetricName
: -X- _ O
F -X- _ O
- -X- _ O
score -X- _ O
on -X- _ O
the -X- _ O
concept -X- _ O
identification -X- _ O
task -X- _ O
. -X- _ O
We -X- _ O
only -X- _ O
regard -X- _ O
Unlabeled -X- _ O
, -X- _ O
Reentrancy -X- _ O
and -X- _ O
SRL -X- _ O
as -X- _ O
" -X- _ O
structure -X- _ O
- -X- _ O
dependent -X- _ O
" -X- _ O
metrics -X- _ O
, -X- _ O
since -X- _ O
: -X- _ O
( -X- _ O
1 -X- _ O
) -X- _ O
Unlabeled -X- _ O
does -X- _ O
not -X- _ O
consider -X- _ O
any -X- _ O
edge -X- _ O
labels -X- _ O
, -X- _ O
and -X- _ O
only -X- _ O
considers -X- _ O
the -X- _ O
graph -X- _ O
structure -X- _ O
. -X- _ O
( -X- _ O
2 -X- _ O
) -X- _ O
Reentrancy -X- _ O
is -X- _ O
a -X- _ O
typical -X- _ O
structure -X- _ O
feature -X- _ O
for -X- _ O
the -X- _ O
AMR -X- _ O
graph -X- _ O
. -X- _ O
Without -X- _ O
reentrant -X- _ O
edges -X- _ O
, -X- _ O
the -X- _ O
AMR -X- _ O
graph -X- _ O
is -X- _ O
reduced -X- _ O
to -X- _ O
a -X- _ O
tree -X- _ O
. -X- _ O
( -X- _ O
3 -X- _ O
) -X- _ O
SRL -X- _ O
denotes -X- _ O
the -X- _ O
core -X- _ O
- -X- _ O
semantic -X- _ O
relation -X- _ O
of -X- _ O
the -X- _ O
AMR -X- _ O
, -X- _ O
which -X- _ O
determines -X- _ O
the -X- _ O
core -X- _ O
structure -X- _ O
of -X- _ O
the -X- _ O
AMR -X- _ O
. -X- _ O
( -X- _ O
4 -X- _ O
) -X- _ O
As -X- _ O
described -X- _ O
above -X- _ O
, -X- _ O
all -X- _ O
other -X- _ O
metrics -X- _ O
have -X- _ O
little -X- _ O
relationship -X- _ O
with -X- _ O
the -X- _ O
structure -X- _ O
. -X- _ O
For -X- _ O
the -X- _ O
input -X- _ O
sentence -X- _ O
, -X- _ O
our -X- _ O
method -X- _ O
achieves -X- _ O
the -X- _ O
right -X- _ O
AMR -X- _ O
, -X- _ O
while -X- _ O
the -X- _ O
baseline -X- _ O
model -X- _ O
( -X- _ O
i.e. -X- _ O
, -X- _ O
SPRING -X- _ O
( -X- _ O
Bevilacqua -X- _ O
et -X- _ O
al -X- _ O
. -X- _ O
, -X- _ O
2021 -X- _ O
) -X- _ O
) -X- _ O
gets -X- _ O
a -X- _ O
shallower -X- _ O
and -X- _ O
wrong -X- _ O
structure -X- _ O
AMR -X- _ O
. -X- _ O

Some -X- _ O
human -X- _ O
preferences -X- _ O
are -X- _ O
universal -X- _ O
. -X- _ O
The -X- _ O
odor -X- _ O
of -X- _ O
vanilla -X- _ O
is -X- _ O
perceived -X- _ O
as -X- _ O
pleasant -X- _ O
all -X- _ O
around -X- _ O
the -X- _ O
world -X- _ O
. -X- _ O
We -X- _ O
expect -X- _ O
neural -X- _ O
models -X- _ O
trained -X- _ O
on -X- _ O
human -X- _ O
texts -X- _ O
to -X- _ O
exhibit -X- _ O
these -X- _ O
kind -X- _ O
of -X- _ O
preferences -X- _ O
, -X- _ O
i.e. -X- _ O
biases -X- _ O
, -X- _ O
but -X- _ O
we -X- _ O
show -X- _ O
that -X- _ O
this -X- _ O
is -X- _ O
not -X- _ O
always -X- _ O
the -X- _ O
case -X- _ O
. -X- _ O
We -X- _ O
explore -X- _ O
16 -X- _ O
static -X- _ O
and -X- _ O
contextual -X- _ O
embedding -X- _ O
models -X- _ O
in -X- _ O
9 -X- _ O
languages -X- _ O
and -X- _ O
, -X- _ O
when -X- _ O
possible -X- _ O
, -X- _ O
compare -X- _ O
them -X- _ O
under -X- _ O
similar -X- _ O
training -X- _ O
conditions -X- _ O
. -X- _ O
We -X- _ O
introduce -X- _ O
and -X- _ O
release -X- _ O
CA -X- _ B-MethodName
- -X- _ I-MethodName
WEAT -X- _ I-MethodName
, -X- _ I-MethodName
multilingual -X- _ O
cultural -X- _ O
aware -X- _ O
tests -X- _ O
to -X- _ O
quantify -X- _ O
biases -X- _ O
, -X- _ O
and -X- _ O
compare -X- _ O
them -X- _ O
to -X- _ O
previous -X- _ O
English -X- _ O
- -X- _ O
centric -X- _ O
tests -X- _ O
. -X- _ O
Our -X- _ O
experiments -X- _ O
confirm -X- _ O
that -X- _ O
monolingual -X- _ O
static -X- _ O
embeddings -X- _ O
do -X- _ O
exhibit -X- _ O
human -X- _ O
biases -X- _ O
, -X- _ O
but -X- _ O
values -X- _ O
differ -X- _ O
across -X- _ O
languages -X- _ O
, -X- _ O
being -X- _ O
far -X- _ O
from -X- _ O
universal -X- _ O
. -X- _ O
Biases -X- _ O
are -X- _ O
less -X- _ O
evident -X- _ O
in -X- _ O
contextual -X- _ O
models -X- _ O
, -X- _ O
to -X- _ O
the -X- _ O
point -X- _ O
that -X- _ O
the -X- _ O
original -X- _ O
human -X- _ O
association -X- _ O
might -X- _ O
be -X- _ O
reversed -X- _ O
. -X- _ O
Multilinguality -X- _ O
proves -X- _ O
to -X- _ O
be -X- _ O
another -X- _ O
variable -X- _ O
that -X- _ O
attenuates -X- _ O
and -X- _ O
even -X- _ O
reverses -X- _ O
the -X- _ O
effect -X- _ O
of -X- _ O
the -X- _ O
bias -X- _ O
, -X- _ O
specially -X- _ O
in -X- _ O
contextual -X- _ O
multilingual -X- _ O
models -X- _ O
. -X- _ O
In -X- _ O
order -X- _ O
to -X- _ O
explain -X- _ O
this -X- _ O
variance -X- _ O
among -X- _ O
models -X- _ O
and -X- _ O
languages -X- _ O
, -X- _ O
we -X- _ O
examine -X- _ O
the -X- _ O
effect -X- _ O
of -X- _ O
asymmetries -X- _ O
in -X- _ O
the -X- _ O
training -X- _ O
corpus -X- _ O
, -X- _ O
departures -X- _ O
from -X- _ O
isomorphism -X- _ O
in -X- _ O
multilingual -X- _ O
embedding -X- _ O
spaces -X- _ O
and -X- _ O
discrepancies -X- _ O
in -X- _ O
the -X- _ O
testing -X- _ O
measures -X- _ O
between -X- _ O
languages -X- _ O
. -X- _ O

As -X- _ O
long -X- _ O
as -X- _ O
neural -X- _ O
systems -X- _ O
are -X- _ O
trained -X- _ O
on -X- _ O
generaldomain -X- _ O
texts -X- _ O
written -X- _ O
by -X- _ O
humans -X- _ O
, -X- _ O
one -X- _ O
would -X- _ O
expect -X- _ O
and -X- _ O
desire -X- _ O
human -X- _ O
biases -X- _ O
to -X- _ O
be -X- _ O
present -X- _ O
in -X- _ O
embedding -X- _ O
models -X- _ O
for -X- _ O
all -X- _ O
languages -X- _ O
. -X- _ O
One -X- _ O
would -X- _ O
also -X- _ O
expect -X- _ O
( -X- _ O
but -X- _ O
not -X- _ O
always -X- _ O
desire -X- _ O
) -X- _ O
cultural -X- _ O
biases -X- _ O
, -X- _ O
but -X- _ O
these -X- _ O
would -X- _ O
depend -X- _ O
on -X- _ O
the -X- _ O
language -X- _ O
or -X- _ O
the -X- _ O
culture -X- _ O
behind -X- _ O
it -X- _ O
. -X- _ O
Lots -X- _ O
of -X- _ O
work -X- _ O
has -X- _ O
been -X- _ O
done -X- _ O
on -X- _ O
detecting -X- _ O
social -X- _ O
cultural -X- _ O
biases -X- _ O
and -X- _ O
trying -X- _ O
to -X- _ O
mitigate -X- _ O
them -X- _ O
( -X- _ O
Bolukbasi -X- _ O
et -X- _ O
al -X- _ O
. -X- _ O
, -X- _ O
2016 -X- _ O
; -X- _ O
Zhao -X- _ O
et -X- _ O
al -X- _ O
. -X- _ O
, -X- _ O
2018 -X- _ O
; -X- _ O
Gonen -X- _ O
and -X- _ O
Goldberg -X- _ O
, -X- _ O
2019 -X- _ O
; -X- _ O
Ravfogel -X- _ O
et -X- _ O
al -X- _ O
. -X- _ O
, -X- _ O
2020 -X- _ O
; -X- _ O
Dev -X- _ O
et -X- _ O
al -X- _ O
. -X- _ O
, -X- _ O
2020 -X- _ O
; -X- _ O
Schick -X- _ O
et -X- _ O
al -X- _ O
. -X- _ O
, -X- _ O
2021 -X- _ O
; -X- _ O
Zhou -X- _ O
et -X- _ O
al -X- _ O
. -X- _ O
, -X- _ O
2022 -X- _ O
) -X- _ O
. -X- _ O
Also -X- _ O
recent -X- _ O
work -X- _ O
has -X- _ O
investigated -X- _ O
the -X- _ O
presence -X- _ O
of -X- _ O
human -X- _ O
biases -X- _ O
in -X- _ O
static -X- _ O
word -X- _ O
embeddings -X- _ O
; -X- _ O
first -X- _ O
in -X- _ O
English -X- _ O
( -X- _ O
Caliskan -X- _ O
et -X- _ O
al -X- _ O
. -X- _ O
, -X- _ O
2017 -X- _ O
) -X- _ O
and -X- _ O
later -X- _ O
in -X- _ O
other -X- _ O
languages -X- _ O
( -X- _ O
Lauscher -X- _ O
and -X- _ O
Glavaš -X- _ O
, -X- _ O
2019 -X- _ O
; -X- _ O
Lauscher -X- _ O
et -X- _ O
al -X- _ O
. -X- _ O
, -X- _ O
2020a -X- _ O
, -X- _ O
b -X- _ O
) -X- _ O
. -X- _ O
These -X- _ O
works -X- _ O
make -X- _ O
use -X- _ O
of -X- _ O
the -X- _ O
Word -X- _ B-MethodName
Embedding -X- _ I-MethodName
Association -X- _ I-MethodName
Test -X- _ I-MethodName
( -X- _ I-MethodName
WEAT -X- _ I-MethodName
) -X- _ I-MethodName
for -X- _ O
English -X- _ O
-lists -X- _ O
of -X- _ O
concepts -X- _ O
and -X- _ O
attributes -X- _ O
that -X- _ O
hide -X- _ O
implicit -X- _ O
human -X- _ O
associations -X- _ O
as -X- _ O
described -X- _ O
in -X- _ O
Section -X- _ O
2 -X- _ O
- -X- _ O
and -X- _ O
X -X- _ B-MethodName
- -X- _ I-MethodName
WEAT -X- _ I-MethodName
, -X- _ O
WEAT -X- _ O
's -X- _ O
translations -X- _ O
, -X- _ O
for -X- _ O
other -X- _ O
languages -X- _ O
. -X- _ O
To -X- _ O
the -X- _ O
best -X- _ O
of -X- _ O
our -X- _ O
knowledge -X- _ O
, -X- _ O
research -X- _ O
on -X- _ O
language -X- _ O
models -X- _ O
and -X- _ O
contextualised -X- _ O
embeddings -X- _ O
, -X- _ O
has -X- _ O
been -X- _ O
done -X- _ O
only -X- _ O
in -X- _ O
English -X- _ O
, -X- _ O
using -X- _ O
extensions -X- _ O
or -X- _ O
variations -X- _ O
of -X- _ O
WEAT -X- _ O
( -X- _ O
May -X- _ O
et -X- _ O
al -X- _ O
. -X- _ O
, -X- _ O
2019 -X- _ O
; -X- _ O
Kurita -X- _ O
et -X- _ O
al -X- _ O
. -X- _ O
, -X- _ O
2019 -X- _ O
; -X- _ O
Guo -X- _ O
and -X- _ O
Caliskan -X- _ O
, -X- _ O
2021 -X- _ O
) -X- _ O
. -X- _ O

We -X- _ O
go -X- _ O
deeper -X- _ O
into -X- _ O
the -X- _ O
understanding -X- _ O
of -X- _ O
multilingual -X- _ B-TaskName
embedding -X- _ I-TaskName
models -X- _ O
and -X- _ O
the -X- _ O
effect -X- _ O
, -X- _ O
if -X- _ O
any -X- _ O
, -X- _ O
of -X- _ O
the -X- _ O
different -X- _ O
approaches -X- _ O
used -X- _ O
to -X- _ O
build -X- _ O
them -X- _ O
. -X- _ O
For -X- _ O
this -X- _ O
purpose -X- _ O
, -X- _ O
we -X- _ O
first -X- _ O
review -X- _ O
results -X- _ O
and -X- _ O
some -X- _ O
of -X- _ O
the -X- _ O
implicit -X- _ O
assumptions -X- _ O
made -X- _ O
in -X- _ O
previous -X- _ O
works -X- _ O
by -X- _ O
investigating -X- _ O
( -X- _ O
i -X- _ O
) -X- _ O
whether -X- _ O
translations -X- _ O
from -X- _ O
the -X- _ O
original -X- _ O
WEAT -X- _ O
English -X- _ O
lists -X- _ O
( -X- _ O
X -X- _ O
- -X- _ O
WEAT -X- _ O
) -X- _ O
are -X- _ O
fair -X- _ O
tests -X- _ O
for -X- _ O
other -X- _ O
languages -X- _ O
and -X- _ O
( -X- _ O
ii -X- _ O
) -X- _ O
whether -X- _ O
a -X- _ O
single -X- _ O
list -X- _ O
, -X- _ O
either -X- _ O
original -X- _ O
or -X- _ O
translated -X- _ O
, -X- _ O
is -X- _ O
representative -X- _ O
for -X- _ O
a -X- _ O
language -X- _ O
. -X- _ O
Second -X- _ O
, -X- _ O
for -X- _ O
the -X- _ O
first -X- _ O
time -X- _ O
we -X- _ O
define -X- _ O
and -X- _ O
collect -X- _ O
cultural -X- _ B-MethodName
aware -X- _ I-MethodName
WEAT -X- _ I-MethodName
lists -X- _ I-MethodName
( -X- _ I-MethodName
CA -X- _ I-MethodName
- -X- _ I-MethodName
WEAT -X- _ I-MethodName
) -X- _ I-MethodName
to -X- _ O
enable -X- _ O
multilingual -X- _ O
analyses -X- _ O
completely -X- _ O
independent -X- _ O
of -X- _ O
English -X- _ O
. -X- _ O
Third -X- _ O
, -X- _ O
we -X- _ O
use -X- _ O
WEAT -X- _ B-MethodName
, -X- _ O
X -X- _ B-MethodName
- -X- _ I-MethodName
WEAT -X- _ I-MethodName
and -X- _ O
CA -X- _ B-MethodName
- -X- _ I-MethodName
WEAT -X- _ I-MethodName
to -X- _ O
study -X- _ O
the -X- _ O
effect -X- _ O
of -X- _ O
crossand -X- _ O
multilinguality -X- _ O
in -X- _ O
embedding -X- _ O
models -X- _ O
; -X- _ O
that -X- _ O
is -X- _ O
, -X- _ O
how -X- _ O
they -X- _ O
differ -X- _ O
with -X- _ O
respect -X- _ O
to -X- _ O
the -X- _ O
monolingual -X- _ O
English -X- _ O
. -X- _ O
Since -X- _ O
differences -X- _ O
do -X- _ O
exist -X- _ O
, -X- _ O
we -X- _ O
try -X- _ O
to -X- _ O
explain -X- _ O
them -X- _ O
in -X- _ O
terms -X- _ O
of -X- _ O
the -X- _ O
testing -X- _ O
measure -X- _ O
( -X- _ O
* -X- _ O
-WEAT -X- _ O
) -X- _ O
, -X- _ O
the -X- _ O
nature -X- _ O
of -X- _ O
the -X- _ O
training -X- _ O
corpora -X- _ O
, -X- _ O
the -X- _ O
method -X- _ O
to -X- _ O
achieve -X- _ O
multilinguality -X- _ O
and -X- _ O
the -X- _ O
final -X- _ O
differences -X- _ O
in -X- _ O
the -X- _ O
topology -X- _ O
of -X- _ O
the -X- _ O
embedding -X- _ O
spaces -X- _ O
between -X- _ O
languages -X- _ O
. -X- _ O
We -X- _ O
perform -X- _ O
a -X- _ O
systematic -X- _ O
study -X- _ O
over -X- _ O
9 -X- _ O
languages -X- _ O
of -X- _ O
3 -X- _ O
families -X- _ O
in -X- _ O
word -X- _ O
embeddings -X- _ O
from -X- _ O
16 -X- _ O
static -X- _ O
and -X- _ O
contextual -X- _ O
models -X- _ O
. -X- _ O
Our -X- _ O
premise -X- _ O
is -X- _ O
that -X- _ O
biases -X- _ O
should -X- _ O
be -X- _ O
equally -X- _ O
present -X- _ O
, -X- _ O
and -X- _ O
we -X- _ O
analyse -X- _ O
departures -X- _ O
from -X- _ O
this -X- _ O
premise -X- _ O
with -X- _ O
the -X- _ O
focus -X- _ O
on -X- _ O
multilinguality -X- _ O
. -X- _ O

The -X- _ O
Word -X- _ B-MethodName
Embedding -X- _ I-MethodName
Association -X- _ I-MethodName
Test -X- _ I-MethodName
( -X- _ I-MethodName
WEAT -X- _ I-MethodName
) -X- _ I-MethodName
( -X- _ O
Caliskan -X- _ O
et -X- _ O
al -X- _ O
. -X- _ O
, -X- _ O
2017 -X- _ O
) -X- _ O
is -X- _ O
a -X- _ O
bias -X- _ O
measurement -X- _ O
method -X- _ O
for -X- _ O
word -X- _ O
embeddings -X- _ O
. -X- _ O
WEAT -X- _ O
is -X- _ O
inspired -X- _ O
by -X- _ O
the -X- _ O
Implicit -X- _ O
Association -X- _ O
Test -X- _ O
( -X- _ O
IAT -X- _ O
) -X- _ O
for -X- _ O
humans -X- _ O
( -X- _ O
Greenwald -X- _ O
et -X- _ O
al -X- _ O
. -X- _ O
, -X- _ O
1998 -X- _ O
) -X- _ O
, -X- _ O
which -X- _ O
measures -X- _ O
differences -X- _ O
in -X- _ O
response -X- _ O
time -X- _ O
when -X- _ O
subjects -X- _ O
are -X- _ O
requested -X- _ O
to -X- _ O
pair -X- _ O
items -X- _ O
and -X- _ O
attributes -X- _ O
that -X- _ O
they -X- _ O
find -X- _ O
similar -X- _ O
and -X- _ O
when -X- _ O
pairing -X- _ O
items -X- _ O
and -X- _ O
attributes -X- _ O
that -X- _ O
they -X- _ O
find -X- _ O
different -X- _ O
. -X- _ O
To -X- _ O
give -X- _ O
an -X- _ O
example -X- _ O
, -X- _ O
subjects -X- _ O
would -X- _ O
be -X- _ O
first -X- _ O
asked -X- _ O
to -X- _ O
label -X- _ O
the -X- _ O
item -X- _ O
orchid -X- _ O
as -X- _ O
flower -X- _ O
- -X- _ O
pleasant -X- _ O
or -X- _ O
insect -X- _ O
- -X- _ O
unpleasant -X- _ O
. -X- _ O
This -X- _ O
would -X- _ O
be -X- _ O
repeated -X- _ O
for -X- _ O
several -X- _ O
flowers -X- _ O
and -X- _ O
insects -X- _ O
. -X- _ O
In -X- _ O
a -X- _ O
second -X- _ O
part -X- _ O
, -X- _ O
subjects -X- _ O
would -X- _ O
be -X- _ O
asked -X- _ O
to -X- _ O
label -X- _ O
the -X- _ O
same -X- _ O
list -X- _ O
of -X- _ O
items -X- _ O
as -X- _ O
insect -X- _ O
- -X- _ O
pleasant -X- _ O
or -X- _ O
flower -X- _ O
- -X- _ O
unpleasant -X- _ O
. -X- _ O
Experiments -X- _ O
show -X- _ O
that -X- _ O
the -X- _ O
response -X- _ O
time -X- _ O
for -X- _ O
the -X- _ O
first -X- _ O
part -X- _ O
is -X- _ O
lower -X- _ O
than -X- _ O
for -X- _ O
the -X- _ O
second -X- _ O
one -X- _ O
. -X- _ O
The -X- _ O
cognitive -X- _ O
effort -X- _ O
for -X- _ O
the -X- _ O
latter -X- _ O
is -X- _ O
higher -X- _ O
because -X- _ O
the -X- _ O
association -X- _ O
flower -X- _ O
- -X- _ O
unpleasant -X- _ O
is -X- _ O
less -X- _ O
expected -X- _ O
than -X- _ O
flower -X- _ O
- -X- _ O
pleasant -X- _ O
. -X- _ O
These -X- _ O
results -X- _ O
expose -X- _ O
a -X- _ O
human -X- _ O
bias -X- _ O
: -X- _ O
flowers -X- _ O
are -X- _ O
more -X- _ O
pleasant -X- _ O
than -X- _ O
insects -X- _ O
and -X- _ O
insects -X- _ O
are -X- _ O
more -X- _ O
unpleasant -X- _ O
than -X- _ O
flowers -X- _ O
. -X- _ O
If -X- _ O
this -X- _ O
is -X- _ O
a -X- _ O
universal -X- _ O
human -X- _ O
bias -X- _ O
, -X- _ O
one -X- _ O
would -X- _ O
expect -X- _ O
it -X- _ O
to -X- _ O
be -X- _ O
present -X- _ O
also -X- _ O
in -X- _ O
embeddings -X- _ O
created -X- _ O
from -X- _ O
human -X- _ O
texts -X- _ O
. -X- _ O
Flowers -X- _ O
in -X- _ O
a -X- _ O
semantic -X- _ O
space -X- _ O
should -X- _ O
be -X- _ O
closer -X- _ O
to -X- _ O
pleasant -X- _ O
attributes -X- _ O
than -X- _ O
insects -X- _ O
, -X- _ O
and -X- _ O
insects -X- _ O
closer -X- _ O
to -X- _ O
unpleasant -X- _ O
attributes -X- _ O
than -X- _ O
flowers -X- _ O
. -X- _ O

The -X- _ O
original -X- _ O
WEAT -X- _ O
measure -X- _ O
( -X- _ O
Caliskan -X- _ O
et -X- _ O
al -X- _ O
. -X- _ O
, -X- _ O
2017 -X- _ O
) -X- _ O
defines -X- _ O
the -X- _ O
association -X- _ O
of -X- _ O
each -X- _ O
term -X- _ O
t -X- _ O
( -X- _ O
e.g. -X- _ O
orchid -X- _ O
) -X- _ O
as -X- _ O
its -X- _ O
average -X- _ O
cosine -X- _ B-MetricName
similarity -X- _ I-MetricName
to -X- _ O
the -X- _ O
list -X- _ O
of -X- _ O
target -X- _ O
attributes -X- _ O
A -X- _ O
( -X- _ O
e.g. -X- _ O
pleasant -X- _ O
concepts -X- _ O
) -X- _ O
: -X- _ O

We -X- _ O
use -X- _ O
Cohen -X- _ B-MetricName
's -X- _ I-MetricName
d -X- _ I-MetricName
to -X- _ O
estimate -X- _ O
the -X- _ O
effect -X- _ O
size -X- _ O
( -X- _ O
i.e. -X- _ O
the -X- _ O
strength -X- _ O
of -X- _ O
the -X- _ O
bias -X- _ O
) -X- _ O
. -X- _ O
Cohen -X- _ B-MetricName
's -X- _ I-MetricName
d -X- _ I-MetricName
is -X- _ O
a -X- _ O
standardised -X- _ O
measure -X- _ O
of -X- _ O
the -X- _ O
effect -X- _ O
defined -X- _ O
as -X- _ O
the -X- _ O
difference -X- _ O
between -X- _ O
the -X- _ O
two -X- _ O
means -X- _ O
divided -X- _ O
by -X- _ O
the -X- _ O
standard -X- _ O
deviation -X- _ O
for -X- _ O
all -X- _ O
instances -X- _ O
in -X- _ O
X -X- _ O
and -X- _ O
Y -X- _ O
: -X- _ O

Multilingual -X- _ O
Aspects -X- _ O
and -X- _ O
CA -X- _ B-MethodName
- -X- _ I-MethodName
WEAT -X- _ I-MethodName

The -X- _ O
first -X- _ O
experiment -X- _ O
with -X- _ O
word -X- _ O
embeddings -X- _ O
was -X- _ O
done -X- _ O
by -X- _ O
Caliskan -X- _ O
et -X- _ O
al -X- _ O
. -X- _ O
( -X- _ O
2017 -X- _ O
) -X- _ O
who -X- _ O
used -X- _ O
pretrained -X- _ O
English -X- _ O
GloVe -X- _ O
embeddings -X- _ O
( -X- _ O
Pennington -X- _ O
et -X- _ O
al -X- _ O
. -X- _ O
, -X- _ O
2014 -X- _ O
) -X- _ O
. -X- _ O
They -X- _ O
observed -X- _ O
that -X- _ O
, -X- _ O
according -X- _ O
to -X- _ O
their -X- _ O
results -X- _ O
on -X- _ O
social -X- _ O
biases -X- _ O
, -X- _ O
the -X- _ O
training -X- _ O
corpus -X- _ O
" -X- _ O
may -X- _ O
be -X- _ O
disproportionately -X- _ O
American -X- _ O
" -X- _ O
. -X- _ O
Subsequent -X- _ O
studies -X- _ O
used -X- _ O
crosslingual -X- _ B-MethodName
WEAT -X- _ I-MethodName
( -X- _ I-MethodName
X -X- _ I-MethodName
- -X- _ I-MethodName
WEAT -X- _ I-MethodName
) -X- _ I-MethodName
to -X- _ O
go -X- _ O
beyond -X- _ O
analyses -X- _ O
in -X- _ O
English -X- _ O
( -X- _ O
Lauscher -X- _ O
and -X- _ O
Glavaš -X- _ O
, -X- _ O
2019 -X- _ O
; -X- _ O
Lauscher -X- _ O
et -X- _ O
al -X- _ O
. -X- _ O
, -X- _ O
2020a -X- _ O
) -X- _ O
. -X- _ O
The -X- _ O
original -X- _ O
lists -X- _ O
were -X- _ O
translated -X- _ O
into -X- _ O
several -X- _ O
languages -X- _ O
and -X- _ O
biases -X- _ O
estimated -X- _ O
using -X- _ O
the -X- _ O
translated -X- _ O
items -X- _ O
and -X- _ O
attributes -X- _ O
. -X- _ O
They -X- _ O
found -X- _ O
differences -X- _ O
in -X- _ O
the -X- _ O
biases -X- _ O
obtained -X- _ O
across -X- _ O
languages -X- _ O
and -X- _ O
connected -X- _ O
them -X- _ O
to -X- _ O
differences -X- _ O
in -X- _ O
the -X- _ O
size -X- _ O
of -X- _ O
the -X- _ O
training -X- _ O
corpora -X- _ O
. -X- _ O
They -X- _ O
also -X- _ O
explored -X- _ O
bilingual -X- _ O
spaces -X- _ O
and -X- _ O
observed -X- _ O
that -X- _ O
the -X- _ O
bias -X- _ O
effects -X- _ O
were -X- _ O
in -X- _ O
the -X- _ O
middle -X- _ O
of -X- _ O
the -X- _ O
two -X- _ O
corresponding -X- _ O
biases -X- _ O
in -X- _ O
the -X- _ O
monolingual -X- _ O
spaces -X- _ O
. -X- _ O

As -X- _ O
discussed -X- _ O
, -X- _ O
WEAT1 -X- _ B-MethodName
and -X- _ O
WEAT2 -X- _ B-MethodName
originate -X- _ O
in -X- _ O
the -X- _ O
US -X- _ O
. -X- _ O
Even -X- _ O
if -X- _ O
a -X- _ O
concept -X- _ O
( -X- _ O
flower -X- _ O
) -X- _ O
might -X- _ O
be -X- _ O
considered -X- _ O
pleasant -X- _ O
in -X- _ O
every -X- _ O
culture -X- _ O
, -X- _ O
the -X- _ O
items -X- _ O
themselves -X- _ O
( -X- _ O
orchid -X- _ O
, -X- _ O
broom -X- _ O
, -X- _ O
etc -X- _ O
. -X- _ O
) -X- _ O
can -X- _ O
be -X- _ O
different -X- _ O
across -X- _ O
cultures -X- _ O
. -X- _ O
This -X- _ O
is -X- _ O
most -X- _ O
evident -X- _ O
for -X- _ O
elements -X- _ O
that -X- _ O
depend -X- _ O
on -X- _ O
geography -X- _ O
( -X- _ O
a -X- _ O
flower -X- _ O
that -X- _ O
grows -X- _ O
in -X- _ O
the -X- _ O
US -X- _ O
or -X- _ O
an -X- _ O
insect -X- _ O
that -X- _ O
lives -X- _ O
there -X- _ O
might -X- _ O
not -X- _ O
be -X- _ O
present -X- _ O
in -X- _ O
other -X- _ O
locations -X- _ O
) -X- _ O
, -X- _ O
but -X- _ O
it -X- _ O
could -X- _ O
happen -X- _ O
for -X- _ O
all -X- _ O
the -X- _ O
other -X- _ O
items -X- _ O
in -X- _ O
WEAT1 -X- _ B-MethodName
and -X- _ O
WEAT2 -X- _ B-MethodName
. -X- _ O
As -X- _ O
a -X- _ O
result -X- _ O
, -X- _ O
the -X- _ O
representation -X- _ O
of -X- _ O
the -X- _ O
original -X- _ O
translated -X- _ O
items -X- _ O
in -X- _ O
the -X- _ O
training -X- _ O
data -X- _ O
in -X- _ O
other -X- _ O
languages -X- _ O
might -X- _ O
be -X- _ O
smaller -X- _ O
or -X- _ O
, -X- _ O
even -X- _ O
worse -X- _ O
, -X- _ O
the -X- _ O
distribution -X- _ O
of -X- _ O
the -X- _ O
opposite -X- _ O
attributes -X- _ O
asymmetric -X- _ O
. -X- _ O
As -X- _ O
we -X- _ O
will -X- _ O
show -X- _ O
, -X- _ O
there -X- _ O
is -X- _ O
already -X- _ O
a -X- _ O
variation -X- _ O
in -X- _ O
the -X- _ O
terms -X- _ O
and -X- _ O
attributes -X- _ O
used -X- _ O
by -X- _ O
different -X- _ O
people -X- _ O
within -X- _ O
a -X- _ O
common -X- _ O
culture -X- _ O
, -X- _ O
but -X- _ O
testing -X- _ O
the -X- _ O
existence -X- _ O
of -X- _ O
human -X- _ O
biases -X- _ O
with -X- _ O
translations -X- _ O
from -X- _ O
American -X- _ O
English -X- _ O
might -X- _ O
be -X- _ O
inducing -X- _ O
an -X- _ O
additional -X- _ O
cultural -X- _ O
bias -X- _ O
in -X- _ O
the -X- _ O
results -X- _ O
. -X- _ O
There -X- _ O
is -X- _ O
a -X- _ O
second -X- _ O
argument -X- _ O
to -X- _ O
avoid -X- _ O
X -X- _ B-MethodName
- -X- _ I-MethodName
WEAT -X- _ I-MethodName
: -X- _ O
translations -X- _ O
are -X- _ O
not -X- _ O
perfect -X- _ O
and -X- _ O
one -X- _ O
can -X- _ O
not -X- _ O
assure -X- _ O
that -X- _ O
the -X- _ O
requirements -X- _ O
in -X- _ O
Greenwald -X- _ O
et -X- _ O
al -X- _ O
. -X- _ O
( -X- _ O
1998 -X- _ O
) -X- _ O
( -X- _ O
unambiguous -X- _ O
and -X- _ O
frequent -X- _ O
words -X- _ O
) -X- _ O
hold -X- _ O
. -X- _ O
For -X- _ O
example -X- _ O
, -X- _ O
the -X- _ O
Spanish -X- _ O
X -X- _ B-MethodName
- -X- _ I-MethodName
WEAT -X- _ I-MethodName
translates -X- _ O
blade -X- _ O
as -X- _ O
hoja -X- _ O
( -X- _ O
the -X- _ O
edge -X- _ O
of -X- _ O
a -X- _ O
knife -X- _ O
, -X- _ O
but -X- _ O
also -X- _ O
a -X- _ O
sheet -X- _ O
of -X- _ O
paper -X- _ O
) -X- _ O
and -X- _ O
turns -X- _ O
both -X- _ O
fiddle -X- _ O
and -X- _ O
violin -X- _ O
into -X- _ O
violín -X- _ O
. -X- _ O
Whereas -X- _ O
correct -X- _ O
, -X- _ O
translation -X- _ O
introduces -X- _ O
an -X- _ O
ambiguous -X- _ O
word -X- _ O
lacking -X- _ O
any -X- _ O
association -X- _ O
to -X- _ O
( -X- _ O
un -X- _ O
) -X- _ O
pleasant -X- _ O
attributes -X- _ O
in -X- _ O
the -X- _ O
former -X- _ O
case -X- _ O
, -X- _ O
and -X- _ O
reduces -X- _ O
the -X- _ O
size -X- _ O
of -X- _ O
the -X- _ O
list -X- _ O
in -X- _ O
the -X- _ O
latter -X- _ O
. -X- _ O

To -X- _ O
mitigate -X- _ O
the -X- _ O
problems -X- _ O
introduced -X- _ O
by -X- _ O
translations -X- _ O
and -X- _ O
to -X- _ O
estimate -X- _ O
their -X- _ O
impact -X- _ O
in -X- _ O
the -X- _ O
analysis -X- _ O
, -X- _ O
we -X- _ O
create -X- _ O
CA -X- _ B-MethodName
- -X- _ I-MethodName
WEAT -X- _ I-MethodName
: -X- _ O
a -X- _ O
new -X- _ O
collection -X- _ O
of -X- _ O
culturalaware -X- _ O
lists -X- _ O
written -X- _ O
by -X- _ O
native -X- _ O
speakers -X- _ O
of -X- _ O
different -X- _ O
languages -X- _ O
. -X- _ O
We -X- _ O
asked -X- _ O
volunteers -X- _ O
to -X- _ O
create -X- _ O
lists -X- _ O
of -X- _ O
flowers -X- _ O
, -X- _ O
insects -X- _ O
, -X- _ O
weapons -X- _ O
and -X- _ O
musical -X- _ O
instruments -X- _ O
, -X- _ O
as -X- _ O
well -X- _ O
as -X- _ O
both -X- _ O
pleasant -X- _ O
and -X- _ O
unpleasant -X- _ O
concepts -X- _ O
with -X- _ O
25 -X- _ O
elements -X- _ O
each -X- _ O
without -X- _ O
any -X- _ O
time -X- _ O
constraint -X- _ O
. -X- _ O
The -X- _ O
only -X- _ O
requirement -X- _ O
was -X- _ O
that -X- _ O
words -X- _ O
needed -X- _ O
to -X- _ O
be -X- _ O
common -X- _ O
in -X- _ O
their -X- _ O
culture -X- _ O
. -X- _ O
Lists -X- _ O
from -X- _ O
different -X- _ O
volunteers -X- _ O
are -X- _ O
semantically -X- _ O
equivalent -X- _ O
, -X- _ O
since -X- _ O
they -X- _ O
characterise -X- _ O
the -X- _ O
same -X- _ O
concepts -X- _ O
, -X- _ O
and -X- _ O
can -X- _ O
be -X- _ O
seen -X- _ O
as -X- _ O
perturbations -X- _ O
on -X- _ O
a -X- _ O
prototypical -X- _ O
( -X- _ O
or -X- _ O
average -X- _ O
) -X- _ O
set -X- _ O
. -X- _ O

We -X- _ O
test -X- _ O
this -X- _ O
hypothesis -X- _ O
by -X- _ O
studying -X- _ O
the -X- _ O
correlation -X- _ O
between -X- _ O
the -X- _ O
bias -X- _ O
effect -X- _ O
size -X- _ O
and -X- _ O
the -X- _ O
difference -X- _ O
between -X- _ O
the -X- _ O
counts -X- _ O
of -X- _ O
the -X- _ O
positive -X- _ O
( -X- _ O
pleasant -X- _ O
) -X- _ O
and -X- _ O
the -X- _ O
negative -X- _ O
( -X- _ O
unpleasant -X- _ O
) -X- _ O
attributes -X- _ O
. -X- _ O
11 -X- _ O
Figure -X- _ O
3 -X- _ O
shows -X- _ O
the -X- _ O
relation -X- _ O
for -X- _ O
the -X- _ O
monolingual -X- _ O
CCe -X- _ O
embedding -X- _ O
models -X- _ O
. -X- _ O
The -X- _ O
correlation -X- _ O
seems -X- _ O
important -X- _ O
for -X- _ O
X -X- _ O
- -X- _ O
WEAT1 -X- _ O
( -X- _ O
top -X- _ O
plot -X- _ O
) -X- _ O
, -X- _ O
which -X- _ O
shows -X- _ O
a -X- _ O
positive -X- _ O
trend -X- _ O
with -X- _ O
half -X- _ O
of -X- _ O
the -X- _ O
variation -X- _ O
in -X- _ O
the -X- _ O
effect -X- _ O
size -X- _ O
being -X- _ O
explained -X- _ O
by -X- _ O
the -X- _ O
number -X- _ O
of -X- _ O
counts -X- _ O
R -X- _ B-MetricName
2 -X- _ I-MetricName
= -X- _ O
0.493 -X- _ B-MetricValue
. -X- _ O
However -X- _ O
, -X- _ O
this -X- _ O
might -X- _ O
be -X- _ O
an -X- _ O
effect -X- _ O
of -X- _ O
either -X- _ O
having -X- _ O
only -X- _ O
9 -X- _ O
data -X- _ O
points -X- _ O
or -X- _ O
X -X- _ O
- -X- _ O
WEAT -X- _ O
and -X- _ O
CA -X- _ O
- -X- _ O
WEAT -X- _ O
coming -X- _ O
from -X- _ O
two -X- _ O
different -X- _ O
distributions -X- _ O
. -X- _ O
When -X- _ O
we -X- _ O
consider -X- _ O
the -X- _ O
82 -X- _ O
CA -X- _ O
- -X- _ O
WEAT1 -X- _ O
tests -X- _ O
and -X- _ O
the -X- _ O
9 -X- _ O
X -X- _ O
- -X- _ O
WEAT1 -X- _ O
( -X- _ O
bottom -X- _ O
plot -X- _ O
) -X- _ O
, -X- _ O
we -X- _ O
observe -X- _ O
a -X- _ O
flat -X- _ O
slope -X- _ O
11 -X- _ O
The -X- _ O
asymmetry -X- _ O
could -X- _ O
also -X- _ O
come -X- _ O
with -X- _ O
the -X- _ O
target -X- _ O
items -X- _ O
, -X- _ O
but -X- _ O
attributes -X- _ O
are -X- _ O
an -X- _ O
order -X- _ O
of -X- _ O
magnitude -X- _ O
more -X- _ O
abundant -X- _ O
and -X- _ O
differences -X- _ O
more -X- _ O
significant -X- _ O
( -X- _ O
see -X- _ O
counts -X- _ O
in -X- _ O
Appendix -X- _ O
D -X- _ O
) -X- _ O
. -X- _ O

where -X- _ O
the -X- _ O
variance -X- _ B-MetricName
is -X- _ O
not -X- _ O
explained -X- _ O
by -X- _ O
the -X- _ O
counts -X- _ O
( -X- _ O
R -X- _ B-MetricName
2 -X- _ I-MetricName
= -X- _ O
0.001 -X- _ B-MetricValue
) -X- _ O
. -X- _ O
Results -X- _ O
for -X- _ O
X- -X- _ O
/ -X- _ O
CA -X- _ O
- -X- _ O
WEAT2 -X- _ O
are -X- _ O
equivalent -X- _ O
, -X- _ O
with -X- _ O
R -X- _ B-MetricName
2 -X- _ I-MetricName
= -X- _ O
0.334 -X- _ B-MetricValue
and -X- _ O
R -X- _ B-MetricName
2 -X- _ I-MetricName
= -X- _ O
0.008 -X- _ B-MetricValue
respectively -X- _ O
. -X- _ O
CA -X- _ O
- -X- _ O
WEAT -X- _ O
lists -X- _ O
allow -X- _ O
to -X- _ O
see -X- _ O
that -X- _ O
the -X- _ O
lack -X- _ O
of -X- _ O
trend -X- _ O
is -X- _ O
language -X- _ O
independent -X- _ O
. -X- _ O
The -X- _ O
average -X- _ O
effect -X- _ O
size -X- _ O
for -X- _ O
Spanish -X- _ O
is -X- _ O
higher -X- _ O
than -X- _ O
for -X- _ O
German -X- _ O
, -X- _ O
the -X- _ O
count -X- _ O
difference -X- _ O
is -X- _ O
larger -X- _ O
for -X- _ O
English -X- _ O
than -X- _ O
for -X- _ O
Croatian -X- _ O
, -X- _ O
but -X- _ O
in -X- _ O
none -X- _ O
of -X- _ O
the -X- _ O
cases -X- _ O
can -X- _ O
the -X- _ O
asymmetry -X- _ O
counts -X- _ O
explain -X- _ O
the -X- _ O
effect -X- _ O
size -X- _ O
variance -X- _ O
. -X- _ O

Figure -X- _ O
5 -X- _ O
: -X- _ O
The -X- _ O
CA -X- _ O
- -X- _ O
WEAT -X- _ O
lists -X- _ O
were -X- _ O
obtained -X- _ O
thorough -X- _ O
an -X- _ O
online -X- _ B-DatasetName
form -X- _ I-DatasetName
. -X- _ O
In -X- _ O
the -X- _ O
first -X- _ O
section -X- _ O
, -X- _ O
the -X- _ O
interface -X- _ O
presents -X- _ O
the -X- _ O
guidelines -X- _ O
for -X- _ O
the -X- _ O
task -X- _ O
. -X- _ O
The -X- _ O
second -X- _ O
part -X- _ O
collects -X- _ O
a -X- _ O
minimal -X- _ O
amount -X- _ O
of -X- _ O
personal -X- _ O
information -X- _ O
such -X- _ O
as -X- _ O
birth -X- _ O
place -X- _ O
and -X- _ O
native -X- _ O
language -X- _ O
. -X- _ O
Finally -X- _ O
, -X- _ O
the -X- _ O
third -X- _ O
part -X- _ O
collects -X- _ O
the -X- _ O
list -X- _ O
of -X- _ O
words -X- _ O
per -X- _ O
concept -X- _ O
. -X- _ O
The -X- _ O
form -X- _ O
was -X- _ O
created -X- _ O
in -X- _ O
English -X- _ O
, -X- _ O
Spanish -X- _ O
, -X- _ O
Catalan -X- _ O
, -X- _ O
French -X- _ O
, -X- _ O
Italian -X- _ O
and -X- _ O
German -X- _ O
for -X- _ O
a -X- _ O
greater -X- _ O
reach -X- _ O
. -X- _ O
WEAT -X- _ O
1 -X- _ O
: -X- _ O
Flowers -X- _ O
and -X- _ O
insects -X- _ O

Improving -X- _ O
Factual -X- _ O
Consistency -X- _ O
in -X- _ O
Summarization -X- _ B-TaskName
with -X- _ O
Compression -X- _ B-MethodName
- -X- _ I-MethodName
Based -X- _ I-MethodName
Post -X- _ I-MethodName
- -X- _ I-MethodName
Editing -X- _ I-MethodName

State -X- _ O
- -X- _ O
of -X- _ O
- -X- _ O
the -X- _ O
- -X- _ O
art -X- _ O
summarization -X- _ B-TaskName
models -X- _ O
still -X- _ O
struggle -X- _ O
to -X- _ O
be -X- _ O
factually -X- _ O
consistent -X- _ O
with -X- _ O
the -X- _ O
input -X- _ O
text -X- _ O
. -X- _ O
A -X- _ O
model -X- _ O
- -X- _ O
agnostic -X- _ O
way -X- _ O
to -X- _ O
address -X- _ O
this -X- _ O
problem -X- _ O
is -X- _ O
post -X- _ O
- -X- _ O
editing -X- _ O
the -X- _ O
generated -X- _ O
summaries -X- _ O
. -X- _ O
However -X- _ O
, -X- _ O
existing -X- _ O
approaches -X- _ O
typically -X- _ O
fail -X- _ O
to -X- _ O
remove -X- _ O
entity -X- _ O
errors -X- _ O
if -X- _ O
a -X- _ O
suitable -X- _ O
input -X- _ O
entity -X- _ O
replacement -X- _ O
is -X- _ O
not -X- _ O
available -X- _ O
or -X- _ O
may -X- _ O
insert -X- _ O
erroneous -X- _ O
content -X- _ O
. -X- _ O
In -X- _ O
our -X- _ O
work -X- _ O
, -X- _ O
we -X- _ O
focus -X- _ O
on -X- _ O
removing -X- _ O
extrinsic -X- _ O
entity -X- _ O
errors -X- _ O
, -X- _ O
or -X- _ O
entities -X- _ O
not -X- _ O
in -X- _ O
the -X- _ O
source -X- _ O
, -X- _ O
to -X- _ O
improve -X- _ O
consistency -X- _ O
while -X- _ O
retaining -X- _ O
the -X- _ O
summary -X- _ O
's -X- _ O
essential -X- _ O
information -X- _ O
and -X- _ O
form -X- _ O
. -X- _ O
We -X- _ O
propose -X- _ O
to -X- _ O
use -X- _ O
sentence -X- _ B-DatasetName
- -X- _ I-DatasetName
compression -X- _ I-DatasetName
data -X- _ I-DatasetName
to -X- _ O
train -X- _ O
the -X- _ O
post -X- _ B-MethodName
- -X- _ I-MethodName
editing -X- _ I-MethodName
model -X- _ O
to -X- _ O
take -X- _ O
a -X- _ O
summary -X- _ O
with -X- _ O
extrinsic -X- _ O
entity -X- _ O
errors -X- _ O
marked -X- _ O
with -X- _ O
special -X- _ O
tokens -X- _ O
and -X- _ O
output -X- _ O
a -X- _ O
compressed -X- _ O
, -X- _ O
well -X- _ O
- -X- _ O
formed -X- _ O
summary -X- _ O
with -X- _ O
those -X- _ O
errors -X- _ O
removed -X- _ O
. -X- _ O
We -X- _ O
show -X- _ O
that -X- _ O
this -X- _ O
model -X- _ O
improves -X- _ O
factual -X- _ O
consistency -X- _ O
while -X- _ O
maintaining -X- _ O
ROUGE -X- _ O
, -X- _ O
improving -X- _ O
entity -X- _ B-MetricName
precision -X- _ I-MetricName
by -X- _ O
up -X- _ O
to -X- _ O
30 -X- _ B-MetricValue
% -X- _ I-MetricValue
on -X- _ O
XSum -X- _ O
, -X- _ O
and -X- _ O
that -X- _ O
this -X- _ O
model -X- _ O
can -X- _ O
be -X- _ O
applied -X- _ O
on -X- _ O
top -X- _ O
of -X- _ O
another -X- _ O
post -X- _ O
- -X- _ O
editor -X- _ O
, -X- _ O
improving -X- _ O
entity -X- _ B-MetricName
precision -X- _ I-MetricName
by -X- _ O
up -X- _ O
to -X- _ O
a -X- _ O
total -X- _ O
of -X- _ O
38 -X- _ B-MetricValue
% -X- _ I-MetricValue
. -X- _ O
We -X- _ O
perform -X- _ O
an -X- _ O
extensive -X- _ O
comparison -X- _ O
of -X- _ O
post -X- _ O
- -X- _ O
editing -X- _ O
approaches -X- _ O
that -X- _ O
demonstrate -X- _ O
trade -X- _ O
- -X- _ O
offs -X- _ O
between -X- _ O
factual -X- _ O
consistency -X- _ O
, -X- _ O
informativeness -X- _ O
, -X- _ O
and -X- _ O
grammaticality -X- _ O
, -X- _ O
and -X- _ O
we -X- _ O
analyze -X- _ O
settings -X- _ O
where -X- _ O
posteditors -X- _ O
show -X- _ O
the -X- _ O
largest -X- _ O
improvements -X- _ O
. -X- _ O

Text -X- _ B-TaskName
summarization -X- _ I-TaskName
aims -X- _ O
to -X- _ O
compress -X- _ O
a -X- _ O
long -X- _ O
document -X- _ O
( -X- _ O
s -X- _ O
) -X- _ O
into -X- _ O
a -X- _ O
short -X- _ O
and -X- _ O
fluent -X- _ O
form -X- _ O
that -X- _ O
preserves -X- _ O
salient -X- _ O
information -X- _ O
. -X- _ O
State -X- _ O
- -X- _ O
of -X- _ O
- -X- _ O
the -X- _ O
- -X- _ O
art -X- _ O
models -X- _ O
, -X- _ O
however -X- _ O
, -X- _ O
are -X- _ O
often -X- _ O
not -X- _ O
factually -X- _ O
consistent -X- _ O
with -X- _ O
the -X- _ O
input -X- _ O
they -X- _ O
are -X- _ O
conditioned -X- _ O
on -X- _ O
( -X- _ O
Maynez -X- _ O
et -X- _ O
al -X- _ O
. -X- _ O
, -X- _ O
2020 -X- _ O
; -X- _ O
Fabbri -X- _ O
et -X- _ O
al -X- _ O
. -X- _ O
, -X- _ O
2022 -X- _ O
) -X- _ O
. -X- _ O
While -X- _ O
recent -X- _ O
modeling -X- _ O
techniques -X- _ O
have -X- _ O
been -X- _ O
proposed -X- _ O
to -X- _ O
improve -X- _ O
factual -X- _ O
consistency -X- _ O
( -X- _ O
Nan -X- _ O
et -X- _ O
al -X- _ O
. -X- _ O
, -X- _ O
2021 -X- _ O
; -X- _ O
Kang -X- _ O
and -X- _ O
Hashimoto -X- _ O
, -X- _ O
2020 -X- _ O
; -X- _ O
Aralikatte -X- _ O
et -X- _ O
al -X- _ O
. -X- _ O
, -X- _ O
2021 -X- _ O
) -X- _ O
, -X- _ O
a -X- _ O
model -X- _ O
- -X- _ O
agnostic -X- _ O
approach -X- _ O
is -X- _ O
to -X- _ O
post -X- _ O
- -X- _ O
edit -X- _ O
the -X- _ O
summaries -X- _ O
. -X- _ O

Our -X- _ O
contributions -X- _ O
are -X- _ O
the -X- _ O
following -X- _ O
: -X- _ O
1 -X- _ O
) -X- _ O
We -X- _ O
propose -X- _ O
a -X- _ O
compression -X- _ B-MethodName
- -X- _ I-MethodName
based -X- _ I-MethodName
method -X- _ I-MethodName
for -X- _ O
summary -X- _ O
post -X- _ B-MethodName
- -X- _ I-MethodName
editing -X- _ I-MethodName
that -X- _ O
removes -X- _ O
extrinsic -X- _ O
entity -X- _ O
errors -X- _ O
, -X- _ O
improving -X- _ O
entity -X- _ O
precision -X- _ O
with -X- _ O
respect -X- _ O
to -X- _ O
the -X- _ O
input -X- _ O
by -X- _ O
up -X- _ O
to -X- _ O
25 -X- _ O
% -X- _ O
along -X- _ O
with -X- _ O
improvements -X- _ O
in -X- _ O
other -X- _ O
factual -X- _ O
consistency -X- _ O
metrics -X- _ O
while -X- _ O
retaining -X- _ O
informativeness -X- _ O
according -X- _ O
to -X- _ O
automatic -X- _ O
analysis -X- _ O
. -X- _ O
2 -X- _ O
) -X- _ O
We -X- _ O
show -X- _ O
that -X- _ O
this -X- _ O
method -X- _ O
can -X- _ O
be -X- _ O
applied -X- _ O
on -X- _ O
top -X- _ O
of -X- _ O
a -X- _ O
rewriting -X- _ O
- -X- _ O
based -X- _ O
post -X- _ O
- -X- _ O
editor -X- _ O
, -X- _ O
improving -X- _ O
entity -X- _ B-MetricName
precision -X- _ I-MetricName
by -X- _ O
up -X- _ O
to -X- _ O
38 -X- _ B-MetricValue
% -X- _ I-MetricValue
overall -X- _ O
with -X- _ O
a -X- _ O
small -X- _ O
decrease -X- _ O
in -X- _ O
ROUGE -X- _ B-MetricName
score -X- _ I-MetricName
. -X- _ O
3 -X- _ O
) -X- _ O
We -X- _ O
perform -X- _ O
an -X- _ O
extensive -X- _ O
comparison -X- _ O
of -X- _ O
prior -X- _ O
post -X- _ O
- -X- _ O
editing -X- _ O
methods -X- _ O
across -X- _ O
two -X- _ O
datasets -X- _ O
and -X- _ O
six -X- _ O
summarization -X- _ O
models -X- _ O
to -X- _ O
better -X- _ O
understand -X- _ O
the -X- _ O
trade -X- _ O
- -X- _ O
offs -X- _ O
between -X- _ O
factual -X- _ O
consistency -X- _ O
, -X- _ O
informativeness -X- _ O
, -X- _ O
and -X- _ O
grammaticality -X- _ O
. -X- _ O
Models -X- _ O
are -X- _ O
made -X- _ O
publicly -X- _ O
available -X- _ O
: -X- _ O
https -X- _ O
: -X- _ O
/ -X- _ O
/ -X- _ O
github.com -X- _ O
/ -X- _ O
salesforce -X- _ O
/ -X- _ O
CompEdit -X- _ O
. -X- _ O

SpanFact -X- _ B-MethodName
We -X- _ O
implement -X- _ O
a -X- _ O
variation -X- _ O
of -X- _ O
the -X- _ O
autoregressive -X- _ O
model -X- _ O
from -X- _ O
. -X- _ O
We -X- _ O
train -X- _ O
a -X- _ O
BART -X- _ O
- -X- _ O
large -X- _ O
( -X- _ O
Lewis -X- _ O
et -X- _ O
al -X- _ O
. -X- _ O
, -X- _ O
2020 -X- _ O
) -X- _ O
model -X- _ O
to -X- _ O
take -X- _ O
the -X- _ O
source -X- _ O
document -X- _ O
and -X- _ O
the -X- _ O
summary -X- _ O
with -X- _ O
entity -X- _ O
slots -X- _ O
masked -X- _ O
and -X- _ O
fill -X- _ O
in -X- _ O
the -X- _ O
masked -X- _ O
slots -X- _ O
. -X- _ O
We -X- _ O
also -X- _ O
train -X- _ O
the -X- _ O
model -X- _ O
on -X- _ O
the -X- _ O
data -X- _ O
subset -X- _ O
whose -X- _ O
summaries -X- _ O
contain -X- _ O
only -X- _ O
named -X- _ O
entities -X- _ O
found -X- _ O
in -X- _ O
the -X- _ O
input -X- _ O
, -X- _ O
which -X- _ O
we -X- _ O
call -X- _ O
SpanFact -X- _ B-MethodName
- -X- _ I-MethodName
c. -X- _ I-MethodName
CCGS -X- _ B-MethodName
We -X- _ O
apply -X- _ O
the -X- _ O
model -X- _ O
from -X- _ O
Chen -X- _ O
et -X- _ O
al -X- _ O
. -X- _ O
( -X- _ O
2021 -X- _ O
) -X- _ O
that -X- _ O
generates -X- _ O
candidate -X- _ O
summaries -X- _ O
by -X- _ O
enumerating -X- _ O
all -X- _ O
ways -X- _ O
to -X- _ O
replace -X- _ O
summary -X- _ O
entities -X- _ O
with -X- _ O
similartyped -X- _ O
input -X- _ O
entities -X- _ O
and -X- _ O
training -X- _ O
BART -X- _ O
with -X- _ O
a -X- _ O
clas -X- _ O
- -X- _ O
sification -X- _ O
layer -X- _ O
to -X- _ O
re -X- _ O
- -X- _ O
rank -X- _ O
these -X- _ O
summaries -X- _ O
. -X- _ O
ReDRESS -X- _ B-MethodName
We -X- _ O
apply -X- _ O
the -X- _ O
approach -X- _ O
from -X- _ O
Adams -X- _ O
et -X- _ O
al -X- _ O
. -X- _ O
( -X- _ O
2022 -X- _ O
) -X- _ O
for -X- _ O
revising -X- _ O
clinical -X- _ O
reference -X- _ O
summaries -X- _ O
to -X- _ O
news -X- _ O
summarization -X- _ O
. -X- _ O
The -X- _ O
approach -X- _ O
consists -X- _ O
of -X- _ O
two -X- _ O
stages -X- _ O
: -X- _ O
1 -X- _ O
) -X- _ O
a -X- _ O
perturber -X- _ O
learns -X- _ O
to -X- _ O
corrupt -X- _ O
a -X- _ O
summary -X- _ O
by -X- _ O
using -X- _ O
entity -X- _ O
swaps -X- _ O
between -X- _ O
the -X- _ O
input -X- _ O
and -X- _ O
a -X- _ O
retrieved -X- _ O
set -X- _ O
of -X- _ O
entities -X- _ O
, -X- _ O
span -X- _ O
deletion -X- _ O
, -X- _ O
and -X- _ O
shuffling -X- _ O
as -X- _ O
training -X- _ O
data -X- _ O
. -X- _ O
2 -X- _ O
) -X- _ O
The -X- _ O
perturber -X- _ O
is -X- _ O
then -X- _ O
applied -X- _ O
to -X- _ O
the -X- _ O
reference -X- _ O
summaries -X- _ O
to -X- _ O
create -X- _ O
training -X- _ O
samples -X- _ O
for -X- _ O
a -X- _ O
reviser -X- _ O
that -X- _ O
learns -X- _ O
to -X- _ O
remove -X- _ O
errors -X- _ O
through -X- _ O
contrastive -X- _ O
learning -X- _ O
. -X- _ O
In -X- _ O
contrast -X- _ O
, -X- _ O
our -X- _ O
approach -X- _ O
focuses -X- _ O
on -X- _ O
more -X- _ O
controlled -X- _ O
perturbations -X- _ O
and -X- _ O
revisions -X- _ O
to -X- _ O
remove -X- _ O
and -X- _ O
compress -X- _ O
rather -X- _ O
than -X- _ O
rewrite -X- _ O
, -X- _ O
which -X- _ O
may -X- _ O
insert -X- _ O
errors -X- _ O
. -X- _ O
FactPegasus -X- _ B-MethodName
We -X- _ O
apply -X- _ O
the -X- _ O
deletion -X- _ O
- -X- _ O
based -X- _ O
corrector -X- _ O
component -X- _ O
of -X- _ O
Wan -X- _ O
and -X- _ O
Bansal -X- _ O
( -X- _ O
2022 -X- _ O
) -X- _ O
. -X- _ O
This -X- _ O
method -X- _ O
removes -X- _ O
extrinsic -X- _ O
entity -X- _ O
error -X- _ O
tokens -X- _ O
and -X- _ O
surrounding -X- _ O
words -X- _ O
based -X- _ O
on -X- _ O
manually -X- _ O
- -X- _ O
defined -X- _ O
rules -X- _ O
over -X- _ O
the -X- _ O
dependency -X- _ O
parse -X- _ O
of -X- _ O
the -X- _ O
summary -X- _ O
, -X- _ O
which -X- _ O
may -X- _ O
introduce -X- _ O
grammatical -X- _ O
errors -X- _ O
. -X- _ O

We -X- _ O
train -X- _ O
a -X- _ O
post -X- _ O
- -X- _ O
editor -X- _ O
in -X- _ O
two -X- _ O
steps -X- _ O
on -X- _ O
sentence -X- _ O
compression -X- _ O
data -X- _ O
from -X- _ O
Filippova -X- _ O
and -X- _ O
Altun -X- _ O
( -X- _ O
2013 -X- _ O
) -X- _ O
, -X- _ O
where -X- _ O
the -X- _ O
uncompressed -X- _ O
sentence -X- _ O
can -X- _ O
be -X- _ O
viewed -X- _ O
as -X- _ O
the -X- _ O
summary -X- _ O
containing -X- _ O
information -X- _ O
not -X- _ O
present -X- _ O
in -X- _ O
the -X- _ O
compressed -X- _ O
version -X- _ O
. -X- _ O
Example -X- _ O
input -X- _ O
and -X- _ O
output -X- _ O
for -X- _ O
these -X- _ O
two -X- _ O
steps -X- _ O
are -X- _ O
shown -X- _ O
in -X- _ O
Figure -X- _ O
1 -X- _ O
. -X- _ O
We -X- _ O
first -X- _ O
train -X- _ O
a -X- _ O
BART -X- _ B-MethodName
- -X- _ I-MethodName
large -X- _ I-MethodName
perturber -X- _ O
model -X- _ O
conditioned -X- _ O
upon -X- _ O
a -X- _ O
compressed -X- _ O
sentence -X- _ O
and -X- _ O
entities -X- _ O
present -X- _ O
in -X- _ O
the -X- _ O
longer -X- _ O
sentence -X- _ O
but -X- _ O
not -X- _ O
present -X- _ O
in -X- _ O
the -X- _ O
compressed -X- _ O
one -X- _ O
to -X- _ O
produce -X- _ O
a -X- _ O
longer -X- _ O
sentence -X- _ O
. -X- _ O
In -X- _ O
other -X- _ O
words -X- _ O
, -X- _ O
we -X- _ O
maximize -X- _ O
the -X- _ O
following -X- _ O
probability -X- _ O
: -X- _ O
P -X- _ O
( -X- _ O
Uncompressed -X- _ O
| -X- _ O
Compressed -X- _ O
, -X- _ O
Ents -X- _ O
) -X- _ O
. -X- _ O
Then -X- _ O
, -X- _ O
for -X- _ O
a -X- _ O
given -X- _ O
data -X- _ O
point -X- _ O
in -X- _ O
the -X- _ O
summarization -X- _ O
dataset -X- _ O
, -X- _ O
we -X- _ O
select -X- _ O
each -X- _ O
of -X- _ O
one -X- _ O
, -X- _ O
two -X- _ O
, -X- _ O
and -X- _ O
three -X- _ O
entities -X- _ O
from -X- _ O
the -X- _ O
source -X- _ O
not -X- _ O
present -X- _ O
in -X- _ O
the -X- _ O
reference -X- _ O
and -X- _ O
condition -X- _ O
upon -X- _ O
those -X- _ O
entities -X- _ O
and -X- _ O
the -X- _ O
reference -X- _ O
summary -X- _ O
to -X- _ O
produce -X- _ O
a -X- _ O
longer -X- _ O
, -X- _ O
perturbed -X- _ O
version -X- _ O
containing -X- _ O
those -X- _ O
entities -X- _ O
. -X- _ O
Varying -X- _ O
the -X- _ O
number -X- _ O
of -X- _ O
en- -X- _ O
tities -X- _ O
inserted -X- _ O
mirrors -X- _ O
differing -X- _ O
levels -X- _ O
of -X- _ O
editing -X- _ O
required -X- _ O
. -X- _ O
Note -X- _ O
that -X- _ O
while -X- _ O
the -X- _ O
entities -X- _ O
inserted -X- _ O
are -X- _ O
not -X- _ O
extrinsic -X- _ O
errors -X- _ O
since -X- _ O
they -X- _ O
appear -X- _ O
in -X- _ O
the -X- _ O
source -X- _ O
, -X- _ O
they -X- _ O
are -X- _ O
inserted -X- _ O
out -X- _ O
- -X- _ O
of -X- _ O
- -X- _ O
context -X- _ O
since -X- _ O
the -X- _ O
perturber -X- _ O
does -X- _ O
not -X- _ O
condition -X- _ O
upon -X- _ O
the -X- _ O
source -X- _ O
document -X- _ O
. -X- _ O
We -X- _ O
then -X- _ O
train -X- _ O
our -X- _ O
BART -X- _ O
- -X- _ O
large -X- _ O
model -X- _ O
post -X- _ O
- -X- _ O
editor -X- _ O
model -X- _ O
, -X- _ O
which -X- _ O
we -X- _ O
call -X- _ O
CompEdit -X- _ B-MethodName
, -X- _ O
to -X- _ O
produce -X- _ O
the -X- _ O
original -X- _ O
reference -X- _ O
summaries -X- _ O
conditioned -X- _ O
upon -X- _ O
the -X- _ O
source -X- _ O
document -X- _ O
and -X- _ O
these -X- _ O
perturbed -X- _ O
summaries -X- _ O
, -X- _ O
with -X- _ O
special -X- _ O
tokens -X- _ O
surrounding -X- _ O
the -X- _ O
entities -X- _ O
that -X- _ O
should -X- _ O
be -X- _ O
removed -X- _ O
. -X- _ O
In -X- _ O
this -X- _ O
setup -X- _ O
, -X- _ O
the -X- _ O
post -X- _ O
- -X- _ O
editor -X- _ O
learns -X- _ O
to -X- _ O
remove -X- _ O
related -X- _ O
, -X- _ O
out -X- _ O
- -X- _ O
of -X- _ O
- -X- _ O
context -X- _ O
entities -X- _ O
during -X- _ O
training -X- _ O
. -X- _ O
We -X- _ O
only -X- _ O
train -X- _ O
on -X- _ O
references -X- _ O
for -X- _ O
which -X- _ O
all -X- _ O
named -X- _ O
entities -X- _ O
were -X- _ O
found -X- _ O
in -X- _ O
the -X- _ O
source -X- _ O
and -X- _ O
thus -X- _ O
maximize -X- _ O
the -X- _ O
following -X- _ O
: -X- _ O
P -X- _ O
( -X- _ O
Gold -X- _ O
summary -X- _ O
| -X- _ O
source -X- _ O
, -X- _ O
special -X- _ O
- -X- _ O
token -X- _ O
perturbed -X- _ O
summary -X- _ O
) -X- _ O
. -X- _ O
While -X- _ O
a -X- _ O
post -X- _ O
- -X- _ O
editor -X- _ O
could -X- _ O
be -X- _ O
trained -X- _ O
directly -X- _ O
from -X- _ O
sentence -X- _ O
compression -X- _ O
data -X- _ O
or -X- _ O
on -X- _ O
summarization -X- _ O
data -X- _ O
without -X- _ O
access -X- _ O
to -X- _ O
the -X- _ O
source -X- _ O
, -X- _ O
such -X- _ O
models -X- _ O
resulted -X- _ O
in -X- _ O
a -X- _ O
degradation -X- _ O
of -X- _ O
summary -X- _ O
salience -X- _ O
. -X- _ O
During -X- _ O
inference -X- _ O
, -X- _ O
we -X- _ O
surround -X- _ O
extrinsic -X- _ O
entity -X- _ O
errors -X- _ O
, -X- _ O
as -X- _ O
determined -X- _ O
by -X- _ O
named -X- _ O
entity -X- _ O
overlap -X- _ O
with -X- _ O
the -X- _ O
input -X- _ O
, -X- _ O
with -X- _ O
special -X- _ O
tokens -X- _ O
to -X- _ O
signal -X- _ O
the -X- _ O
model -X- _ O
to -X- _ O
remove -X- _ O
them -X- _ O
. -X- _ O

We -X- _ O
evaluate -X- _ O
the -X- _ O
above -X- _ O
approaches -X- _ O
on -X- _ O
the -X- _ O
XSUM -X- _ O
( -X- _ O
Narayan -X- _ O
et -X- _ O
al -X- _ O
. -X- _ O
, -X- _ O
2018 -X- _ O
) -X- _ O
and -X- _ O
CNN -X- _ O
/ -X- _ O
DM -X- _ O
( -X- _ O
Hermann -X- _ O
et -X- _ O
al -X- _ O
. -X- _ O
, -X- _ O
2015 -X- _ O
) -X- _ O
datasets -X- _ O
. -X- _ O
We -X- _ O
apply -X- _ O
BART -X- _ B-MethodName
- -X- _ I-MethodName
large -X- _ I-MethodName
as -X- _ O
the -X- _ O
base -X- _ O
summarization -X- _ O
model -X- _ O
, -X- _ O
and -X- _ O
post -X- _ O
- -X- _ O
editing -X- _ O
models -X- _ O
are -X- _ O
applied -X- _ O
to -X- _ O
this -X- _ O
base -X- _ O
model -X- _ O
's -X- _ O
output -X- _ O
. -X- _ O
We -X- _ O
also -X- _ O
report -X- _ O
results -X- _ O
for -X- _ O
BART -X- _ B-MethodName
- -X- _ I-MethodName
large -X- _ I-MethodName
trained -X- _ O
on -X- _ O
a -X- _ O
data -X- _ O
subset -X- _ O
in -X- _ O
which -X- _ O
all -X- _ O
summary -X- _ O
named -X- _ O
entities -X- _ O
are -X- _ O
found -X- _ O
in -X- _ O
the -X- _ O
source -X- _ O
, -X- _ O
which -X- _ O
we -X- _ O
call -X- _ O
BART -X- _ B-MethodName
- -X- _ I-MethodName
c. -X- _ I-MethodName
All -X- _ O
SpanFact -X- _ B-MethodName
and -X- _ O
CompEdit -X- _ B-MethodName
models -X- _ O
are -X- _ O
trained -X- _ O
for -X- _ O
10 -X- _ B-HyperparameterValue
epochs -X- _ B-HyperparameterName
with -X- _ O
a -X- _ O
batch -X- _ B-HyperparameterName
size -X- _ I-HyperparameterName
of -X- _ O
64 -X- _ B-HyperparameterValue
, -X- _ O
with -X- _ O
the -X- _ O
best -X- _ O
checkpoint -X- _ O
chosen -X- _ O
according -X- _ O
to -X- _ O
the -X- _ O
highest -X- _ O
average -X- _ O
of -X- _ O
ROUGE-1 -X- _ O
/ -X- _ O
2 -X- _ O
/ -X- _ O
L -X- _ O
( -X- _ O
Lin -X- _ O
, -X- _ O
2004 -X- _ O
) -X- _ O
CNN -X- _ O
/ -X- _ O
DM -X- _ O
results -X- _ O
, -X- _ O
are -X- _ O
found -X- _ O
in -X- _ O
the -X- _ O
Appendix -X- _ O
. -X- _ O

To -X- _ O
show -X- _ O
the -X- _ O
generalizability -X- _ O
of -X- _ O
our -X- _ O
results -X- _ O
to -X- _ O
post -X- _ O
- -X- _ O
editing -X- _ O
models -X- _ O
other -X- _ O
than -X- _ O
BART -X- _ O
, -X- _ O
we -X- _ O
test -X- _ O
the -X- _ O
best -X- _ O
post -X- _ O
- -X- _ O
editors -X- _ O
on -X- _ O
UniLM -X- _ B-MethodName
( -X- _ O
Dong -X- _ O
et -X- _ O
al -X- _ O
. -X- _ O
, -X- _ O
2019 -X- _ O
) -X- _ O
and -X- _ O
BottomUp -X- _ B-MethodName
( -X- _ O
Gehrmann -X- _ O
et -X- _ O
al -X- _ O
. -X- _ O
, -X- _ O
2018 -X- _ O
) -X- _ O
outputs -X- _ O
( -X- _ O
additional -X- _ O
models -X- _ O
in -X- _ O
the -X- _ O
Appendix -X- _ O
) -X- _ O
. -X- _ O
released -X- _ O
the -X- _ O
output -X- _ O
of -X- _ O
their -X- _ O
post -X- _ O
- -X- _ O
editor -X- _ O
FASumFC -X- _ B-MethodName
on -X- _ O
these -X- _ O
outputs -X- _ O
but -X- _ O
not -X- _ O
their -X- _ O
trained -X- _ O
model -X- _ O
. -X- _ O
This -X- _ O
post -X- _ O
- -X- _ O
editor -X- _ O
is -X- _ O
a -X- _ O
seq2seq -X- _ O
denoising -X- _ O
model -X- _ O
trained -X- _ O
with -X- _ O
entity -X- _ O
swaps -X- _ O
for -X- _ O
inserting -X- _ O
inconsistencies -X- _ O
and -X- _ O
backtranslation -X- _ O
to -X- _ O
create -X- _ O
paraphrases -X- _ O
. -X- _ O

We -X- _ O
evaluate -X- _ O
using -X- _ O
standard -X- _ O
ROUGE-1 -X- _ B-MetricName
/ -X- _ I-MetricName
2 -X- _ I-MetricName
/ -X- _ I-MetricName
L -X- _ I-MetricName
( -X- _ I-MetricName
R-1 -X- _ I-MetricName
/ -X- _ I-MetricName
2 -X- _ I-MetricName
/ -X- _ I-MetricName
L -X- _ I-MetricName
) -X- _ I-MetricName
and -X- _ O
include -X- _ O
a -X- _ O
variation -X- _ O
called -X- _ O
R1 -X- _ B-MetricName
- -X- _ I-MetricName
c -X- _ I-MetricName
that -X- _ O
evaluates -X- _ O
R1 -X- _ O
on -X- _ O
the -X- _ O
reference -X- _ O
summaries -X- _ O
with -X- _ O
entities -X- _ O
not -X- _ O
found -X- _ O
in -X- _ O
the -X- _ O
input -X- _ O
removed -X- _ O
from -X- _ O
the -X- _ O
summary -X- _ O
. -X- _ O
We -X- _ O
include -X- _ O
the -X- _ O
percentage -X- _ O
of -X- _ O
the -X- _ O
base -X- _ O
model -X- _ O
summaries -X- _ O
that -X- _ O
are -X- _ O
edited -X- _ O
by -X- _ O
the -X- _ O
post -X- _ O
- -X- _ O
editor -X- _ O
( -X- _ O
Edit -X- _ O
% -X- _ O
) -X- _ O
and -X- _ O
the -X- _ O
following -X- _ O
metrics -X- _ O
: -X- _ O
E -X- _ B-MetricName
- -X- _ I-MetricName
P -X- _ I-MetricName
src -X- _ I-MetricName
( -X- _ O
E -X- _ O
- -X- _ O
R -X- _ O
ref -X- _ O
) -X- _ O
measures -X- _ O
the -X- _ O
percentage -X- _ O
of -X- _ O
entities -X- _ O
in -X- _ O
the -X- _ O
generated -X- _ O
summary -X- _ O
( -X- _ O
reference -X- _ O
) -X- _ O
present -X- _ O
in -X- _ O
the -X- _ O
input -X- _ O
( -X- _ O
generated -X- _ O
summary -X- _ O
) -X- _ O
. -X- _ O
E -X- _ O
- -X- _ O
P -X- _ O
src -X- _ O
as -X- _ O
a -X- _ O
metric -X- _ O
performs -X- _ O
on -X- _ O
par -X- _ O
with -X- _ O
model -X- _ O
- -X- _ O
based -X- _ O
, -X- _ O
token -X- _ O
- -X- _ O
level -X- _ O
metrics -X- _ O
( -X- _ O
Zhou -X- _ O
et -X- _ O
al -X- _ O
. -X- _ O
, -X- _ O
2021 -X- _ O
; -X- _ O
Cao -X- _ O
et -X- _ O
al -X- _ O
. -X- _ O
, -X- _ O
2022 -X- _ O
) -X- _ O
. -X- _ O
The -X- _ O
subset -X- _ O
of -X- _ O
data -X- _ O
without -X- _ O
named -X- _ O
entity -X- _ O
errors -X- _ O
has -X- _ O
an -X- _ O
E -X- _ O
- -X- _ O
P -X- _ O
src -X- _ O
of -X- _ O
100 -X- _ O
. -X- _ O
BS -X- _ B-MetricName
- -X- _ I-MetricName
P -X- _ I-MetricName
src -X- _ I-MetricName
( -X- _ O
BS -X- _ O
- -X- _ O
F1 -X- _ O
ref -X- _ O
) -X- _ O
represents -X- _ O
the -X- _ O
BERTScore -X- _ O
precision -X- _ O
( -X- _ O
F1 -X- _ O
) -X- _ O
w.r.t -X- _ O
. -X- _ O
the -X- _ O
source -X- _ O
article -X- _ O
( -X- _ O
reference -X- _ O
summary -X- _ O
) -X- _ O
. -X- _ O
D -X- _ B-MetricName
arc -X- _ I-MetricName
measures -X- _ O
the -X- _ O
percentage -X- _ O
of -X- _ O
dependency -X- _ O
arcs -X- _ O
in -X- _ O
summary -X- _ O
entailed -X- _ O
by -X- _ O
the -X- _ O
source -X- _ O
article -X- _ O
using -X- _ O
the -X- _ O
model -X- _ O
from -X- _ O
Goyal -X- _ O
and -X- _ O
Durrett -X- _ O
( -X- _ O
2021 -X- _ O
) -X- _ O
. -X- _ O
QAFE -X- _ B-MetricName
is -X- _ O
the -X- _ O
QAFactEval -X- _ O
question -X- _ O
answeringbased -X- _ O
consistency -X- _ O
metric -X- _ O
( -X- _ O
Fabbri -X- _ O
et -X- _ O
al -X- _ O
. -X- _ O
, -X- _ O
2021 -X- _ O
) -X- _ O
. -X- _ O

CoLA -X- _ B-MetricName
To -X- _ O
evaluate -X- _ O
grammaticality -X- _ O
, -X- _ O
we -X- _ O
apply -X- _ O
a -X- _ O
RoBERTa -X- _ B-MethodName
- -X- _ I-MethodName
large -X- _ I-MethodName
) -X- _ O
model -X- _ O
from -X- _ O
Krishna -X- _ O
et -X- _ O
al -X- _ O
. -X- _ O
( -X- _ O
2020 -X- _ O
) -X- _ O
trained -X- _ O
on -X- _ O
the -X- _ O
CoLA -X- _ O
dataset -X- _ O
( -X- _ O
Warstadt -X- _ O
et -X- _ O
al -X- _ O
. -X- _ O
, -X- _ O
2019 -X- _ O
) -X- _ O
, -X- _ O
which -X- _ O
includes -X- _ O
sentences -X- _ O
and -X- _ O
labels -X- _ O
for -X- _ O
their -X- _ O
grammatical -X- _ O
acceptability -X- _ O
. -X- _ O

In -X- _ O
this -X- _ O
section -X- _ O
, -X- _ O
we -X- _ O
provide -X- _ O
additional -X- _ O
details -X- _ O
for -X- _ O
our -X- _ O
model -X- _ O
, -X- _ O
baselines -X- _ O
, -X- _ O
and -X- _ O
metrics -X- _ O
. -X- _ O
To -X- _ O
encourage -X- _ O
retaining -X- _ O
essential -X- _ O
information -X- _ O
, -X- _ O
we -X- _ O
filter -X- _ O
data -X- _ O
points -X- _ O
from -X- _ O
Filippova -X- _ O
and -X- _ O
Altun -X- _ O
( -X- _ O
2013 -X- _ O
) -X- _ O
in -X- _ O
which -X- _ O
the -X- _ O
compressed -X- _ O
sentences -X- _ O
contain -X- _ O
less -X- _ O
than -X- _ O
75 -X- _ O
% -X- _ O
the -X- _ O
number -X- _ O
of -X- _ O
tokens -X- _ O
in -X- _ O
the -X- _ O
longer -X- _ O
sentence -X- _ O
. -X- _ O
We -X- _ O
compared -X- _ O
the -X- _ O
effect -X- _ O
of -X- _ O
sentence -X- _ O
compression -X- _ O
data -X- _ O
on -X- _ O
downstream -X- _ O
post -X- _ O
- -X- _ O
editor -X- _ O
performance -X- _ O
, -X- _ O
experimenting -X- _ O
with -X- _ O
higher -X- _ O
compression -X- _ O
ratios -X- _ O
as -X- _ O
well -X- _ O
as -X- _ O
other -X- _ O
sentence -X- _ O
compression -X- _ O
datasets -X- _ O
( -X- _ O
Clarke -X- _ O
and -X- _ O
Lapata -X- _ O
, -X- _ O
2008 -X- _ O
) -X- _ O
, -X- _ O
but -X- _ O
these -X- _ O
models -X- _ O
resulted -X- _ O
either -X- _ O
in -X- _ O
lower -X- _ O
ROUGE -X- _ O
performance -X- _ O
or -X- _ O
a -X- _ O
decrease -X- _ O
in -X- _ O
entity -X- _ O
precision -X- _ O
on -X- _ O
the -X- _ O
validation -X- _ O
set -X- _ O
. -X- _ O
To -X- _ O
create -X- _ O
training -X- _ O
examples -X- _ O
for -X- _ O
our -X- _ O
post -X- _ O
- -X- _ O
editor -X- _ O
, -X- _ O
we -X- _ O
inserted -X- _ O
one -X- _ O
, -X- _ O
two -X- _ O
, -X- _ O
and -X- _ O
three -X- _ O
entities -X- _ O
into -X- _ O
the -X- _ O
references -X- _ O
by -X- _ O
applying -X- _ O
our -X- _ O
perturber -X- _ O
. -X- _ O
The -X- _ O
size -X- _ O
of -X- _ O
the -X- _ O
subsets -X- _ O
of -X- _ O
reference -X- _ O
summaries -X- _ O
entity -X- _ B-HyperparameterName
precision -X- _ I-HyperparameterName
of -X- _ O
100 -X- _ B-HyperparameterValue
on -X- _ O
( -X- _ O
training -X- _ B-HyperparameterName
, -X- _ O
validation -X- _ B-HyperparameterName
) -X- _ O
is -X- _ O
( -X- _ O
52k -X- _ B-HyperparameterValue
, -X- _ O
2.9k -X- _ B-HyperparameterValue
) -X- _ O
for -X- _ O
XSum -X- _ O
and -X- _ O
( -X- _ O
160k -X- _ B-HyperparameterValue
, -X- _ O
6.5k -X- _ B-HyperparameterValue
) -X- _ O
for -X- _ O
CNN -X- _ O
/ -X- _ O
DM -X- _ O
. -X- _ O
We -X- _ O
then -X- _ O
sample -X- _ O
200k -X- _ O
data -X- _ O
points -X- _ O
to -X- _ O
train -X- _ O
on -X- _ O
a -X- _ O
dataset -X- _ O
of -X- _ O
size -X- _ O
similar -X- _ O
to -X- _ O
XSum -X- _ O
and -X- _ O
found -X- _ O
that -X- _ O
doubling -X- _ O
the -X- _ O
size -X- _ O
of -X- _ O
this -X- _ O
data -X- _ O
did -X- _ O
not -X- _ O
give -X- _ O
further -X- _ O
improvements -X- _ O
. -X- _ O

We -X- _ O
use -X- _ O
the -X- _ O
following -X- _ O
inference -X- _ O
parameters -X- _ O
: -X- _ O
( -X- _ O
beam -X- _ B-HyperparameterName
size -X- _ I-HyperparameterName
, -X- _ O
min -X- _ B-HyperparameterName
generation -X- _ I-HyperparameterName
length -X- _ I-HyperparameterName
, -X- _ O
max -X- _ B-HyperparameterName
generation -X- _ I-HyperparameterName
length -X- _ I-HyperparameterName
, -X- _ O
length -X- _ B-HyperparameterName
penalty -X- _ I-HyperparameterName
) -X- _ O
for -X- _ O
XSum -X- _ O
= -X- _ O
( -X- _ O
6 -X- _ B-HyperparameterValue
, -X- _ O
11 -X- _ B-HyperparameterValue
, -X- _ O
62 -X- _ B-HyperparameterValue
, -X- _ O
1.0 -X- _ B-HyperparameterValue
) -X- _ O
and -X- _ O
CNN -X- _ O
/ -X- _ O
DM -X- _ O
= -X- _ O
( -X- _ O
4 -X- _ B-HyperparameterValue
, -X- _ O
40 -X- _ B-HyperparameterValue
, -X- _ O
140 -X- _ B-HyperparameterValue
, -X- _ O
2.0 -X- _ B-HyperparameterValue
) -X- _ O
. -X- _ O
We -X- _ O
retrain -X- _ O
BART -X- _ B-MethodName
- -X- _ I-MethodName
large -X- _ I-MethodName
on -X- _ O
XSum -X- _ B-DatasetName
, -X- _ O
and -X- _ O
for -X- _ O
CNN -X- _ O
/ -X- _ O
DM -X- _ O
we -X- _ O
run -X- _ O
inference -X- _ O
from -X- _ O
the -X- _ O
fairseq -X- _ O
/ -X- _ O
bart -X- _ O
- -X- _ O
large -X- _ O
- -X- _ O
cnn -X- _ O
1 -X- _ O
checkpoint -X- _ O
from -X- _ O
the -X- _ O
transformers -X- _ O
library -X- _ O
( -X- _ O
Wolf -X- _ O
et -X- _ O
al -X- _ O
. -X- _ O
, -X- _ O
2020 -X- _ O
) -X- _ O
. -X- _ O

For -X- _ O
ReDRESS -X- _ O
, -X- _ O
we -X- _ O
train -X- _ O
BART -X- _ B-MethodName
- -X- _ I-MethodName
large -X- _ I-MethodName
rather -X- _ O
than -X- _ O
the -X- _ O
BART -X- _ O
- -X- _ O
base -X- _ O
model -X- _ O
used -X- _ O
in -X- _ O
the -X- _ O
original -X- _ O
paper -X- _ O
for -X- _ O
and -X- _ O
TConvS2S -X- _ O
( -X- _ O
Gehring -X- _ O
et -X- _ O
al -X- _ O
. -X- _ O
, -X- _ O
2017 -X- _ O
) -X- _ O
outputs -X- _ O
on -X- _ O
XSum -X- _ O
. -X- _ O
consistency -X- _ O
with -X- _ O
the -X- _ O
above -X- _ O
models -X- _ O
. -X- _ O
A -X- _ O
key -X- _ O
component -X- _ O
of -X- _ O
this -X- _ O
post -X- _ O
- -X- _ O
editor -X- _ O
is -X- _ O
the -X- _ O
over -X- _ O
- -X- _ O
generation -X- _ O
and -X- _ O
reranking -X- _ O
of -X- _ O
the -X- _ O
edited -X- _ O
summaries -X- _ O
; -X- _ O
we -X- _ O
rerank -X- _ O
according -X- _ O
to -X- _ O
entity -X- _ O
precision -X- _ O
over -X- _ O
the -X- _ O
input -X- _ O
. -X- _ O
We -X- _ O
also -X- _ O
vary -X- _ O
how -X- _ O
entities -X- _ O
are -X- _ O
matched -X- _ O
in -X- _ O
the -X- _ O
ReDRESS -X- _ O
retrieval -X- _ O
component -X- _ O
and -X- _ O
use -X- _ O
exact -X- _ O
string -X- _ O
matching -X- _ O
to -X- _ O
match -X- _ O
how -X- _ O
we -X- _ O
filtered -X- _ O
the -X- _ O
clean -X- _ O
data -X- _ O
subset -X- _ O
. -X- _ O

For -X- _ O
DAE -X- _ O
, -X- _ O
we -X- _ O
apply -X- _ O
the -X- _ O
DAE_xsum_human_best -X- _ B-MethodName
model -X- _ O
. -X- _ O
2 -X- _ O
We -X- _ O
provide -X- _ O
our -X- _ O
BERTScore -X- _ O
run -X- _ O
hash -X- _ O
. -X- _ O

Overcoming -X- _ O
Catastrophic -X- _ O
Forgetting -X- _ O
During -X- _ O
Domain -X- _ O
Adaptation -X- _ O
of -X- _ O
Seq2seq -X- _ O
Language -X- _ B-TaskName
Generation -X- _ I-TaskName

Seq2seq -X- _ O
language -X- _ B-TaskName
generation -X- _ I-TaskName
models -X- _ O
that -X- _ O
are -X- _ O
trained -X- _ O
offline -X- _ O
with -X- _ O
multiple -X- _ O
domains -X- _ O
in -X- _ O
a -X- _ O
sequential -X- _ O
fashion -X- _ O
often -X- _ O
suffer -X- _ O
from -X- _ O
catastrophic -X- _ O
forgetting -X- _ O
. -X- _ O
Lifelong -X- _ O
learning -X- _ O
has -X- _ O
been -X- _ O
proposed -X- _ O
to -X- _ O
handle -X- _ O
this -X- _ O
problem -X- _ O
. -X- _ O
However -X- _ O
, -X- _ O
existing -X- _ O
work -X- _ O
such -X- _ O
as -X- _ O
experience -X- _ O
replay -X- _ O
or -X- _ O
elastic -X- _ O
weighted -X- _ O
consolidation -X- _ O
requires -X- _ O
incremental -X- _ O
memory -X- _ O
space -X- _ O
. -X- _ O
In -X- _ O
this -X- _ O
work -X- _ O
, -X- _ O
we -X- _ O
propose -X- _ O
an -X- _ O
innovative -X- _ O
framework -X- _ O
, -X- _ O
RMR_DSE -X- _ B-MethodName
that -X- _ O
leverages -X- _ O
a -X- _ O
recall -X- _ O
optimization -X- _ O
mechanism -X- _ O
to -X- _ O
selectively -X- _ O
memorize -X- _ O
important -X- _ O
parameters -X- _ O
of -X- _ O
previous -X- _ O
tasks -X- _ O
via -X- _ O
regularization -X- _ O
, -X- _ O
and -X- _ O
uses -X- _ O
a -X- _ O
domain -X- _ O
drift -X- _ O
estimation -X- _ O
algorithm -X- _ O
to -X- _ O
compensate -X- _ O
for -X- _ O
the -X- _ O
drift -X- _ O
between -X- _ O
different -X- _ O
domains -X- _ O
in -X- _ O
the -X- _ O
embedding -X- _ O
space -X- _ O
. -X- _ O
These -X- _ O
designs -X- _ O
enable -X- _ O
the -X- _ O
model -X- _ O
to -X- _ O
be -X- _ O
trained -X- _ O
on -X- _ O
the -X- _ O
current -X- _ O
task -X- _ O
while -X- _ O
keeping -X- _ O
the -X- _ O
memory -X- _ O
of -X- _ O
previous -X- _ O
tasks -X- _ O
, -X- _ O
and -X- _ O
avoid -X- _ O
much -X- _ O
additional -X- _ O
data -X- _ O
storage -X- _ O
. -X- _ O
Furthermore -X- _ O
, -X- _ O
RMR_DSE -X- _ O
can -X- _ O
be -X- _ O
combined -X- _ O
with -X- _ O
existing -X- _ O
lifelong -X- _ O
learning -X- _ O
approaches -X- _ O
. -X- _ O
Our -X- _ O
experiments -X- _ O
on -X- _ O
two -X- _ O
seq2seq -X- _ O
language -X- _ B-TaskName
generation -X- _ I-TaskName
tasks -X- _ O
, -X- _ O
paraphrase -X- _ O
and -X- _ O
dialog -X- _ O
response -X- _ O
generation -X- _ O
, -X- _ O
show -X- _ O
that -X- _ O
RMR_DSE -X- _ O
outperforms -X- _ O
stateof -X- _ O
- -X- _ O
the -X- _ O
- -X- _ O
art -X- _ O
models -X- _ O
by -X- _ O
a -X- _ O
considerable -X- _ O
margin -X- _ O
and -X- _ O
greatly -X- _ O
reduces -X- _ O
forgetting -X- _ O
. -X- _ O

Seq2seq -X- _ O
language -X- _ B-TaskName
generation -X- _ I-TaskName
is -X- _ O
the -X- _ O
essential -X- _ O
framework -X- _ O
for -X- _ O
many -X- _ O
tasks -X- _ O
such -X- _ O
as -X- _ O
machine -X- _ O
translation -X- _ O
, -X- _ O
summarization -X- _ O
, -X- _ O
paraphrase -X- _ O
, -X- _ O
question -X- _ O
answering -X- _ O
, -X- _ O
dialog -X- _ O
response -X- _ O
generation -X- _ O
. -X- _ O
In -X- _ O
these -X- _ O
applications -X- _ O
, -X- _ O
models -X- _ O
are -X- _ O
typically -X- _ O
trained -X- _ O
offline -X- _ O
using -X- _ O
annotated -X- _ O
data -X- _ O
from -X- _ O
a -X- _ O
fixed -X- _ O
set -X- _ O
of -X- _ O
domains -X- _ O
. -X- _ O
However -X- _ O
, -X- _ O
in -X- _ O
real -X- _ O
- -X- _ O
world -X- _ O
applications -X- _ O
, -X- _ O
it -X- _ O
is -X- _ O
desirable -X- _ O
for -X- _ O
the -X- _ O
system -X- _ O
to -X- _ O
expand -X- _ O
its -X- _ O
knowledge -X- _ O
to -X- _ O
new -X- _ O
domains -X- _ O
and -X- _ O
functionalities -X- _ O
, -X- _ O
that -X- _ O
is -X- _ O
, -X- _ O
it -X- _ O
has -X- _ O
the -X- _ O
capability -X- _ O
of -X- _ O
human -X- _ O
- -X- _ O
like -X- _ O
lifelong -X- _ O
learning -X- _ O
( -X- _ O
LLL -X- _ O
) -X- _ O
( -X- _ O
Ring -X- _ O
et -X- _ O
al -X- _ O
. -X- _ O
, -X- _ O
1994 -X- _ O
; -X- _ O
Chaudhry -X- _ O
et -X- _ O
al -X- _ O
. -X- _ O
, -X- _ O
2019 -X- _ O
) -X- _ O
of -X- _ O
acquiring -X- _ O
new -X- _ O
utterance -X- _ O
patterns -X- _ O
without -X- _ O
forgetting -X- _ O
what -X- _ O
it -X- _ O
has -X- _ O
already -X- _ O
learned -X- _ O
. -X- _ O
Neural -X- _ O
networks -X- _ O
struggle -X- _ O
to -X- _ O
learn -X- _ O
continuously -X- _ O
and -X- _ O
experience -X- _ O
catastrophic -X- _ O
forgetting -X- _ O
( -X- _ O
CF -X- _ O
) -X- _ O
when -X- _ O
optimized -X- _ O
on -X- _ O
a -X- _ O
sequence -X- _ O
of -X- _ O
learning -X- _ O
problems -X- _ O
( -X- _ O
McCloskey -X- _ O
and -X- _ O
Cohen -X- _ O
, -X- _ O
1989 -X- _ O
; -X- _ O
French -X- _ O
, -X- _ O
1999 -X- _ O
) -X- _ O
. -X- _ O
Some -X- _ O
past -X- _ O
work -X- _ O
in -X- _ O
LLL -X- _ O
has -X- _ O
demonstrated -X- _ O
that -X- _ O
discriminative -X- _ O
models -X- _ O
can -X- _ O
be -X- _ O
incrementally -X- _ O
learnt -X- _ O
for -X- _ O
a -X- _ O
sequence -X- _ O
of -X- _ O
tasks -X- _ O
( -X- _ O
Kirkpatrick -X- _ O
et -X- _ O
al -X- _ O
. -X- _ O
, -X- _ O
2017 -X- _ O
; -X- _ O
Wang -X- _ O
et -X- _ O
al -X- _ O
. -X- _ O
, -X- _ O
2019 -X- _ O
) -X- _ O
. -X- _ O
In -X- _ O
contrast -X- _ O
, -X- _ O
under -X- _ O
generative -X- _ O
settings -X- _ O
there -X- _ O
has -X- _ O
been -X- _ O
limited -X- _ O
research -X- _ O
. -X- _ O
Recent -X- _ O
work -X- _ O
in -X- _ O
this -X- _ O
area -X- _ O
includes -X- _ O
( -X- _ O
Mi -X- _ O
et -X- _ O
al -X- _ O
. -X- _ O
, -X- _ O
2020 -X- _ O
; -X- _ O
Madotto -X- _ O
et -X- _ O
al -X- _ O
. -X- _ O
, -X- _ O
2020 -X- _ O
; -X- _ O
He -X- _ O
et -X- _ O
al -X- _ O
. -X- _ O
, -X- _ O
2021 -X- _ O
; -X- _ O
Shin -X- _ O
et -X- _ O
al -X- _ O
. -X- _ O
, -X- _ O
2017 -X- _ O
) -X- _ O
. -X- _ O

In -X- _ O
this -X- _ O
work -X- _ O
, -X- _ O
we -X- _ O
propose -X- _ O
a -X- _ O
novel -X- _ O
method -X- _ O
, -X- _ O
regularized -X- _ B-MethodName
memory -X- _ I-MethodName
recall -X- _ I-MethodName
mechanism -X- _ I-MethodName
with -X- _ I-MethodName
additional -X- _ I-MethodName
domain -X- _ I-MethodName
shift -X- _ I-MethodName
estimation -X- _ I-MethodName
( -X- _ I-MethodName
RMR_DSE -X- _ I-MethodName
) -X- _ I-MethodName
, -X- _ O
to -X- _ O
alleviate -X- _ O
CF -X- _ O
in -X- _ O
continuous -X- _ O
seq2seq -X- _ O
language -X- _ B-TaskName
generation -X- _ I-TaskName
. -X- _ O
The -X- _ O
first -X- _ O
RMR -X- _ B-MethodName
component -X- _ O
improves -X- _ O
the -X- _ O
regularization -X- _ O
- -X- _ O
based -X- _ O
method -X- _ O
through -X- _ O
adaptive -X- _ O
regularization -X- _ O
. -X- _ O
We -X- _ O
convert -X- _ O
fisher -X- _ O
information -X- _ O
matrix -X- _ O
deployed -X- _ O
in -X- _ O
EWC -X- _ O
to -X- _ O
a -X- _ O
tunable -X- _ O
hyperparameter -X- _ O
constrained -X- _ O
by -X- _ O
a -X- _ O
vocabulary -X- _ O
- -X- _ O
related -X- _ O
hyperparameter -X- _ O
. -X- _ O
Further -X- _ O
, -X- _ O
we -X- _ O
add -X- _ O
a -X- _ O
regularizer -X- _ O
derived -X- _ O
from -X- _ O
the -X- _ O
gradients -X- _ O
of -X- _ O
the -X- _ O
generative -X- _ O
function -X- _ O
to -X- _ O
tune -X- _ O
model -X- _ O
parameters -X- _ O
. -X- _ O
The -X- _ O
second -X- _ O
DSE -X- _ B-MethodName
component -X- _ O
compen- -X- _ O
sates -X- _ O
the -X- _ O
representation -X- _ O
difference -X- _ O
from -X- _ O
the -X- _ O
two -X- _ O
domains -X- _ O
by -X- _ O
estimating -X- _ O
the -X- _ O
semantic -X- _ O
gap -X- _ O
between -X- _ O
them -X- _ O
. -X- _ O
We -X- _ O
obtain -X- _ O
embeddings -X- _ O
for -X- _ O
the -X- _ O
current -X- _ O
task -X- _ O
's -X- _ O
data -X- _ O
using -X- _ O
the -X- _ O
previous -X- _ O
and -X- _ O
current -X- _ O
models -X- _ O
, -X- _ O
and -X- _ O
group -X- _ O
embeddings -X- _ O
from -X- _ O
previous -X- _ O
models -X- _ O
into -X- _ O
clusters -X- _ O
. -X- _ O
Semantic -X- _ O
shifts -X- _ O
are -X- _ O
computed -X- _ O
for -X- _ O
each -X- _ O
cluster -X- _ O
, -X- _ O
and -X- _ O
then -X- _ O
used -X- _ O
during -X- _ O
inference -X- _ O
time -X- _ O
on -X- _ O
previous -X- _ O
test -X- _ O
data -X- _ O
to -X- _ O
adjust -X- _ O
its -X- _ O
semantic -X- _ O
representation -X- _ O
to -X- _ O
match -X- _ O
the -X- _ O
current -X- _ O
model -X- _ O
. -X- _ O

In -X- _ O
this -X- _ O
section -X- _ O
, -X- _ O
we -X- _ O
introduce -X- _ O
our -X- _ O
proposed -X- _ O
framework -X- _ O
RMR_DSE -X- _ B-MethodName
, -X- _ O
as -X- _ O
illustrated -X- _ O
in -X- _ O
Figure -X- _ O
2 -X- _ O
. -X- _ O
In -X- _ O
the -X- _ O
LLL -X- _ O
scenario -X- _ O
, -X- _ O
models -X- _ O
are -X- _ O
trained -X- _ O
for -X- _ O
a -X- _ O
sequence -X- _ O
of -X- _ O
domains -X- _ O
( -X- _ O
or -X- _ O
tasks -X- _ O
) -X- _ O
. -X- _ O
For -X- _ O
the -X- _ O
first -X- _ O
task -X- _ O
, -X- _ O
the -X- _ O
model -X- _ O
can -X- _ O
be -X- _ O
trained -X- _ O
from -X- _ O
scratch -X- _ O
or -X- _ O
using -X- _ O
pretrained -X- _ O
models -X- _ O
. -X- _ O

Starting -X- _ O
from -X- _ O
the -X- _ O
second -X- _ O
model -X- _ O
, -X- _ O
parameters -X- _ O
are -X- _ O
initialized -X- _ O
with -X- _ O
the -X- _ O
previous -X- _ O
model -X- _ O
. -X- _ O
Our -X- _ O
RMR_DSE -X- _ B-MethodName
method -X- _ O
is -X- _ O
a -X- _ O
combination -X- _ O
of -X- _ O
regularization -X- _ O
and -X- _ O
domain -X- _ O
shift -X- _ O
estimation -X- _ O
( -X- _ O
DSE -X- _ O
) -X- _ O
. -X- _ O
For -X- _ O
the -X- _ O
first -X- _ O
part -X- _ O
, -X- _ O
we -X- _ O
incorporate -X- _ O
the -X- _ O
mechanism -X- _ O
of -X- _ O
EWC -X- _ O
to -X- _ O
obtain -X- _ O
a -X- _ O
regularized -X- _ O
memory -X- _ O
recall -X- _ O
mechanism -X- _ O
( -X- _ O
RMR -X- _ O
) -X- _ O
to -X- _ O
optimize -X- _ O
model -X- _ O
training -X- _ O
. -X- _ O
For -X- _ O
the -X- _ O
second -X- _ O
DSE -X- _ O
part -X- _ O
, -X- _ O
we -X- _ O
design -X- _ O
an -X- _ O
algorithm -X- _ O
to -X- _ O
integrate -X- _ O
both -X- _ O
K -X- _ O
- -X- _ O
means -X- _ O
and -X- _ O
mean -X- _ O
shift -X- _ O
. -X- _ O
A -X- _ O
shift -X- _ O
of -X- _ O
embedding -X- _ O
representations -X- _ O
is -X- _ O
estimated -X- _ O
using -X- _ O
the -X- _ O
previous -X- _ O
and -X- _ O
current -X- _ O
models -X- _ O
, -X- _ O
and -X- _ O
it -X- _ O
is -X- _ O
compensated -X- _ O
to -X- _ O
reduce -X- _ O
forgetting -X- _ O
when -X- _ O
we -X- _ O
evaluate -X- _ O
the -X- _ O
current -X- _ O
model -X- _ O
on -X- _ O
test -X- _ O
data -X- _ O
from -X- _ O
the -X- _ O
previous -X- _ O
domain -X- _ O
. -X- _ O
Although -X- _ O
RMR_DSE -X- _ B-MethodName
is -X- _ O
a -X- _ O
generic -X- _ O
mechanism -X- _ O
, -X- _ O
we -X- _ O
evaluate -X- _ O
on -X- _ O
two -X- _ O
seq2seq -X- _ B-TaskName
language -X- _ I-TaskName
generation -X- _ I-TaskName
tasks -X- _ O
in -X- _ O
this -X- _ O
work -X- _ O
. -X- _ O
The -X- _ O
underlying -X- _ O
models -X- _ O
in -X- _ O
seq2seq -X- _ O
language -X- _ B-TaskName
generation -X- _ I-TaskName
can -X- _ O
be -X- _ O
any -X- _ O
models -X- _ O
, -X- _ O
including -X- _ O
transformers -X- _ O
, -X- _ O
LSTM -X- _ O
or -X- _ O
variational -X- _ O
auto -X- _ O
- -X- _ O
encoders -X- _ O
. -X- _ O
The -X- _ O
following -X- _ O
describes -X- _ O
the -X- _ O
RMR -X- _ O
and -X- _ O
DSE -X- _ O
components -X- _ O
in -X- _ O
details -X- _ O
. -X- _ O

Losst -X- _ B-MetricName
= -X- _ O
λ -X- _ O
( -X- _ O
τ -X- _ O
) -X- _ O
Lt -X- _ O
( -X- _ O
θ -X- _ O
) -X- _ O
+ -X- _ O
( -X- _ O
1 -X- _ O
− -X- _ O
λ -X- _ O
( -X- _ O
τ -X- _ O
) -X- _ O
) -X- _ O
γF -X- _ O
ij -X- _ O
Πij -X- _ O
( -X- _ O
θij -X- _ O
− -X- _ O
θ -X- _ O
* -X- _ O
ij -X- _ O
) -X- _ O
2 -X- _ O
( -X- _ O
1 -X- _ O
) -X- _ O

where -X- _ O
L -X- _ B-MetricName
t -X- _ I-MetricName
( -X- _ I-MetricName
θ -X- _ I-MetricName
) -X- _ I-MetricName
is -X- _ O
the -X- _ O
loss -X- _ B-MetricName
for -X- _ O
the -X- _ O
current -X- _ O
task -X- _ O
. -X- _ O
In -X- _ O
our -X- _ O
generation -X- _ O
task -X- _ O
, -X- _ O
we -X- _ O
use -X- _ O
standard -X- _ O
label -X- _ B-MetricName
smooth -X- _ I-MetricName
cross -X- _ I-MetricName
entropy -X- _ I-MetricName
. -X- _ O

In -X- _ O
the -X- _ O
regularization -X- _ O
part -X- _ O
, -X- _ O
θ -X- _ B-HyperparameterName
* -X- _ I-HyperparameterName
represents -X- _ O
the -X- _ O
parameters -X- _ O
from -X- _ O
earlier -X- _ O
models -X- _ O
, -X- _ O
e.g. -X- _ O
, -X- _ O
that -X- _ O
learned -X- _ O
from -X- _ O
task -X- _ O
t -X- _ O
− -X- _ O
1 -X- _ O
: -X- _ O

In -X- _ O
EWC -X- _ O
, -X- _ O
F -X- _ B-HyperparameterName
is -X- _ O
the -X- _ O
diagonal -X- _ O
element -X- _ O
of -X- _ O
the -X- _ O
Fisher -X- _ O
Information -X- _ O
Matrix -X- _ O
. -X- _ O
It -X- _ O
measures -X- _ O
the -X- _ O
importance -X- _ O
of -X- _ O
θ -X- _ O
after -X- _ O
being -X- _ O
updated -X- _ O
with -X- _ O
the -X- _ O
set -X- _ O
of -X- _ O
data -X- _ O
points -X- _ O
in -X- _ O
the -X- _ O
current -X- _ O
task -X- _ O
to -X- _ O
previous -X- _ O
tasks -X- _ O
. -X- _ O
However -X- _ O
, -X- _ O
in -X- _ O
our -X- _ O
work -X- _ O
, -X- _ O
we -X- _ O
suppose -X- _ O
that -X- _ O
we -X- _ O
do -X- _ O
not -X- _ O
have -X- _ O
access -X- _ O
to -X- _ O
data -X- _ O
of -X- _ O
previous -X- _ O
tasks -X- _ O
. -X- _ O
Therefore -X- _ O
, -X- _ O
we -X- _ O
can -X- _ O
not -X- _ O
compute -X- _ O
fine -X- _ O
- -X- _ O
grained -X- _ O
values -X- _ O
based -X- _ O
on -X- _ O
data -X- _ O
, -X- _ O
and -X- _ O
thus -X- _ O
convert -X- _ O
F -X- _ B-HyperparameterName
to -X- _ O
a -X- _ O
tunable -X- _ O
hyperparameter -X- _ O
without -X- _ O
dependency -X- _ O
on -X- _ O
data -X- _ O
from -X- _ O
the -X- _ O
previous -X- _ O
task -X- _ O
. -X- _ O
It -X- _ O
is -X- _ O
used -X- _ O
to -X- _ O
penalize -X- _ O
the -X- _ O
quadratic -X- _ O
function -X- _ O
( -X- _ O
θ -X- _ O
ij -X- _ O
− -X- _ O
θ -X- _ O
* -X- _ O
ij -X- _ O
) -X- _ O
2 -X- _ O
. -X- _ O
In -X- _ O
order -X- _ O
to -X- _ O
make -X- _ O
the -X- _ O
parameters -X- _ O
in -X- _ O
a -X- _ O
reasonable -X- _ O
range -X- _ O
, -X- _ O
we -X- _ O
add -X- _ O
a -X- _ O
hyperparameter -X- _ O
γ -X- _ B-HyperparameterName
to -X- _ O
help -X- _ O
tune -X- _ O
F -X- _ O
. -X- _ O
For -X- _ O
simplicity -X- _ O
, -X- _ O
the -X- _ O
value -X- _ O
of -X- _ O
γ -X- _ B-HyperparameterName
is -X- _ O
determined -X- _ O
by -X- _ O
the -X- _ O
ratio -X- _ O
of -X- _ O
the -X- _ O
vocabulary -X- _ O
size -X- _ O
of -X- _ O
the -X- _ O
current -X- _ O
corpus -X- _ O
and -X- _ O
the -X- _ O
previous -X- _ O
ones -X- _ O
. -X- _ O
Furthermore -X- _ O
, -X- _ O
to -X- _ O
control -X- _ O
the -X- _ O
learning -X- _ O
between -X- _ O
the -X- _ O
loss -X- _ O
for -X- _ O
the -X- _ O
current -X- _ O
task -X- _ O
and -X- _ O
the -X- _ O
regularization -X- _ O
term -X- _ O
, -X- _ O
we -X- _ O
add -X- _ O
λ -X- _ B-HyperparameterName
( -X- _ I-HyperparameterName
τ -X- _ I-HyperparameterName
) -X- _ I-HyperparameterName
, -X- _ O
a -X- _ O
sigmoid -X- _ B-HyperparameterName
annealing -X- _ I-HyperparameterName
function -X- _ I-HyperparameterName
: -X- _ O

where -X- _ O
k -X- _ B-HyperparameterName
and -X- _ O
τ -X- _ B-HyperparameterName
0 -X- _ I-HyperparameterName
are -X- _ O
hyperparameters -X- _ O
controlling -X- _ O
the -X- _ O
annealing -X- _ O
rate -X- _ O
and -X- _ O
timesteps -X- _ O
, -X- _ O
and -X- _ O
τ -X- _ B-HyperparameterName
refers -X- _ O
to -X- _ O
the -X- _ O
update -X- _ O
timesteps -X- _ O
during -X- _ O
fine -X- _ O
- -X- _ O
tuning -X- _ O
. -X- _ O
Finally -X- _ O
similar -X- _ O
to -X- _ O
MAS -X- _ O
( -X- _ O
Aljundi -X- _ O
et -X- _ O
al -X- _ O
. -X- _ O
, -X- _ O
2018 -X- _ O
) -X- _ O
, -X- _ O
to -X- _ O
model -X- _ O
the -X- _ O
varying -X- _ O
importance -X- _ O
of -X- _ O
individual -X- _ O
parameters -X- _ O
and -X- _ O
the -X- _ O
changes -X- _ O
of -X- _ O
model -X- _ O
parameters -X- _ O
, -X- _ O
we -X- _ O
integrate -X- _ O
Π -X- _ B-HyperparameterName
for -X- _ O
fine -X- _ O
- -X- _ O
grained -X- _ O
regularization -X- _ O
: -X- _ O

The -X- _ O
mean -X- _ B-MetricName
shift -X- _ I-MetricName
M -X- _ B-MetricName
h -X- _ I-MetricName
( -X- _ I-MetricName
x -X- _ I-MetricName
) -X- _ I-MetricName
for -X- _ O
each -X- _ O
data -X- _ O
point -X- _ O
of -X- _ O
each -X- _ O
cluster -X- _ O
is -X- _ O
defined -X- _ O
as -X- _ O
: -X- _ O

is -X- _ O
the -X- _ O
Gaussian -X- _ O
kernel -X- _ O
, -X- _ O
h -X- _ B-HyperparameterName
is -X- _ O
the -X- _ O
bandwidth -X- _ B-HyperparameterName
, -X- _ O
x -X- _ O
i -X- _ O
is -X- _ O
the -X- _ O
data -X- _ O
belonging -X- _ O
to -X- _ O
the -X- _ O
cluster -X- _ O
containing -X- _ O
x -X- _ O
, -X- _ O
and -X- _ O
n -X- _ B-HyperparameterName
is -X- _ O
the -X- _ O
number -X- _ B-HyperparameterName
of -X- _ I-HyperparameterName
data -X- _ I-HyperparameterName
points -X- _ I-HyperparameterName
in -X- _ O
each -X- _ O
cluster -X- _ O
. -X- _ O

For -X- _ O
paraphrase -X- _ O
generation -X- _ O
, -X- _ O
we -X- _ O
use -X- _ O
three -X- _ O
existing -X- _ O
paraphrase -X- _ O
datasets -X- _ O
, -X- _ O
Quora -X- _ B-DatasetName
, -X- _ O
Twitter -X- _ B-DatasetName
and -X- _ O
Wiki_data -X- _ B-DatasetName
, -X- _ O
in -X- _ O
a -X- _ O
sequential -X- _ O
fashion -X- _ O
, -X- _ O
that -X- _ O
is -X- _ O
, -X- _ O
the -X- _ O
model -X- _ O
is -X- _ O
first -X- _ O
trained -X- _ O
on -X- _ O
the -X- _ O
Quora -X- _ O
data -X- _ O
, -X- _ O
then -X- _ O
Twitter -X- _ O
, -X- _ O
then -X- _ O
Wiki_data -X- _ O
. -X- _ O
We -X- _ O
name -X- _ O
this -X- _ O
experimental -X- _ O
setting -X- _ O
as -X- _ O
QTW -X- _ O
. -X- _ O
Statistics -X- _ O
of -X- _ O
the -X- _ O
data -X- _ O
are -X- _ O
provided -X- _ O
in -X- _ O
Table -X- _ O
1 -X- _ O
. -X- _ O

• -X- _ O
Finetune -X- _ B-MethodName
: -X- _ O
for -X- _ O
each -X- _ O
task -X- _ O
, -X- _ O
each -X- _ O
model -X- _ O
is -X- _ O
initialized -X- _ O
with -X- _ O
the -X- _ O
model -X- _ O
obtained -X- _ O
until -X- _ O
the -X- _ O
last -X- _ O
task -X- _ O
, -X- _ O
and -X- _ O
then -X- _ O
fine -X- _ O
- -X- _ O
tuned -X- _ O
with -X- _ O
the -X- _ O
data -X- _ O
of -X- _ O
the -X- _ O
current -X- _ O
task -X- _ O
. -X- _ O

• -X- _ O
Full -X- _ B-MethodName
: -X- _ O
we -X- _ O
train -X- _ O
a -X- _ O
model -X- _ O
with -X- _ O
all -X- _ O
the -X- _ O
three -X- _ O
data -X- _ O
sets -X- _ O
together -X- _ O
. -X- _ O

• -X- _ O
EWC -X- _ B-MethodName
: -X- _ O
the -X- _ O
model -X- _ O
is -X- _ O
trained -X- _ O
with -X- _ O
the -X- _ O
base -X- _ O
EWC -X- _ O
model -X- _ O
on -X- _ O
the -X- _ O
data -X- _ O
from -X- _ O
the -X- _ O
current -X- _ O
task -X- _ O
with -X- _ O
the -X- _ O
initialization -X- _ O
of -X- _ O
the -X- _ O
previous -X- _ O
model -X- _ O
. -X- _ O

For -X- _ O
evaluation -X- _ O
metrics -X- _ O
, -X- _ O
we -X- _ O
use -X- _ O
BLEU-4 -X- _ B-MetricName
, -X- _ O
ROUGE -X- _ B-MetricName
- -X- _ I-MetricName
L -X- _ I-MetricName
and -X- _ O
METEOR -X- _ B-MetricName
for -X- _ O
the -X- _ O
generation -X- _ O
task -X- _ O
. -X- _ O
Because -X- _ O
of -X- _ O
space -X- _ O
limit -X- _ O
, -X- _ O
we -X- _ O
only -X- _ O
report -X- _ O
bar -X- _ O
figures -X- _ O
with -X- _ O
METEOR -X- _ B-MetricName
scores -X- _ O
and -X- _ O
leave -X- _ O
tables -X- _ O
with -X- _ O
full -X- _ O
scores -X- _ O
in -X- _ O
the -X- _ O
Appendix -X- _ O
. -X- _ O
To -X- _ O
measure -X- _ O
the -X- _ O
forgetting -X- _ O
rates -X- _ O
of -X- _ O
different -X- _ O
methods -X- _ O
, -X- _ O
we -X- _ O
apply -X- _ O
models -X- _ O
trained -X- _ O
using -X- _ O
new -X- _ O
data -X- _ O
to -X- _ O
past -X- _ O
data -X- _ O
. -X- _ O

For -X- _ O
QTW -X- _ O
setting -X- _ O
, -X- _ O
Figure -X- _ O
3 -X- _ O
shows -X- _ O
results -X- _ O
when -X- _ O
models -X- _ O
are -X- _ O
evaluated -X- _ O
on -X- _ O
the -X- _ O
data -X- _ O
corresponding -X- _ O
to -X- _ O
the -X- _ O
current -X- _ O
task -X- _ O
. -X- _ O
Note -X- _ O
that -X- _ O
since -X- _ O
DSE -X- _ O
is -X- _ O
only -X- _ O
applicable -X- _ O
when -X- _ O
models -X- _ O
are -X- _ O
evaluated -X- _ O
on -X- _ O
the -X- _ O
past -X- _ O
data -X- _ O
, -X- _ O
we -X- _ O
do -X- _ O
not -X- _ O
use -X- _ O
DSE -X- _ O
in -X- _ O
this -X- _ O
experiment -X- _ O
. -X- _ O
From -X- _ O
left -X- _ O
to -X- _ O
right -X- _ O
are -X- _ O
domains -X- _ O
for -X- _ O
Quora -X- _ B-DatasetName
, -X- _ O
Twitter -X- _ B-DatasetName
and -X- _ O
Wik_data -X- _ B-DatasetName
respectively -X- _ O
. -X- _ O

Evaluating -X- _ O
on -X- _ O
Previous -X- _ O
Tasks -X- _ O
Figure -X- _ O
4 -X- _ O
shows -X- _ O
the -X- _ O
results -X- _ O
when -X- _ O
models -X- _ O
trained -X- _ O
on -X- _ O
new -X- _ O
domains -X- _ O
are -X- _ O
evaluated -X- _ O
on -X- _ O
data -X- _ O
from -X- _ O
past -X- _ O
domains -X- _ O
. -X- _ O
Since -X- _ O
we -X- _ O
only -X- _ O
report -X- _ O
results -X- _ O
of -X- _ O
QTW -X- _ O
setting -X- _ O
in -X- _ O
the -X- _ O
main -X- _ O
page -X- _ O
, -X- _ O
they -X- _ O
are -X- _ O
presented -X- _ O
for -X- _ O
evaluating -X- _ O
on -X- _ O
Quora -X- _ O
and -X- _ O
Twitter -X- _ O
data -X- _ O
. -X- _ O
For -X- _ O
the -X- _ O
Quora -X- _ O
test -X- _ O
set -X- _ O
, -X- _ O
we -X- _ O
show -X- _ O
results -X- _ O
after -X- _ O
training -X- _ O
with -X- _ O
Twitter -X- _ O
data -X- _ O
, -X- _ O
and -X- _ O
then -X- _ O
subsequently -X- _ O
Wik_data -X- _ O
. -X- _ O
The -X- _ O
first -X- _ O
bar -X- _ O
of -X- _ O
each -X- _ O
domain -X- _ O
is -X- _ O
the -X- _ O
result -X- _ O
of -X- _ O
the -X- _ O
BART -X- _ O
model -X- _ O
trained -X- _ O
on -X- _ O
only -X- _ O
the -X- _ O
corresponding -X- _ O
data -X- _ O
. -X- _ O
The -X- _ O
second -X- _ O
bar -X- _ O
uses -X- _ O
the -X- _ O
baseline -X- _ O
fine -X- _ O
tuning -X- _ O
fashion -X- _ O
. -X- _ O
We -X- _ O
show -X- _ O
results -X- _ O
using -X- _ O
our -X- _ O
proposed -X- _ O
method -X- _ O
, -X- _ O
RMR_DSE -X- _ B-MethodName
, -X- _ O
and -X- _ O
its -X- _ O
individual -X- _ O
components -X- _ O
, -X- _ O
MR -X- _ O
, -X- _ O
RMR -X- _ O
, -X- _ O
and -X- _ O
DSE -X- _ O
. -X- _ O
Each -X- _ O
of -X- _ O
them -X- _ O
yields -X- _ O
much -X- _ O
better -X- _ O
results -X- _ O
than -X- _ O
the -X- _ O
finetune -X- _ O
or -X- _ O
EWC -X- _ O
baselines -X- _ O
, -X- _ O
with -X- _ O
much -X- _ O
less -X- _ O
drop -X- _ O
rates -X- _ O
. -X- _ O
On -X- _ O
all -X- _ O
the -X- _ O
datasets -X- _ O
, -X- _ O
we -X- _ O
can -X- _ O
see -X- _ O
the -X- _ O
incremental -X- _ O
improvement -X- _ O
from -X- _ O
MR -X- _ O
to -X- _ O
RMR -X- _ O
and -X- _ O
to -X- _ O
RMR_DSE -X- _ O
. -X- _ O
This -X- _ O
shows -X- _ O
each -X- _ O
module -X- _ O
can -X- _ O
reduce -X- _ O
forget -X- _ O
rates -X- _ O
. -X- _ O
In -X- _ O
addition -X- _ O
, -X- _ O
after -X- _ O
the -X- _ O
model -X- _ O
is -X- _ O
trained -X- _ O
on -X- _ O
Wik_data -X- _ O
, -X- _ O
forgetting -X- _ O
rates -X- _ O
for -X- _ O
Quora -X- _ O
Test -X- _ O
( -X- _ O
the -X- _ O
first -X- _ O
dataset -X- _ O
) -X- _ O
are -X- _ O
even -X- _ O
lower -X- _ O
than -X- _ O
the -X- _ O
model -X- _ O
trained -X- _ O
on -X- _ O
Twitter -X- _ O
. -X- _ O
This -X- _ O
again -X- _ O
indicates -X- _ O
Wik_data -X- _ O
and -X- _ O
Quora -X- _ O
are -X- _ O
more -X- _ O
similar -X- _ O
in -X- _ O
style -X- _ O
than -X- _ O
Twitter -X- _ O
. -X- _ O

• -X- _ O
Finetune -X- _ B-MethodName
: -X- _ O
This -X- _ O
is -X- _ O
finetuning -X- _ O
the -X- _ O
model -X- _ O
trained -X- _ O
from -X- _ O
the -X- _ O
previous -X- _ O
domain -X- _ O
using -X- _ O
data -X- _ O
for -X- _ O
the -X- _ O
current -X- _ O
domain -X- _ O
. -X- _ O

• -X- _ O
Full -X- _ B-MethodName
: -X- _ O
This -X- _ O
is -X- _ O
using -X- _ O
the -X- _ O
data -X- _ O
from -X- _ O
all -X- _ O
the -X- _ O
domains -X- _ O
. -X- _ O

• -X- _ O
ARPER -X- _ B-MethodName
: -X- _ O
We -X- _ O
run -X- _ O
ARPER -X- _ O
following -X- _ O
the -X- _ O
setting -X- _ O
of -X- _ O
the -X- _ O
original -X- _ O
paper -X- _ O
( -X- _ O
Mi -X- _ O
et -X- _ O
al -X- _ O
. -X- _ O
, -X- _ O
2020 -X- _ O
) -X- _ O
. -X- _ O

• -X- _ O
EWC -X- _ B-MethodName
: -X- _ O
ARPER -X- _ O
without -X- _ O
exemplars -X- _ O
is -X- _ O
EWC -X- _ O
. -X- _ O

Throughout -X- _ O
the -X- _ O
paper -X- _ O
, -X- _ O
we -X- _ O
use -X- _ O
those -X- _ O
evaluation -X- _ O
metrics -X- _ O
that -X- _ O
have -X- _ O
been -X- _ O
widely -X- _ O
used -X- _ O
in -X- _ O
the -X- _ O
previous -X- _ O
work -X- _ O
to -X- _ O
measure -X- _ O
the -X- _ O
quality -X- _ O
of -X- _ O
the -X- _ O
paraphrases -X- _ O
. -X- _ O
In -X- _ O
general -X- _ O
, -X- _ O
BLEU -X- _ B-MetricName
measures -X- _ O
how -X- _ O
much -X- _ O
the -X- _ O
words -X- _ O
( -X- _ O
and -X- _ O
/ -X- _ O
or -X- _ O
n -X- _ O
- -X- _ O
grams -X- _ O
) -X- _ O
in -X- _ O
the -X- _ O
machine -X- _ O
generated -X- _ O
summaries -X- _ O
appeared -X- _ O
in -X- _ O
the -X- _ O
human -X- _ O
reference -X- _ O
summaries -X- _ O
. -X- _ O
Rouge -X- _ O
measures -X- _ O
how -X- _ O
much -X- _ O
the -X- _ O
words -X- _ O
( -X- _ O
and -X- _ O
/ -X- _ O
or -X- _ O
ngrams -X- _ O
) -X- _ O
in -X- _ O
the -X- _ O
human -X- _ O
reference -X- _ O
summaries -X- _ O
appeared -X- _ O
in -X- _ O
the -X- _ O
machine -X- _ O
generated -X- _ O
summaries -X- _ O
. -X- _ O
Specifically -X- _ O
, -X- _ O
we -X- _ O
use -X- _ O
the -X- _ O
library -X- _ O
1 -X- _ O
from -X- _ O
HuggingFace -X- _ O
to -X- _ O
compute -X- _ O
BLEU -X- _ B-MetricName
scores -X- _ O
and -X- _ O
py -X- _ O
- -X- _ O
rouge -X- _ O
2 -X- _ O
to -X- _ O
compute -X- _ O
ROUGE -X- _ B-MetricName
scores -X- _ O
. -X- _ O
As -X- _ O
BLEU -X- _ O
and -X- _ O
ROUGE -X- _ O
could -X- _ O
not -X- _ O
measure -X- _ O
the -X- _ O
diversity -X- _ O
between -X- _ O
the -X- _ O
generated -X- _ O
and -X- _ O
the -X- _ O
original -X- _ O
sentences -X- _ O
, -X- _ O
we -X- _ O
follow -X- _ O
unsupervised -X- _ O
paraphrasing -X- _ O
methods -X- _ O
and -X- _ O
adopt -X- _ O
meteor -X- _ O
to -X- _ O
measure -X- _ O
the -X- _ O
diversity -X- _ O
of -X- _ O
expression -X- _ O
in -X- _ O
the -X- _ O
generated -X- _ O
paraphrases -X- _ O
by -X- _ O
penalizing -X- _ O
copying -X- _ O
words -X- _ O
from -X- _ O
input -X- _ O
sentences -X- _ O
. -X- _ O
The -X- _ O
introduction -X- _ O
of -X- _ O
Slot -X- _ B-MetricName
error -X- _ I-MetricName
rate -X- _ I-MetricName
, -X- _ O
Ω -X- _ O
all -X- _ O
and -X- _ O
Ω -X- _ O
f -X- _ O
irst -X- _ O
can -X- _ O
be -X- _ O
seen -X- _ O
in -X- _ O
the -X- _ O
data -X- _ O
setting -X- _ O
of -X- _ O
MultiWoz2 -X- _ O
. -X- _ O

A.3 -X- _ O
Bleu4 -X- _ O
scores -X- _ O
for -X- _ O
MultiWoZ-2.0 -X- _ O
dataset -X- _ O
Due -X- _ O
to -X- _ O
page -X- _ O
limit -X- _ O
, -X- _ O
we -X- _ O
put -X- _ O
figures -X- _ O
of -X- _ O
Bleu4 -X- _ O
for -X- _ O
MultiWoZ-2.0 -X- _ O
with -X- _ O
zero -X- _ O
exemplars -X- _ O
in -X- _ O
appendix -X- _ O
as -X- _ O
well -X- _ O
. -X- _ O
From -X- _ O
all -X- _ O
experiments -X- _ O
, -X- _ O
we -X- _ O
can -X- _ O
see -X- _ O
that -X- _ O
RMR_DSE -X- _ O
achieves -X- _ O
consistently -X- _ O
better -X- _ O
results -X- _ O
than -X- _ O
ARPER -X- _ O
. -X- _ O
Without -X- _ O
doubt -X- _ O
, -X- _ O
ARPER -X- _ B-MethodName
is -X- _ O
a -X- _ O
strong -X- _ O
baseline -X- _ O
. -X- _ O
Its -X- _ O
adaptive -X- _ O
EWC -X- _ O
enables -X- _ O
ARPER -X- _ O
to -X- _ O
update -X- _ O
parameters -X- _ O
discriminatively -X- _ O
. -X- _ O
However -X- _ O
, -X- _ O
RMR_DSE -X- _ O
can -X- _ O
update -X- _ O
parameters -X- _ O
more -X- _ O
differentially -X- _ O
with -X- _ O
its -X- _ O
memory -X- _ O
aware -X- _ O
penalty -X- _ O
mechanisms -X- _ O
. -X- _ O

RNSum -X- _ B-DatasetName
: -X- _ O
A -X- _ O
Large -X- _ O
- -X- _ O
Scale -X- _ O
Dataset -X- _ O
for -X- _ O
Automatic -X- _ O
Release -X- _ B-TaskName
Note -X- _ I-TaskName
Generation -X- _ I-TaskName
via -X- _ O
Commit -X- _ B-TaskName
Logs -X- _ I-TaskName
Summarization -X- _ I-TaskName

A -X- _ O
release -X- _ O
note -X- _ O
is -X- _ O
a -X- _ O
technical -X- _ O
document -X- _ O
that -X- _ O
describes -X- _ O
the -X- _ O
latest -X- _ O
changes -X- _ O
to -X- _ O
a -X- _ O
software -X- _ O
product -X- _ O
and -X- _ O
is -X- _ O
crucial -X- _ O
in -X- _ O
open -X- _ O
source -X- _ O
software -X- _ O
development -X- _ O
. -X- _ O
However -X- _ O
, -X- _ O
it -X- _ O
still -X- _ O
remains -X- _ O
challenging -X- _ O
to -X- _ O
generate -X- _ O
release -X- _ O
notes -X- _ O
automatically -X- _ O
. -X- _ O
In -X- _ O
this -X- _ O
paper -X- _ O
, -X- _ O
we -X- _ O
present -X- _ O
a -X- _ O
new -X- _ O
dataset -X- _ O
called -X- _ O
RNSum -X- _ B-DatasetName
, -X- _ O
which -X- _ O
contains -X- _ O
approximately -X- _ O
82,000 -X- _ O
English -X- _ O
release -X- _ O
notes -X- _ O
and -X- _ O
the -X- _ O
associated -X- _ O
commit -X- _ O
messages -X- _ O
derived -X- _ O
from -X- _ O
the -X- _ O
online -X- _ O
repositories -X- _ O
in -X- _ O
GitHub -X- _ O
. -X- _ O
Then -X- _ O
, -X- _ O
we -X- _ O
propose -X- _ O
classwise -X- _ O
extractivethen -X- _ O
- -X- _ O
abstractive -X- _ O
/ -X- _ O
abstractive -X- _ O
summarization -X- _ B-TaskName
approaches -X- _ O
to -X- _ O
this -X- _ O
task -X- _ O
, -X- _ O
which -X- _ O
can -X- _ O
employ -X- _ O
a -X- _ O
modern -X- _ O
transformer -X- _ O
- -X- _ O
based -X- _ O
seq2seq -X- _ O
network -X- _ O
like -X- _ O
BART -X- _ O
and -X- _ O
can -X- _ O
be -X- _ O
applied -X- _ O
to -X- _ O
various -X- _ O
repositories -X- _ O
without -X- _ O
specific -X- _ O
constraints -X- _ O
. -X- _ O
The -X- _ O
experimental -X- _ O
results -X- _ O
on -X- _ O
the -X- _ O
RNSum -X- _ O
dataset -X- _ O
show -X- _ O
that -X- _ O
the -X- _ O
proposed -X- _ O
methods -X- _ O
can -X- _ O
generate -X- _ O
less -X- _ O
noisy -X- _ O
release -X- _ O
notes -X- _ O
at -X- _ O
higher -X- _ O
coverage -X- _ O
than -X- _ O
the -X- _ O
baselines -X- _ O
. -X- _ O
We -X- _ O
also -X- _ O
observe -X- _ O
that -X- _ O
there -X- _ O
is -X- _ O
a -X- _ O
significant -X- _ O
gap -X- _ O
in -X- _ O
the -X- _ O
coverage -X- _ O
of -X- _ O
essential -X- _ O
information -X- _ O
when -X- _ O
compared -X- _ O
to -X- _ O
human -X- _ O
references -X- _ O
. -X- _ O
Our -X- _ O
dataset -X- _ O
and -X- _ O
the -X- _ O
code -X- _ O
are -X- _ O
publicly -X- _ O
available -X- _ O
. -X- _ O

The -X- _ O
difficulty -X- _ O
of -X- _ O
this -X- _ O
task -X- _ O
is -X- _ O
that -X- _ O
there -X- _ O
is -X- _ O
no -X- _ O
explicit -X- _ O
alignment -X- _ O
between -X- _ O
each -X- _ O
commit -X- _ O
message -X- _ O
and -X- _ O
the -X- _ O
release -X- _ O
note -X- _ O
categories -X- _ O
. -X- _ O
For -X- _ O
example -X- _ O
, -X- _ O
in -X- _ O
Figure -X- _ O
1 -X- _ O
, -X- _ O
the -X- _ O
first -X- _ O
commit -X- _ O
message -X- _ O
( -X- _ O
" -X- _ O
chore -X- _ O
: -X- _ O
make -X- _ O
documentation -X- _ O
clearer -X- _ O
( -X- _ O
# -X- _ O
9450 -X- _ O
) -X- _ O
" -X- _ O
) -X- _ O
is -X- _ O
not -X- _ O
reflected -X- _ O
in -X- _ O
the -X- _ O
release -X- _ O
notes -X- _ O
. -X- _ O
In -X- _ O
contrast -X- _ O
, -X- _ O
the -X- _ O
second -X- _ O
commit -X- _ O
message -X- _ O
( -X- _ O
" -X- _ O
fix -X- _ O
: -X- _ O
empty -X- _ O
scoped -X- _ O
slot -X- _ O
should -X- _ O
return -X- _ O
undefined -X- _ O
fix -X- _ O
# -X- _ O
9452 -X- _ O
" -X- _ O
) -X- _ O
is -X- _ O
reflected -X- _ O
as -X- _ O
the -X- _ O
third -X- _ O
release -X- _ O
note -X- _ O
in -X- _ O
the -X- _ O
Bug -X- _ O
Fixes -X- _ O
class -X- _ O
. -X- _ O
We -X- _ O
propose -X- _ O
two -X- _ O
approaches -X- _ O
to -X- _ O
this -X- _ O
task -X- _ O
: -X- _ O
Classwise -X- _ B-MethodName
Extractive -X- _ I-MethodName
- -X- _ I-MethodName
then -X- _ I-MethodName
- -X- _ I-MethodName
Abstractive -X- _ I-MethodName
Summarization -X- _ I-MethodName
( -X- _ I-MethodName
CEAS -X- _ I-MethodName
) -X- _ I-MethodName
and -X- _ O
Classwise -X- _ B-MethodName
Abstractive -X- _ I-MethodName
Summarization -X- _ I-MethodName
( -X- _ I-MethodName
CAS -X- _ I-MethodName
) -X- _ I-MethodName
models -X- _ O
, -X- _ O
which -X- _ O
learn -X- _ O
to -X- _ O
produce -X- _ O
categorized -X- _ O
release -X- _ O
notes -X- _ O
given -X- _ O
unlabeled -X- _ O
commit -X- _ O
messages -X- _ O
in -X- _ O
extractive -X- _ O
and -X- _ O
abstractive -X- _ O
manners -X- _ O
, -X- _ O
respectively -X- _ O
. -X- _ O
The -X- _ O
two -X- _ O
proposed -X- _ O
models -X- _ O
can -X- _ O
leverage -X- _ O
modern -X- _ O
transformer -X- _ O
- -X- _ O
based -X- _ O
sequence -X- _ O
- -X- _ O
to -X- _ O
- -X- _ O
sequence -X- _ O
( -X- _ O
seq2seq -X- _ O
) -X- _ O
architectures -X- _ O
( -X- _ O
e.g. -X- _ O
, -X- _ O
BART -X- _ O
( -X- _ O
Lewis -X- _ O
et -X- _ O
al -X- _ O
. -X- _ O
, -X- _ O
2020 -X- _ O
) -X- _ O
) -X- _ O
and -X- _ O
can -X- _ O
be -X- _ O
used -X- _ O
for -X- _ O
various -X- _ O
repositories -X- _ O
without -X- _ O
any -X- _ O
special -X- _ O
constraints -X- _ O
. -X- _ O

We -X- _ O
evaluate -X- _ O
the -X- _ O
proposed -X- _ O
models -X- _ O
and -X- _ O
the -X- _ O
previous -X- _ O
systems -X- _ O
on -X- _ O
the -X- _ O
RNSum -X- _ B-DatasetName
dataset -X- _ O
and -X- _ O
report -X- _ O
that -X- _ O
our -X- _ O
approaches -X- _ O
generate -X- _ O
less -X- _ O
noisy -X- _ O
release -X- _ O
notes -X- _ O
at -X- _ O
higher -X- _ O
coverage -X- _ O
than -X- _ O
the -X- _ O
baselines -X- _ O
given -X- _ O
only -X- _ O
unlabeled -X- _ O
commit -X- _ O
messages -X- _ O
. -X- _ O
We -X- _ O
also -X- _ O
perform -X- _ O
human -X- _ O
evaluations -X- _ O
carefully -X- _ O
to -X- _ O
assess -X- _ O
how -X- _ O
well -X- _ O
the -X- _ O
systems -X- _ O
could -X- _ O
generate -X- _ O
release -X- _ O
notes -X- _ O
in -X- _ O
terms -X- _ O
of -X- _ O
quality -X- _ B-MetricName
( -X- _ O
precision -X- _ B-MetricName
) -X- _ O
and -X- _ O
coverage -X- _ B-MetricName
( -X- _ O
recall -X- _ B-MetricName
) -X- _ O
, -X- _ O
revealing -X- _ O
that -X- _ O
there -X- _ O
still -X- _ O
remains -X- _ O
a -X- _ O
significant -X- _ O
gap -X- _ O
in -X- _ O
the -X- _ O
coverage -X- _ O
when -X- _ O
compared -X- _ O
to -X- _ O
human -X- _ O
references -X- _ O
. -X- _ O
Our -X- _ O
dataset -X- _ O
and -X- _ O
the -X- _ O
source -X- _ O
code -X- _ O
are -X- _ O
publicly -X- _ O
available -X- _ O
. -X- _ O
1 -X- _ O

RNSum -X- _ B-DatasetName
Dataset -X- _ O

We -X- _ O
investigate -X- _ O
the -X- _ O
statistics -X- _ O
of -X- _ O
the -X- _ O
RNsum -X- _ O
dataset -X- _ O
. -X- _ O
Table -X- _ O
2 -X- _ O
summarizes -X- _ O
the -X- _ O
results -X- _ O
. -X- _ O
Our -X- _ O
dataset -X- _ O
consists -X- _ O
of -X- _ O
81,996 -X- _ O
release -X- _ O
notes -X- _ O
from -X- _ O
7,216 -X- _ O
repositories -X- _ O
in -X- _ O
total -X- _ O
. -X- _ O
The -X- _ O
average -X- _ O
number -X- _ O
of -X- _ O
release -X- _ O
note -X- _ O
sentences -X- _ O
and -X- _ O
commit -X- _ O
messages -X- _ O
per -X- _ O
release -X- _ O
note -X- _ O
is -X- _ O
3.3 -X- _ O
and -X- _ O
14.9 -X- _ O
, -X- _ O
respectively -X- _ O
. -X- _ O
The -X- _ O
average -X- _ O
number -X- _ O
of -X- _ O
tokens -X- _ O
in -X- _ O
release -X- _ O
notes -X- _ O
and -X- _ O
commit -X- _ O
messages -X- _ O
are -X- _ O
63.3 -X- _ O
and -X- _ O
260.4 -X- _ O
, -X- _ O
respectively -X- _ O
. -X- _ O
5 -X- _ O
The -X- _ O
number -X- _ O
of -X- _ O
unique -X- _ O
word -X- _ O
types -X- _ O
( -X- _ O
i.e. -X- _ O
, -X- _ O
vocabulary -X- _ B-HyperparameterName
size -X- _ I-HyperparameterName
) -X- _ O
is -X- _ O
833,984 -X- _ B-HyperparameterValue
, -X- _ O
which -X- _ O
is -X- _ O
significantly -X- _ O
large -X- _ O
because -X- _ O
many -X- _ O
project -X- _ O
- -X- _ O
specific -X- _ O
terms -X- _ O
such -X- _ O
as -X- _ O
class -X- _ O
and -X- _ O
method -X- _ O
names -X- _ O
are -X- _ O
detected -X- _ O
. -X- _ O

We -X- _ O
also -X- _ O
examine -X- _ O
the -X- _ O
word -X- _ B-MetricName
overlap -X- _ I-MetricName
rate -X- _ I-MetricName
of -X- _ O
the -X- _ O
commit -X- _ O
messages -X- _ O
against -X- _ O
the -X- _ O
release -X- _ O
notes -X- _ O
. -X- _ O
We -X- _ O
remove -X- _ O
special -X- _ O
symbols -X- _ O
such -X- _ O
as -X- _ O
URL -X- _ O
, -X- _ O
hash -X- _ O
values -X- _ O
, -X- _ O
and -X- _ O
issue -X- _ O
numbers -X- _ O
by -X- _ O
using -X- _ O
the -X- _ O
spaCy -X- _ O
POS -X- _ O
tagger -X- _ O
. -X- _ O
6 -X- _ O
The -X- _ O
resulting -X- _ O
overlap -X- _ O
rate -X- _ O
is -X- _ O
56.7 -X- _ B-MetricValue
% -X- _ I-MetricValue
, -X- _ O
indicating -X- _ O
that -X- _ O
extractive -X- _ O
approaches -X- _ O
( -X- _ O
e.g. -X- _ O
, -X- _ O
Glyph -X- _ O
) -X- _ O
, -X- _ O
which -X- _ O
simply -X- _ O
classify -X- _ O
commit -X- _ O
messages -X- _ O
into -X- _ O
a -X- _ O
fixed -X- _ O
set -X- _ O
of -X- _ O
predefined -X- _ O
classes -X- _ O
, -X- _ O
has -X- _ O
a -X- _ O
limitation -X- _ O
to -X- _ O
achieving -X- _ O
higher -X- _ O
recall -X- _ O
. -X- _ O
7 -X- _ O
The -X- _ O
result -X- _ O
also -X- _ O
indicates -X- _ O
that -X- _ O
information -X- _ O
outside -X- _ O
the -X- _ O
commit -X- _ O
messages -X- _ O
( -X- _ O
e.g. -X- _ O
, -X- _ O
pull -X- _ O
requests -X- _ O
, -X- _ O
issues -X- _ O
associated -X- _ O
with -X- _ O
the -X- _ O
commit -X- _ O
messages -X- _ O
) -X- _ O
may -X- _ O
improve -X- _ O
the -X- _ O
performance -X- _ O
further -X- _ O
, -X- _ O
which -X- _ O
we -X- _ O
leave -X- _ O
left -X- _ O
for -X- _ O
future -X- _ O
work -X- _ O
. -X- _ O

Automatic -X- _ O
release -X- _ O
note -X- _ O
generation -X- _ O
can -X- _ O
be -X- _ O
viewed -X- _ O
as -X- _ O
a -X- _ O
task -X- _ O
of -X- _ O
summarizing -X- _ O
commit -X- _ O
messages -X- _ O
x -X- _ O
into -X- _ O
the -X- _ O
labeled -X- _ O
release -X- _ O
notes -X- _ O
y -X- _ O
c -X- _ O
. -X- _ O
In -X- _ O
this -X- _ O
paper -X- _ O
, -X- _ O
we -X- _ O
introduce -X- _ O
Classwise -X- _ B-MethodName
Extractive -X- _ I-MethodName
- -X- _ I-MethodName
then -X- _ I-MethodName
- -X- _ I-MethodName
Abstractive -X- _ I-MethodName
Summarization -X- _ I-MethodName
( -X- _ I-MethodName
CEAS -X- _ I-MethodName
) -X- _ I-MethodName
and -X- _ O
Classwise -X- _ B-MethodName
Abstractive -X- _ I-MethodName
Summarization -X- _ I-MethodName
( -X- _ I-MethodName
CAS -X- _ I-MethodName
) -X- _ I-MethodName
models -X- _ O
, -X- _ O
which -X- _ O
we -X- _ O
instantiate -X- _ O
by -X- _ O
modern -X- _ O
transformer -X- _ O
- -X- _ O
based -X- _ O
sequence -X- _ O
- -X- _ O
to -X- _ O
- -X- _ O
sequence -X- _ O
( -X- _ O
seq2seq -X- _ O
) -X- _ O
networks -X- _ O
and -X- _ O
can -X- _ O
be -X- _ O
universally -X- _ O
used -X- _ O
in -X- _ O
various -X- _ O
repositories -X- _ O
without -X- _ O
any -X- _ O
special -X- _ O
constraints -X- _ O
. -X- _ O

We -X- _ O
divided -X- _ O
the -X- _ O
RNSum -X- _ O
dataset -X- _ O
into -X- _ O
training -X- _ B-HyperparameterName
, -X- _ I-HyperparameterName
validation -X- _ I-HyperparameterName
, -X- _ I-HyperparameterName
and -X- _ I-HyperparameterName
test -X- _ I-HyperparameterName
splits -X- _ I-HyperparameterName
, -X- _ O
each -X- _ O
containing -X- _ O
74 -X- _ B-HyperparameterValue
K -X- _ I-HyperparameterValue
, -X- _ I-HyperparameterValue
4 -X- _ I-HyperparameterValue
K -X- _ I-HyperparameterValue
, -X- _ I-HyperparameterValue
and -X- _ I-HyperparameterValue
4 -X- _ I-HyperparameterValue
K -X- _ I-HyperparameterValue
examples -X- _ O
. -X- _ O
To -X- _ O
avoid -X- _ O
data -X- _ O
leaks -X- _ O
, -X- _ O
examples -X- _ O
derived -X- _ O
from -X- _ O
the -X- _ O
same -X- _ O
repository -X- _ O
did -X- _ O
not -X- _ O
belong -X- _ O
to -X- _ O
multiple -X- _ O
splits -X- _ O
. -X- _ O
We -X- _ O
also -X- _ O
removed -X- _ O
the -X- _ O
training -X- _ O
examples -X- _ O
with -X- _ O
release -X- _ O
note -X- _ O
text -X- _ O
( -X- _ O
after -X- _ O
concatenation -X- _ O
) -X- _ O
of -X- _ O
longer -X- _ O
than -X- _ O
500 -X- _ O
tokens -X- _ O
to -X- _ O
shorten -X- _ O
the -X- _ O
training -X- _ O
time -X- _ O
. -X- _ O

Since -X- _ O
a -X- _ O
release -X- _ O
note -X- _ O
y -X- _ O
c -X- _ O
can -X- _ O
consist -X- _ O
of -X- _ O
multiple -X- _ O
sentences -X- _ O
, -X- _ O
we -X- _ O
concatenate -X- _ O
the -X- _ O
sentences -X- _ O
by -X- _ O
inserting -X- _ O
spaces -X- _ O
and -X- _ O
represent -X- _ O
the -X- _ O
release -X- _ O
note -X- _ O
as -X- _ O
one -X- _ O
long -X- _ O
text -X- _ O
in -X- _ O
evaluation -X- _ O
. -X- _ O
Following -X- _ O
the -X- _ O
conventional -X- _ O
summarization -X- _ B-TaskName
literature -X- _ O
, -X- _ O
we -X- _ O
employ -X- _ O
ROUGE -X- _ B-MetricName
( -X- _ O
Lin -X- _ O
, -X- _ O
2004 -X- _ O
) -X- _ O
as -X- _ O
the -X- _ O
automatic -X- _ O
evaluation -X- _ O
metric -X- _ O
. -X- _ O
We -X- _ O
also -X- _ O
employ -X- _ O
BLEU -X- _ B-MetricName
( -X- _ O
Papineni -X- _ O
et -X- _ O
al -X- _ O
. -X- _ O
, -X- _ O
2002 -X- _ O
) -X- _ O
to -X- _ O
evaluate -X- _ O
the -X- _ O
fluency -X- _ O
of -X- _ O
generated -X- _ O
release -X- _ O
notes -X- _ O
. -X- _ O
Specifically -X- _ O
, -X- _ O
we -X- _ O
compute -X- _ O
ROUGE -X- _ B-MetricName
- -X- _ I-MetricName
L -X- _ I-MetricName
( -X- _ O
F1 -X- _ B-MetricName
) -X- _ O
, -X- _ O
BLEU-3 -X- _ B-MetricName
, -X- _ O
and -X- _ O
BLEU-4 -X- _ B-MetricName
scores -X- _ O
. -X- _ O
8 -X- _ O
We -X- _ O
skip -X- _ O
a -X- _ O
test -X- _ O
example -X- _ O
if -X- _ O
the -X- _ O
reference -X- _ O
text -X- _ O
is -X- _ O
empty -X- _ O
. -X- _ O
It -X- _ O
is -X- _ O
also -X- _ O
important -X- _ O
for -X- _ O
the -X- _ O
system -X- _ O
not -X- _ O
to -X- _ O
generate -X- _ O
release -X- _ O
notes -X- _ O
when -X- _ O
the -X- _ O
reference -X- _ O
release -X- _ O
note -X- _ O
is -X- _ O
empty -X- _ O
( -X- _ O
i.e. -X- _ O
, -X- _ O
y -X- _ O
c -X- _ O
= -X- _ O
∅ -X- _ O
) -X- _ O
. -X- _ O
To -X- _ O
evaluate -X- _ O
such -X- _ O
ability -X- _ O
, -X- _ O
we -X- _ O
also -X- _ O
compute -X- _ O
Specificity -X- _ O
, -X- _ O
i.e. -X- _ O
, -X- _ O
TN -X- _ O
TN+FP -X- _ O
, -X- _ O
where -X- _ O
positive -X- _ O
means -X- _ O
that -X- _ O
the -X- _ O
generated -X- _ O
release -X- _ O
note -X- _ O
is -X- _ O
NOT -X- _ O
empty -X- _ O
. -X- _ O

As -X- _ O
baseline -X- _ O
systems -X- _ O
for -X- _ O
comparison -X- _ O
, -X- _ O
we -X- _ O
develop -X- _ O
Glyph -X- _ B-MethodName
( -X- _ O
Pokorný -X- _ O
, -X- _ O
2020 -X- _ O
) -X- _ O
and -X- _ O
a -X- _ O
clustering -X- _ O
- -X- _ O
based -X- _ O
commit -X- _ O
message -X- _ O
classifier -X- _ O
. -X- _ O
These -X- _ O
baselines -X- _ O
are -X- _ O
extractive -X- _ O
summarization -X- _ O
methods -X- _ O
because -X- _ O
these -X- _ O
methods -X- _ O
generate -X- _ O
release -X- _ O
notes -X- _ O
by -X- _ O
just -X- _ O
classifying -X- _ O
each -X- _ O
input -X- _ O
commit -X- _ O
message -X- _ O
into -X- _ O
a -X- _ O
fixed -X- _ O
set -X- _ O
of -X- _ O
releasenote -X- _ O
classes -X- _ O
. -X- _ O
In -X- _ O
contrast -X- _ O
, -X- _ O
CEAS -X- _ B-MethodName
and -X- _ O
CAS -X- _ B-MethodName
employ -X- _ O
seq2seq -X- _ O
generators -X- _ O
to -X- _ O
transform -X- _ O
input -X- _ O
commit -X- _ O
messages -X- _ O
into -X- _ O
novel -X- _ O
texts -X- _ O
. -X- _ O

Glyph -X- _ B-MethodName
Glyph -X- _ B-MethodName
is -X- _ O
a -X- _ O
publicly -X- _ O
available -X- _ O
commit -X- _ O
message -X- _ O
classifier -X- _ O
, -X- _ O
which -X- _ O
groups -X- _ O
each -X- _ O
input -X- _ O
commit -X- _ O
message -X- _ O
into -X- _ O
the -X- _ O
following -X- _ O
five -X- _ O
classes -X- _ O
: -X- _ O
Features -X- _ O
, -X- _ O
Improvements -X- _ O
, -X- _ O
Bug -X- _ O
Fixes -X- _ O
, -X- _ O
Non -X- _ O
- -X- _ O
functional -X- _ O
, -X- _ O
and -X- _ O
Other -X- _ O
. -X- _ O
The -X- _ O
text -X- _ O
classification -X- _ O
model -X- _ O
relies -X- _ O
simply -X- _ O
on -X- _ O
pretrained -X- _ O
word -X- _ O
embeddings -X- _ O
in -X- _ O
fastText -X- _ O
( -X- _ O
Joulin -X- _ O
et -X- _ O
al -X- _ O
. -X- _ O
, -X- _ O
2017 -X- _ O
) -X- _ O
. -X- _ O
Since -X- _ O
the -X- _ O
Non -X- _ O
- -X- _ O
functional -X- _ O
class -X- _ O
is -X- _ O
not -X- _ O
included -X- _ O
in -X- _ O
our -X- _ O
task -X- _ O
, -X- _ O
we -X- _ O
exclude -X- _ O
the -X- _ O
commit -X- _ O
messages -X- _ O
classified -X- _ O
as -X- _ O
Other -X- _ O
or -X- _ O
Non -X- _ O
- -X- _ O
functional -X- _ O
from -X- _ O
the -X- _ O
output -X- _ O
. -X- _ O
It -X- _ O
must -X- _ O
be -X- _ O
noted -X- _ O
here -X- _ O
that -X- _ O
Glyph -X- _ O
can -X- _ O
not -X- _ O
generate -X- _ O
the -X- _ O
Deprecations+ -X- _ O
class -X- _ O
. -X- _ O

CEAS -X- _ B-MethodName
We -X- _ O
employ -X- _ O
BERT -X- _ B-MethodName
( -X- _ O
Devlin -X- _ O
et -X- _ O
al -X- _ O
. -X- _ O
, -X- _ O
2019 -X- _ O
) -X- _ O
and -X- _ O
CodeBERT -X- _ B-MethodName
( -X- _ O
Feng -X- _ O
et -X- _ O
al -X- _ O
. -X- _ O
, -X- _ O
2020 -X- _ O
) -X- _ O
as -X- _ O
the -X- _ O
commit -X- _ O
message -X- _ O
classifier -X- _ O
F -X- _ O
. -X- _ O
CodeBERT -X- _ O
is -X- _ O
a -X- _ O
bimodal -X- _ O
pre -X- _ O
- -X- _ O
trained -X- _ O
model -X- _ O
for -X- _ O
programming -X- _ O
language -X- _ O
and -X- _ O
natural -X- _ O
language -X- _ O
. -X- _ O
Specifically -X- _ O
, -X- _ O
we -X- _ O
apply -X- _ O
a -X- _ O
multilayer -X- _ O
perceptron -X- _ O
to -X- _ O
the -X- _ O
CLS -X- _ O
embedding -X- _ O
of -X- _ O
the -X- _ O
input -X- _ O
. -X- _ O
When -X- _ O
training -X- _ O
the -X- _ O
classifier -X- _ O
, -X- _ O
class -X- _ O
- -X- _ O
identifiable -X- _ O
words -X- _ O
, -X- _ O
such -X- _ O
as -X- _ O
" -X- _ O
fix -X- _ O
: -X- _ O
" -X- _ O
and -X- _ O
" -X- _ O
feat -X- _ O
: -X- _ O
" -X- _ O
, -X- _ O
are -X- _ O
removed -X- _ O
because -X- _ O
they -X- _ O
can -X- _ O
be -X- _ O
too -X- _ O
strong -X- _ O
class -X- _ O
indicators -X- _ O
. -X- _ O
We -X- _ O
describe -X- _ O
the -X- _ O
detail -X- _ O
of -X- _ O
removing -X- _ O
class -X- _ O
- -X- _ O
identifiable -X- _ O
words -X- _ O
in -X- _ O
the -X- _ O
Appendix -X- _ O
. -X- _ O
We -X- _ O
employ -X- _ O
BART -X- _ B-MethodName
( -X- _ O
Lewis -X- _ O
7 -X- _ O
Results -X- _ O
and -X- _ O
Discussion -X- _ O

We -X- _ O
also -X- _ O
show -X- _ O
the -X- _ O
results -X- _ O
on -X- _ O
the -X- _ O
cleaned -X- _ O
version -X- _ O
of -X- _ O
the -X- _ O
test -X- _ O
set -X- _ O
, -X- _ O
where -X- _ O
we -X- _ O
removed -X- _ O
URLs -X- _ O
, -X- _ O
hash -X- _ O
values -X- _ O
, -X- _ O
and -X- _ O
email -X- _ O
addresses -X- _ O
, -X- _ O
which -X- _ O
are -X- _ O
significantly -X- _ O
difficult -X- _ O
to -X- _ O
produce -X- _ O
accurately -X- _ O
. -X- _ O
CEAS -X- _ B-MethodName
and -X- _ O
CAS -X- _ B-MethodName
achieved -X- _ O
ROUGE -X- _ B-MetricName
- -X- _ I-MetricName
L -X- _ I-MetricName
scores -X- _ O
more -X- _ B-MetricValue
than -X- _ I-MetricValue
10 -X- _ I-MetricValue
points -X- _ I-MetricValue
higher -X- _ O
than -X- _ O
the -X- _ O
baselines -X- _ O
. -X- _ O
In -X- _ O
particular -X- _ O
, -X- _ O
on -X- _ O
the -X- _ O
cleaned -X- _ O
test -X- _ O
set -X- _ O
, -X- _ O
the -X- _ O
score -X- _ O
gap -X- _ O
between -X- _ O
the -X- _ O
proposed -X- _ O
methods -X- _ O
and -X- _ O
the -X- _ O
baselines -X- _ O
jumped -X- _ O
to -X- _ O
more -X- _ O
than -X- _ O
20 -X- _ O
points -X- _ O
. -X- _ O
These -X- _ O
results -X- _ O
indicate -X- _ O
that -X- _ O
CEAS -X- _ B-MethodName
and -X- _ O
CAS -X- _ B-MethodName
are -X- _ O
significantly -X- _ O
effective -X- _ O
. -X- _ O

In -X- _ O
addition -X- _ O
, -X- _ O
CEAS -X- _ O
got -X- _ O
a -X- _ O
better -X- _ O
ROUGE -X- _ B-MetricName
- -X- _ I-MetricName
L -X- _ I-MetricName
score -X- _ O
than -X- _ O
CAS -X- _ O
, -X- _ O
suggesting -X- _ O
that -X- _ O
combining -X- _ O
a -X- _ O
classifier -X- _ O
and -X- _ O
a -X- _ O
generator -X- _ O
is -X- _ O
effective -X- _ O
and -X- _ O
training -X- _ O
the -X- _ O
classifier -X- _ O
using -X- _ O
pseudo -X- _ O
labels -X- _ O
. -X- _ O
The -X- _ O
high -X- _ O
coverage -X- _ O
of -X- _ O
CEAS -X- _ O
can -X- _ O
be -X- _ O
achieved -X- _ O
probably -X- _ O
because -X- _ O
the -X- _ O
classifier -X- _ O
can -X- _ O
focus -X- _ O
on -X- _ O
selecting -X- _ O
relevant -X- _ O
commit -X- _ O
messages -X- _ O
for -X- _ O
each -X- _ O
class -X- _ O
. -X- _ O
Moreover -X- _ O
, -X- _ O
CEAS -X- _ B-MethodName
( -X- _ O
BERT -X- _ B-MethodName
) -X- _ O
got -X- _ O
higher -X- _ O
scores -X- _ O
than -X- _ O
CEAS -X- _ B-MethodName
( -X- _ O
CodeBERT -X- _ B-MethodName
) -X- _ O
, -X- _ O
indicating -X- _ O
that -X- _ O
it -X- _ O
is -X- _ O
better -X- _ O
to -X- _ O
use -X- _ O
BERT -X- _ O
for -X- _ O
tasks -X- _ O
where -X- _ O
the -X- _ O
commit -X- _ O
message -X- _ O
is -X- _ O
the -X- _ O
input -X- _ O
. -X- _ O
CodeBERT -X- _ O
is -X- _ O
closer -X- _ O
to -X- _ O
the -X- _ O
domain -X- _ O
of -X- _ O
commit -X- _ O
messages -X- _ O
than -X- _ O
BERT -X- _ O
, -X- _ O
but -X- _ O
we -X- _ O
assume -X- _ O
that -X- _ O
this -X- _ O
is -X- _ O
because -X- _ O
it -X- _ O
was -X- _ O
trained -X- _ O
with -X- _ O
relatively -X- _ O
little -X- _ O
natural -X- _ O
language -X- _ O
data -X- _ O
. -X- _ O
Furthermore -X- _ O
, -X- _ O
CAS -X- _ O
- -X- _ O
Multi -X- _ O
tended -X- _ O
to -X- _ O
yield -X- _ O
higher -X- _ O
ROUGE -X- _ O
- -X- _ O
L -X- _ O
than -X- _ O
CAS -X- _ O
- -X- _ O
Single -X- _ O
, -X- _ O
suggesting -X- _ O
that -X- _ O
it -X- _ O
is -X- _ O
also -X- _ O
effective -X- _ O
to -X- _ O
independently -X- _ O
develop -X- _ O
different -X- _ O
abstractive -X- _ O
summarization -X- _ O
models -X- _ O
for -X- _ O
each -X- _ O
release -X- _ O
- -X- _ O
note -X- _ O
class -X- _ O
. -X- _ O
Although -X- _ O
not -X- _ O
as -X- _ O
apparent -X- _ O
as -X- _ O
ROUGE -X- _ O
- -X- _ O
L -X- _ O
, -X- _ O
CAS -X- _ O
models -X- _ O
( -X- _ O
CAS -X- _ O
- -X- _ O
Single -X- _ O
and -X- _ O
CAS -X- _ O
- -X- _ O
Multi -X- _ O
) -X- _ O
generated -X- _ O
comparable -X- _ O
or -X- _ O
higher -X- _ O
BLEU -X- _ B-MetricName
scores -X- _ O
than -X- _ O
CEAS -X- _ O
and -X- _ O
the -X- _ O
baselines -X- _ O
. -X- _ O
CAS -X- _ O
models -X- _ O
were -X- _ O
also -X- _ O
able -X- _ O
to -X- _ O
achieve -X- _ O
significantly -X- _ O
higher -X- _ O
Specificity -X- _ B-MetricName
scores -X- _ O
( -X- _ O
> -X- _ B-MetricValue
30 -X- _ I-MetricValue
points -X- _ I-MetricValue
) -X- _ O
compared -X- _ O
to -X- _ O
the -X- _ O
baselines -X- _ O
. -X- _ O
These -X- _ O
results -X- _ O
indicate -X- _ O
that -X- _ O
CAS -X- _ O
models -X- _ O
can -X- _ O
generate -X- _ O
less -X- _ O
noisy -X- _ O
release -X- _ O
notes -X- _ O
than -X- _ O
the -X- _ O
baselines -X- _ O
. -X- _ O
We -X- _ O
hypothesize -X- _ O
that -X- _ O
CAS -X- _ O
is -X- _ O
trained -X- _ O
a -X- _ O
lot -X- _ O
to -X- _ O
remove -X- _ O
noise -X- _ O
from -X- _ O
all -X- _ O
commit -X- _ O
messages -X- _ O
, -X- _ O
including -X- _ O
Other -X- _ O
class -X- _ O
, -X- _ O
which -X- _ O
strengths -X- _ O
the -X- _ O
ability -X- _ O
to -X- _ O
deal -X- _ O
with -X- _ O
noise -X- _ O
. -X- _ O

Human -X- _ B-MethodName
Evaluation -X- _ I-MethodName
Results -X- _ O

We -X- _ O
employed -X- _ O
twelve -X- _ O
human -X- _ B-MethodName
evaluators -X- _ I-MethodName
to -X- _ O
manually -X- _ O
assess -X- _ O
the -X- _ O
quality -X- _ O
of -X- _ O
the -X- _ O
release -X- _ O
notes -X- _ O
generated -X- _ O
by -X- _ O
the -X- _ O
systems -X- _ O
and -X- _ O
the -X- _ O
reference -X- _ O
release -X- _ O
notes -X- _ O
. -X- _ O
The -X- _ O
evaluators -X- _ O
were -X- _ O
graduate -X- _ O
students -X- _ O
or -X- _ O
working -X- _ O
pro -X- _ O
- -X- _ O
fessionals -X- _ O
with -X- _ O
at -X- _ O
least -X- _ O
one -X- _ O
year -X- _ O
of -X- _ O
experience -X- _ O
reading -X- _ O
release -X- _ O
notes -X- _ O
and -X- _ O
updating -X- _ O
software -X- _ O
libraries -X- _ O
. -X- _ O
We -X- _ O
randomly -X- _ O
chose -X- _ O
120 -X- _ O
release -X- _ O
notes -X- _ O
from -X- _ O
the -X- _ O
test -X- _ O
set -X- _ O
. -X- _ O
The -X- _ O
allocations -X- _ O
of -X- _ O
the -X- _ O
Features -X- _ O
, -X- _ O
Improvements -X- _ O
, -X- _ O
Bug -X- _ O
Fixes -X- _ O
, -X- _ O
and -X- _ O
Deprecations+ -X- _ O
classes -X- _ O
were -X- _ O
40 -X- _ O
, -X- _ O
25 -X- _ O
, -X- _ O
40 -X- _ O
, -X- _ O
and -X- _ O
15 -X- _ O
, -X- _ O
respectively -X- _ O
. -X- _ O
We -X- _ O
divided -X- _ O
the -X- _ O
evaluation -X- _ O
tasks -X- _ O
into -X- _ O
three -X- _ O
groups -X- _ O
of -X- _ O
40 -X- _ O
questions -X- _ O
, -X- _ O
and -X- _ O
each -X- _ O
group -X- _ O
was -X- _ O
assigned -X- _ O
to -X- _ O
four -X- _ O
different -X- _ O
evaluators -X- _ O
. -X- _ O
We -X- _ O
used -X- _ O
a -X- _ O
crowdsourcing -X- _ O
platform -X- _ O
, -X- _ O
Yahoo -X- _ O
! -X- _ O
Crowdsourcing -X- _ O
, -X- _ O
11 -X- _ O
operated -X- _ O
by -X- _ O
Yahoo -X- _ O
Japan -X- _ O
Corporation -X- _ O
for -X- _ O
the -X- _ O
evaluations -X- _ O
. -X- _ O
In -X- _ O
the -X- _ O
following -X- _ O
, -X- _ O
we -X- _ O
explain -X- _ O
the -X- _ O
evaluation -X- _ O
task -X- _ O
and -X- _ O
scoring -X- _ O
measures -X- _ O
. -X- _ O

Scoring -X- _ O
We -X- _ O
employed -X- _ O
a -X- _ O
five -X- _ O
- -X- _ O
point -X- _ O
scoring -X- _ O
scheme -X- _ O
for -X- _ O
evaluating -X- _ O
the -X- _ O
release -X- _ O
notes -X- _ O
. -X- _ O
The -X- _ O
evaluation -X- _ O
scores -X- _ O
were -X- _ O
determined -X- _ O
based -X- _ O
on -X- _ O
two -X- _ O
criteria -X- _ O
: -X- _ O
Percentage -X- _ O
of -X- _ O
necessary -X- _ O
information -X- _ O
( -X- _ O
coverage -X- _ O
) -X- _ O
and -X- _ O
percentage -X- _ O
of -X- _ O
unnecessary -X- _ O
information -X- _ O
( -X- _ O
noise -X- _ O
contamination -X- _ O
) -X- _ O
. -X- _ O
For -X- _ O
the -X- _ O
coverage -X- _ O
- -X- _ O
oriented -X- _ O
scoring -X- _ O
, -X- _ O
the -X- _ O
following -X- _ O
guidance -X- _ O
was -X- _ O
used -X- _ O
for -X- _ O
the -X- _ O
scoring -X- _ O
; -X- _ O
5 -X- _ O
: -X- _ O
90 -X- _ B-MetricValue
% -X- _ I-MetricValue
or -X- _ O
more -X- _ O
necessary -X- _ B-MetricName
information -X- _ I-MetricName
( -X- _ O
NI -X- _ B-MetricName
) -X- _ O
, -X- _ O
4 -X- _ O
: -X- _ O
70 -X- _ B-MetricValue
% -X- _ I-MetricValue
or -X- _ O
more -X- _ O
NI -X- _ B-MetricName
, -X- _ O
3 -X- _ O
: -X- _ O
50 -X- _ B-MetricValue
% -X- _ I-MetricValue
or -X- _ O
more -X- _ O
NI -X- _ B-MetricName
, -X- _ O
2 -X- _ O
: -X- _ O
30 -X- _ B-MetricValue
% -X- _ I-MetricValue
or -X- _ I-MetricValue
more -X- _ O
NI -X- _ B-MetricName
, -X- _ O
and -X- _ O
1 -X- _ O
: -X- _ O
less -X- _ O
30 -X- _ B-MetricValue
% -X- _ I-MetricValue
of -X- _ O
NI -X- _ O
. -X- _ O
For -X- _ O
the -X- _ O
noise -X- _ O
- -X- _ O
oriented -X- _ O
scoring -X- _ O
, -X- _ O
the -X- _ O
following -X- _ O
guidance -X- _ O
was -X- _ O
used -X- _ O
; -X- _ O
5 -X- _ O
: -X- _ O
no -X- _ O
unnecessary -X- _ O
information -X- _ O
( -X- _ O
UI -X- _ O
) -X- _ O
, -X- _ O
4 -X- _ O
: -X- _ O
less -X- _ O
UI -X- _ O
, -X- _ O
3 -X- _ O
: -X- _ O
slightly -X- _ O
less -X- _ O
UI -X- _ O
, -X- _ O
2 -X- _ O
: -X- _ O
a -X- _ O
little -X- _ O
UI -X- _ O
, -X- _ O
1 -X- _ O
: -X- _ O
much -X- _ O
UI -X- _ O
. -X- _ O
We -X- _ O
use -X- _ O
Fleiss -X- _ O
' -X- _ O
Kappa -X- _ O
to -X- _ O
measure -X- _ O
inter -X- _ O
- -X- _ O
annotator -X- _ O
agreement -X- _ O
( -X- _ O
Davies -X- _ O
and -X- _ O
Fleiss -X- _ O
, -X- _ O
1982 -X- _ O
) -X- _ O
and -X- _ O
obtain -X- _ O
a -X- _ O
score -X- _ O
of -X- _ O
0.39 -X- _ O
, -X- _ O
which -X- _ O
indicates -X- _ O
fair -X- _ O
agreement -X- _ O
. -X- _ O

We -X- _ O
also -X- _ O
tested -X- _ O
the -X- _ O
statistical -X- _ O
significance -X- _ O
of -X- _ O
the -X- _ O
results -X- _ O
using -X- _ O
a -X- _ O
permutation -X- _ O
test -X- _ O
( -X- _ O
Pitman -X- _ O
, -X- _ O
1937 -X- _ O
) -X- _ O
. -X- _ O
Since -X- _ O
evaluating -X- _ O
all -X- _ O
possible -X- _ O
permutations -X- _ O
would -X- _ O
require -X- _ O
a -X- _ O
considerable -X- _ O
amount -X- _ O
of -X- _ O
time -X- _ O
, -X- _ O
we -X- _ O
used -X- _ O
the -X- _ O
approximation -X- _ O
method -X- _ O
. -X- _ O
Note -X- _ O
that -X- _ O
sampling -X- _ O
all -X- _ O
permutation -X- _ O
is -X- _ O
typically -X- _ O
not -X- _ O
feasible -X- _ O
unless -X- _ O
the -X- _ O
dataset -X- _ O
size -X- _ O
is -X- _ O
relatively -X- _ O
small -X- _ O
. -X- _ O
12 -X- _ O
We -X- _ O
set -X- _ O
the -X- _ O
number -X- _ B-HyperparameterName
of -X- _ I-HyperparameterName
rounds -X- _ I-HyperparameterName
to -X- _ O
10,000 -X- _ B-HyperparameterValue
. -X- _ O
We -X- _ O
applied -X- _ O
Cov -X- _ O
. -X- _ O
+ -X- _ O
Noise -X- _ O
scores -X- _ O
to -X- _ O
the -X- _ O
test -X- _ O
. -X- _ O
Comparing -X- _ O
CAS -X- _ O
- -X- _ O
Multi -X- _ O
with -X- _ O
the -X- _ O
baselines -X- _ O
, -X- _ O
all -X- _ O
the -X- _ O
p -X- _ B-HyperparameterName
- -X- _ I-HyperparameterName
values -X- _ I-HyperparameterName
of -X- _ O
the -X- _ O
permutation -X- _ O
tests -X- _ O
were -X- _ O
less -X- _ O
than -X- _ O
0.001 -X- _ B-HyperparameterValue
, -X- _ O
indicating -X- _ O
that -X- _ O
the -X- _ O
improvements -X- _ O
are -X- _ O
statistically -X- _ O
significant -X- _ O
. -X- _ O

First -X- _ O
, -X- _ O
we -X- _ O
found -X- _ O
that -X- _ O
CAS -X- _ O
- -X- _ O
Multi -X- _ O
tends -X- _ O
to -X- _ O
produce -X- _ O
significantly -X- _ O
shorter -X- _ O
release -X- _ O
notes -X- _ O
than -X- _ O
human -X- _ O
references -X- _ O
. -X- _ O
In -X- _ O
the -X- _ O
first -X- _ O
two -X- _ O
examples -X- _ O
in -X- _ O
Table -X- _ O
6 -X- _ O
, -X- _ O
CAS -X- _ O
- -X- _ O
Multi -X- _ O
generates -X- _ O
only -X- _ O
a -X- _ O
single -X- _ O
sentence -X- _ O
, -X- _ O
while -X- _ O
the -X- _ O
human -X- _ O
references -X- _ O
contain -X- _ O
multiple -X- _ O
sentences -X- _ O
. -X- _ O
This -X- _ O
is -X- _ O
probably -X- _ O
due -X- _ O
to -X- _ O
the -X- _ O
fact -X- _ O
that -X- _ O
the -X- _ O
release -X- _ O
note -X- _ O
classes -X- _ O
are -X- _ O
significantly -X- _ O
scarce -X- _ O
in -X- _ O
the -X- _ O
training -X- _ O
set -X- _ O
, -X- _ O
and -X- _ O
the -X- _ O
model -X- _ O
is -X- _ O
trained -X- _ O
to -X- _ O
be -X- _ O
reluctant -X- _ O
to -X- _ O
generate -X- _ O
release -X- _ O
note -X- _ O
text -X- _ O
. -X- _ O
Actually -X- _ O
, -X- _ O
the -X- _ O
numbers -X- _ O
of -X- _ O
release -X- _ O
notes -X- _ O
containing -X- _ O
the -X- _ O
Features -X- _ O
and -X- _ O
Improvements -X- _ O
classes -X- _ O
in -X- _ O
the -X- _ O
training -X- _ O
set -X- _ O
are -X- _ O
only -X- _ O
33.4 -X- _ B-MetricValue
% -X- _ I-MetricValue
and -X- _ O
14.0 -X- _ B-MetricValue
% -X- _ I-MetricValue
, -X- _ O
respectively -X- _ O
. -X- _ O
We -X- _ O
used -X- _ O
the -X- _ O
upsampling -X- _ O
technique -X- _ O
to -X- _ O
reduce -X- _ O
the -X- _ O
class -X- _ O
imbalance -X- _ O
problem -X- _ O
; -X- _ O
however -X- _ O
, -X- _ O
upsampling -X- _ O
can -X- _ O
not -X- _ O
inherently -X- _ O
increase -X- _ O
the -X- _ O
number -X- _ O
of -X- _ O
unique -X- _ O
training -X- _ O
examples -X- _ O
. -X- _ O
Therefore -X- _ O
, -X- _ O
it -X- _ O
is -X- _ O
necessary -X- _ O
to -X- _ O
explore -X- _ O
ways -X- _ O
to -X- _ O
augment -X- _ O
the -X- _ O
training -X- _ O
patterns -X- _ O
inherently -X- _ O
in -X- _ O
the -X- _ O
future -X- _ O
. -X- _ O

-Fixed -X- _ O
a -X- _ O
bug -X- _ O
where -X- _ O
the -X- _ O
date -X- _ O
and -X- _ O
time -X- _ O
filter -X- _ O
were -X- _ O
not -X- _ O
being -X- _ O
applied -X- _ O
properly -X- _ O
. -X- _ O
CAS -X- _ O
- -X- _ O
Multi -X- _ O
Release -X- _ O
Note -X- _ O
( -X- _ O
Cov -X- _ O
. -X- _ O
: -X- _ O
2.5 -X- _ O
, -X- _ O
Noise -X- _ O
: -X- _ O
5.0 -X- _ O
) -X- _ O
: -X- _ O

Estimating -X- _ B-TaskName
the -X- _ I-TaskName
Entropy -X- _ I-TaskName
of -X- _ O
Linguistic -X- _ O
Distributions -X- _ O

Shannon -X- _ O
entropy -X- _ O
is -X- _ O
often -X- _ O
a -X- _ O
quantity -X- _ O
of -X- _ O
interest -X- _ O
to -X- _ O
linguists -X- _ O
studying -X- _ O
the -X- _ O
communicative -X- _ O
capacity -X- _ O
of -X- _ O
human -X- _ O
language -X- _ O
. -X- _ O
However -X- _ O
, -X- _ O
entropy -X- _ O
must -X- _ O
typically -X- _ O
be -X- _ O
estimated -X- _ O
from -X- _ O
observed -X- _ O
data -X- _ O
because -X- _ O
researchers -X- _ O
do -X- _ O
not -X- _ O
have -X- _ O
access -X- _ O
to -X- _ O
the -X- _ O
underlying -X- _ O
probability -X- _ O
distribution -X- _ O
that -X- _ O
gives -X- _ O
rise -X- _ O
to -X- _ O
these -X- _ O
data -X- _ O
. -X- _ O
While -X- _ O
entropy -X- _ B-TaskName
estimation -X- _ I-TaskName
is -X- _ O
a -X- _ O
well -X- _ O
- -X- _ O
studied -X- _ O
problem -X- _ O
in -X- _ O
other -X- _ O
fields -X- _ O
, -X- _ O
there -X- _ O
is -X- _ O
not -X- _ O
yet -X- _ O
a -X- _ O
comprehensive -X- _ O
exploration -X- _ O
of -X- _ O
the -X- _ O
efficacy -X- _ O
of -X- _ O
entropy -X- _ O
estimators -X- _ O
for -X- _ O
use -X- _ O
with -X- _ O
linguistic -X- _ O
data -X- _ O
. -X- _ O
In -X- _ O
this -X- _ O
work -X- _ O
, -X- _ O
we -X- _ O
fill -X- _ O
this -X- _ O
void -X- _ O
, -X- _ O
studying -X- _ O
the -X- _ O
empirical -X- _ O
effectiveness -X- _ O
of -X- _ O
different -X- _ O
entropy -X- _ O
estimators -X- _ O
for -X- _ O
linguistic -X- _ O
distributions -X- _ O
. -X- _ O
In -X- _ O
a -X- _ O
replication -X- _ O
of -X- _ O
two -X- _ O
recent -X- _ O
information -X- _ O
- -X- _ O
theoretic -X- _ O
linguistic -X- _ O
studies -X- _ O
, -X- _ O
we -X- _ O
find -X- _ O
evidence -X- _ O
that -X- _ O
the -X- _ O
reported -X- _ O
effect -X- _ O
size -X- _ O
is -X- _ O
over -X- _ O
- -X- _ O
estimated -X- _ O
due -X- _ O
to -X- _ O
overreliance -X- _ O
on -X- _ O
poor -X- _ O
entropy -X- _ O
estimators -X- _ O
. -X- _ O
Finally -X- _ O
, -X- _ O
we -X- _ O
end -X- _ O
our -X- _ O
paper -X- _ O
with -X- _ O
concrete -X- _ O
recommendations -X- _ O
for -X- _ O
entropy -X- _ B-TaskName
estimation -X- _ I-TaskName
depending -X- _ O
on -X- _ O
distribution -X- _ O
type -X- _ O
and -X- _ O
data -X- _ O
availability -X- _ O
. -X- _ O

Introduction -X- _ O

There -X- _ O
is -X- _ O
a -X- _ O
natural -X- _ O
connection -X- _ O
between -X- _ O
information -X- _ O
theory -X- _ O
, -X- _ O
the -X- _ O
mathematical -X- _ O
study -X- _ O
of -X- _ O
communication -X- _ O
systems -X- _ O
, -X- _ O
and -X- _ O
linguistics -X- _ O
, -X- _ O
the -X- _ O
study -X- _ O
of -X- _ O
human -X- _ O
language -X- _ O
- -X- _ O
the -X- _ O
primary -X- _ O
vehicle -X- _ O
that -X- _ O
humans -X- _ O
employ -X- _ O
to -X- _ O
communicate -X- _ O
. -X- _ O
Researchers -X- _ O
have -X- _ O
exploited -X- _ O
this -X- _ O
connection -X- _ O
since -X- _ O
information -X- _ O
theory -X- _ O
's -X- _ O
inception -X- _ O
( -X- _ O
Shannon -X- _ O
, -X- _ O
1951 -X- _ O
; -X- _ O
Cherry -X- _ O
et -X- _ O
al -X- _ O
. -X- _ O
, -X- _ O
1953 -X- _ O
; -X- _ O
Harris -X- _ O
, -X- _ O
1991 -X- _ O
) -X- _ O
. -X- _ O
With -X- _ O
the -X- _ O
advent -X- _ O
of -X- _ O
modern -X- _ O
computing -X- _ O
, -X- _ O
the -X- _ O
number -X- _ O
of -X- _ O
information -X- _ O
- -X- _ O
theoretic -X- _ O
linguistic -X- _ O
studies -X- _ O
has -X- _ O
risen -X- _ O
, -X- _ O
exploring -X- _ O
claims -X- _ O
about -X- _ O
language -X- _ O
such -X- _ O
as -X- _ O
the -X- _ O
optimality -X- _ O
of -X- _ O
the -X- _ O
lexicon -X- _ O
( -X- _ O
Piantadosi -X- _ O
et -X- _ O
al -X- _ O
. -X- _ O
, -X- _ O
2011 -X- _ O
; -X- _ O
, -X- _ O
the -X- _ O
complexity -X- _ O
of -X- _ O
morphological -X- _ O
systems -X- _ O
( -X- _ O
Cotterell -X- _ O
et -X- _ O
al -X- _ O
. -X- _ O
, -X- _ O
2019 -X- _ O
; -X- _ O
Wu -X- _ O
et -X- _ O
al -X- _ O
. -X- _ O
, -X- _ O
2019 -X- _ O
; -X- _ O
Rathi -X- _ O
et -X- _ O
al -X- _ O
. -X- _ O
, -X- _ O
2021 -X- _ O
) -X- _ O
, -X- _ O
and -X- _ O
the -X- _ O
correlation -X- _ O
between -X- _ O
surprisal -X- _ O
and -X- _ O
language -X- _ O
processing -X- _ O
time -X- _ O
( -X- _ O
Smith -X- _ O
and -X- _ O
Levy -X- _ O
, -X- _ O
2013 -X- _ O
; -X- _ O
Bentz -X- _ O
et -X- _ O
al -X- _ O
. -X- _ O
, -X- _ O
2017 -X- _ O
; -X- _ O
Goodkind -X- _ O
and -X- _ O
Bicknell -X- _ O
, -X- _ O
2018 -X- _ O
; -X- _ O
Cotterell -X- _ O
et -X- _ O
al -X- _ O
. -X- _ O
, -X- _ O
2018 -X- _ O
; -X- _ O
Meister -X- _ O
et -X- _ O
al -X- _ O
. -X- _ O
, -X- _ O
2021 -X- _ O
, -X- _ O
inter -X- _ O
alia -X- _ O
) -X- _ O
. -X- _ O

In -X- _ O
information -X- _ O
- -X- _ O
theoretic -X- _ O
linguistics -X- _ O
, -X- _ O
a -X- _ O
fundamental -X- _ O
quantity -X- _ O
of -X- _ O
research -X- _ O
interest -X- _ O
is -X- _ O
entropy -X- _ O
. -X- _ O
Entropy -X- _ O
is -X- _ O
both -X- _ O
useful -X- _ O
to -X- _ O
linguists -X- _ O
in -X- _ O
its -X- _ O
own -X- _ O
right -X- _ O
, -X- _ O
and -X- _ O
is -X- _ O
necessary -X- _ O
for -X- _ O
estimating -X- _ O
other -X- _ O
useful -X- _ O
quantities -X- _ O
, -X- _ O
e.g. -X- _ O
, -X- _ O
mutual -X- _ O
information -X- _ O
. -X- _ O
However -X- _ O
, -X- _ O
the -X- _ O
estimation -X- _ B-TaskName
of -X- _ I-TaskName
entropy -X- _ I-TaskName
from -X- _ O
raw -X- _ O
data -X- _ O
can -X- _ O
be -X- _ O
quite -X- _ O
challenging -X- _ O
( -X- _ O
Paninski -X- _ O
, -X- _ O
2003 -X- _ O
; -X- _ O
Nowozin -X- _ O
, -X- _ O
2015 -X- _ O
) -X- _ O
, -X- _ O
e.g. -X- _ O
, -X- _ O
in -X- _ O
expectation -X- _ O
, -X- _ O
the -X- _ O
plug -X- _ O
- -X- _ O
in -X- _ O
estimator -X- _ O
underestimates -X- _ O
entropy -X- _ O
( -X- _ O
Miller -X- _ O
, -X- _ O
1955 -X- _ O
) -X- _ O
. -X- _ O
Linguistic -X- _ O
distributions -X- _ O
often -X- _ O
present -X- _ O
additional -X- _ O
challenges -X- _ O
. -X- _ O
For -X- _ O
instance -X- _ O
, -X- _ O
many -X- _ O
linguistic -X- _ O
distributions -X- _ O
, -X- _ O
such -X- _ O
as -X- _ O
the -X- _ O
unigram -X- _ O
distribution -X- _ O
, -X- _ O
follow -X- _ O
a -X- _ O
power -X- _ O
law -X- _ O
( -X- _ O
Zipf -X- _ O
, -X- _ O
1935 -X- _ O
; -X- _ O
Mitzenmacher -X- _ O
, -X- _ O
2004 -X- _ O
) -X- _ O
. -X- _ O
1 -X- _ O
Linguistics -X- _ O
is -X- _ O
not -X- _ O
the -X- _ O
only -X- _ O
field -X- _ O
with -X- _ O
such -X- _ O
nuances -X- _ O
, -X- _ O
and -X- _ O
so -X- _ O
a -X- _ O
large -X- _ O
number -X- _ O
of -X- _ O
entropy -X- _ O
estimators -X- _ O
have -X- _ O
been -X- _ O
proposed -X- _ O
in -X- _ O
other -X- _ O
fields -X- _ O
( -X- _ O
Chao -X- _ O
and -X- _ O
Shen -X- _ O
, -X- _ O
2003 -X- _ O
; -X- _ O
Archer -X- _ O
et -X- _ O
al -X- _ O
. -X- _ O
, -X- _ O
2014 -X- _ O
, -X- _ O
inter -X- _ O
alia -X- _ O
) -X- _ O
. -X- _ O
However -X- _ O
, -X- _ O
no -X- _ O
work -X- _ O
to -X- _ O
date -X- _ O
has -X- _ O
attempted -X- _ O
a -X- _ O
practical -X- _ O
comparison -X- _ O
of -X- _ O
these -X- _ O
estimators -X- _ O
on -X- _ O
natural -X- _ O
language -X- _ O
data -X- _ O
. -X- _ O
This -X- _ O
work -X- _ O
fills -X- _ O
this -X- _ O
empirical -X- _ O
void -X- _ O
. -X- _ O

Our -X- _ O
paper -X- _ O
offers -X- _ O
a -X- _ O
large -X- _ O
empirical -X- _ O
comparison -X- _ O
of -X- _ O
the -X- _ O
performance -X- _ O
of -X- _ O
6 -X- _ O
different -X- _ O
entropy -X- _ O
estimators -X- _ O
on -X- _ O
both -X- _ O
synthetic -X- _ O
and -X- _ O
natural -X- _ O
language -X- _ O
data -X- _ O
, -X- _ O
an -X- _ O
example -X- _ O
of -X- _ O
which -X- _ O
is -X- _ O
shown -X- _ O
in -X- _ O
Figure -X- _ O
1 -X- _ O
. -X- _ O
We -X- _ O
find -X- _ O
that -X- _ O
Chao -X- _ O
and -X- _ O
Shen -X- _ O
's -X- _ O
( -X- _ O
2003 -X- _ O
) -X- _ O
is -X- _ O
the -X- _ O
best -X- _ O
estimator -X- _ O
when -X- _ O
very -X- _ O
few -X- _ O
data -X- _ O
are -X- _ O
available -X- _ O
, -X- _ O
but -X- _ O
Nemenman -X- _ O
et -X- _ O
al -X- _ O
. -X- _ O
's -X- _ O
( -X- _ O
2002 -X- _ O
) -X- _ O
is -X- _ O
superior -X- _ O
as -X- _ O
more -X- _ O
data -X- _ O
become -X- _ O
available -X- _ O
. -X- _ O
Both -X- _ O
are -X- _ O
significantly -X- _ O
better -X- _ O
( -X- _ O
in -X- _ O
terms -X- _ O
of -X- _ O
meansquared -X- _ O
error -X- _ O
) -X- _ O
than -X- _ O
the -X- _ O
naïve -X- _ O
plug -X- _ O
- -X- _ O
in -X- _ O
estimator -X- _ O
. -X- _ O
Importantly -X- _ O
, -X- _ O
we -X- _ O
also -X- _ O
show -X- _ O
that -X- _ O
two -X- _ O
recent -X- _ O
studies -X- _ O
( -X- _ O
Williams -X- _ O
et -X- _ O
al -X- _ O
. -X- _ O
, -X- _ O
2021 -X- _ O
; -X- _ O
McCarthy -X- _ O
et -X- _ O
al -X- _ O
. -X- _ O
, -X- _ O
2020 -X- _ O
) -X- _ O
show -X- _ O
smaller -X- _ O
effect -X- _ O
sizes -X- _ O
when -X- _ O
a -X- _ O
better -X- _ O
estimator -X- _ O
is -X- _ O
employed -X- _ O
; -X- _ O
however -X- _ O
, -X- _ O
we -X- _ O
are -X- _ O
able -X- _ O
to -X- _ O
reproduce -X- _ O
a -X- _ O
significant -X- _ O
effect -X- _ O
in -X- _ O
both -X- _ O
replications -X- _ O
. -X- _ O
We -X- _ O
recommend -X- _ O
that -X- _ O
future -X- _ O
studies -X- _ O
carefully -X- _ O
consider -X- _ O
their -X- _ O
choice -X- _ O
of -X- _ O
entropy -X- _ O
estimators -X- _ O
, -X- _ O
taking -X- _ O
into -X- _ O
account -X- _ O
data -X- _ O
availability -X- _ O
and -X- _ O
the -X- _ O
nature -X- _ O
of -X- _ O
the -X- _ O
underlying -X- _ O
distribution -X- _ O
. -X- _ O
2 -X- _ O

Entropy -X- _ O
and -X- _ O
Language -X- _ O

Shannon -X- _ O
entropy -X- _ O
is -X- _ O
a -X- _ O
quantification -X- _ O
of -X- _ O
the -X- _ O
uncertainty -X- _ O
in -X- _ O
a -X- _ O
random -X- _ O
variable -X- _ O
. -X- _ O
Given -X- _ O
a -X- _ O
( -X- _ O
discrete -X- _ O
) -X- _ O
random -X- _ O
variable -X- _ O
X -X- _ O
with -X- _ O
probability -X- _ O
distribution -X- _ O
p -X- _ O
over -X- _ O
K -X- _ O
possible -X- _ O
outcomes -X- _ O
X -X- _ O
= -X- _ O
{ -X- _ O
x -X- _ O
k -X- _ O
} -X- _ O
K -X- _ O
k=1 -X- _ O
, -X- _ O
the -X- _ O
Shannon -X- _ O
entropy -X- _ O
of -X- _ O
X -X- _ O
is -X- _ O
defined -X- _ O
as -X- _ O

H -X- _ O
( -X- _ O
X -X- _ O
) -X- _ O
= -X- _ O
H -X- _ O
( -X- _ O
p -X- _ O
) -X- _ O
def -X- _ O
= -X- _ O
− -X- _ O
K -X- _ O
k=1 -X- _ O
p -X- _ O
( -X- _ O
x -X- _ O
k -X- _ O
) -X- _ O
log -X- _ O
p -X- _ O
( -X- _ O
x -X- _ O
k -X- _ O
) -X- _ O
( -X- _ O
1 -X- _ O
) -X- _ O

Entropy -X- _ O
has -X- _ O
many -X- _ O
uses -X- _ O
throughout -X- _ O
science -X- _ O
and -X- _ O
engineering -X- _ O
; -X- _ O
for -X- _ O
instance -X- _ O
, -X- _ O
Shannon -X- _ O
( -X- _ O
1948 -X- _ O
) -X- _ O
originally -X- _ O
proposed -X- _ O
entropy -X- _ O
as -X- _ O
a -X- _ O
lower -X- _ O
bound -X- _ O
on -X- _ O
the -X- _ O
compressibility -X- _ O
of -X- _ O
a -X- _ O
stochastic -X- _ O
source -X- _ O
. -X- _ O

Yet -X- _ O
the -X- _ O
application -X- _ O
of -X- _ O
information -X- _ O
- -X- _ O
theoretic -X- _ O
techniques -X- _ O
to -X- _ O
linguistics -X- _ O
is -X- _ O
not -X- _ O
so -X- _ O
straightforward -X- _ O
: -X- _ O
Information -X- _ O
- -X- _ O
theoretic -X- _ O
measures -X- _ O
are -X- _ O
defined -X- _ O
over -X- _ O
probability -X- _ O
distributions -X- _ O
and -X- _ O
, -X- _ O
in -X- _ O
the -X- _ O
study -X- _ O
of -X- _ O
natural -X- _ O
language -X- _ O
, -X- _ O
we -X- _ O
typically -X- _ O
only -X- _ O
have -X- _ O
access -X- _ O
to -X- _ O
samples -X- _ O
from -X- _ O
the -X- _ O
distribution -X- _ O
of -X- _ O
interest -X- _ O
, -X- _ O
e.g. -X- _ O
, -X- _ O
the -X- _ O
phonotactic -X- _ O
distribution -X- _ O
in -X- _ O
English -X- _ O
, -X- _ O
which -X- _ O
permits -X- _ O
word -X- _ O
we -X- _ O
can -X- _ O
not -X- _ O
find -X- _ O
in -X- _ O
a -X- _ O
corpus -X- _ O
, -X- _ O
like -X- _ O
blick -X- _ O
, -X- _ O
rather -X- _ O
than -X- _ O
the -X- _ O
true -X- _ O
probabilities -X- _ O
required -X- _ O
in -X- _ O
the -X- _ O
computation -X- _ O
of -X- _ O
Eq -X- _ O
. -X- _ O
( -X- _ O
1 -X- _ O
) -X- _ O
. -X- _ O
Indeed -X- _ O
, -X- _ O
it -X- _ O
is -X- _ O
often -X- _ O
the -X- _ O
case -X- _ O
that -X- _ O
not -X- _ O
all -X- _ O
elements -X- _ O
of -X- _ O
X -X- _ O
are -X- _ O
even -X- _ O
observed -X- _ O
in -X- _ O
available -X- _ O
data -X- _ O
- -X- _ O
such -X- _ O
as -X- _ O
words -X- _ O
that -X- _ O
were -X- _ O
coined -X- _ O
after -X- _ O
the -X- _ O
a -X- _ O
corpus -X- _ O
was -X- _ O
collected -X- _ O
. -X- _ O

Rather -X- _ O
, -X- _ O
p -X- _ O
must -X- _ O
be -X- _ O
approximated -X- _ O
in -X- _ O
order -X- _ O
to -X- _ O
estimate -X- _ O
H -X- _ O
( -X- _ O
p -X- _ O
) -X- _ O
. -X- _ O
One -X- _ O
solution -X- _ O
is -X- _ O
plug -X- _ B-MethodName
- -X- _ I-MethodName
in -X- _ I-MethodName
estimation -X- _ I-MethodName
: -X- _ O
Given -X- _ O
samples -X- _ O
from -X- _ O
p -X- _ O
, -X- _ O
the -X- _ O
maximum -X- _ B-MethodName
- -X- _ I-MethodName
likelihood -X- _ I-MethodName
estimate -X- _ I-MethodName
for -X- _ O
p -X- _ O
is -X- _ O
" -X- _ O
plugged -X- _ O
" -X- _ O
into -X- _ O
Eq -X- _ O
. -X- _ O
( -X- _ O
1 -X- _ O
) -X- _ O
. -X- _ O
However -X- _ O
, -X- _ O
as -X- _ O
originally -X- _ O
noted -X- _ O
by -X- _ O
Miller -X- _ O
( -X- _ O
1955 -X- _ O
) -X- _ O
, -X- _ O
this -X- _ O
strategy -X- _ O
generally -X- _ O
yields -X- _ O
poor -X- _ O
estimates -X- _ O
. -X- _ O
3 -X- _ O
It -X- _ O
is -X- _ O
thus -X- _ O
necessary -X- _ O
2 -X- _ O
Our -X- _ O
code -X- _ O
is -X- _ O
available -X- _ O
at -X- _ O
https -X- _ O
: -X- _ O
/ -X- _ O
/ -X- _ O
github.com -X- _ O
/ -X- _ O
aryamanarora -X- _ O
/ -X- _ O
entropy -X- _ O
- -X- _ O
estimation -X- _ O
. -X- _ O

3 -X- _ O
A -X- _ O
proof -X- _ O
of -X- _ O
this -X- _ O
result -X- _ O
in -X- _ O
given -X- _ O
in -X- _ O
full -X- _ O
in -X- _ O
Proposition -X- _ O
1 -X- _ O
. -X- _ O

to -X- _ O
derive -X- _ O
more -X- _ O
nuanced -X- _ O
estimators -X- _ O
. -X- _ O

Statistical -X- _ O
Estimation -X- _ O
Theory -X- _ O

Statistical -X- _ O
estimation -X- _ O
theory -X- _ O
provides -X- _ O
us -X- _ O
with -X- _ O
the -X- _ O
tools -X- _ O
for -X- _ O
estimating -X- _ O
various -X- _ O
quantities -X- _ O
of -X- _ O
interest -X- _ O
based -X- _ O
on -X- _ O
samples -X- _ O
from -X- _ O
a -X- _ O
distribution -X- _ O
. -X- _ O
Central -X- _ O
to -X- _ O
this -X- _ O
theory -X- _ O
is -X- _ O
the -X- _ O
estimator -X- _ O
: -X- _ O
A -X- _ O
statistic -X- _ O
that -X- _ O
approximates -X- _ O
a -X- _ O
property -X- _ O
of -X- _ O
the -X- _ O
distribution -X- _ O
our -X- _ O
data -X- _ O
is -X- _ O
drawn -X- _ O
from -X- _ O
. -X- _ O
More -X- _ O
formally -X- _ O
, -X- _ O
let -X- _ O
D -X- _ O
= -X- _ O
{ -X- _ O
x -X- _ O
( -X- _ O
n -X- _ O
) -X- _ O
} -X- _ O
N -X- _ O
n=1 -X- _ O
be -X- _ O
samples -X- _ O
from -X- _ O
an -X- _ O
unknown -X- _ O
distribution -X- _ O
p. -X- _ O
Suppose -X- _ O
we -X- _ O
are -X- _ O
interested -X- _ O
in -X- _ O
a -X- _ O
quantity -X- _ O
θ -X- _ O
that -X- _ O
can -X- _ O
be -X- _ O
computed -X- _ O
as -X- _ O
a -X- _ O
function -X- _ O
of -X- _ O
the -X- _ O
distribution -X- _ O
p. -X- _ O
An -X- _ O
estimator -X- _ O
θ -X- _ O
( -X- _ O
D -X- _ O
) -X- _ O
for -X- _ O
θ -X- _ O
is -X- _ O
then -X- _ O
a -X- _ O
function -X- _ O
of -X- _ O
the -X- _ O
data -X- _ O
D -X- _ O
that -X- _ O
provides -X- _ O
an -X- _ O
approximation -X- _ O
of -X- _ O
θ -X- _ O
. -X- _ O

Two -X- _ O
properties -X- _ O
of -X- _ O
an -X- _ O
estimator -X- _ O
are -X- _ O
often -X- _ O
of -X- _ O
interest -X- _ O
: -X- _ O
bias -X- _ O
- -X- _ O
the -X- _ O
difference -X- _ O
between -X- _ O
the -X- _ O
true -X- _ O
value -X- _ O
of -X- _ O
θ -X- _ O
and -X- _ O
the -X- _ O
expected -X- _ O
value -X- _ O
of -X- _ O
our -X- _ O
estimator -X- _ O
θ -X- _ O
( -X- _ O
D -X- _ O
) -X- _ O
under -X- _ O
p -X- _ O
- -X- _ O
and -X- _ O
variance -X- _ O
- -X- _ O
how -X- _ O
much -X- _ O
θ -X- _ O
( -X- _ O
D -X- _ O
) -X- _ O
fluctuates -X- _ O
from -X- _ O
sample -X- _ O
set -X- _ O
to -X- _ O
sample -X- _ O
set -X- _ O
: -X- _ O

bias -X- _ O
( -X- _ O
θ -X- _ O
( -X- _ O
D -X- _ O
) -X- _ O
) -X- _ O
def -X- _ O
= -X- _ O
E -X- _ O
p -X- _ O
[ -X- _ O
θ -X- _ O
( -X- _ O
D -X- _ O
) -X- _ O
] -X- _ O
− -X- _ O
θ -X- _ O
( -X- _ O
2 -X- _ O
) -X- _ O
var -X- _ O
( -X- _ O
θ -X- _ O
( -X- _ O
D -X- _ O
) -X- _ O
) -X- _ O
def -X- _ O
= -X- _ O
E -X- _ O
p -X- _ O
[ -X- _ O
( -X- _ O
θ -X- _ O
( -X- _ O
D -X- _ O
) -X- _ O
− -X- _ O
E -X- _ O
p -X- _ O
[ -X- _ O
θ -X- _ O
( -X- _ O
D -X- _ O
) -X- _ O
] -X- _ O
) -X- _ O
2 -X- _ O
] -X- _ O
( -X- _ O
3 -X- _ O
) -X- _ O

It -X- _ O
is -X- _ O
desirable -X- _ O
to -X- _ O
construct -X- _ O
an -X- _ O
estimator -X- _ O
that -X- _ O
has -X- _ O
both -X- _ O
low -X- _ O
bias -X- _ O
and -X- _ O
low -X- _ O
variance -X- _ O
. -X- _ O
However -X- _ O
, -X- _ O
the -X- _ O
bias -X- _ O
- -X- _ O
variance -X- _ O
trade -X- _ O
- -X- _ O
off -X- _ O
tells -X- _ O
us -X- _ O
that -X- _ O
we -X- _ O
often -X- _ O
have -X- _ O
to -X- _ O
pick -X- _ O
one -X- _ O
, -X- _ O
and -X- _ O
we -X- _ O
should -X- _ O
focus -X- _ O
on -X- _ O
a -X- _ O
balance -X- _ O
between -X- _ O
the -X- _ O
two -X- _ O
. -X- _ O
This -X- _ O
trade -X- _ O
- -X- _ O
off -X- _ O
is -X- _ O
evinced -X- _ O
through -X- _ O
mean -X- _ B-MetricName
- -X- _ I-MetricName
squared -X- _ I-MetricName
error -X- _ I-MetricName
( -X- _ O
MSE -X- _ B-MetricName
) -X- _ O
, -X- _ O
a -X- _ O
metric -X- _ O
oft -X- _ O
- -X- _ O
employed -X- _ O
for -X- _ O
assessing -X- _ O
estimator -X- _ O
quality -X- _ O
: -X- _ O

MSE -X- _ B-MetricName
( -X- _ O
θ -X- _ O
( -X- _ O
D -X- _ O
) -X- _ O
) -X- _ O
= -X- _ O
bias -X- _ O
( -X- _ O
θ -X- _ O
( -X- _ O
D -X- _ O
) -X- _ O
) -X- _ O
2 -X- _ O
+ -X- _ O
var -X- _ O
( -X- _ O
θ -X- _ O
( -X- _ O
D -X- _ O
) -X- _ O
) -X- _ O
( -X- _ O
4 -X- _ O
) -X- _ O

To -X- _ O
recognize -X- _ O
the -X- _ O
trade -X- _ O
- -X- _ O
oft -X- _ O
note -X- _ O
that -X- _ O
, -X- _ O
for -X- _ O
any -X- _ O
fixed -X- _ O
MSE -X- _ B-MetricName
, -X- _ O
a -X- _ O
decrease -X- _ O
in -X- _ O
bias -X- _ O
must -X- _ O
be -X- _ O
compensated -X- _ O
with -X- _ O
an -X- _ O
increase -X- _ O
in -X- _ O
variance -X- _ O
and -X- _ O
vice -X- _ O
versa -X- _ O
. -X- _ O
Indeed -X- _ O
, -X- _ O
it -X- _ O
is -X- _ O
important -X- _ O
to -X- _ O
recognize -X- _ O
that -X- _ O
there -X- _ O
is -X- _ O
typically -X- _ O
no -X- _ O
single -X- _ O
estimator -X- _ O
that -X- _ O
is -X- _ O
seen -X- _ O
as -X- _ O
" -X- _ O
best -X- _ O
. -X- _ O
" -X- _ O
Different -X- _ O
estimators -X- _ O
balance -X- _ O
the -X- _ O
bias -X- _ O
- -X- _ O
variance -X- _ O
trade -X- _ O
- -X- _ O
off -X- _ O
differently -X- _ O
, -X- _ O
making -X- _ O
their -X- _ O
perceived -X- _ O
quality -X- _ O
specific -X- _ O
to -X- _ O
one -X- _ O
's -X- _ O
use -X- _ O
- -X- _ O
case -X- _ O
. -X- _ O
Importantly -X- _ O
, -X- _ O
the -X- _ O
effectiveness -X- _ O
of -X- _ O
an -X- _ O
estimator -X- _ O
also -X- _ O
depends -X- _ O
on -X- _ O
the -X- _ O
domain -X- _ O
of -X- _ O
interest -X- _ O
. -X- _ O
Consequently -X- _ O
, -X- _ O
an -X- _ O
empirical -X- _ O
study -X- _ O
of -X- _ O
various -X- _ O
entropy -X- _ O
estimators -X- _ O
, -X- _ O
which -X- _ O
this -X- _ O
paper -X- _ O
provides -X- _ O
, -X- _ O
is -X- _ O
necessary -X- _ O
in -X- _ O
order -X- _ O
to -X- _ O
determine -X- _ O
which -X- _ O
entropy -X- _ O
estimators -X- _ O
are -X- _ O
best -X- _ O
suited -X- _ O
for -X- _ O
linguistic -X- _ O
distributions -X- _ O
. -X- _ O

Plug -X- _ O
- -X- _ O
in -X- _ O
Estimation -X- _ O
of -X- _ O
Entropy -X- _ O

A -X- _ O
simple -X- _ O
, -X- _ O
two -X- _ O
- -X- _ O
step -X- _ O
approach -X- _ O
for -X- _ O
estimating -X- _ B-TaskName
entropy -X- _ I-TaskName
is -X- _ O
plug -X- _ O
- -X- _ O
in -X- _ O
estimation -X- _ O
. -X- _ O
In -X- _ O
the -X- _ O
first -X- _ O
step -X- _ O
, -X- _ O
we -X- _ O
compute -X- _ O
the -X- _ O
maximum -X- _ B-MethodName
- -X- _ I-MethodName
likelihood -X- _ I-MethodName
estimate -X- _ I-MethodName
for -X- _ O
p -X- _ O
from -X- _ O
our -X- _ O
dataset -X- _ O
D -X- _ O
as -X- _ O
follows -X- _ O

p -X- _ O
MLE -X- _ B-MethodName
( -X- _ O
x -X- _ O
k -X- _ O
) -X- _ O
def -X- _ O
= -X- _ O
N -X- _ O
n=1 -X- _ O
1 -X- _ O
{ -X- _ O
x -X- _ O
( -X- _ O
n -X- _ O
) -X- _ O
= -X- _ O
x -X- _ O
k -X- _ O
} -X- _ O
N -X- _ O
( -X- _ O
5 -X- _ O
) -X- _ O

In -X- _ O
the -X- _ O
second -X- _ O
step -X- _ O
, -X- _ O
we -X- _ O
plug -X- _ O
Eq -X- _ O
. -X- _ O
( -X- _ O
5 -X- _ O
) -X- _ O
into -X- _ O
Eq -X- _ O
. -X- _ O
( -X- _ O
1 -X- _ O
) -X- _ O
directly -X- _ O
, -X- _ O
which -X- _ O
results -X- _ O
in -X- _ O
the -X- _ O
estimator -X- _ O
H -X- _ O
MLE -X- _ B-MethodName
( -X- _ O
D -X- _ O
) -X- _ O
. -X- _ O
So -X- _ O
why -X- _ O
is -X- _ O
this -X- _ O
a -X- _ O
bad -X- _ O
idea -X- _ O
? -X- _ O
While -X- _ O
our -X- _ O
probability -X- _ O
estimates -X- _ O
themselves -X- _ O
are -X- _ O
unbiased -X- _ O
, -X- _ O
entropy -X- _ O
is -X- _ O
a -X- _ O
concave -X- _ O
function -X- _ O
. -X- _ O
Consequently -X- _ O
, -X- _ O
by -X- _ O
Jensen -X- _ O
's -X- _ O
inequality -X- _ O
, -X- _ O
this -X- _ O
estimator -X- _ O
is -X- _ O
, -X- _ O
in -X- _ O
expectation -X- _ O
, -X- _ O
a -X- _ O
lower -X- _ O
bound -X- _ O
on -X- _ O
the -X- _ O
true -X- _ O
entropy -X- _ O
( -X- _ O
see -X- _ O
App -X- _ O
. -X- _ O
E.1 -X- _ O
for -X- _ O
proof -X- _ O
) -X- _ O
. -X- _ O
Moreover -X- _ O
, -X- _ O
when -X- _ O
N -X- _ O
≪ -X- _ O
K -X- _ O
, -X- _ O
which -X- _ O
is -X- _ O
often -X- _ O
the -X- _ O
case -X- _ O
in -X- _ O
power -X- _ O
- -X- _ O
law -X- _ O
distributed -X- _ O
data -X- _ O
, -X- _ O
the -X- _ O
estimate -X- _ O
becomes -X- _ O
quite -X- _ O
unreliable -X- _ O
( -X- _ O
Nemenman -X- _ O
et -X- _ O
al -X- _ O
. -X- _ O
, -X- _ O
2002 -X- _ O
) -X- _ O
. -X- _ O

An -X- _ O
Ensemble -X- _ O
of -X- _ O
Entropy -X- _ O
Estimators -X- _ O

MM- -X- _ B-MethodName
Miller -X- _ O
( -X- _ O
1955 -X- _ O
) -X- _ O
and -X- _ O
Madow -X- _ O
( -X- _ O
1948 -X- _ O
) -X- _ O
. -X- _ O
The -X- _ O
first -X- _ O
innovation -X- _ O
in -X- _ O
entropy -X- _ O
estimation -X- _ O
known -X- _ O
to -X- _ O
the -X- _ O
authors -X- _ O
is -X- _ O
a -X- _ O
simple -X- _ O
fix -X- _ O
derived -X- _ O
from -X- _ O
a -X- _ O
first -X- _ O
- -X- _ O
order -X- _ O
Taylor -X- _ O
expansion -X- _ O
of -X- _ O
MLE -X- _ B-MethodName
( -X- _ O
described -X- _ O
above -X- _ O
) -X- _ O
. -X- _ O
The -X- _ O
Miller -X- _ O
- -X- _ O
Madow -X- _ O
estimator -X- _ O
only -X- _ O
involves -X- _ O
a -X- _ O
simple -X- _ O
additive -X- _ O
correction -X- _ O
, -X- _ O
which -X- _ O
is -X- _ O
shown -X- _ O
below -X- _ O
: -X- _ O

H -X- _ O
MM -X- _ B-MethodName
( -X- _ O
D -X- _ O
) -X- _ O
def -X- _ O
= -X- _ O
H -X- _ O
MLE -X- _ B-MethodName
( -X- _ O
D -X- _ O
) -X- _ O
+ -X- _ O
K -X- _ O
− -X- _ O
1 -X- _ O
2N -X- _ O
( -X- _ O
6 -X- _ O
) -X- _ O

where -X- _ O
K -X- _ O
is -X- _ O
size -X- _ O
of -X- _ O
the -X- _ O
support -X- _ O
of -X- _ O
X -X- _ O
. -X- _ O
The -X- _ O
Miller -X- _ B-MethodName
- -X- _ I-MethodName
Madow -X- _ I-MethodName
correction -X- _ O
should -X- _ O
seem -X- _ O
intuitive -X- _ O
in -X- _ O
that -X- _ O
we -X- _ O
add -X- _ O
K−1 -X- _ O
2N -X- _ O
≥ -X- _ O
0 -X- _ O
to -X- _ O
compensate -X- _ O
for -X- _ O
the -X- _ O
negative -X- _ O
bias -X- _ O
of -X- _ O
the -X- _ O
estimator -X- _ O
. -X- _ O
A -X- _ O
full -X- _ O
derivation -X- _ O
of -X- _ O
the -X- _ O
Miller -X- _ B-MethodName
- -X- _ I-MethodName
Madow -X- _ I-MethodName
estimator -X- _ O
is -X- _ O
given -X- _ O
in -X- _ O
Proposition -X- _ O
2 -X- _ O
. -X- _ O

JACK- -X- _ B-MethodName
Zahl -X- _ O
( -X- _ O
1977 -X- _ O
) -X- _ O
. -X- _ O
Next -X- _ O
we -X- _ O
consider -X- _ O
the -X- _ O
jackknife -X- _ B-MethodName
, -X- _ O
which -X- _ O
is -X- _ O
a -X- _ O
common -X- _ O
strategy -X- _ O
used -X- _ O
to -X- _ O
correct -X- _ O
for -X- _ O
the -X- _ O
bias -X- _ O
of -X- _ O
statistical -X- _ O
estimators -X- _ O
. -X- _ O
In -X- _ O
the -X- _ O
case -X- _ O
of -X- _ O
entropy -X- _ B-TaskName
estimation -X- _ I-TaskName
, -X- _ O
we -X- _ O
can -X- _ O
apply -X- _ O
the -X- _ O
jackknife -X- _ B-MethodName
out -X- _ O
of -X- _ O
the -X- _ O
box -X- _ O
to -X- _ O
correct -X- _ O
the -X- _ O
bias -X- _ O
inherent -X- _ O
in -X- _ O
the -X- _ O
MLE -X- _ B-MethodName
estimator -X- _ O
. -X- _ O
Explicitly -X- _ O
, -X- _ O
this -X- _ O
is -X- _ O
done -X- _ O
by -X- _ O
averaging -X- _ O
plug -X- _ O
- -X- _ O
in -X- _ O
entropy -X- _ O
estimates -X- _ O
H -X- _ O
MLE -X- _ B-MethodName
( -X- _ O
D -X- _ O
) -X- _ O
albeit -X- _ O
with -X- _ O
the -X- _ O
n -X- _ O
th -X- _ O
sample -X- _ O
from -X- _ O
the -X- _ O
data -X- _ O
removed -X- _ O
; -X- _ O
we -X- _ O
denote -X- _ O
this -X- _ O
held -X- _ O
- -X- _ O
out -X- _ O
plug -X- _ O
- -X- _ O
in -X- _ O
estimator -X- _ O
as -X- _ O
H -X- _ O
\n -X- _ O
MLE -X- _ B-MethodName
( -X- _ O
D -X- _ O
) -X- _ O
. -X- _ O
Averaging -X- _ O
these -X- _ O
" -X- _ O
held -X- _ O
- -X- _ O
out -X- _ O
" -X- _ O
plug -X- _ O
- -X- _ O
in -X- _ O
estimators -X- _ O
results -X- _ O
in -X- _ O
the -X- _ O
following -X- _ O
simple -X- _ O
entropy -X- _ O
estimator -X- _ O

H -X- _ O
JACK -X- _ B-MethodName
( -X- _ O
D -X- _ O
) -X- _ O
def -X- _ O
= -X- _ O
N -X- _ O
H -X- _ O
MLE -X- _ B-MethodName
( -X- _ O
D -X- _ O
) -X- _ O
− -X- _ O
N -X- _ O
− -X- _ O
1 -X- _ O
N -X- _ O
N -X- _ O
n=1 -X- _ O
H -X- _ O
\n -X- _ O
MLE -X- _ B-MethodName
( -X- _ O
D -X- _ O
) -X- _ O
( -X- _ O
7 -X- _ O

) -X- _ O
Note -X- _ O
that -X- _ O
the -X- _ O
jackknife -X- _ B-MethodName
is -X- _ O
applicable -X- _ O
to -X- _ O
any -X- _ O
estimator -X- _ O
, -X- _ O
not -X- _ O
just -X- _ O
H -X- _ O
MLE -X- _ B-MethodName
( -X- _ O
D -X- _ O
) -X- _ O
, -X- _ O
and -X- _ O
, -X- _ O
thus -X- _ O
, -X- _ O
can -X- _ O
be -X- _ O
combined -X- _ O
with -X- _ O
any -X- _ O
of -X- _ O
the -X- _ O
other -X- _ O
approaches -X- _ O
mentioned -X- _ O
. -X- _ O

HT- -X- _ B-MethodName
Horvitz -X- _ O
and -X- _ O
Thompson -X- _ O
( -X- _ O
1952 -X- _ O
) -X- _ O
. -X- _ O
Horvitz -X- _ B-MethodName
- -X- _ I-MethodName
Thompson -X- _ I-MethodName
is -X- _ O
a -X- _ O
general -X- _ O
scheme -X- _ O
for -X- _ O
building -X- _ O
estimators -X- _ O
that -X- _ O
employs -X- _ O
importance -X- _ O
weighting -X- _ O
in -X- _ O
order -X- _ O
to -X- _ O
more -X- _ O
efficiently -X- _ O
estimate -X- _ O
a -X- _ O
function -X- _ O
of -X- _ O
a -X- _ O
random -X- _ O
variable -X- _ O
. -X- _ O
Importantly -X- _ O
, -X- _ O
this -X- _ O
estimator -X- _ O
gives -X- _ O
us -X- _ O
the -X- _ O
ability -X- _ O
to -X- _ O
compensate -X- _ O
for -X- _ O
situations -X- _ O
where -X- _ O
the -X- _ O
probability -X- _ O
of -X- _ O
an -X- _ O
outcome -X- _ O
is -X- _ O
so -X- _ O
low -X- _ O
that -X- _ O
it -X- _ O
is -X- _ O
often -X- _ O
not -X- _ O
observed -X- _ O
in -X- _ O
a -X- _ O
sample -X- _ O
, -X- _ O
which -X- _ O
is -X- _ O
often -X- _ O
the -X- _ O
case -X- _ O
for -X- _ O
e.g. -X- _ O
, -X- _ O
power -X- _ O
- -X- _ O
law -X- _ O
distributions -X- _ O
. -X- _ O

While -X- _ O
a -X- _ O
full -X- _ O
exposition -X- _ O
of -X- _ O
HT -X- _ B-MethodName
estimators -X- _ O
is -X- _ O
outside -X- _ O
of -X- _ O
the -X- _ O
scope -X- _ O
of -X- _ O
this -X- _ O
work -X- _ O
, -X- _ O
in -X- _ O
essence -X- _ O
, -X- _ O
we -X- _ O
can -X- _ O
divide -X- _ O
the -X- _ O
expected -X- _ O
probability -X- _ O
of -X- _ O
a -X- _ O
class -X- _ O
by -X- _ O
each -X- _ O
class -X- _ O
's -X- _ O
estimated -X- _ O
inclusion -X- _ O
probability -X- _ O
to -X- _ O
compensate -X- _ O
for -X- _ O
such -X- _ O
situations -X- _ O
. -X- _ O
Given -X- _ O
the -X- _ O
true -X- _ O
probability -X- _ O
of -X- _ O
an -X- _ O
outcome -X- _ O
p -X- _ O
( -X- _ O
x -X- _ O
k -X- _ O
) -X- _ O
, -X- _ O
the -X- _ O
probability -X- _ O
that -X- _ O
it -X- _ O
occurs -X- _ O
at -X- _ O
least -X- _ O
once -X- _ O
in -X- _ O
a -X- _ O
sample -X- _ O
of -X- _ O
size -X- _ O
N -X- _ O
is -X- _ O
1 -X- _ O
− -X- _ O
( -X- _ O
1 -X- _ O
− -X- _ O
p -X- _ O
( -X- _ O
x -X- _ O
k -X- _ O
) -X- _ O
) -X- _ O
N -X- _ O
. -X- _ O
The -X- _ O
HT -X- _ B-MethodName
estimator -X- _ O
for -X- _ O
entropy -X- _ O
is -X- _ O
then -X- _ O
defined -X- _ O
as -X- _ O

H -X- _ O
HT -X- _ B-MethodName
( -X- _ O
D -X- _ O
) -X- _ O
def -X- _ O
= -X- _ O
− -X- _ O
K -X- _ O
k=1 -X- _ O
p -X- _ O
MLE -X- _ B-MethodName
( -X- _ O
x -X- _ O
k -X- _ O
) -X- _ O
log -X- _ O
p -X- _ O
MLE -X- _ B-MethodName
( -X- _ O
x -X- _ O
k -X- _ O
) -X- _ O
1 -X- _ O
− -X- _ O
( -X- _ O
1 -X- _ O
− -X- _ O
p -X- _ O
MLE -X- _ B-MethodName
( -X- _ O
x -X- _ O
k -X- _ O
) -X- _ O
) -X- _ O
N -X- _ O
( -X- _ O
8 -X- _ O
) -X- _ O

using -X- _ O
our -X- _ O
MLE -X- _ B-MethodName
probability -X- _ O
estimates -X- _ O
p -X- _ O
MLE -X- _ B-MethodName
( -X- _ O
x -X- _ O
k -X- _ O
) -X- _ O
. -X- _ O
-Chao -X- _ O
and -X- _ O
Shen -X- _ O
( -X- _ O
2003 -X- _ O
) -X- _ O
. -X- _ O
Chao -X- _ O
- -X- _ O
Shen -X- _ O
modifies -X- _ O
HT -X- _ B-MethodName
by -X- _ O
multiplying -X- _ O
the -X- _ O
MLE -X- _ B-MethodName
probability -X- _ O
estimates -X- _ O
by -X- _ O
an -X- _ O
estimate -X- _ O
of -X- _ O
sample -X- _ O
coverage -X- _ O
. -X- _ O
Formally -X- _ O
, -X- _ O
let -X- _ O
f -X- _ O
1 -X- _ O
be -X- _ O
the -X- _ O
number -X- _ O
of -X- _ O
observed -X- _ O
singletons -X- _ O
4 -X- _ O
in -X- _ O
sample -X- _ O
; -X- _ O
our -X- _ O
sample -X- _ O
coverage -X- _ O
can -X- _ O
be -X- _ O
estimated -X- _ O
as -X- _ O

CS -X- _ O

C -X- _ O
= -X- _ O
1 -X- _ O
− -X- _ O
f -X- _ O
1 -X- _ O
N -X- _ O
. -X- _ O

WW- -X- _ B-MethodName
Wolpert -X- _ O
and -X- _ O
Wolf -X- _ O
( -X- _ O
1995 -X- _ O
) -X- _ O
. -X- _ O
One -X- _ O
family -X- _ O
of -X- _ O
entropy -X- _ O
estimators -X- _ O
in -X- _ O
information -X- _ O
theory -X- _ O
is -X- _ O
based -X- _ O
on -X- _ O
Bayesian -X- _ O
principles -X- _ O
. -X- _ O
The -X- _ O
first -X- _ O
of -X- _ O
these -X- _ O
was -X- _ O
the -X- _ O
Wolpert -X- _ B-MethodName
- -X- _ I-MethodName
Wolf -X- _ I-MethodName
estimator -X- _ O
, -X- _ O
which -X- _ O
uses -X- _ O
a -X- _ O
Dirichlet -X- _ O
prior -X- _ O
( -X- _ O
with -X- _ O
concentration -X- _ O
parameter -X- _ O
α -X- _ O
and -X- _ O
a -X- _ O
uniform -X- _ O
base -X- _ O
distribution -X- _ O
) -X- _ O
. -X- _ O
This -X- _ O
Bayesian -X- _ O
estimator -X- _ O
has -X- _ O
a -X- _ O
clean -X- _ O
, -X- _ O
closed -X- _ O
form -X- _ O
: -X- _ O

H -X- _ O
WW -X- _ B-MethodName
( -X- _ O
D -X- _ O
| -X- _ O
α -X- _ O
) -X- _ O
def -X- _ O
= -X- _ O
ψ -X- _ O
A -X- _ O
+ -X- _ O
1 -X- _ O
− -X- _ O
K -X- _ O
k=1 -X- _ O
α -X- _ O
k -X- _ O
A -X- _ O
ψ -X- _ O
( -X- _ O
α -X- _ O
k -X- _ O
+ -X- _ O
1 -X- _ O
) -X- _ O
( -X- _ O
10 -X- _ O
) -X- _ O

where -X- _ O
α -X- _ O
k -X- _ O
= -X- _ O
c -X- _ O
( -X- _ O
x -X- _ O
k -X- _ O
) -X- _ O
+ -X- _ O
α -X- _ O
k -X- _ O
( -X- _ O
for -X- _ O
the -X- _ O
histogram -X- _ O
count -X- _ O
c -X- _ O
( -X- _ O
x -X- _ O
k -X- _ O
) -X- _ O
of -X- _ O
class -X- _ O
k -X- _ O
in -X- _ O
the -X- _ O
sample -X- _ O
; -X- _ O
this -X- _ O
is -X- _ O
analogous -X- _ O
to -X- _ O
Laplace -X- _ O
smoothing -X- _ O
) -X- _ O
, -X- _ O
A -X- _ O
= -X- _ O
K -X- _ O
k=1 -X- _ O
α -X- _ O
k -X- _ O
, -X- _ O
and -X- _ O
ψ -X- _ O
is -X- _ O
the -X- _ O
digamma -X- _ O
function -X- _ O
. -X- _ O
A -X- _ O
full -X- _ O
derivation -X- _ O
of -X- _ O
Eq -X- _ O
. -X- _ O
( -X- _ O
10 -X- _ O
) -X- _ O
is -X- _ O
given -X- _ O
in -X- _ O
Proposition -X- _ O
3 -X- _ O
. -X- _ O
Unfortunately -X- _ O
, -X- _ O
Eq -X- _ O
. -X- _ O
( -X- _ O
10 -X- _ O
Table -X- _ O
1 -X- _ O
: -X- _ O
The -X- _ O
best -X- _ O
unigram -X- _ O
entropy -X- _ O
estimators -X- _ O
on -X- _ O
the -X- _ O
corpora -X- _ O
studied -X- _ O
, -X- _ O
tested -X- _ O
on -X- _ O
various -X- _ O
N -X- _ O
averaged -X- _ O
over -X- _ O
100 -X- _ O
samples -X- _ O
. -X- _ O
All -X- _ O
differences -X- _ O
are -X- _ O
statistically -X- _ O
significant -X- _ O
on -X- _ O
the -X- _ O
permutation -X- _ O
test -X- _ O
; -X- _ O
lighter -X- _ O
color -X- _ O
indicates -X- _ O
fewer -X- _ O
statistically -X- _ O
significant -X- _ O
comparisons -X- _ O
on -X- _ O
the -X- _ O
Tukey -X- _ O
test -X- _ O
. -X- _ O
Scale -X- _ O
: -X- _ O
significantly -X- _ O
better -X- _ O
than -X- _ O
6 -X- _ O
5 -X- _ O
4 -X- _ O
3 -X- _ O
2 -X- _ O
1 -X- _ O
0 -X- _ O
other -X- _ O
estimators -X- _ O
. -X- _ O

very -X- _ O
dependent -X- _ O
on -X- _ O
the -X- _ O
choice -X- _ O
of -X- _ O
α -X- _ O
: -X- _ O
For -X- _ O
large -X- _ O
K -X- _ O
, -X- _ O
α -X- _ O
almost -X- _ O
completely -X- _ O
determines -X- _ O
the -X- _ O
final -X- _ O
entropy -X- _ O
estimate -X- _ O
, -X- _ O
an -X- _ O
observation -X- _ O
first -X- _ O
made -X- _ O
by -X- _ O
Nemenman -X- _ O
et -X- _ O
al -X- _ O
. -X- _ O
( -X- _ O
2002 -X- _ O
) -X- _ O
which -X- _ O
motivated -X- _ O
their -X- _ O
improved -X- _ O
estimator -X- _ O
described -X- _ O
below -X- _ O
. -X- _ O
-Nemenman -X- _ O
et -X- _ O
al -X- _ O
. -X- _ O
( -X- _ O
2002 -X- _ O
) -X- _ O
. -X- _ O
Nemenman -X- _ O
et -X- _ O
al -X- _ O
. -X- _ O
( -X- _ O
NSB -X- _ B-MethodName
) -X- _ O
attempt -X- _ O
to -X- _ O
alleviate -X- _ O
the -X- _ O
Wolpert -X- _ B-MethodName
- -X- _ I-MethodName
Wolf -X- _ I-MethodName
estimator -X- _ O
's -X- _ O
dependence -X- _ O
on -X- _ O
α -X- _ O
. -X- _ O
They -X- _ O
take -X- _ O
α -X- _ O
= -X- _ O
α -X- _ O
• -X- _ O
1 -X- _ O
, -X- _ O
enforcing -X- _ O
that -X- _ O
the -X- _ O
Dirichlet -X- _ O
prior -X- _ O
is -X- _ O
symmetric -X- _ O
, -X- _ O
and -X- _ O
develop -X- _ O
a -X- _ O
hyperprior -X- _ O
over -X- _ O
α -X- _ O
that -X- _ O
results -X- _ O
in -X- _ O
a -X- _ O
nearuniform -X- _ O
distribution -X- _ O
over -X- _ O
entropy -X- _ O
. -X- _ O
The -X- _ O
hyperprior -X- _ O
is -X- _ O
given -X- _ O
by -X- _ O

NSB -X- _ B-MethodName

p -X- _ O
NSB -X- _ B-MethodName
( -X- _ O
α -X- _ O
) -X- _ O
def -X- _ O
= -X- _ O
Kψ -X- _ O
1 -X- _ O
( -X- _ O
Kα -X- _ O
+ -X- _ O
1 -X- _ O
) -X- _ O
− -X- _ O
ψ -X- _ O
1 -X- _ O
( -X- _ O
α -X- _ O
+ -X- _ O
1 -X- _ O
) -X- _ O
log -X- _ O
K -X- _ O
( -X- _ O
11 -X- _ O
) -X- _ O

where -X- _ O
ψ -X- _ O
1 -X- _ O
is -X- _ O
the -X- _ O
trigamma -X- _ O
function -X- _ O
. -X- _ O
A -X- _ O
full -X- _ O
derivation -X- _ O
of -X- _ O
Eq -X- _ O
. -X- _ O
( -X- _ O
11 -X- _ O
) -X- _ O
is -X- _ O
given -X- _ O
in -X- _ O
Proposition -X- _ O
4 -X- _ O
. -X- _ O
This -X- _ O
choice -X- _ O
of -X- _ O
hyperprior -X- _ O
mitigates -X- _ O
the -X- _ O
effect -X- _ O
that -X- _ O
the -X- _ O
chosen -X- _ O
α -X- _ O
has -X- _ O
on -X- _ O
the -X- _ O
entropy -X- _ O
estimate -X- _ O
. -X- _ O
Nemenman -X- _ O
et -X- _ O
al -X- _ O
. -X- _ O
's -X- _ O
( -X- _ O
2002 -X- _ O
) -X- _ O
entropy -X- _ O
estimator -X- _ O
is -X- _ O
then -X- _ O
the -X- _ O
posterior -X- _ O
mean -X- _ O
of -X- _ O
the -X- _ O
Wolpert -X- _ B-MethodName
- -X- _ I-MethodName
Wolft -X- _ I-MethodName
estimator -X- _ O
taken -X- _ O
under -X- _ O
p -X- _ O
NSB -X- _ B-MethodName
: -X- _ O

H -X- _ O
NSB -X- _ B-MethodName
( -X- _ O
D -X- _ O
) -X- _ O
= -X- _ O
∞ -X- _ O
0 -X- _ O
H -X- _ O
WW -X- _ B-MethodName
( -X- _ O
D -X- _ O
| -X- _ O
α -X- _ O
• -X- _ O
1 -X- _ O
) -X- _ O
p -X- _ O
NSB -X- _ B-MethodName
( -X- _ O
α -X- _ O
) -X- _ O
dα -X- _ O
( -X- _ O

12 -X- _ O
) -X- _ O
Typically -X- _ O
, -X- _ O
numerical -X- _ O
integration -X- _ O
is -X- _ O
used -X- _ O
to -X- _ O
quickly -X- _ O
compute -X- _ O
the -X- _ O
unidimensional -X- _ O
integral -X- _ O
. -X- _ O

Experiments -X- _ O

Here -X- _ O
we -X- _ O
provide -X- _ O
an -X- _ O
evaluation -X- _ O
of -X- _ O
the -X- _ O
entropy -X- _ O
estimators -X- _ O
presented -X- _ O
in -X- _ O
§ -X- _ O
3.2 -X- _ O
on -X- _ O
linguistic -X- _ O
data -X- _ O
. -X- _ O

Entropy -X- _ O
of -X- _ O
the -X- _ O
Unigram -X- _ O
Distribution -X- _ O

We -X- _ O
start -X- _ O
our -X- _ O
study -X- _ O
with -X- _ O
a -X- _ O
controlled -X- _ O
experiment -X- _ O
where -X- _ O
we -X- _ O
estimate -X- _ O
the -X- _ O
entropy -X- _ O
of -X- _ O
the -X- _ O
truncated -X- _ O
unigram -X- _ O
distribution -X- _ O
, -X- _ O
the -X- _ O
( -X- _ O
finite -X- _ O
) -X- _ O
distribution -X- _ O
over -X- _ O
the -X- _ O
frequent -X- _ O
word -X- _ O
tokens -X- _ O
in -X- _ O
a -X- _ O
language -X- _ O
without -X- _ O
regard -X- _ O
to -X- _ O
context -X- _ O
( -X- _ O
Baayen -X- _ O
et -X- _ O
al -X- _ O
. -X- _ O
, -X- _ O
2016 -X- _ O
; -X- _ O
Diessel -X- _ O
, -X- _ O
2017 -X- _ O
; -X- _ O
Divjak -X- _ O
, -X- _ O
2019 -X- _ O
; -X- _ O
. -X- _ O
We -X- _ O
renormalize -X- _ O
the -X- _ O
frequency -X- _ O
counts -X- _ O
of -X- _ O
corpora -X- _ O
in -X- _ O
English -X- _ O
, -X- _ O
German -X- _ O
, -X- _ O
and -X- _ O
Dutch -X- _ O
( -X- _ O
taken -X- _ O
from -X- _ O
CELEX -X- _ B-DatasetName
; -X- _ O
Baayen -X- _ O
et -X- _ O
al -X- _ O
. -X- _ O
, -X- _ O
1995 -X- _ O
) -X- _ O
, -X- _ O
as -X- _ O
well -X- _ O
as -X- _ O
Mongolian -X- _ O
and -X- _ O
Tagalog -X- _ O
( -X- _ O
from -X- _ O
Wikipedia -X- _ B-DatasetName
5 -X- _ O
) -X- _ O
. -X- _ O
We -X- _ O
take -X- _ O
this -X- _ O
renormalization -X- _ O
as -X- _ O
a -X- _ O
gold -X- _ O
standard -X- _ O
distribution -X- _ O
, -X- _ O
since -X- _ O
we -X- _ O
can -X- _ O
not -X- _ O
access -X- _ O
the -X- _ O
underlying -X- _ O
unigram -X- _ O
distribution -X- _ O
. -X- _ O
We -X- _ O
then -X- _ O
draw -X- _ O
samples -X- _ O
of -X- _ O
varying -X- _ O
sizes -X- _ O
( -X- _ O
N -X- _ O
∈ -X- _ O
{ -X- _ O
10 -X- _ O
2 -X- _ O
, -X- _ O
10 -X- _ O
3 -X- _ O
, -X- _ O
10 -X- _ O
4 -X- _ O
, -X- _ O
10 -X- _ O
5 -X- _ O
} -X- _ O
) -X- _ O
from -X- _ O
the -X- _ O
distribution -X- _ O
of -X- _ O
renormalized -X- _ O
frequency -X- _ O
counts -X- _ O
to -X- _ O
test -X- _ O
the -X- _ O
estimators -X- _ O
' -X- _ O
ability -X- _ O
to -X- _ O
recover -X- _ O
the -X- _ O
underlying -X- _ O
distributions -X- _ O
' -X- _ O
entropy -X- _ O
. -X- _ O
While -X- _ O
the -X- _ O
renormalized -X- _ O
frequency -X- _ O
counts -X- _ O
are -X- _ O
not -X- _ O
necessarily -X- _ O
representative -X- _ O
of -X- _ O
the -X- _ O
true -X- _ O
unigram -X- _ O
distribution -X- _ O
, -X- _ O
they -X- _ O
nevertheless -X- _ O
provide -X- _ O
us -X- _ O
with -X- _ O
a -X- _ O
controlled -X- _ O
setting -X- _ O
to -X- _ O
benchmark -X- _ O
various -X- _ O
entropy -X- _ O
estimators -X- _ O
. -X- _ O

We -X- _ O
evaluate -X- _ O
the -X- _ O
estimators -X- _ O
on -X- _ O
both -X- _ O
bias -X- _ O
and -X- _ O
MSE -X- _ B-MetricName
, -X- _ O
as -X- _ O
defined -X- _ O
in -X- _ O
( -X- _ O
2 -X- _ O
) -X- _ O
and -X- _ O
( -X- _ O
4 -X- _ O
) -X- _ O
, -X- _ O
as -X- _ O
well -X- _ O
as -X- _ O
mean -X- _ O
absolute -X- _ O
bias -X- _ O
( -X- _ O
MAB -X- _ B-MetricName
) -X- _ O
. -X- _ O
To -X- _ O
test -X- _ O
the -X- _ O
statistical -X- _ O
significance -X- _ O
of -X- _ O
differences -X- _ O
in -X- _ O
metrics -X- _ O
between -X- _ O
entropy -X- _ O
estimators -X- _ O
, -X- _ O
we -X- _ O
use -X- _ O
paired -X- _ O
permutation -X- _ O
tests -X- _ O
( -X- _ O
Good -X- _ O
, -X- _ O
2000 -X- _ O
) -X- _ O
( -X- _ O
sampling -X- _ O
1 -X- _ O
, -X- _ O
000 -X- _ O
permutations -X- _ O
) -X- _ O
between -X- _ O
pairs -X- _ O
of -X- _ O
estimators -X- _ O
, -X- _ O
checking -X- _ O
MAB -X- _ B-MetricName
and -X- _ O
MSE -X- _ B-MetricName
. -X- _ O
We -X- _ O
run -X- _ O
Tukey -X- _ O
's -X- _ O
test -X- _ O
( -X- _ O
1949 -X- _ O
) -X- _ O
to -X- _ O
judge -X- _ O
the -X- _ O
statistical -X- _ O
significance -X- _ O
of -X- _ O
differences -X- _ O
in -X- _ O
MAB -X- _ B-MetricName
and -X- _ O
MSE -X- _ B-MetricName
between -X- _ O
all -X- _ O
pairs -X- _ O
of -X- _ O
estimators -X- _ O
, -X- _ O
which -X- _ O
found -X- _ O
only -X- _ O
a -X- _ O
few -X- _ O
insignificant -X- _ O
comparisons -X- _ O
when -X- _ O
N -X- _ O
was -X- _ O
large -X- _ O
. -X- _ O

Results -X- _ O
are -X- _ O
shown -X- _ O
in -X- _ O
Table -X- _ O
1 -X- _ O
and -X- _ O
Figure -X- _ O
1 -X- _ O
. -X- _ O
We -X- _ O
find -X- _ O
that -X- _ O
NSB -X- _ B-MethodName
( -X- _ O
followed -X- _ O
closely -X- _ O
by -X- _ O
CS -X- _ B-MethodName
) -X- _ O
converges -X- _ O
almost -X- _ O
to -X- _ O
the -X- _ O
true -X- _ O
entropy -X- _ O
from -X- _ O
below -X- _ O
using -X- _ O
with -X- _ O
only -X- _ O
a -X- _ O
few -X- _ O
samples -X- _ O
. -X- _ O
HT -X- _ B-MethodName
is -X- _ O
the -X- _ O
best -X- _ O
estimator -X- _ O
for -X- _ O
N -X- _ O
< -X- _ O
2 -X- _ O
, -X- _ O
000 -X- _ O
, -X- _ O
but -X- _ O
as -X- _ O
N -X- _ O
increases -X- _ O
it -X- _ O
tends -X- _ O
to -X- _ O
overestimate -X- _ O
entropy -X- _ O
to -X- _ O
the -X- _ O
point -X- _ O
where -X- _ O
its -X- _ O
bias -X- _ O
is -X- _ O
greater -X- _ O
than -X- _ O
that -X- _ O
of -X- _ O
MLE -X- _ B-MethodName
. -X- _ O
Besides -X- _ O
HT -X- _ B-MethodName
, -X- _ O
all -X- _ O
estimators -X- _ O
at -X- _ O
all -X- _ O
tested -X- _ O
sample -X- _ O
sizes -X- _ O
N -X- _ O
have -X- _ O
lower -X- _ O
MAB -X- _ O
and -X- _ O
MSE -X- _ B-MetricName
than -X- _ O
MLE -X- _ B-MethodName
. -X- _ O

Replication -X- _ O
of -X- _ O
Williams -X- _ O
et -X- _ O
al -X- _ O
. -X- _ O
( -X- _ O
2021 -X- _ O
) -X- _ O

Next -X- _ O
, -X- _ O
we -X- _ O
turn -X- _ O
to -X- _ O
a -X- _ O
replication -X- _ O
of -X- _ O
Williams -X- _ O
et -X- _ O
al -X- _ O
. -X- _ O
's -X- _ O
( -X- _ O
2021 -X- _ O
) -X- _ O
information -X- _ O
- -X- _ O
theoretic -X- _ O
study -X- _ O
on -X- _ O
the -X- _ O
associa- -X- _ O
tion -X- _ O
between -X- _ O
gendered -X- _ O
inanimate -X- _ O
nouns -X- _ O
and -X- _ O
their -X- _ O
modifying -X- _ O
adjectives -X- _ O
. -X- _ O
They -X- _ O
estimate -X- _ O
mutual -X- _ B-MetricName
information -X- _ I-MetricName
by -X- _ O
using -X- _ O
its -X- _ O
familiar -X- _ O
decomposition -X- _ O
as -X- _ O
the -X- _ O
difference -X- _ O
of -X- _ O
two -X- _ O
entropies -X- _ O
: -X- _ O

MI -X- _ B-MetricName
( -X- _ O
X -X- _ O
; -X- _ O
Y -X- _ O
) -X- _ O
= -X- _ O
H -X- _ O
( -X- _ O
X -X- _ O
) -X- _ O
− -X- _ O
H -X- _ O
( -X- _ O
X -X- _ O
| -X- _ O
Y -X- _ O
) -X- _ O
. -X- _ O

The -X- _ O
entropies -X- _ O
H -X- _ O
( -X- _ O
X -X- _ O
) -X- _ O
and -X- _ O
H -X- _ O
( -X- _ O
X -X- _ O
| -X- _ O
Y -X- _ O
) -X- _ O
are -X- _ O
estimated -X- _ O
independently -X- _ O
and -X- _ O
then -X- _ O
their -X- _ O
difference -X- _ O
is -X- _ O
computed -X- _ O
. -X- _ O
We -X- _ O
replicate -X- _ O
Williams -X- _ O
et -X- _ O
al -X- _ O
. -X- _ O
's -X- _ O
( -X- _ O
2021 -X- _ O
) -X- _ O
experiments -X- _ O
using -X- _ O
gold -X- _ O
- -X- _ O
parsed -X- _ O
Universal -X- _ B-DatasetName
Dependencies -X- _ I-DatasetName
corpora -X- _ O
, -X- _ O
filtering -X- _ O
out -X- _ O
animate -X- _ O
nouns -X- _ O
with -X- _ O
Multilingual -X- _ O
WordNet -X- _ O
( -X- _ O
Bond -X- _ O
and -X- _ O
Foster -X- _ O
, -X- _ O
2013 -X- _ O
) -X- _ O
. -X- _ O
We -X- _ O
rerun -X- _ O
their -X- _ O
experimental -X- _ O
set -X- _ O
- -X- _ O
up -X- _ O
using -X- _ O
our -X- _ O
full -X- _ O
suite -X- _ O
of -X- _ O
entropy -X- _ O
estimators -X- _ O
to -X- _ O
determine -X- _ O
whether -X- _ O
the -X- _ O
relationship -X- _ O
they -X- _ O
posit -X- _ O
remains -X- _ O
significant -X- _ O
, -X- _ O
checking -X- _ O
3 -X- _ O
more -X- _ O
languages -X- _ O
not -X- _ O
in -X- _ O
the -X- _ O
original -X- _ O
study -X- _ O
. -X- _ O

We -X- _ O
report -X- _ O
results -X- _ O
for -X- _ O
normalized -X- _ B-MetricName
mutual -X- _ I-MetricName
information -X- _ I-MetricName
( -X- _ O
dividing -X- _ O
MI -X- _ B-MetricName
by -X- _ O
maximum -X- _ O
possible -X- _ O
MI -X- _ B-MetricName
) -X- _ O
in -X- _ O
Table -X- _ O
2 -X- _ O
. -X- _ O
We -X- _ O
find -X- _ O
that -X- _ O
using -X- _ O
NSB -X- _ B-MethodName
( -X- _ O
the -X- _ O
estimator -X- _ O
we -X- _ O
found -X- _ O
most -X- _ O
effective -X- _ O
in -X- _ O
§ -X- _ O
4.1 -X- _ O
) -X- _ O
instead -X- _ O
of -X- _ O
MLE -X- _ B-MethodName
, -X- _ O
nearly -X- _ O
halves -X- _ O
the -X- _ O
measured -X- _ O
effect -X- _ O
in -X- _ O
all -X- _ O
languages -X- _ O
. -X- _ O
However -X- _ O
, -X- _ O
the -X- _ O
effect -X- _ O
remains -X- _ O
statistically -X- _ O
significant -X- _ O
in -X- _ O
5 -X- _ O
of -X- _ O
7 -X- _ O
languages -X- _ O
tested -X- _ O
, -X- _ O
including -X- _ O
the -X- _ O
4 -X- _ O
that -X- _ O
were -X- _ O
also -X- _ O
in -X- _ O
the -X- _ O
original -X- _ O
study -X- _ O
. -X- _ O

Replication -X- _ O
of -X- _ O
McCarthy -X- _ O
et -X- _ O
al -X- _ O
. -X- _ O
( -X- _ O
2020 -X- _ O
) -X- _ O

Finally -X- _ O
, -X- _ O
we -X- _ O
turn -X- _ O
our -X- _ O
attention -X- _ O
to -X- _ O
McCarthy -X- _ O
et -X- _ O
al -X- _ O
. -X- _ O
's -X- _ O
( -X- _ O
2020 -X- _ O
) -X- _ O
study -X- _ O
on -X- _ O
the -X- _ O
similarity -X- _ O
between -X- _ O
grammatical -X- _ O
gender -X- _ O
partitions -X- _ O
between -X- _ O
languages -X- _ O
. -X- _ O
Using -X- _ O
information -X- _ O
- -X- _ O
theoretic -X- _ O
measures -X- _ O
, -X- _ O
they -X- _ O
found -X- _ O
that -X- _ O
closely -X- _ O
related -X- _ O
languages -X- _ O
have -X- _ O
more -X- _ O
similar -X- _ O
gender -X- _ O
groupings -X- _ O
of -X- _ O
core -X- _ O
lexical -X- _ O
items -X- _ O
. -X- _ O
We -X- _ O
replicate -X- _ O
their -X- _ O
experiment -X- _ O
on -X- _ O
Swadesh -X- _ O
lists -X- _ O
( -X- _ O
Swadesh -X- _ O
, -X- _ O
1955 -X- _ O
) -X- _ O
for -X- _ O
10 -X- _ O
European -X- _ O
languages -X- _ O
with -X- _ O
different -X- _ O
estimators -X- _ O
, -X- _ O
and -X- _ O
find -X- _ O
that -X- _ O
hierarchical -X- _ O
clustering -X- _ O
over -X- _ O
both -X- _ O
mutual -X- _ B-MetricName
( -X- _ O
MI -X- _ B-MetricName
) -X- _ O
and -X- _ O
variational -X- _ B-MetricName
information -X- _ I-MetricName
( -X- _ O
VI -X- _ B-MetricName
) -X- _ O
produces -X- _ O
the -X- _ O
same -X- _ O
trees -X- _ O
as -X- _ O
the -X- _ O
original -X- _ O
study -X- _ O
. -X- _ O
In -X- _ O
this -X- _ O
case -X- _ O
, -X- _ O
using -X- _ O
NSB -X- _ B-MethodName
, -X- _ O
our -X- _ O
recommended -X- _ O
estimator -X- _ O
, -X- _ O
results -X- _ O
in -X- _ O
a -X- _ O
reduced -X- _ O
estimate -X- _ O
of -X- _ O
MI -X- _ B-MetricName
( -X- _ O
e.g. -X- _ O
Croatian -X- _ O
- -X- _ O
Slovak -X- _ O
: -X- _ O
0.54 -X- _ O
with -X- _ O
MLE -X- _ B-MethodName
→ -X- _ O
0.46 -X- _ O
with -X- _ O
NSB -X- _ B-MethodName
) -X- _ O
, -X- _ O
but -X- _ O
significance -X- _ O
testing -X- _ O
with -X- _ O
1,000 -X- _ O
permutations -X- _ O
finds -X- _ O
the -X- _ O
same -X- _ O
pairs -X- _ O
were -X- _ O
statistically -X- _ O
significant -X- _ O
for -X- _ O
both -X- _ O
MI -X- _ B-MethodName
and -X- _ O
VI -X- _ B-MethodName
regardless -X- _ O
of -X- _ O
estimator -X- _ O
: -X- _ O
all -X- _ O
pairs -X- _ O
of -X- _ O
Slavic -X- _ O
languages -X- _ O
and -X- _ O
Romance -X- _ O
languages -X- _ O
, -X- _ O
and -X- _ O
Bulgarian -X- _ O
- -X- _ O
Spanish -X- _ O
( -X- _ O
see -X- _ O
Figure -X- _ O
2 -X- _ O
) -X- _ O
. -X- _ O
Thus -X- _ O
, -X- _ O
we -X- _ O
see -X- _ O
a -X- _ O
similar -X- _ O
result -X- _ O
here -X- _ O
as -X- _ O
in -X- _ O
the -X- _ O
previous -X- _ O
replication -X- _ O
. -X- _ O

Conclusion -X- _ O

This -X- _ O
work -X- _ O
presents -X- _ O
the -X- _ O
first -X- _ O
empirical -X- _ O
study -X- _ O
comparing -X- _ O
the -X- _ O
performance -X- _ O
of -X- _ O
various -X- _ O
entropy -X- _ O
estimators -X- _ O
for -X- _ O
use -X- _ O
with -X- _ O
natural -X- _ O
language -X- _ O
distributions -X- _ O
. -X- _ O
From -X- _ O
experiments -X- _ O
on -X- _ O
synthetic -X- _ B-DatasetName
data -X- _ I-DatasetName
( -X- _ O
appendix -X- _ O
) -X- _ O
and -X- _ O
natural -X- _ O
data -X- _ O
( -X- _ O
CELEX -X- _ B-DatasetName
) -X- _ O
, -X- _ O
and -X- _ O
two -X- _ O
replication -X- _ O
studies -X- _ O
of -X- _ O
recent -X- _ O
papers -X- _ O
in -X- _ O
information -X- _ O
- -X- _ O
theoretic -X- _ O
linguistics -X- _ O
, -X- _ O
we -X- _ O
find -X- _ O
that -X- _ O
the -X- _ O
oft -X- _ O
- -X- _ O
employed -X- _ O
plug -X- _ O
- -X- _ O
in -X- _ O
estimator -X- _ O
of -X- _ O
entropy -X- _ O
can -X- _ O
cause -X- _ O
misleading -X- _ O
results -X- _ O
, -X- _ O
e.g. -X- _ O
, -X- _ O
the -X- _ O
overestimates -X- _ O
of -X- _ O
effect -X- _ O
sizes -X- _ O
seen -X- _ O
in -X- _ O
both -X- _ O
replication -X- _ O
studies -X- _ O
. -X- _ O
The -X- _ O
recommendation -X- _ O
of -X- _ O
our -X- _ O
paper -X- _ O
is -X- _ O
that -X- _ O
researchers -X- _ O
should -X- _ O
carefully -X- _ O
consider -X- _ O
their -X- _ O
choice -X- _ O
of -X- _ O
entropy -X- _ O
estimator -X- _ O
based -X- _ O
on -X- _ O
data -X- _ O
availability -X- _ O
and -X- _ O
the -X- _ O
nature -X- _ O
of -X- _ O
the -X- _ O
underlying -X- _ O
distribution -X- _ O
. -X- _ O

Ethics -X- _ O
Statement -X- _ O

The -X- _ O
authors -X- _ O
foresee -X- _ O
no -X- _ O
ethical -X- _ O
concerns -X- _ O
with -X- _ O
the -X- _ O
research -X- _ O
presented -X- _ O
in -X- _ O
this -X- _ O
paper -X- _ O
. -X- _ O

A -X- _ O
Implementation -X- _ O

The -X- _ O
code -X- _ O
for -X- _ O
each -X- _ O
of -X- _ O
the -X- _ O
entropy -X- _ O
estimators -X- _ O
is -X- _ O
implemented -X- _ O
in -X- _ O
Python -X- _ O
using -X- _ O
numpy -X- _ O
( -X- _ O
Harris -X- _ O
et -X- _ O
al -X- _ O
. -X- _ O
, -X- _ O
2020 -X- _ O
) -X- _ O
, -X- _ O
except -X- _ O
for -X- _ O
NSB -X- _ B-MethodName
which -X- _ O
was -X- _ O
taken -X- _ O
from -X- _ O
an -X- _ O
existing -X- _ O
efficient -X- _ O
implementation -X- _ O
in -X- _ O
the -X- _ O
ndd -X- _ O
module -X- _ O
( -X- _ O
Marsili -X- _ O
, -X- _ O
2016 -X- _ O
) -X- _ O
. -X- _ O
We -X- _ O
calculated -X- _ O
entropies -X- _ O
with -X- _ O
base -X- _ O
e -X- _ O
( -X- _ O
in -X- _ O
nats -X- _ O
) -X- _ O
. -X- _ O

B -X- _ O
Experiments -X- _ O
with -X- _ O
simulated -X- _ B-DatasetName
data -X- _ I-DatasetName

In -X- _ O
our -X- _ O
experiments -X- _ O
with -X- _ O
simulated -X- _ B-DatasetName
data -X- _ I-DatasetName
, -X- _ O
we -X- _ O
explore -X- _ O
distributions -X- _ O
sampled -X- _ O
from -X- _ O
a -X- _ O
symmetric -X- _ O
Dirichlet -X- _ O
prior -X- _ O
with -X- _ O
varying -X- _ O
number -X- _ B-HyperparameterName
of -X- _ I-HyperparameterName
classes -X- _ I-HyperparameterName
K -X- _ B-HyperparameterName
and -X- _ O
known -X- _ O
distributions -X- _ O
of -X- _ O
Zipfian -X- _ O
form -X- _ O
with -X- _ O
various -X- _ O
parameters -X- _ O
. -X- _ O

Words -X- _ O
in -X- _ O
natural -X- _ O
languages -X- _ O
have -X- _ O
a -X- _ O
roughly -X- _ O
Zipfian -X- _ O
distribution -X- _ O
, -X- _ O
with -X- _ O
probability -X- _ O
inversely -X- _ O
proportional -X- _ O
to -X- _ O
rank -X- _ O
( -X- _ O
Zipf -X- _ O
, -X- _ O
1935 -X- _ O
) -X- _ O
, -X- _ O
and -X- _ O
a -X- _ O
symmetric -X- _ O
Dirichlet -X- _ O
distribution -X- _ O
is -X- _ O
analogous -X- _ O
to -X- _ O
e.g. -X- _ O
POS -X- _ O
tag -X- _ O
label -X- _ O
distributions -X- _ O
in -X- _ O
natural -X- _ O
language -X- _ O
. -X- _ O
Thus -X- _ O
, -X- _ O
studying -X- _ O
synthetic -X- _ O
data -X- _ O
from -X- _ O
such -X- _ O
distributions -X- _ O
as -X- _ O
a -X- _ O
start -X- _ O
is -X- _ O
useful -X- _ O
. -X- _ O

B.1 -X- _ O
Experiment -X- _ O
1 -X- _ O
: -X- _ O
Symmetric -X- _ O
Dirichlet -X- _ O
distributions -X- _ O

We -X- _ O
sample -X- _ O
1 -X- _ O
, -X- _ O
000 -X- _ O
distributions -X- _ O
from -X- _ O
a -X- _ O
symmetric -X- _ O
Dirichlet -X- _ O
distribution -X- _ O
with -X- _ O
variable -X- _ O
number -X- _ B-HyperparameterName
of -X- _ I-HyperparameterName
classes -X- _ I-HyperparameterName
K -X- _ B-HyperparameterName
, -X- _ O
i.e. -X- _ O
with -X- _ O
paramater -X- _ O
α -X- _ B-HyperparameterName
= -X- _ O
[ -X- _ O
α -X- _ O
1 -X- _ O
, -X- _ O
. -X- _ O
. -X- _ O
. -X- _ O
, -X- _ O
α -X- _ O
K -X- _ O
] -X- _ O
= -X- _ O
[ -X- _ O
1 -X- _ O
, -X- _ O
. -X- _ O
. -X- _ O
. -X- _ O
, -X- _ O
1 -X- _ O
] -X- _ O
. -X- _ O
We -X- _ O
calculate -X- _ O
entropy -X- _ O
estimates -X- _ O
on -X- _ O
different -X- _ O
sample -X- _ B-HyperparameterName
sizes -X- _ I-HyperparameterName
N -X- _ B-HyperparameterName
. -X- _ O
Since -X- _ O
we -X- _ O
know -X- _ O
the -X- _ O
parameters -X- _ O
of -X- _ O
the -X- _ O
true -X- _ O
distribution -X- _ O
, -X- _ O
we -X- _ O
can -X- _ O
compare -X- _ O
estimates -X- _ O
with -X- _ O
the -X- _ O
true -X- _ O
entropy -X- _ O
. -X- _ O
We -X- _ O
do -X- _ O
pairwise -X- _ O
comparisons -X- _ O
of -X- _ O
the -X- _ O
MAB -X- _ B-MetricName
and -X- _ O
MSE -X- _ B-MetricName
of -X- _ O
estimators -X- _ O
, -X- _ O
using -X- _ O
paired -X- _ O
permutation -X- _ O
tests -X- _ O
to -X- _ O
establish -X- _ O
significance -X- _ O
. -X- _ O
Table -X- _ O
3 -X- _ O
shows -X- _ O
our -X- _ O
results -X- _ O
, -X- _ O
including -X- _ O
significance -X- _ O
tests -X- _ O
. -X- _ O
It -X- _ O
is -X- _ O
clear -X- _ O
that -X- _ O
when -X- _ O
N -X- _ B-HyperparameterName
≫ -X- _ O
K -X- _ B-HyperparameterName
, -X- _ O
all -X- _ O
of -X- _ O
the -X- _ O
estimators -X- _ O
have -X- _ O
nearly -X- _ O
converged -X- _ O
to -X- _ O
the -X- _ O
true -X- _ O
value -X- _ O
and -X- _ O
estimator -X- _ O
choice -X- _ O
does -X- _ O
not -X- _ O
matter -X- _ O
. -X- _ O
However -X- _ O
, -X- _ O
in -X- _ O
the -X- _ O
low -X- _ O
- -X- _ O
sample -X- _ O
regime -X- _ O
some -X- _ O
estimators -X- _ O
are -X- _ O
indeed -X- _ O
significantly -X- _ O
better -X- _ O
at -X- _ O
approximating -X- _ O
the -X- _ O
true -X- _ O
entropy -X- _ O
. -X- _ O
Our -X- _ O
results -X- _ O
are -X- _ O
mixed -X- _ O
as -X- _ O
to -X- _ O
which -X- _ O
estimator -X- _ O
is -X- _ O
best -X- _ O
in -X- _ O
what -X- _ O
context -X- _ O
; -X- _ O
the -X- _ O
one -X- _ O
found -X- _ O
to -X- _ O
be -X- _ O
most -X- _ O
frequently -X- _ O
significantly -X- _ O
better -X- _ O
than -X- _ O
other -X- _ O
estimators -X- _ O
was -X- _ O
Chao -X- _ O
- -X- _ O
Shen -X- _ O
. -X- _ O
What -X- _ O
is -X- _ O
clear -X- _ O
is -X- _ O
that -X- _ O
MLE -X- _ B-MethodName
is -X- _ O
never -X- _ O
the -X- _ O
best -X- _ O
choice -X- _ O
. -X- _ O

B.2 -X- _ O
Experiment -X- _ O
2 -X- _ O
: -X- _ O
Zipfian -X- _ O
distributions -X- _ O

We -X- _ O
sample -X- _ O
1 -X- _ O
, -X- _ O
000 -X- _ O
finite -X- _ O
Zipfian -X- _ O
distributions -X- _ O
with -X- _ O
K -X- _ O
classes -X- _ O
which -X- _ O
obey -X- _ O
Zipf -X- _ O
's -X- _ O
law -X- _ O
, -X- _ O
that -X- _ O
the -X- _ O
probability -X- _ O
of -X- _ O
an -X- _ O
outcome -X- _ O
is -X- _ O
inverse -X- _ O
proportional -X- _ O
to -X- _ O
its -X- _ O
rank -X- _ O
. -X- _ O
The -X- _ O
experimental -X- _ O
setup -X- _ O
is -X- _ O
the -X- _ O
same -X- _ O
as -X- _ O
in -X- _ O
Experiment -X- _ O
1 -X- _ O
. -X- _ O
A -X- _ O
Zipfian -X- _ O
distribution -X- _ O
approximates -X- _ O
( -X- _ O
but -X- _ O
is -X- _ O
not -X- _ O
a -X- _ O
perfect -X- _ O
model -X- _ O
of -X- _ O
) -X- _ O
the -X- _ O
distribution -X- _ O
of -X- _ O
tokens -X- _ O
in -X- _ O
natural -X- _ O
language -X- _ O
text -X- _ O
in -X- _ O
some -X- _ O
languages -X- _ O
, -X- _ O
including -X- _ O
English -X- _ O
, -X- _ O
which -X- _ O
was -X- _ O
the -X- _ O
basis -X- _ O
for -X- _ O
the -X- _ O
law -X- _ O
being -X- _ O
proposed -X- _ O
. -X- _ O

Compare -X- _ O
similar -X- _ O
experiments -X- _ O
on -X- _ O
infinite -X- _ O
Zipf -X- _ O
distributions -X- _ O
by -X- _ O
Zhang -X- _ O
( -X- _ O
2012 -X- _ O
) -X- _ O
. -X- _ O
Results -X- _ O
are -X- _ O
in -X- _ O
Table -X- _ O
4 -X- _ O
. -X- _ O

C -X- _ O
Replication -X- _ O
of -X- _ O
Williams -X- _ O
et -X- _ O
al -X- _ O
. -X- _ O
( -X- _ O
2021 -X- _ O
) -X- _ O

We -X- _ O
used -X- _ O
the -X- _ O
following -X- _ O
UD -X- _ O
treebanks -X- _ O
: -X- _ O
Pairwise -X- _ O
MSE -X- _ B-MetricName
p -X- _ O
- -X- _ O
values -X- _ O
( -X- _ O
Dirichlet -X- _ O
) -X- _ O

Figure -X- _ O
4 -X- _ O
: -X- _ O
The -X- _ O
heatmaps -X- _ O
display -X- _ O
the -X- _ O
p -X- _ O
- -X- _ O
values -X- _ O
calculated -X- _ O
between -X- _ O
pairs -X- _ O
of -X- _ O
estimators -X- _ O
for -X- _ O
mean -X- _ B-MetricName
absolute -X- _ I-MetricName
bias -X- _ I-MetricName
( -X- _ O
MAB -X- _ B-MetricName
) -X- _ O
and -X- _ O
mean -X- _ B-MetricName
squared -X- _ I-MetricName
error -X- _ I-MetricName
( -X- _ O
MSE -X- _ B-MetricName
) -X- _ O
for -X- _ O
Experiment -X- _ O
1 -X- _ O
. -X- _ O
More -X- _ O
purple -X- _ O
values -X- _ O
mean -X- _ O
the -X- _ O
estimator -X- _ O
on -X- _ O
the -X- _ O
y -X- _ O
- -X- _ O
axis -X- _ O
( -X- _ O
Estimator -X- _ O
2 -X- _ O
) -X- _ O
is -X- _ O
better -X- _ O
than -X- _ O
the -X- _ O
estimator -X- _ O
on -X- _ O
the -X- _ O
x -X- _ O
- -X- _ O
axis -X- _ O
( -X- _ O
Estimator -X- _ O
1 -X- _ O
) -X- _ O
. -X- _ O
Comparisons -X- _ O
tend -X- _ O
to -X- _ O
become -X- _ O
non -X- _ O
- -X- _ O
significant -X- _ O
as -X- _ O
N -X- _ O
increases -X- _ O
, -X- _ O
since -X- _ O
all -X- _ O
the -X- _ O
estimators -X- _ O
gradually -X- _ O
converge -X- _ O
to -X- _ O
the -X- _ O
true -X- _ O
entropy -X- _ O
. -X- _ O

E -X- _ O
Derivation -X- _ O
of -X- _ O
the -X- _ O
Entropy -X- _ O
Estimators -X- _ O

Given -X- _ O
a -X- _ O
dataset -X- _ O
of -X- _ O
N -X- _ O
samples -X- _ O
D -X- _ O
sampled -X- _ O
i.i.d -X- _ O
. -X- _ O
from -X- _ O
p -X- _ O
, -X- _ O
our -X- _ O
goal -X- _ O
is -X- _ O
to -X- _ O
estimate -X- _ O
the -X- _ O
entropy -X- _ O
H -X- _ O
( -X- _ O
p -X- _ O
) -X- _ O
from -X- _ O
samples -X- _ O
D -X- _ O
from -X- _ O
the -X- _ O
true -X- _ O
distribution -X- _ O
p. -X- _ O
We -X- _ O
will -X- _ O
denote -X- _ O
the -X- _ O
count -X- _ O
of -X- _ O
an -X- _ O
item -X- _ O
n -X- _ O
) -X- _ O
. -X- _ O
The -X- _ O
maximum -X- _ B-MethodName
- -X- _ I-MethodName
likelihood -X- _ I-MethodName
estimate -X- _ I-MethodName
( -X- _ O
MLE -X- _ B-MethodName
) -X- _ O
of -X- _ O
p -X- _ O
given -X- _ O
D -X- _ O
is -X- _ O
denoted -X- _ O

The -X- _ O
plug -X- _ O
- -X- _ O
in -X- _ O
estimate -X- _ O
of -X- _ O
H -X- _ O
( -X- _ O
p -X- _ O
) -X- _ O
is -X- _ O
defined -X- _ O
to -X- _ O
be -X- _ O
the -X- _ O
estimate -X- _ O
of -X- _ O
H -X- _ O
( -X- _ O
p -X- _ O
) -X- _ O
obtained -X- _ O
by -X- _ O
plugging -X- _ O
the -X- _ O
MLE -X- _ B-MethodName
estimate -X- _ O
p -X- _ O
MLE -X- _ B-MethodName
directly -X- _ O
into -X- _ O
the -X- _ O
definition -X- _ O
of -X- _ O
entropy -X- _ O
, -X- _ O
i.e. -X- _ O
, -X- _ O

H -X- _ O
MLE -X- _ B-MethodName
( -X- _ O
D -X- _ O
) -X- _ O
= -X- _ O
H -X- _ O
( -X- _ O
p -X- _ O
MLE -X- _ B-MethodName
) -X- _ O
= -X- _ O
− -X- _ O
K -X- _ O
k=1 -X- _ O
p -X- _ O
MLE -X- _ B-MethodName
( -X- _ O
x -X- _ O
k -X- _ O
) -X- _ O
log -X- _ O
p -X- _ O
MLE -X- _ B-MethodName
( -X- _ O
x -X- _ O
k -X- _ O
) -X- _ O
= -X- _ O
− -X- _ O
K -X- _ O
k=1 -X- _ O
c -X- _ O
( -X- _ O
x -X- _ O
k -X- _ O
) -X- _ O
N -X- _ O
log -X- _ O
c -X- _ O
( -X- _ O
x -X- _ O
k -X- _ O
) -X- _ O
N -X- _ O
( -X- _ O
14 -X- _ O

) -X- _ O

This -X- _ O
section -X- _ O
discusses -X- _ O
the -X- _ O
problems -X- _ O
with -X- _ O
Eq -X- _ O
. -X- _ O
( -X- _ O
14 -X- _ O
) -X- _ O
as -X- _ O
an -X- _ O
estimator -X- _ O
and -X- _ O
provides -X- _ O
detailed -X- _ O
derivations -X- _ O
of -X- _ O
improved -X- _ O
estimators -X- _ O
found -X- _ O
in -X- _ O
the -X- _ O
literature -X- _ O
. -X- _ O

E.1 -X- _ O
The -X- _ O
Plug -X- _ O
- -X- _ O
in -X- _ O
Estimator -X- _ O
is -X- _ O
Negatively -X- _ O
Biased -X- _ O

Proposition -X- _ O
1 -X- _ O
. -X- _ O
The -X- _ O
MLE -X- _ B-MethodName
entropy -X- _ O
estimator -X- _ O
in -X- _ O
expectation -X- _ O
underestimates -X- _ O
true -X- _ O
entropy -X- _ O
, -X- _ O
i.e. -X- _ O
, -X- _ O

H -X- _ O
MLE -X- _ B-MethodName
( -X- _ O
D -X- _ O
) -X- _ O
= -X- _ O
E -X- _ O
K -X- _ O
k=1 -X- _ O
− -X- _ O
p -X- _ O
MLE -X- _ B-MethodName
( -X- _ O
x -X- _ O
k -X- _ O
) -X- _ O
log -X- _ O
p -X- _ O
MLE -X- _ B-MethodName
( -X- _ O
x -X- _ O
k -X- _ O
) -X- _ O
≤ -X- _ O
H -X- _ O
( -X- _ O
p -X- _ O
) -X- _ O
( -X- _ O
15 -X- _ O
) -X- _ O

Proof -X- _ O
. -X- _ O
The -X- _ O
result -X- _ O
is -X- _ O
a -X- _ O
simple -X- _ O
consequence -X- _ O
of -X- _ O
Jensen -X- _ O
's -X- _ O
inequality -X- _ O
and -X- _ O
some -X- _ O
basic -X- _ O
manipulations -X- _ O
: -X- _ O

E -X- _ O
K -X- _ O
k=1 -X- _ O
− -X- _ O
p -X- _ O
MLE -X- _ B-MethodName
( -X- _ O
x -X- _ O
k -X- _ O
) -X- _ O
log -X- _ O
p -X- _ O
MLE -X- _ B-MethodName
( -X- _ O
x -X- _ O
k -X- _ O
) -X- _ O
= -X- _ O
K -X- _ O
k=1 -X- _ O
E -X- _ O
[ -X- _ O
− -X- _ O
p -X- _ O
MLE -X- _ B-MethodName
( -X- _ O
x -X- _ O
k -X- _ O
) -X- _ O
log -X- _ O
p -X- _ O
MLE -X- _ B-MethodName
( -X- _ O
x -X- _ O
k -X- _ O
) -X- _ O
] -X- _ O
( -X- _ O
linearity -X- _ O
of -X- _ O
expectation -X- _ O
) -X- _ O
≤ -X- _ O
− -X- _ O
K -X- _ O
k=1 -X- _ O
E -X- _ O
[ -X- _ O
p -X- _ O
MLE -X- _ B-MethodName
( -X- _ O
x -X- _ O
k -X- _ O
) -X- _ O
] -X- _ O
log -X- _ O
E -X- _ O
[ -X- _ O
p -X- _ O
MLE -X- _ B-MethodName
( -X- _ O
x -X- _ O
k -X- _ O
) -X- _ O
] -X- _ O
( -X- _ O
Jensen -X- _ O
's -X- _ O
inequality -X- _ O
) -X- _ O
= -X- _ O
− -X- _ O
K -X- _ O
k=1 -X- _ O
p -X- _ O
( -X- _ O
x -X- _ O
k -X- _ O
) -X- _ O
log -X- _ O
p -X- _ O
( -X- _ O
x -X- _ O
k -X- _ O
) -X- _ O
( -X- _ O
E -X- _ O
[ -X- _ O
p -X- _ O
MLE -X- _ B-MethodName
( -X- _ O
x -X- _ O
k -X- _ O
) -X- _ O
] -X- _ O
= -X- _ O
p -X- _ O
( -X- _ O
x -X- _ O
k -X- _ O
) -X- _ O
) -X- _ O
= -X- _ O
H -X- _ O
( -X- _ O
p -X- _ O
) -X- _ O
( -X- _ O
definition -X- _ O
of -X- _ O
entropy -X- _ O
) -X- _ O

This -X- _ O
completes -X- _ O
the -X- _ O
result -X- _ O
. -X- _ O

E.2 -X- _ O
Miller -X- _ B-MethodName
- -X- _ I-MethodName
Madow -X- _ I-MethodName

Proposition -X- _ O
2 -X- _ O
. -X- _ O
Let -X- _ O
p -X- _ O
be -X- _ O
a -X- _ O
categorical -X- _ O
distribution -X- _ O
over -X- _ O
X -X- _ O
= -X- _ O
{ -X- _ O
x -X- _ O
1 -X- _ O
, -X- _ O
. -X- _ O
. -X- _ O
. -X- _ O
, -X- _ O
x -X- _ O
K -X- _ O
} -X- _ O
, -X- _ O
i.e. -X- _ O
, -X- _ O
a -X- _ O
categorical -X- _ O
distribution -X- _ O
with -X- _ O
support -X- _ O
K. -X- _ O
Let -X- _ O
D -X- _ O
be -X- _ O
our -X- _ O
dataset -X- _ O
of -X- _ O
size -X- _ O
N -X- _ O
sampled -X- _ O
from -X- _ O
p. -X- _ O
Finally -X- _ O
, -X- _ O
let -X- _ O
p -X- _ O
MLE -X- _ B-MethodName
be -X- _ O
the -X- _ O
maximumlikelihood -X- _ B-MethodName
estimate -X- _ I-MethodName
computed -X- _ O
on -X- _ O
D. -X- _ O
Then -X- _ O
, -X- _ O
we -X- _ O
have -X- _ O

bias -X- _ O
H -X- _ O
MLE -X- _ B-MethodName
( -X- _ O
D -X- _ O
) -X- _ O
def -X- _ O
= -X- _ O
E -X- _ O
p -X- _ O
H -X- _ O
MLE -X- _ B-MethodName
( -X- _ O
D -X- _ O
) -X- _ O
− -X- _ O
H -X- _ O
( -X- _ O
p -X- _ O
) -X- _ O
( -X- _ O
16 -X- _ O
) -X- _ O
= -X- _ O
− -X- _ O
K -X- _ O
− -X- _ O
1 -X- _ O
2N -X- _ O
+ -X- _ O
o -X- _ O
N -X- _ O
−1 -X- _ O
( -X- _ O
17 -X- _ O
) -X- _ O

Proof -X- _ O
. -X- _ O
We -X- _ O
start -X- _ O
by -X- _ O
taking -X- _ O
a -X- _ O
first -X- _ O
- -X- _ O
order -X- _ O
Taylor -X- _ O
expansion -X- _ O
and -X- _ O
take -X- _ O
an -X- _ O
expectation -X- _ O
of -X- _ O
both -X- _ O
sides -X- _ O
. -X- _ O

H -X- _ O
MLE -X- _ B-MethodName
( -X- _ O
D -X- _ O
) -X- _ O
= -X- _ O
H -X- _ O
( -X- _ O
p -X- _ O
MLE -X- _ B-MethodName
, -X- _ O
p -X- _ O
) -X- _ O
cross -X- _ O
- -X- _ O
entropy -X- _ O
−KL -X- _ O
( -X- _ O
p -X- _ O
MLE -X- _ B-MethodName
|| -X- _ O
p -X- _ O
) -X- _ O
( -X- _ O
Lemma -X- _ O
1 -X- _ O
) -X- _ O
( -X- _ O
18 -X- _ O

) -X- _ O

E -X- _ O
p -X- _ O
H -X- _ O
MLE -X- _ B-MethodName
( -X- _ O
D -X- _ O
) -X- _ O
= -X- _ O
E -X- _ O
p -X- _ O
[ -X- _ O
H -X- _ O
( -X- _ O
p -X- _ O
MLE -X- _ B-MethodName
, -X- _ O
p -X- _ O
) -X- _ O
] -X- _ O
− -X- _ O
E -X- _ O
p -X- _ O
[ -X- _ O
KL -X- _ O
( -X- _ O
p -X- _ O
MLE -X- _ B-MethodName
|| -X- _ O
p -X- _ O
) -X- _ O
] -X- _ O
( -X- _ O
expectation -X- _ O
) -X- _ O
( -X- _ O
19 -X- _ O
) -X- _ O
= -X- _ O
E -X- _ O
p -X- _ O
− -X- _ O
K -X- _ O
k=1 -X- _ O
p -X- _ O
MLE -X- _ B-MethodName
( -X- _ O
x -X- _ O
k -X- _ O
) -X- _ O
log -X- _ O
p -X- _ O
( -X- _ O
x -X- _ O
k -X- _ O
) -X- _ O
− -X- _ O
E -X- _ O
p -X- _ O
[ -X- _ O
KL -X- _ O
( -X- _ O
p -X- _ O
MLE -X- _ B-MethodName
|| -X- _ O
p -X- _ O
) -X- _ O
] -X- _ O
( -X- _ O
defn -X- _ O
. -X- _ O
H -X- _ O
( -X- _ O
p -X- _ O
, -X- _ O
q -X- _ O
) -X- _ O
) -X- _ O
( -X- _ O
20 -X- _ O
) -X- _ O
= -X- _ O
− -X- _ O
K -X- _ O
k=1 -X- _ O
E -X- _ O
p -X- _ O
[ -X- _ O
p -X- _ O
MLE -X- _ B-MethodName
( -X- _ O
x -X- _ O
k -X- _ O
) -X- _ O
log -X- _ O
p -X- _ O
( -X- _ O
x -X- _ O
k -X- _ O
) -X- _ O
] -X- _ O
− -X- _ O
E -X- _ O
p -X- _ O
[ -X- _ O
KL -X- _ O
( -X- _ O
p -X- _ O
MLE -X- _ B-MethodName
|| -X- _ O
p -X- _ O
) -X- _ O
] -X- _ O
( -X- _ O
linearity -X- _ O
) -X- _ O
( -X- _ O
21 -X- _ O
) -X- _ O
= -X- _ O
− -X- _ O
K -X- _ O
k=1 -X- _ O
E -X- _ O
p -X- _ O
[ -X- _ O
p -X- _ O
MLE -X- _ B-MethodName
( -X- _ O
x -X- _ O
k -X- _ O
) -X- _ O
] -X- _ O
log -X- _ O
p -X- _ O
( -X- _ O
x -X- _ O
k -X- _ O
) -X- _ O
− -X- _ O
E -X- _ O
p -X- _ O
[ -X- _ O
KL -X- _ O
( -X- _ O
p -X- _ O
MLE -X- _ B-MethodName
|| -X- _ O
p -X- _ O
) -X- _ O
] -X- _ O
( -X- _ O
algebra -X- _ O
) -X- _ O
( -X- _ O
22 -X- _ O
) -X- _ O
= -X- _ O
− -X- _ O
K -X- _ O
k=1 -X- _ O
p -X- _ O
( -X- _ O
x -X- _ O
k -X- _ O
) -X- _ O
log -X- _ O
p -X- _ O
( -X- _ O
x -X- _ O
k -X- _ O
) -X- _ O
− -X- _ O
E -X- _ O
p -X- _ O
[ -X- _ O
KL -X- _ O
( -X- _ O
p -X- _ O
MLE -X- _ B-MethodName
|| -X- _ O
p -X- _ O
) -X- _ O
] -X- _ O
( -X- _ O
unbiased -X- _ O
) -X- _ O
( -X- _ O
23 -X- _ O
) -X- _ O
= -X- _ O
H -X- _ O
( -X- _ O
p -X- _ O
) -X- _ O
− -X- _ O
E -X- _ O
p -X- _ O
[ -X- _ O
KL -X- _ O
( -X- _ O
p -X- _ O
MLE -X- _ B-MethodName
|| -X- _ O
p -X- _ O
) -X- _ O
] -X- _ O
( -X- _ O
defn -X- _ O
. -X- _ O
of -X- _ O
H -X- _ O
( -X- _ O
p -X- _ O
) -X- _ O
) -X- _ O
( -X- _ O
24 -X- _ O
) -X- _ O

( -X- _ O
25 -X- _ O
) -X- _ O

This -X- _ O
gives -X- _ O
us -X- _ O
: -X- _ O

E -X- _ O
p -X- _ O
H -X- _ O
MLE -X- _ B-MethodName
( -X- _ O
D -X- _ O
) -X- _ O
− -X- _ O
H -X- _ O
( -X- _ O
p -X- _ O
) -X- _ O
= -X- _ O
−E -X- _ O
p -X- _ O
[ -X- _ O
KL -X- _ O
( -X- _ O
p -X- _ O
MLE -X- _ B-MethodName
|| -X- _ O
p -X- _ O
) -X- _ O
] -X- _ O
( -X- _ O
subtract -X- _ O
H -X- _ O
( -X- _ O
p -X- _ O
) -X- _ O
) -X- _ O
( -X- _ O
26 -X- _ O
) -X- _ O

Thus -X- _ O
, -X- _ O
we -X- _ O
may -X- _ O
compactly -X- _ O
write -X- _ O
the -X- _ O
bias -X- _ O
as -X- _ O
: -X- _ O

bias -X- _ O
H -X- _ O
MLE -X- _ B-MethodName
( -X- _ O
D -X- _ O
) -X- _ O
= -X- _ O
E -X- _ O
p -X- _ O
[ -X- _ O
H -X- _ O
( -X- _ O
p -X- _ O
MLE -X- _ B-MethodName
) -X- _ O
] -X- _ O
− -X- _ O
H -X- _ O
( -X- _ O
p -X- _ O
) -X- _ O
( -X- _ O
definition -X- _ O
of -X- _ O
bias -X- _ O
) -X- _ O
( -X- _ O
27 -X- _ O
) -X- _ O
= -X- _ O
−E -X- _ O
p -X- _ O
[ -X- _ O
KL -X- _ O
( -X- _ O
p -X- _ O
MLE -X- _ B-MethodName
|| -X- _ O
p -X- _ O
) -X- _ O
] -X- _ O
( -X- _ O
above -X- _ O
computation -X- _ O
) -X- _ O
( -X- _ O
28 -X- _ O
) -X- _ O
≤ -X- _ O
0 -X- _ O
( -X- _ O
non -X- _ O
- -X- _ O
negativity -X- _ O
of -X- _ O
KL -X- _ O
) -X- _ O
( -X- _ O
29 -X- _ O
) -X- _ O

Now -X- _ O
, -X- _ O
we -X- _ O
find -X- _ O
a -X- _ O
simpler -X- _ O
expression -X- _ O
for -X- _ O
the -X- _ O
remainder -X- _ O
E -X- _ O
p -X- _ O
[ -X- _ O
KL -X- _ O
( -X- _ O
p -X- _ O
MLE -X- _ B-MethodName
|| -X- _ O
p -X- _ O
) -X- _ O
] -X- _ O
. -X- _ O
Again -X- _ O
, -X- _ O
we -X- _ O
start -X- _ O
with -X- _ O
a -X- _ O
secondorder -X- _ O
Taylor -X- _ O
expansion -X- _ O

KL -X- _ O
( -X- _ O
p -X- _ O
|| -X- _ O
q -X- _ O
) -X- _ O
= -X- _ O
x∈X -X- _ O
∆ -X- _ O
( -X- _ O
x -X- _ O
) -X- _ O
2 -X- _ O
2q -X- _ O
( -X- _ O
x -X- _ O
) -X- _ O
+ -X- _ O
o -X- _ O
∆ -X- _ O
( -X- _ O
x -X- _ O
) -X- _ O
2 -X- _ O
( -X- _ O
Lemma -X- _ O
2 -X- _ O
) -X- _ O
( -X- _ O
30 -X- _ O

) -X- _ O

around -X- _ O
the -X- _ O
point -X- _ O
∆ -X- _ O
( -X- _ O
x -X- _ O
) -X- _ O
= -X- _ O
p -X- _ O
( -X- _ O
x -X- _ O
) -X- _ O
− -X- _ O
q -X- _ O
( -X- _ O
x -X- _ O
) -X- _ O
. -X- _ O
Define -X- _ O
p -X- _ O
MLE -X- _ B-MethodName
( -X- _ O
x -X- _ O
k -X- _ O
) -X- _ O
= -X- _ O
c -X- _ O
( -X- _ O
x -X- _ O
k -X- _ O
) -X- _ O

Next -X- _ O
, -X- _ O
we -X- _ O
simplify -X- _ O
the -X- _ O
second -X- _ O
term -X- _ O
, -X- _ O
o -X- _ O
∆ -X- _ O
( -X- _ O
x -X- _ O
) -X- _ O
2 -X- _ O
, -X- _ O
in -X- _ O
the -X- _ O
MLE -X- _ B-MethodName
case -X- _ O
: -X- _ O

Putting -X- _ O
it -X- _ O
all -X- _ O
together -X- _ O
, -X- _ O
we -X- _ O
get -X- _ O
that -X- _ O
bias -X- _ O
( -X- _ O
H -X- _ O
( -X- _ O
p -X- _ O
MLE -X- _ B-MethodName
) -X- _ O
) -X- _ O
= -X- _ O
− -X- _ O
K−1 -X- _ O
2N -X- _ O
+ -X- _ O
o -X- _ O
N -X- _ O
−1 -X- _ O
which -X- _ O
is -X- _ O
the -X- _ O
desired -X- _ O
result -X- _ O
. -X- _ O

Interestingly -X- _ O
, -X- _ O
it -X- _ O
can -X- _ O
be -X- _ O
seen -X- _ O
that -X- _ O
the -X- _ O
negative -X- _ O
bias -X- _ O
of -X- _ O
the -X- _ O
MLE -X- _ B-MethodName
gets -X- _ O
worse -X- _ O
as -X- _ O
the -X- _ O
number -X- _ B-HyperparameterName
of -X- _ I-HyperparameterName
classes -X- _ I-HyperparameterName
K -X- _ B-HyperparameterName
grows -X- _ O
. -X- _ O
Distributions -X- _ O
with -X- _ O
large -X- _ O
K -X- _ B-HyperparameterName
pop -X- _ O
up -X- _ O
frequently -X- _ O
when -X- _ O
dealing -X- _ O
with -X- _ O
natural -X- _ O
language -X- _ O
. -X- _ O

Corollary -X- _ O
1 -X- _ O
. -X- _ O
The -X- _ O
plug -X- _ O
- -X- _ O
in -X- _ O
estimator -X- _ O
of -X- _ O
entropy -X- _ O
is -X- _ O
consistent -X- _ O
. -X- _ O

Proof -X- _ O
. -X- _ O
From -X- _ O
Proposition -X- _ O
2 -X- _ O
, -X- _ O
we -X- _ O
have -X- _ O
bias -X- _ O
( -X- _ O
H -X- _ O
( -X- _ O
p -X- _ O

MLE -X- _ B-MethodName
) -X- _ O
) -X- _ O
= -X- _ O
− -X- _ O
K−1 -X- _ O
2N -X- _ O
+ -X- _ O
o -X- _ O
N -X- _ O
−1 -X- _ O
. -X- _ O

Clearly -X- _ O
, -X- _ O
as -X- _ O
N -X- _ B-HyperparameterName
→ -X- _ O
0 -X- _ O
, -X- _ O
we -X- _ O
have -X- _ O
bias -X- _ O
( -X- _ O
H -X- _ O
( -X- _ O
p -X- _ O
MLE -X- _ B-MethodName
) -X- _ O
) -X- _ O
→ -X- _ O
0 -X- _ O
, -X- _ O
so -X- _ O
the -X- _ O
estimator -X- _ O
is -X- _ O
consistent -X- _ O
. -X- _ O
One -X- _ O
could -X- _ O
also -X- _ O
prove -X- _ O
consistency -X- _ O
through -X- _ O
a -X- _ O
simple -X- _ O
application -X- _ O
of -X- _ O
the -X- _ O
continuous -X- _ O
mapping -X- _ O
theorem -X- _ O
. -X- _ O

Estimator -X- _ O
1 -X- _ O
( -X- _ O
Miller -X- _ B-MethodName
- -X- _ I-MethodName
Madow -X- _ I-MethodName
) -X- _ O
. -X- _ O
Let -X- _ O
p -X- _ O
be -X- _ O
a -X- _ O
categorical -X- _ O
over -X- _ O
K -X- _ B-HyperparameterName
categories -X- _ O
. -X- _ O
We -X- _ O
seek -X- _ O
to -X- _ O
estimate -X- _ O
the -X- _ O
entropy -X- _ O
H -X- _ O
( -X- _ O
p -X- _ O
) -X- _ O
. -X- _ O
Let -X- _ O
D -X- _ O
be -X- _ O
our -X- _ O
dataset -X- _ O
of -X- _ O
size -X- _ O
N -X- _ B-HyperparameterName
sampled -X- _ O
from -X- _ O
p. -X- _ O
Then -X- _ O
, -X- _ O
the -X- _ O
Miller -X- _ B-MethodName
- -X- _ I-MethodName
Madow -X- _ I-MethodName
estimator -X- _ O
of -X- _ O
H -X- _ O
( -X- _ O
p -X- _ O
) -X- _ O
is -X- _ O
given -X- _ O
by -X- _ O

H -X- _ O
MM -X- _ B-MethodName
( -X- _ O
D -X- _ O
) -X- _ O
def -X- _ O
= -X- _ O
H -X- _ O
MLE -X- _ B-MethodName
( -X- _ O
D -X- _ O
) -X- _ O
+ -X- _ O
K -X- _ O
− -X- _ O
1 -X- _ O
2N -X- _ O
( -X- _ O
52 -X- _ O
) -X- _ O

The -X- _ O
Miller -X- _ B-MethodName
- -X- _ I-MethodName
Madow -X- _ I-MethodName
estimator -X- _ O
is -X- _ O
biased -X- _ O
, -X- _ O
however -X- _ O
it -X- _ O
is -X- _ O
consistent -X- _ O
. -X- _ O

Lemma -X- _ O
1 -X- _ O
. -X- _ O
The -X- _ O
the -X- _ O
first -X- _ O
- -X- _ O
order -X- _ O
Taylor -X- _ O
approximation -X- _ O
of -X- _ O
H -X- _ O
MLE -X- _ B-MethodName
( -X- _ O
D -X- _ O
) -X- _ O
around -X- _ O
the -X- _ O
distribution -X- _ O
p -X- _ O
is -X- _ O
given -X- _ O
by -X- _ O

H -X- _ O
MLE -X- _ B-MethodName
( -X- _ O
D -X- _ O
) -X- _ O
= -X- _ O
H -X- _ O
( -X- _ O
p -X- _ O
MLE -X- _ B-MethodName
, -X- _ O
p -X- _ O
) -X- _ O
+ -X- _ O
R -X- _ O
( -X- _ O
p -X- _ O
, -X- _ O
p -X- _ O
MLE -X- _ B-MethodName
) -X- _ O
( -X- _ O
53 -X- _ O
) -X- _ O

where -X- _ O
the -X- _ O
remainder -X- _ O
R -X- _ O
is -X- _ O
given -X- _ O
by -X- _ O

R -X- _ O
( -X- _ O
p -X- _ O
, -X- _ O
p -X- _ O
MLE -X- _ B-MethodName
) -X- _ O
= -X- _ O
−KL -X- _ O
( -X- _ O
p -X- _ O
MLE -X- _ B-MethodName
|| -X- _ O
p -X- _ O
) -X- _ O
( -X- _ O
54 -X- _ O
) -X- _ O

Proof -X- _ O
. -X- _ O
The -X- _ O
result -X- _ O
follows -X- _ O
from -X- _ O
direct -X- _ O
computation -X- _ O
. -X- _ O
We -X- _ O
start -X- _ O
by -X- _ O
taking -X- _ O
the -X- _ O
Taylor -X- _ O
expansion -X- _ O
of -X- _ O
H -X- _ O
( -X- _ O
p -X- _ O
MLE -X- _ B-MethodName
) -X- _ O
around -X- _ O
H -X- _ O
( -X- _ O
p -X- _ O
) -X- _ O
: -X- _ O

which -X- _ O
is -X- _ O
the -X- _ O
desired -X- _ O
result -X- _ O
. -X- _ O
Proof -X- _ O
. -X- _ O
Now -X- _ O
we -X- _ O
compute -X- _ O
the -X- _ O
series -X- _ O
expansion -X- _ O
of -X- _ O
the -X- _ O
KL -X- _ O
- -X- _ O
divergence -X- _ O
. -X- _ O
We -X- _ O
first -X- _ O
make -X- _ O
a -X- _ O
tricky -X- _ O
substitution -X- _ O
: -X- _ O

Now -X- _ O
, -X- _ O
we -X- _ O
proceed -X- _ O
with -X- _ O
the -X- _ O
derivation -X- _ O
: -X- _ O

which -X- _ O
is -X- _ O
the -X- _ O
desired -X- _ O
result -X- _ O
. -X- _ O

E.3 -X- _ O
Jackknife -X- _ B-MethodName

The -X- _ O
jackknife -X- _ B-MethodName
resampling -X- _ O
method -X- _ O
is -X- _ O
used -X- _ O
to -X- _ O
estimate -X- _ O
the -X- _ O
bias -X- _ O
of -X- _ O
an -X- _ O
estimator -X- _ O
and -X- _ O
correct -X- _ O
for -X- _ O
it -X- _ O
, -X- _ O
by -X- _ O
sampling -X- _ O
all -X- _ O
subsamples -X- _ O
of -X- _ O
size -X- _ O
N -X- _ B-HyperparameterName
− -X- _ O
1 -X- _ O
from -X- _ O
the -X- _ O
available -X- _ O
sample -X- _ B-MethodName
of -X- _ I-MethodName
size -X- _ I-MethodName
N -X- _ B-HyperparameterName
, -X- _ O
computing -X- _ O
their -X- _ O
average -X- _ O
for -X- _ O
the -X- _ O
statistic -X- _ O
being -X- _ O
estimated -X- _ O
. -X- _ O
Generally -X- _ O
, -X- _ O
this -X- _ O
reduces -X- _ O
the -X- _ O
order -X- _ O
of -X- _ O
the -X- _ O
bias -X- _ O
of -X- _ O
an -X- _ O
estimator -X- _ O
from -X- _ O
O -X- _ O
( -X- _ O
N -X- _ B-HyperparameterName
−1 -X- _ O
) -X- _ O
to -X- _ O
at -X- _ O
most -X- _ O
O -X- _ O
( -X- _ O
N -X- _ B-HyperparameterName
−2 -X- _ O
) -X- _ O
( -X- _ O
Friedl -X- _ O
and -X- _ O
Stampfer -X- _ O
, -X- _ O
2002 -X- _ O
) -X- _ O
. -X- _ O

Estimator -X- _ O
2 -X- _ O
( -X- _ O
Jackknife -X- _ B-MethodName
) -X- _ O
. -X- _ O
Let -X- _ O
p -X- _ O
be -X- _ O
a -X- _ O
categorical -X- _ O
over -X- _ O
K -X- _ B-HyperparameterName
categories -X- _ O
. -X- _ O
We -X- _ O
seek -X- _ O
to -X- _ O
estimate -X- _ O
the -X- _ O
entropy -X- _ O
H -X- _ O
( -X- _ O
p -X- _ O
) -X- _ O
. -X- _ O
Let -X- _ O
D -X- _ O
be -X- _ O
our -X- _ O
dataset -X- _ O
of -X- _ O
size -X- _ O
N -X- _ B-HyperparameterName
sampled -X- _ O
from -X- _ O
p. -X- _ O
Let -X- _ O
H -X- _ O
\n -X- _ O
( -X- _ O
D -X- _ O
) -X- _ O
be -X- _ O
an -X- _ O
estimate -X- _ O
of -X- _ O
the -X- _ O
entropy -X- _ O
from -X- _ O
a -X- _ O
sample -X- _ O
with -X- _ O
the -X- _ O
n -X- _ O
th -X- _ O
observation -X- _ O
held -X- _ O
out -X- _ O
. -X- _ O
Then -X- _ O
, -X- _ O
the -X- _ O
Jackknife -X- _ B-MethodName
estimator -X- _ O
is -X- _ O
given -X- _ O
by -X- _ O

H -X- _ O
JACK -X- _ B-MethodName
( -X- _ O
D -X- _ O
) -X- _ O
def -X- _ O
= -X- _ O
N -X- _ O
H -X- _ O
MLE -X- _ B-MethodName
( -X- _ O
D -X- _ O
) -X- _ O
− -X- _ O
N -X- _ O
− -X- _ O
1 -X- _ O
N -X- _ O
N -X- _ O
n=1 -X- _ O
H -X- _ O
\n -X- _ O
MLE -X- _ B-MethodName
( -X- _ O
D -X- _ O
) -X- _ O
( -X- _ O
84 -X- _ O
) -X- _ O

This -X- _ O
estimator -X- _ O
is -X- _ O
derived -X- _ O
from -X- _ O
the -X- _ O
jackknife -X- _ B-MethodName
- -X- _ O
resampled -X- _ O
estimate -X- _ O
of -X- _ O
the -X- _ O
bias -X- _ O
of -X- _ O
the -X- _ O
MLE -X- _ B-MethodName
estimator -X- _ O
, -X- _ O
multiplied -X- _ O
by -X- _ O
N -X- _ O
− -X- _ O
1 -X- _ O
. -X- _ O

H -X- _ O
JACK -X- _ B-MethodName
( -X- _ O
D -X- _ O
) -X- _ O
− -X- _ O
H -X- _ O
MLE -X- _ B-MethodName
( -X- _ O
D -X- _ O
) -X- _ O
= -X- _ O
( -X- _ O
N -X- _ O
− -X- _ O
1 -X- _ O
) -X- _ O
H -X- _ O
MLE -X- _ B-MethodName
( -X- _ O
D -X- _ O
) -X- _ O
− -X- _ O
1 -X- _ O
N -X- _ O
N -X- _ O
n=1 -X- _ O
H -X- _ O
\n -X- _ O
MLE -X- _ B-MethodName
( -X- _ O
D -X- _ O
) -X- _ O
( -X- _ O
85 -X- _ O
) -X- _ O

E.4 -X- _ O
Horvitz -X- _ B-MethodName
- -X- _ I-MethodName
Thompson -X- _ I-MethodName
Horvitz -X- _ O
and -X- _ O
Thompson -X- _ O
( -X- _ O
HT -X- _ B-MethodName
; -X- _ O
1952 -X- _ O
) -X- _ O
is -X- _ O
a -X- _ O
common -X- _ O
estimator -X- _ O
given -X- _ O
a -X- _ O
finite -X- _ O
universe -X- _ O
, -X- _ O
which -X- _ O
is -X- _ O
our -X- _ O
case -X- _ O
as -X- _ O
K -X- _ B-HyperparameterName
is -X- _ O
finite -X- _ O
. -X- _ O
We -X- _ O
omit -X- _ O
a -X- _ O
derivation -X- _ O
a -X- _ O
full -X- _ O
here -X- _ O
as -X- _ O
it -X- _ O
is -X- _ O
well -X- _ O
documented -X- _ O
in -X- _ O
other -X- _ O
places -X- _ O
( -X- _ O
Vieira -X- _ O
, -X- _ O
2017 -X- _ O
) -X- _ O
. -X- _ O
However -X- _ O
, -X- _ O
we -X- _ O
note -X- _ O
that -X- _ O
, -X- _ O
in -X- _ O
contrast -X- _ O
to -X- _ O
many -X- _ O
applications -X- _ O
of -X- _ O
HT -X- _ B-MethodName
, -X- _ O
the -X- _ O
application -X- _ O
of -X- _ O
HT -X- _ B-MethodName
to -X- _ O
entropy -X- _ B-TaskName
estimation -X- _ I-TaskName
results -X- _ O
in -X- _ O
a -X- _ O
biased -X- _ O
estimator -X- _ O
as -X- _ O
the -X- _ O
function -X- _ O
whose -X- _ O
mean -X- _ O
we -X- _ O
seek -X- _ O
to -X- _ O
estimate -X- _ O
is -X- _ O
log -X- _ O
p -X- _ O
( -X- _ O
x -X- _ O
k -X- _ O
) -X- _ O
, -X- _ O
which -X- _ O
is -X- _ O
dependent -X- _ O
on -X- _ O
the -X- _ O
unknown -X- _ O
distribution -X- _ O
p -X- _ O
. -X- _ O

Estimator -X- _ O
3 -X- _ O
( -X- _ O
Horvitz -X- _ B-MethodName
- -X- _ I-MethodName
Thompson -X- _ I-MethodName
) -X- _ O
. -X- _ O
Let -X- _ O
p -X- _ O
be -X- _ O
a -X- _ O
categorical -X- _ O
over -X- _ O
K -X- _ B-HyperparameterName
categories -X- _ O
. -X- _ O
We -X- _ O
seek -X- _ O
to -X- _ O
estimate -X- _ B-TaskName
the -X- _ I-TaskName
entropy -X- _ I-TaskName
H -X- _ O
( -X- _ O
p -X- _ O
) -X- _ O
. -X- _ O
Let -X- _ O
D -X- _ O
be -X- _ O
our -X- _ O
dataset -X- _ O
of -X- _ O
size -X- _ O
N -X- _ B-HyperparameterName
sampled -X- _ O
from -X- _ O
p. -X- _ O
Then -X- _ O
the -X- _ O
Horvitz -X- _ B-MethodName
- -X- _ I-MethodName
Thompson -X- _ I-MethodName
estimator -X- _ O
is -X- _ O
defined -X- _ O
as -X- _ O

H -X- _ O
HT -X- _ B-MethodName
( -X- _ O
D -X- _ O
) -X- _ O
def -X- _ O
= -X- _ O
− -X- _ O
K -X- _ O
k=1 -X- _ O
p -X- _ O
MLE -X- _ B-MethodName
( -X- _ O
x -X- _ O
k -X- _ O
) -X- _ O
log -X- _ O
p -X- _ O
MLE -X- _ B-MethodName
( -X- _ O
x -X- _ O
k -X- _ O
) -X- _ O
1 -X- _ O
− -X- _ O
( -X- _ O
1 -X- _ O
− -X- _ O
p -X- _ O
MLE -X- _ B-MethodName
( -X- _ O
x -X- _ O
k -X- _ O
) -X- _ O
) -X- _ O
N -X- _ O
( -X- _ O
86 -X- _ O

where -X- _ O
1 -X- _ O
− -X- _ O
( -X- _ O
1 -X- _ O
− -X- _ O
p -X- _ O
MLE -X- _ B-MethodName
( -X- _ O
x -X- _ O
k -X- _ O
) -X- _ O
) -X- _ O

N -X- _ O
is -X- _ O
an -X- _ O
estimate -X- _ O
of -X- _ O
the -X- _ O
inclusion -X- _ O
probability -X- _ O
, -X- _ O
i.e. -X- _ O
, -X- _ O
the -X- _ O
probability -X- _ O
that -X- _ O
x -X- _ O
k -X- _ O
appears -X- _ O
in -X- _ O
a -X- _ O
random -X- _ O
sample -X- _ O
D -X- _ O
of -X- _ O
size -X- _ O
N -X- _ O
. -X- _ O
We -X- _ O
do -X- _ O
not -X- _ O
know -X- _ O
of -X- _ O
a -X- _ O
simple -X- _ O
expression -X- _ O
for -X- _ O
the -X- _ O
bias -X- _ O
of -X- _ O
the -X- _ O
Horvitz -X- _ B-MethodName
- -X- _ I-MethodName
Thompson -X- _ I-MethodName
entropy -X- _ O
estimator -X- _ O
, -X- _ O
but -X- _ O
one -X- _ O
observation -X- _ O
is -X- _ O
that -X- _ O

E -X- _ O
p -X- _ O
( -X- _ O
1 -X- _ O
− -X- _ O
p -X- _ O
MLE -X- _ B-MethodName
( -X- _ O
x -X- _ O
k -X- _ O
) -X- _ O
) -X- _ O
N -X- _ O
> -X- _ O
E -X- _ O
p -X- _ O
( -X- _ O
1 -X- _ O
− -X- _ O
p -X- _ O
( -X- _ O
x -X- _ O
k -X- _ O
) -X- _ O
) -X- _ O
N -X- _ O
when -X- _ O
N -X- _ O
> -X- _ O
1 -X- _ O
( -X- _ O
justified -X- _ O
by -X- _ O
Jensen -X- _ O
's -X- _ O
inequality -X- _ O
, -X- _ O
since -X- _ O
x -X- _ O
N -X- _ O
, -X- _ O
N -X- _ O
> -X- _ O
1 -X- _ O
is -X- _ O
convex -X- _ O
over -X- _ O
[ -X- _ O
0 -X- _ O
, -X- _ O
1 -X- _ O
] -X- _ O
) -X- _ O

; -X- _ O
this -X- _ O
is -X- _ O
an -X- _ O
overestimate -X- _ O
of -X- _ O
the -X- _ O
true -X- _ O
inclusion -X- _ O
probability -X- _ O
. -X- _ O

E.5 -X- _ O
Chao -X- _ B-MethodName
- -X- _ I-MethodName
Shen -X- _ I-MethodName

The -X- _ O
Chao -X- _ B-MethodName
- -X- _ I-MethodName
Shen -X- _ I-MethodName
estimator -X- _ O
builds -X- _ O
upon -X- _ O
Horvitz -X- _ B-MethodName
- -X- _ I-MethodName
Thompson -X- _ I-MethodName
by -X- _ O
noting -X- _ O
that -X- _ O
that -X- _ O
estimator -X- _ O
does -X- _ O
not -X- _ O
correct -X- _ O
for -X- _ O
underestimation -X- _ O
of -X- _ O
number -X- _ B-HyperparameterName
of -X- _ I-HyperparameterName
classes -X- _ I-HyperparameterName
K -X- _ B-MethodName
and -X- _ O
resulting -X- _ O
effect -X- _ O
on -X- _ O
estimates -X- _ O
of -X- _ O
p -X- _ O
( -X- _ O
x -X- _ O
k -X- _ O
) -X- _ O
; -X- _ O
i.e. -X- _ O
1− -X- _ O
( -X- _ O
1− -X- _ O
p -X- _ O
MLE -X- _ B-MethodName
( -X- _ O
x -X- _ O
k -X- _ O
) -X- _ O
) -X- _ O
N -X- _ O
is -X- _ O
always -X- _ O
0 -X- _ O
for -X- _ O
a -X- _ O
class -X- _ O
not -X- _ O
included -X- _ O
in -X- _ O
the -X- _ O
sample -X- _ O
even -X- _ O
if -X- _ O
the -X- _ O
class -X- _ O
is -X- _ O
present -X- _ O
in -X- _ O
the -X- _ O
true -X- _ O
distribution -X- _ O
. -X- _ O
We -X- _ O
can -X- _ O
reweight -X- _ O
the -X- _ O
sample -X- _ O
probabilities -X- _ O
to -X- _ O
compensate -X- _ O
for -X- _ O
missing -X- _ O
classes -X- _ O
using -X- _ O
the -X- _ O
notion -X- _ O
of -X- _ O
sample -X- _ O
coverage -X- _ O
. -X- _ O

Definition -X- _ O
1 -X- _ O
( -X- _ O
Sample -X- _ O
coverage -X- _ O
) -X- _ O
. -X- _ O
We -X- _ O
define -X- _ O
the -X- _ O
sample -X- _ O
coverage -X- _ O
as -X- _ O

The -X- _ O
Chao -X- _ B-MethodName
- -X- _ I-MethodName
Shen -X- _ I-MethodName
estimator -X- _ O
, -X- _ O
described -X- _ O
below -X- _ O
, -X- _ O
simply -X- _ O
re -X- _ O
- -X- _ O
scales -X- _ O
the -X- _ O
MLE -X- _ B-MethodName
estimate -X- _ O
of -X- _ O
probability -X- _ O
p -X- _ O
MLE -X- _ B-MethodName
( -X- _ O
x -X- _ O
k -X- _ O
) -X- _ O
in -X- _ O
the -X- _ O
HT -X- _ B-MethodName
estimator -X- _ O
by -X- _ O
C. -X- _ O
This -X- _ O
corrects -X- _ O
for -X- _ O
the -X- _ O
observed -X- _ O
underestimation -X- _ O
of -X- _ O
p -X- _ O
's -X- _ O
entropy -X- _ O
by -X- _ O
HT -X- _ B-MethodName
. -X- _ O

Estimator -X- _ O
4 -X- _ O
( -X- _ O
Chao -X- _ B-MethodName
- -X- _ I-MethodName
Shen -X- _ I-MethodName
) -X- _ O
. -X- _ O
Let -X- _ O
p -X- _ O
be -X- _ O
a -X- _ O
categorical -X- _ O
over -X- _ O
K -X- _ B-HyperparameterName
categories -X- _ O
. -X- _ O
We -X- _ O
seek -X- _ O
to -X- _ O
estimate -X- _ B-TaskName
the -X- _ I-TaskName
entropy -X- _ I-TaskName
H -X- _ O
( -X- _ O
p -X- _ O
) -X- _ O
. -X- _ O
Let -X- _ O
D -X- _ O
be -X- _ O
our -X- _ O
dataset -X- _ O
of -X- _ O
size -X- _ O
N -X- _ B-HyperparameterName
sampled -X- _ O
from -X- _ O
p. -X- _ O
Let -X- _ O
C -X- _ O
, -X- _ O
an -X- _ O
estimate -X- _ O
of -X- _ O
sample -X- _ O
coverage -X- _ O
, -X- _ O
be -X- _ O
defined -X- _ O
as -X- _ O
in -X- _ O
Eq -X- _ O
. -X- _ O
( -X- _ O
88 -X- _ O
) -X- _ O
. -X- _ O
The -X- _ O
Chao -X- _ B-MethodName
- -X- _ I-MethodName
Shen -X- _ I-MethodName
estimator -X- _ O
is -X- _ O
then -X- _ O
defined -X- _ O
as -X- _ O

H -X- _ O
CS -X- _ B-MethodName
( -X- _ O
D -X- _ O
) -X- _ O
def -X- _ O
= -X- _ O
− -X- _ O
K -X- _ O
k=1 -X- _ O
C -X- _ O
• -X- _ O
p -X- _ O
MLE -X- _ B-MethodName
( -X- _ O
x -X- _ O
k -X- _ O
) -X- _ O
log -X- _ O
( -X- _ O
C -X- _ O
• -X- _ O
p -X- _ O
MLE -X- _ B-MethodName
( -X- _ O
x -X- _ O
k -X- _ O
) -X- _ O
) -X- _ O
1 -X- _ O
− -X- _ O
( -X- _ O
1 -X- _ O
− -X- _ O
C -X- _ O
• -X- _ O
p -X- _ O
MLE -X- _ B-MethodName
( -X- _ O
x -X- _ O
k -X- _ O
) -X- _ O
) -X- _ O
N -X- _ O
( -X- _ O
89 -X- _ O
) -X- _ O
E.6 -X- _ O
Wolpert -X- _ B-MethodName
- -X- _ I-MethodName
Wolf -X- _ I-MethodName
Fact -X- _ O
1 -X- _ O
( -X- _ O
Derivative -X- _ O
of -X- _ O
an -X- _ O
exponent -X- _ O
) -X- _ O
. -X- _ O
d -X- _ O
da -X- _ O
x -X- _ O
a -X- _ O
= -X- _ O
x -X- _ O
a -X- _ O
log -X- _ O
x -X- _ O
( -X- _ O
90 -X- _ O
) -X- _ O

Fact -X- _ O
2 -X- _ O
( -X- _ O
Normalizer -X- _ O
of -X- _ O
a -X- _ O
Dirichlet -X- _ O
) -X- _ O
. -X- _ O
The -X- _ O
normalizer -X- _ O
of -X- _ O
a -X- _ O
Dirichlet -X- _ O
distribution -X- _ O
is -X- _ O

A -X- _ O
relatively -X- _ O
easy -X- _ O
proof -X- _ O
of -X- _ O
this -X- _ O
fact -X- _ O
makes -X- _ O
use -X- _ O
of -X- _ O
a -X- _ O
Laplace -X- _ O
transform -X- _ O
. -X- _ O

Estimator -X- _ O
5 -X- _ O
( -X- _ O
Wolpert -X- _ B-MethodName
- -X- _ I-MethodName
Wolf -X- _ I-MethodName
) -X- _ O
. -X- _ O
Let -X- _ O
p -X- _ O
be -X- _ O
a -X- _ O
categorical -X- _ O
over -X- _ O
K -X- _ B-HyperparameterName
categories -X- _ O
. -X- _ O
We -X- _ O
seek -X- _ O
to -X- _ O
estimate -X- _ B-TaskName
the -X- _ I-TaskName
entropy -X- _ I-TaskName
H -X- _ O
( -X- _ O
p -X- _ O
) -X- _ O
. -X- _ O
Let -X- _ O
D -X- _ O
be -X- _ O
our -X- _ O
dataset -X- _ O
of -X- _ O
size -X- _ O
N -X- _ B-HyperparameterName
sampled -X- _ O
from -X- _ O
p. -X- _ O
Then -X- _ O
, -X- _ O
the -X- _ O
Wolpert -X- _ B-MethodName
- -X- _ I-MethodName
Wolf -X- _ I-MethodName
estimator -X- _ O
is -X- _ O
given -X- _ O
by -X- _ O

where -X- _ O

where -X- _ O
Note -X- _ O
H -X- _ O
is -X- _ O
a -X- _ O
random -X- _ O
variable -X- _ O
and -X- _ O
unrelated -X- _ O
to -X- _ O
the -X- _ O
functional -X- _ O
H -X- _ O
( -X- _ O
• -X- _ O
) -X- _ O
; -X- _ O
the -X- _ O
choice -X- _ O
of -X- _ O
letter -X- _ O
intentionally -X- _ O
reminds -X- _ O
one -X- _ O
that -X- _ O
the -X- _ O
variable -X- _ O
represents -X- _ O
the -X- _ O
expected -X- _ O
entropy -X- _ O
of -X- _ O
under -X- _ O
a -X- _ O
random -X- _ O
distribution -X- _ O
. -X- _ O
Now -X- _ O
we -X- _ O
apply -X- _ O
the -X- _ O
change -X- _ O
- -X- _ O
of -X- _ O
- -X- _ O
variables -X- _ O
formula -X- _ O
at -X- _ O
H -X- _ O
= -X- _ O
g -X- _ O
−1 -X- _ O
( -X- _ O
α -X- _ O
) -X- _ O
and -X- _ O
manipulate -X- _ O
: -X- _ O

A -X- _ O
def -X- _ O
= -X- _ O
K -X- _ O
k=1 -X- _ O
α -X- _ O
k -X- _ O
. -X- _ O

Acknowledgments -X- _ O

We -X- _ O
thank -X- _ O
Adina -X- _ O
Williams -X- _ O
, -X- _ O
Lucas -X- _ O
Torroba -X- _ O
Hennigen -X- _ O
, -X- _ O
Tiago -X- _ O
Pimentel -X- _ O
, -X- _ O
and -X- _ O
the -X- _ O
anonymous -X- _ O
reviewers -X- _ O
for -X- _ O
feedback -X- _ O
on -X- _ O
the -X- _ O
manuscript -X- _ O
. -X- _ O

which -X- _ O
proves -X- _ O
the -X- _ O
result -X- _ O
. -X- _ O

E.7 -X- _ O
Nemenman -X- _ B-MethodName
- -X- _ I-MethodName
Shafee -X- _ I-MethodName
- -X- _ I-MethodName
Bialek -X- _ I-MethodName

Estimator -X- _ O
6 -X- _ O
( -X- _ O
Nemenman -X- _ B-MethodName
- -X- _ I-MethodName
Shafee -X- _ I-MethodName
- -X- _ I-MethodName
Bialek -X- _ I-MethodName
) -X- _ O
. -X- _ O
Let -X- _ O
p -X- _ O
be -X- _ O
a -X- _ O
categorical -X- _ O
over -X- _ O
K -X- _ B-HyperparameterName
categories -X- _ O
. -X- _ O
We -X- _ O
seek -X- _ O
to -X- _ O
estimate -X- _ O
the -X- _ O
entropy -X- _ O
H -X- _ O
( -X- _ O
p -X- _ O
) -X- _ O
. -X- _ O
Let -X- _ O
D -X- _ O
be -X- _ O
our -X- _ O
dataset -X- _ O
of -X- _ O
size -X- _ O
N -X- _ B-MethodName
sampled -X- _ O
from -X- _ O
p. -X- _ O
Define -X- _ O
the -X- _ O
NSB -X- _ B-MethodName
density -X- _ O
as -X- _ O

where -X- _ O
ψ -X- _ O
1 -X- _ O
is -X- _ O
the -X- _ O
trigramma -X- _ O
function -X- _ O
. -X- _ O
Then -X- _ O
, -X- _ O
the -X- _ O
NSB -X- _ B-MethodName
estimator -X- _ O
is -X- _ O
given -X- _ O
by -X- _ O

The -X- _ O
integral -X- _ O
in -X- _ O
Eq -X- _ O
. -X- _ O
( -X- _ O
115 -X- _ O
) -X- _ O
is -X- _ O
typically -X- _ O
computed -X- _ O
by -X- _ O
numerical -X- _ O
integration -X- _ O
. -X- _ O

To -X- _ O
derive -X- _ O
the -X- _ O
Nemenman -X- _ B-MethodName
- -X- _ I-MethodName
Shafee -X- _ I-MethodName
- -X- _ I-MethodName
Bialek -X- _ I-MethodName
( -X- _ O
NSB -X- _ B-MethodName
) -X- _ O
estimator -X- _ O
, -X- _ O
we -X- _ O
start -X- _ O
with -X- _ O
the -X- _ O
idea -X- _ O
that -X- _ O
we -X- _ O
would -X- _ O
like -X- _ O
a -X- _ O
prior -X- _ O
over -X- _ O
distributions -X- _ O
such -X- _ O
that -X- _ O
the -X- _ O
distribution -X- _ O
over -X- _ O
expected -X- _ O
entropy -X- _ O
is -X- _ O
uniform -X- _ O
. -X- _ O
In -X- _ O
other -X- _ O
words -X- _ O
, -X- _ O
we -X- _ O
are -X- _ O
looking -X- _ O
for -X- _ O
a -X- _ O
p -X- _ O
NSB -X- _ B-MethodName
such -X- _ O
that -X- _ O
for -X- _ O
α -X- _ O
∼ -X- _ O
p -X- _ O
NSB -X- _ B-MethodName
, -X- _ O
the -X- _ O
values -X- _ O
of -X- _ O
E -X- _ O
p -X- _ O
[ -X- _ O
H -X- _ O
( -X- _ O
p -X- _ O
) -X- _ O
| -X- _ O
α -X- _ O
] -X- _ O
are -X- _ O
uniformly -X- _ O
distributed -X- _ O
over -X- _ O
[ -X- _ O
0 -X- _ O
, -X- _ O
log -X- _ O
K -X- _ O
] -X- _ O
. -X- _ O
This -X- _ O
is -X- _ O
a -X- _ O
good -X- _ O
idea -X- _ O
since -X- _ O
, -X- _ O
a -X- _ O
- -X- _ O
priori -X- _ O
, -X- _ O
we -X- _ O
do -X- _ O
not -X- _ O
know -X- _ O
entropy -X- _ O
of -X- _ O
p -X- _ O
and -X- _ O
, -X- _ O
in -X- _ O
the -X- _ O
absence -X- _ O
of -X- _ O
any -X- _ O
insight -X- _ O
, -X- _ O
we -X- _ O
should -X- _ O
assume -X- _ O
the -X- _ O
entropy -X- _ O
could -X- _ O
be -X- _ O
anywhere -X- _ O
in -X- _ O
the -X- _ O
range -X- _ O
[ -X- _ O
0 -X- _ O
, -X- _ O
log -X- _ O
K -X- _ O
] -X- _ O
. -X- _ O
We -X- _ O
make -X- _ O
the -X- _ O
above -X- _ O
intuition -X- _ O
formal -X- _ O
with -X- _ O
the -X- _ O
following -X- _ O
proposition -X- _ O
. -X- _ O
Proposition -X- _ O
4 -X- _ O
. -X- _ O
Let -X- _ O
p -X- _ O
NSB -X- _ B-MethodName
be -X- _ O
the -X- _ O
NSB -X- _ B-MethodName
density -X- _ O
given -X- _ O
in -X- _ O
Eq -X- _ O
. -X- _ O
( -X- _ O
114 -X- _ O
) -X- _ O
. -X- _ O
Then -X- _ O
the -X- _ O
following -X- _ O
conditional -X- _ O
expectation -X- _ O

is -X- _ O
uniformly -X- _ O
distributed -X- _ O
over -X- _ O
[ -X- _ O
0 -X- _ O
, -X- _ O
log -X- _ O
K -X- _ O
] -X- _ O
when -X- _ O
α -X- _ O
∼ -X- _ O
p -X- _ O
NSB -X- _ B-MethodName
( -X- _ O
• -X- _ O
) -X- _ O
, -X- _ O
defined -X- _ O
in -X- _ O
Eq -X- _ O
. -X- _ O
( -X- _ O
114 -X- _ O
) -X- _ O
. -X- _ O

Proof -X- _ O
. -X- _ O
First -X- _ O
, -X- _ O
we -X- _ O
note -X- _ O
that -X- _ O
E -X- _ O
p -X- _ O
[ -X- _ O
H -X- _ O
( -X- _ O
p -X- _ O
) -X- _ O
| -X- _ O
α -X- _ O
] -X- _ O
is -X- _ O
a -X- _ O
continuous -X- _ O
, -X- _ O
increasing -X- _ O
function -X- _ O
in -X- _ O
α -X- _ O
. -X- _ O
We -X- _ O
will -X- _ O
not -X- _ O
prove -X- _ O
this -X- _ O
formally -X- _ O
, -X- _ O
but -X- _ O
it -X- _ O
should -X- _ O
make -X- _ O
intuitive -X- _ O
sense -X- _ O
: -X- _ O
α -X- _ O
is -X- _ O
a -X- _ O
smoothing -X- _ O
parameter -X- _ O
and -X- _ O
the -X- _ O
more -X- _ O
the -X- _ O
distribution -X- _ O
is -X- _ O
smoothed -X- _ O
, -X- _ O
the -X- _ O
more -X- _ O
entropic -X- _ O
it -X- _ O
should -X- _ O
be -X- _ O
. -X- _ O
From -X- _ O
basic -X- _ O
analysis -X- _ O
, -X- _ O
we -X- _ O
know -X- _ O
that -X- _ O
a -X- _ O
strictly -X- _ O
continuous -X- _ O
, -X- _ O
increasing -X- _ O
function -X- _ O
has -X- _ O
an -X- _ O
inverse -X- _ O
. -X- _ O
The -X- _ O
above -X- _ O
means -X- _ O
that -X- _ O
we -X- _ O
can -X- _ O
view -X- _ O
E -X- _ O
p -X- _ O
[ -X- _ O
H -X- _ O
( -X- _ O
p -X- _ O
) -X- _ O
| -X- _ O
α -X- _ O
] -X- _ O
as -X- _ O
a -X- _ O
bijection -X- _ O
from -X- _ O
R -X- _ O
≥0 -X- _ O
to -X- _ O
the -X- _ O
interval -X- _ O
[ -X- _ O
0 -X- _ O
, -X- _ O
log -X- _ O
K -X- _ O
] -X- _ O
. -X- _ O
Our -X- _ O
goal -X- _ O
is -X- _ O
to -X- _ O
reparameterize -X- _ O
the -X- _ O
Uniform -X- _ O
distribution -X- _ O
in -X- _ O
terms -X- _ O
of -X- _ O
α -X- _ O
. -X- _ O
To -X- _ O
that -X- _ O
end -X- _ O
, -X- _ O

Problems -X- _ O
with -X- _ O
Cosine -X- _ O
as -X- _ O
a -X- _ O
Measure -X- _ O
of -X- _ O
Embedding -X- _ O
Similarity -X- _ O
for -X- _ O
High -X- _ O
Frequency -X- _ O
Words -X- _ O

Semantic -X- _ O
Framework -X- _ O
based -X- _ O
Query -X- _ O
Generation -X- _ O
for -X- _ O
Temporal -X- _ B-TaskName
Question -X- _ I-TaskName
Answering -X- _ I-TaskName
over -X- _ I-TaskName
Knowledge -X- _ I-TaskName
Graphs -X- _ I-TaskName

Answering -X- _ B-TaskName
factual -X- _ I-TaskName
questions -X- _ I-TaskName
with -X- _ I-TaskName
temporal -X- _ I-TaskName
intent -X- _ I-TaskName
over -X- _ I-TaskName
knowledge -X- _ I-TaskName
graphs -X- _ I-TaskName
( -X- _ O
temporal -X- _ B-TaskName
KGQA -X- _ I-TaskName
) -X- _ O
attracts -X- _ O
rising -X- _ O
attention -X- _ O
in -X- _ O
recent -X- _ O
years -X- _ O
. -X- _ O
In -X- _ O
the -X- _ O
generation -X- _ O
of -X- _ O
temporal -X- _ O
queries -X- _ O
, -X- _ O
existing -X- _ O
KGQA -X- _ B-TaskName
methods -X- _ O
ignore -X- _ O
the -X- _ O
fact -X- _ O
that -X- _ O
some -X- _ O
intrinsic -X- _ O
connections -X- _ O
between -X- _ O
events -X- _ O
can -X- _ O
make -X- _ O
them -X- _ O
temporally -X- _ O
related -X- _ O
, -X- _ O
which -X- _ O
may -X- _ O
limit -X- _ O
their -X- _ O
capability -X- _ O
. -X- _ O
We -X- _ O
systematically -X- _ O
analyze -X- _ O
the -X- _ O
possible -X- _ O
interpretation -X- _ O
of -X- _ O
temporal -X- _ O
constraints -X- _ O
and -X- _ O
conclude -X- _ O
the -X- _ O
interpretation -X- _ O
structures -X- _ O
as -X- _ O
the -X- _ O
Semantic -X- _ O
Framework -X- _ O
of -X- _ O
Temporal -X- _ O
Constraints -X- _ O
, -X- _ O
SF -X- _ O
- -X- _ O
TCons -X- _ O
. -X- _ O
Based -X- _ O
on -X- _ O
the -X- _ O
semantic -X- _ O
framework -X- _ O
, -X- _ O
we -X- _ O
propose -X- _ O
a -X- _ O
temporal -X- _ O
question -X- _ O
answering -X- _ O
method -X- _ O
, -X- _ O
SF -X- _ B-MethodName
- -X- _ I-MethodName
TQA -X- _ I-MethodName
, -X- _ O
which -X- _ O
generates -X- _ O
query -X- _ O
graphs -X- _ O
by -X- _ O
exploring -X- _ O
the -X- _ O
relevant -X- _ O
facts -X- _ O
of -X- _ O
mentioned -X- _ O
entities -X- _ O
, -X- _ O
where -X- _ O
the -X- _ O
exploring -X- _ O
process -X- _ O
is -X- _ O
restricted -X- _ O
by -X- _ O
SF -X- _ O
- -X- _ O
TCons -X- _ O
. -X- _ O
Our -X- _ O
evaluations -X- _ O
show -X- _ O
that -X- _ O
SF -X- _ B-MethodName
- -X- _ I-MethodName
TQA -X- _ I-MethodName
significantly -X- _ O
outperforms -X- _ O
existing -X- _ O
methods -X- _ O
on -X- _ O
two -X- _ O
benchmarks -X- _ O
over -X- _ O
different -X- _ O
knowledge -X- _ O
graphs -X- _ O
. -X- _ O

Introduction -X- _ O

With -X- _ O
the -X- _ O
rapid -X- _ O
growth -X- _ O
of -X- _ O
knowledge -X- _ O
graphs -X- _ O
, -X- _ O
temporal -X- _ B-TaskName
question -X- _ I-TaskName
answering -X- _ I-TaskName
over -X- _ I-TaskName
knowledge -X- _ I-TaskName
graphs -X- _ I-TaskName
( -X- _ O
temporal -X- _ B-TaskName
KGQA -X- _ I-TaskName
) -X- _ O
is -X- _ O
attracting -X- _ O
rising -X- _ O
attention -X- _ O
in -X- _ O
recent -X- _ O
years -X- _ O
( -X- _ O
Jia -X- _ O
et -X- _ O
al -X- _ O
. -X- _ O
, -X- _ O
2018b -X- _ O
( -X- _ O
Jia -X- _ O
et -X- _ O
al -X- _ O
. -X- _ O
, -X- _ O
, -X- _ O
2021 -X- _ O
. -X- _ O
In -X- _ O
temporal -X- _ B-TaskName
KGQA -X- _ I-TaskName
, -X- _ O
a -X- _ O
common -X- _ O
phenomenon -X- _ O
is -X- _ O
that -X- _ O
questions -X- _ O
express -X- _ O
temporal -X- _ O
relations -X- _ O
between -X- _ O
events -X- _ O
or -X- _ O
time -X- _ O
expressions -X- _ O
, -X- _ O
while -X- _ O
knowledge -X- _ O
graphs -X- _ O
describe -X- _ O
the -X- _ O
facts -X- _ O
resulting -X- _ O
from -X- _ O
each -X- _ O
event -X- _ O
. -X- _ O
Existing -X- _ O
methods -X- _ O
handle -X- _ O
the -X- _ O
heterogeneity -X- _ O
between -X- _ O
natural -X- _ O
language -X- _ O
and -X- _ O
knowledge -X- _ O
graph -X- _ O
representation -X- _ O
in -X- _ O
two -X- _ O
ways -X- _ O
. -X- _ O
Some -X- _ O
systems -X- _ O
express -X- _ O
temporal -X- _ O
intents -X- _ O
by -X- _ O
constructing -X- _ O
executable -X- _ O
queries -X- _ O
, -X- _ O
some -X- _ O
apply -X- _ O
time -X- _ O
- -X- _ O
sensitive -X- _ O
neural -X- _ O
models -X- _ O
to -X- _ O
rank -X- _ O
candidate -X- _ O
answers -X- _ O
. -X- _ O
Considering -X- _ O
that -X- _ O
neural -X- _ O
models -X- _ O
are -X- _ O
difficult -X- _ O
to -X- _ O
characterize -X- _ O
the -X- _ O
clear -X- _ O
boundaries -X- _ O
of -X- _ O
concepts -X- _ O
( -X- _ O
e.g. -X- _ O
, -X- _ O
exactly -X- _ O
filter -X- _ O
all -X- _ O
events -X- _ O
that -X- _ O
occur -X- _ O
" -X- _ O
before -X- _ O
2022 -X- _ O
" -X- _ O
) -X- _ O
, -X- _ O
this -X- _ O
paper -X- _ O
focuses -X- _ O
on -X- _ O
generating -X- _ O
queries -X- _ O
that -X- _ O
correspond -X- _ O
to -X- _ O
the -X- _ O
meaning -X- _ O
of -X- _ O
questions -X- _ O
. -X- _ O

From -X- _ O
the -X- _ O
logic -X- _ O
perspective -X- _ O
, -X- _ O
formulated -X- _ O
queries -X- _ O
are -X- _ O
actually -X- _ O
logical -X- _ O
restrictions -X- _ O
about -X- _ O
KG -X- _ O
facts -X- _ O
. -X- _ O
The -X- _ O
answers -X- _ O
to -X- _ O
a -X- _ O
question -X- _ O
is -X- _ O
a -X- _ O
set -X- _ O
of -X- _ O
KG -X- _ O
objects -X- _ O
, -X- _ O
each -X- _ O
of -X- _ O
which -X- _ O
satisfies -X- _ O
the -X- _ O
corresponding -X- _ O
logical -X- _ O
restrictions -X- _ O
. -X- _ O
In -X- _ O
previous -X- _ O
studies -X- _ O
( -X- _ O
e.g. -X- _ O
, -X- _ O
Jia -X- _ O
et -X- _ O
al -X- _ O
. -X- _ O
, -X- _ O
2018b -X- _ O
) -X- _ O
, -X- _ O
temporal -X- _ O
intents -X- _ O
are -X- _ O
converted -X- _ O
into -X- _ O
restrictions -X- _ O
over -X- _ O
KG -X- _ O
facts -X- _ O
with -X- _ O
quantitative -X- _ O
time -X- _ O
values -X- _ O
. -X- _ O
Example -X- _ O
1 -X- _ O
illustrates -X- _ O
a -X- _ O
typical -X- _ O
conversion -X- _ O
from -X- _ O
a -X- _ O
temporal -X- _ O
question -X- _ O
to -X- _ O
such -X- _ O
restriction -X- _ O
. -X- _ O
Example -X- _ O
1 -X- _ O
. -X- _ O
" -X- _ O
Who -X- _ O
was -X- _ O
the -X- _ O
president -X- _ O
of -X- _ O
the -X- _ O
U.S. -X- _ O
when -X- _ O
John -X- _ O
Lennon -X- _ O
was -X- _ O
shot -X- _ O
? -X- _ O
" -X- _ O

The -X- _ O
corresponding -X- _ O
query -X- _ O
on -X- _ O
Wikidata -X- _ O
can -X- _ O
be -X- _ O
formulated -X- _ O
as -X- _ O
the -X- _ O
following -X- _ O
logical -X- _ O
restriction -X- _ O
: -X- _ O

T -X- _ O
1 -X- _ O
= -X- _ O
time -X- _ O
( -X- _ O
position_held -X- _ O
( -X- _ O
AN -X- _ O
S -X- _ O
, -X- _ O
U.S._president -X- _ O
) -X- _ O
) -X- _ O
∧ -X- _ O
T -X- _ O
2 -X- _ O
= -X- _ O
time -X- _ O
( -X- _ O
Murder_of_John_Lennon -X- _ O
) -X- _ O
∧ -X- _ O
OVERLAPS -X- _ O
( -X- _ O
T -X- _ O
1 -X- _ O
, -X- _ O
T -X- _ O
2 -X- _ O
) -X- _ O
. -X- _ O

However -X- _ O
, -X- _ O
the -X- _ O
idea -X- _ O
of -X- _ O
constructing -X- _ O
queries -X- _ O
with -X- _ O
quantitative -X- _ O
restrictions -X- _ O
can -X- _ O
not -X- _ O
exhaust -X- _ O
all -X- _ O
possible -X- _ O
scenarios -X- _ O
. -X- _ O
As -X- _ O
illustrated -X- _ O
in -X- _ O
Example -X- _ O
2 -X- _ O
, -X- _ O
facts -X- _ O
with -X- _ O
time -X- _ O
values -X- _ O
are -X- _ O
not -X- _ O
a -X- _ O
necessary -X- _ O
premise -X- _ O
to -X- _ O
introduce -X- _ O
a -X- _ O
temporal -X- _ O
relation -X- _ O
. -X- _ O

Example -X- _ O
2 -X- _ O
. -X- _ O
" -X- _ O
Where -X- _ O
was -X- _ O
John -X- _ O
Lennon -X- _ O
standing -X- _ O
when -X- _ O
he -X- _ O
was -X- _ O
shot -X- _ O
? -X- _ O
" -X- _ O

To -X- _ O
construct -X- _ O
a -X- _ O
comparison -X- _ O
restriction -X- _ O
, -X- _ O
we -X- _ O
need -X- _ O
to -X- _ O
enumerate -X- _ O
the -X- _ O
" -X- _ O
standing -X- _ O
" -X- _ O
of -X- _ O
J.L. -X- _ O
( -X- _ O
i.e. -X- _ O
all -X- _ O
the -X- _ O
experiences -X- _ O
of -X- _ O
his -X- _ O
life -X- _ O
) -X- _ O
. -X- _ O
The -X- _ O
enumeration -X- _ O
is -X- _ O
hard -X- _ O
to -X- _ O
implement -X- _ O
and -X- _ O
might -X- _ O
introduce -X- _ O
errors -X- _ O
. -X- _ O
1 -X- _ O
In -X- _ O
fact -X- _ O
, -X- _ O
the -X- _ O
temporal -X- _ O
intent -X- _ O
does -X- _ O
not -X- _ O
rely -X- _ O
on -X- _ O
any -X- _ O
time -X- _ O
value -X- _ O
. -X- _ O
The -X- _ O
two -X- _ O
events -X- _ O
occur -X- _ O
simultaneously -X- _ O
just -X- _ O
because -X- _ O
they -X- _ O
are -X- _ O
different -X- _ O
aspects -X- _ O
of -X- _ O
the -X- _ O
same -X- _ O
entity -X- _ O
( -X- _ O
wd -X- _ O
: -X- _ O
Q2341090 -X- _ O
) -X- _ O
, -X- _ O
the -X- _ O
murder -X- _ O
of -X- _ O
John -X- _ O
Lennon -X- _ O
. -X- _ O

The -X- _ O
above -X- _ O
example -X- _ O
reveals -X- _ O
that -X- _ O
intrinsic -X- _ O
connections -X- _ O
can -X- _ O
also -X- _ O
make -X- _ O
events -X- _ O
temporally -X- _ O
related -X- _ O
. -X- _ O
We -X- _ O
argue -X- _ O
that -X- _ O
the -X- _ O
neglect -X- _ O
of -X- _ O
such -X- _ O
cases -X- _ O
may -X- _ O
limit -X- _ O
the -X- _ O
capability -X- _ O
of -X- _ O
existing -X- _ O
methods -X- _ O
. -X- _ O
Therefore -X- _ O
, -X- _ O
the -X- _ O
possible -X- _ O
temporal -X- _ O
constraints -X- _ O
, -X- _ O
especially -X- _ O
those -X- _ O
that -X- _ O
do -X- _ O
not -X- _ O
rely -X- _ O
on -X- _ O
explicit -X- _ O
time -X- _ O
values -X- _ O
, -X- _ O
need -X- _ O
to -X- _ O
be -X- _ O
specifically -X- _ O
studied -X- _ O
. -X- _ O
The -X- _ O
main -X- _ O
challenges -X- _ O
in -X- _ O
concluding -X- _ O
such -X- _ O
constraints -X- _ O
come -X- _ O
from -X- _ O
the -X- _ O
complexity -X- _ O
of -X- _ O
natural -X- _ O
language -X- _ O
and -X- _ O
the -X- _ O
lack -X- _ O
of -X- _ O
supervision -X- _ O
signals -X- _ O
. -X- _ O
Practical -X- _ O
KGQA -X- _ B-TaskName
tasks -X- _ O
often -X- _ O
provide -X- _ O
only -X- _ O
questionanswer -X- _ O
pairs -X- _ O
. -X- _ O
i.e. -X- _ O
, -X- _ O
the -X- _ O
constraints -X- _ O
on -X- _ O
the -X- _ O
relevant -X- _ O
facts -X- _ O
are -X- _ O
unknown -X- _ O
. -X- _ O
Manually -X- _ O
enumerating -X- _ O
all -X- _ O
possible -X- _ O
constraint -X- _ O
structures -X- _ O
in -X- _ O
a -X- _ O
huge -X- _ O
search -X- _ O
space -X- _ O
will -X- _ O
be -X- _ O
cumbersome -X- _ O
or -X- _ O
even -X- _ O
infeasible -X- _ O
. -X- _ O
Thus -X- _ O
, -X- _ O
there -X- _ O
is -X- _ O
a -X- _ O
need -X- _ O
for -X- _ O
a -X- _ O
lightweight -X- _ O
method -X- _ O
to -X- _ O
model -X- _ O
the -X- _ O
various -X- _ O
constraints -X- _ O
that -X- _ O
correspond -X- _ O
to -X- _ O
possible -X- _ O
temporal -X- _ O
intents -X- _ O
. -X- _ O

Inspired -X- _ O
by -X- _ O
the -X- _ O
basic -X- _ O
idea -X- _ O
of -X- _ O
frame -X- _ O
semantics -X- _ O
that -X- _ O
" -X- _ O
one -X- _ O
can -X- _ O
not -X- _ O
understand -X- _ O
the -X- _ O
meaning -X- _ O
of -X- _ O
a -X- _ O
word -X- _ O
without -X- _ O
access -X- _ O
to -X- _ O
all -X- _ O
the -X- _ O
encyclopedic -X- _ O
knowledge -X- _ O
that -X- _ O
relates -X- _ O
to -X- _ O
that -X- _ O
word -X- _ O
. -X- _ O
" -X- _ O
( -X- _ O
Fillmore -X- _ O
et -X- _ O
al -X- _ O
. -X- _ O
, -X- _ O
2006 -X- _ O
) -X- _ O
, -X- _ O
we -X- _ O
assume -X- _ O
that -X- _ O
temporal -X- _ O
intents -X- _ O
are -X- _ O
expressed -X- _ O
as -X- _ O
certain -X- _ O
constraints -X- _ O
about -X- _ O
corresponding -X- _ O
knowledge -X- _ O
and -X- _ O
could -X- _ O
be -X- _ O
interpreted -X- _ O
by -X- _ O
some -X- _ O
structures -X- _ O
over -X- _ O
KG -X- _ O
facts -X- _ O
. -X- _ O
Specifically -X- _ O
, -X- _ O
the -X- _ O
events -X- _ O
involved -X- _ O
in -X- _ O
a -X- _ O
temporal -X- _ O
constraint -X- _ O
should -X- _ O
provide -X- _ O
certain -X- _ O
KG -X- _ O
facts -X- _ O
, -X- _ O
which -X- _ O
support -X- _ O
a -X- _ O
possible -X- _ O
interpretation -X- _ O
of -X- _ O
it -X- _ O
. -X- _ O
We -X- _ O
conclude -X- _ O
the -X- _ O
temporal -X- _ O
constraints -X- _ O
and -X- _ O
their -X- _ O
corresponding -X- _ O
interpretation -X- _ O
structures -X- _ O
as -X- _ O
the -X- _ O
Semantic -X- _ O
Framework -X- _ O
of -X- _ O
Temporal -X- _ O
Constraints -X- _ O
, -X- _ O
SF -X- _ O
- -X- _ O
TCons -X- _ O
. -X- _ O
SF -X- _ O
- -X- _ O
TCons -X- _ O
describes -X- _ O
what -X- _ O
kinds -X- _ O
of -X- _ O
knowledge -X- _ O
are -X- _ O
needed -X- _ O
and -X- _ O
how -X- _ O
they -X- _ O
are -X- _ O
composed -X- _ O
in -X- _ O
the -X- _ O
potential -X- _ O
interpretations -X- _ O
. -X- _ O
It -X- _ O
consists -X- _ O
of -X- _ O
6 -X- _ O
interpretation -X- _ O
structures -X- _ O
, -X- _ O
which -X- _ O
will -X- _ O
be -X- _ O
presented -X- _ O
in -X- _ O
Section -X- _ O
2 -X- _ O
. -X- _ O
To -X- _ O
the -X- _ O
best -X- _ O
of -X- _ O
our -X- _ O
knowledge -X- _ O
, -X- _ O
SF -X- _ O
- -X- _ O
TCons -X- _ O
is -X- _ O
the -X- _ O
first -X- _ O
work -X- _ O
to -X- _ O
systematically -X- _ O
summarize -X- _ O
the -X- _ O
interpretation -X- _ O
structures -X- _ O
for -X- _ O
temporal -X- _ B-TaskName
KGQA -X- _ I-TaskName
tasks -X- _ O
. -X- _ O

Based -X- _ O
on -X- _ O
SF -X- _ O
- -X- _ O
TCons -X- _ O
, -X- _ O
we -X- _ O
propose -X- _ O
a -X- _ O
semanticframework -X- _ B-MethodName
- -X- _ I-MethodName
based -X- _ I-MethodName
question -X- _ I-MethodName
answering -X- _ I-MethodName
method -X- _ O
, -X- _ O
SF -X- _ B-MethodName
- -X- _ I-MethodName
TQA -X- _ I-MethodName
, -X- _ O
to -X- _ O
convert -X- _ O
SF -X- _ O
- -X- _ O
TCons -X- _ O
into -X- _ O
executable -X- _ O
queries -X- _ O
. -X- _ O
SF -X- _ B-MethodName
- -X- _ I-MethodName
TQA -X- _ I-MethodName
generates -X- _ O
query -X- _ O
graphs -X- _ O
by -X- _ O
exploring -X- _ O
the -X- _ O
relevant -X- _ O
facts -X- _ O
of -X- _ O
mentioned -X- _ O
entities -X- _ O
, -X- _ O
where -X- _ O
the -X- _ O
query -X- _ O
graph -X- _ O
is -X- _ O
a -X- _ O
graph -X- _ O
representation -X- _ O
of -X- _ O
executable -X- _ O
logical -X- _ O
queries -X- _ O
that -X- _ O
resembles -X- _ O
subgraphs -X- _ O
of -X- _ O
KG -X- _ O
( -X- _ O
Yih -X- _ O
et -X- _ O
al -X- _ O
. -X- _ O
, -X- _ O
2015 -X- _ O
) -X- _ O
. -X- _ O
SF -X- _ B-MethodName
- -X- _ I-MethodName
TQA -X- _ I-MethodName
improves -X- _ O
the -X- _ O
accuracy -X- _ O
of -X- _ O
query -X- _ O
generation -X- _ O
by -X- _ O
regarding -X- _ O
SF -X- _ O
- -X- _ O
TCons -X- _ O
as -X- _ O
restrictions -X- _ O
in -X- _ O
the -X- _ O
exploration -X- _ O
. -X- _ O
SF -X- _ B-MethodName
- -X- _ I-MethodName
TQA -X- _ I-MethodName
firstly -X- _ O
evokes -X- _ O
possible -X- _ O
interpretations -X- _ O
of -X- _ O
temporal -X- _ O
intents -X- _ O
according -X- _ O
to -X- _ O
TimeML -X- _ O
( -X- _ O
Pustejovsky -X- _ O
et -X- _ O
al -X- _ O
. -X- _ O
, -X- _ O
2010 -X- _ O
) -X- _ O
annotations -X- _ O
. -X- _ O
It -X- _ O
then -X- _ O
grounds -X- _ O
the -X- _ O
temporal -X- _ O
elements -X- _ O
in -X- _ O
corresponding -X- _ O
interpretation -X- _ O
structures -X- _ O
by -X- _ O
the -X- _ O
relevant -X- _ O
KG -X- _ O
facts -X- _ O
. -X- _ O
The -X- _ O
grounding -X- _ O
phase -X- _ O
will -X- _ O
generate -X- _ O
multiple -X- _ O
candidate -X- _ O
queries -X- _ O
, -X- _ O
the -X- _ O
best -X- _ O
candidate -X- _ O
will -X- _ O
be -X- _ O
distinguished -X- _ O
by -X- _ O
ranking -X- _ O
the -X- _ O
pairs -X- _ O
of -X- _ O
questions -X- _ O
and -X- _ O
serialized -X- _ O
queries -X- _ O
with -X- _ O
a -X- _ O
BERT -X- _ O
model -X- _ O
. -X- _ O
The -X- _ O
rest -X- _ O
of -X- _ O
this -X- _ O
paper -X- _ O
is -X- _ O
organized -X- _ O
as -X- _ O
follows -X- _ O
: -X- _ O
Section -X- _ O
2 -X- _ O
discusses -X- _ O
the -X- _ O
SF -X- _ O
- -X- _ O
TCons -X- _ O
in -X- _ O
detail -X- _ O
. -X- _ O
Section -X- _ O
3 -X- _ O
presents -X- _ O
SF -X- _ B-MethodName
- -X- _ I-MethodName
TQA -X- _ I-MethodName
. -X- _ O
Section -X- _ O
4 -X- _ O
evaluates -X- _ O
the -X- _ O
SF -X- _ B-MethodName
- -X- _ I-MethodName
TQA -X- _ I-MethodName
with -X- _ O
two -X- _ O
benchmarks -X- _ O
over -X- _ O
different -X- _ O
knowledge -X- _ O
graphs -X- _ O
. -X- _ O
Section -X- _ O
5 -X- _ O
summarizes -X- _ O
the -X- _ O
related -X- _ O
work -X- _ O
. -X- _ O
The -X- _ O
last -X- _ O
section -X- _ O
concludes -X- _ O
this -X- _ O
paper -X- _ O
. -X- _ O

Semantic -X- _ O
Framework -X- _ O
of -X- _ O
Temporal -X- _ O
Constraints -X- _ O

As -X- _ O
previously -X- _ O
introduced -X- _ O
, -X- _ O
temporal -X- _ O
intents -X- _ O
reflect -X- _ O
constraints -X- _ O
on -X- _ O
events -X- _ O
and -X- _ O
time -X- _ O
expressions -X- _ O
. -X- _ O
We -X- _ O
argue -X- _ O
that -X- _ O
what -X- _ O
really -X- _ O
supports -X- _ O
the -X- _ O
constraints -X- _ O
is -X- _ O
the -X- _ O
essential -X- _ O
knowledge -X- _ O
underlying -X- _ O
the -X- _ O
involved -X- _ O
elements -X- _ O
. -X- _ O
For -X- _ O
example -X- _ O
, -X- _ O
in -X- _ O
a -X- _ O
comparison -X- _ O
like -X- _ O
" -X- _ O
before -X- _ O
WWI -X- _ O
" -X- _ O
, -X- _ O
what -X- _ O
is -X- _ O
needed -X- _ O
is -X- _ O
its -X- _ O
start -X- _ O
time -X- _ O
" -X- _ O
1914 -X- _ O
" -X- _ O
rather -X- _ O
than -X- _ O
the -X- _ O
named -X- _ O
entity -X- _ O
wd -X- _ O
: -X- _ O
Q361 -X- _ O
in -X- _ O
KG -X- _ O
. -X- _ O
Therefore -X- _ O
, -X- _ O
temporal -X- _ O
constraints -X- _ O
can -X- _ O
be -X- _ O
interpreted -X- _ O
by -X- _ O
describing -X- _ O
what -X- _ O
kind -X- _ O
of -X- _ O
knowledge -X- _ O
is -X- _ O
needed -X- _ O
and -X- _ O
how -X- _ O
they -X- _ O
are -X- _ O
composed -X- _ O
. -X- _ O
The -X- _ O
interpretation -X- _ O
structures -X- _ O
of -X- _ O
the -X- _ O
constraints -X- _ O
are -X- _ O
presented -X- _ O
as -X- _ O
SF -X- _ O
- -X- _ O
TCons -X- _ O
, -X- _ O
the -X- _ O
Semantic -X- _ O
Framework -X- _ O
of -X- _ O
Temporal -X- _ O
Constraints -X- _ O
. -X- _ O

Temporal -X- _ O
Constraints -X- _ O
in -X- _ O
Questions -X- _ O

Depending -X- _ O
on -X- _ O
whether -X- _ O
the -X- _ O
constraints -X- _ O
concern -X- _ O
quantitative -X- _ O
attributes -X- _ O
of -X- _ O
a -X- _ O
single -X- _ O
event -X- _ O
or -X- _ O
the -X- _ O
relations -X- _ O
between -X- _ O
events -X- _ O
, -X- _ O
we -X- _ O
classify -X- _ O
the -X- _ O
temporal -X- _ O
constraints -X- _ O
as -X- _ O
follows -X- _ O
. -X- _ O

Value -X- _ O
Constraints -X- _ O
. -X- _ O
The -X- _ O
intentions -X- _ O
about -X- _ O
quantitative -X- _ O
values -X- _ O
are -X- _ O
often -X- _ O
expressed -X- _ O
with -X- _ O
time -X- _ O
values -X- _ O
or -X- _ O
ordinals -X- _ O
( -X- _ O
e.g. -X- _ O
, -X- _ O
" -X- _ O
first -X- _ O
president -X- _ O
" -X- _ O
) -X- _ O
. -X- _ O
They -X- _ O
require -X- _ O
certain -X- _ O
events -X- _ O
to -X- _ O
have -X- _ O
corresponding -X- _ O
temporal -X- _ O
or -X- _ O
ordinal -X- _ O
attributes -X- _ O
. -X- _ O
Thus -X- _ O
, -X- _ O
they -X- _ O
could -X- _ O
be -X- _ O
denoted -X- _ O
as -X- _ O
follow -X- _ O
. -X- _ O

where -X- _ O
E -X- _ O
, -X- _ O
T -X- _ O
, -X- _ O
O -X- _ O
denotes -X- _ O
events -X- _ O
, -X- _ O
time -X- _ O
expressions -X- _ O
and -X- _ O
ordinals -X- _ O
respectively -X- _ O
. -X- _ O
As -X- _ O
an -X- _ O
example -X- _ O
, -X- _ O
the -X- _ O
intent -X- _ O
" -X- _ O
first -X- _ O
president -X- _ O
" -X- _ O
could -X- _ O
be -X- _ O
denoted -X- _ O
as -X- _ O
HASVALUE -X- _ O
( -X- _ O
" -X- _ O
president -X- _ O
" -X- _ O
, -X- _ O
" -X- _ O
first -X- _ O
" -X- _ O
) -X- _ O
. -X- _ O
Specifically -X- _ O
, -X- _ O
temporal -X- _ O
interrogatives -X- _ O
( -X- _ O
e.g. -X- _ O
, -X- _ O
" -X- _ O
when -X- _ O
did -X- _ O
sth -X- _ O
. -X- _ O
happen -X- _ O
? -X- _ O
" -X- _ O
) -X- _ O
are -X- _ O
denoted -X- _ O
as -X- _ O
HASVALUE -X- _ O
( -X- _ O
E -X- _ O
1 -X- _ O
, -X- _ O
T -X- _ O
? -X- _ O
) -X- _ O
, -X- _ O
which -X- _ O
declare -X- _ O
the -X- _ O
existence -X- _ O
of -X- _ O
the -X- _ O
temporal -X- _ O
attributes -X- _ O
but -X- _ O
has -X- _ O
no -X- _ O
restrict -X- _ O
on -X- _ O
the -X- _ O
specific -X- _ O
value -X- _ O
. -X- _ O

Relation -X- _ O
Constraints -X- _ O
. -X- _ O
The -X- _ O
possible -X- _ O
relations -X- _ O
between -X- _ O
time -X- _ O
and -X- _ O
events -X- _ O
have -X- _ O
been -X- _ O
well -X- _ O
studied -X- _ O
in -X- _ O
the -X- _ O
AI -X- _ O
area -X- _ O
. -X- _ O
We -X- _ O
follow -X- _ O
TimeML -X- _ O
, -X- _ O
the -X- _ O
most -X- _ O
commonly -X- _ O
used -X- _ O
annotation -X- _ O
specification -X- _ O
, -X- _ O
to -X- _ O
model -X- _ O
the -X- _ O
relation -X- _ O
constraints -X- _ O
. -X- _ O
when -X- _ O
] -X- _ O
he -X- _ O
was -X- _ O
[ -X- _ O
Event -X- _ O
2 -X- _ O
shot -X- _ O
] -X- _ O
? -X- _ O
⟨TLINK -X- _ O
reltype -X- _ O
= -X- _ O
SIMULTANEOUS -X- _ O
target -X- _ O
= -X- _ O
EVENT -X- _ O
1 -X- _ O
relatedTo -X- _ O
= -X- _ O
EVENT -X- _ O
2 -X- _ O
signal -X- _ O
= -X- _ O
SIGNAL -X- _ O
1 -X- _ O
/ -X- _ O
⟩ -X- _ O
As -X- _ O
illustrated -X- _ O
in -X- _ O
Example -X- _ O
3 -X- _ O
, -X- _ O
temporal -X- _ O
relations -X- _ O
are -X- _ O
triggered -X- _ O
by -X- _ O
certain -X- _ O
signals -X- _ O
( -X- _ O
e.g. -X- _ O
, -X- _ O
" -X- _ O
when -X- _ O
" -X- _ O
) -X- _ O
and -X- _ O
classified -X- _ O
into -X- _ O
pre -X- _ O
- -X- _ O
defined -X- _ O
reltypes -X- _ O
. -X- _ O
For -X- _ O
the -X- _ O
practical -X- _ O
demand -X- _ O
of -X- _ O
QA -X- _ O
tasks -X- _ O
, -X- _ O
we -X- _ O
formalized -X- _ O
the -X- _ O
relation -X- _ O
constraints -X- _ O
as -X- _ O

where -X- _ O
T -X- _ O
R -X- _ O
denotes -X- _ O
the -X- _ O
13 -X- _ O
temporal -X- _ O
reltypes -X- _ O
in -X- _ O
TimeML -X- _ O
( -X- _ O
Pustejovsky -X- _ O
et -X- _ O
al -X- _ O
. -X- _ O
, -X- _ O
2003 -X- _ O
) -X- _ O
, -X- _ O
E -X- _ O
and -X- _ O
T -X- _ O
denotes -X- _ O
events -X- _ O
and -X- _ O
time -X- _ O
expressions -X- _ O
respectively -X- _ O
. -X- _ O
The -X- _ O
TimeML -X- _ O
- -X- _ O
style -X- _ O
annotation -X- _ O
in -X- _ O
the -X- _ O
example -X- _ O
question -X- _ O
corresponds -X- _ O
the -X- _ O
following -X- _ O
RC-2 -X- _ O
constraint -X- _ O
: -X- _ O
RELATION -X- _ O
( -X- _ O
SIMULTANEOUS -X- _ O
, -X- _ O
" -X- _ O
standing -X- _ O
" -X- _ O
, -X- _ O
" -X- _ O
shot -X- _ O
" -X- _ O
) -X- _ O

As -X- _ O
previously -X- _ O
mentioned -X- _ O
, -X- _ O
one -X- _ O
temporal -X- _ O
constraint -X- _ O
could -X- _ O
be -X- _ O
supported -X- _ O
by -X- _ O
various -X- _ O
interpretations -X- _ O
. -X- _ O
We -X- _ O
summarize -X- _ O
6 -X- _ O
interpretation -X- _ O
structures -X- _ O
( -X- _ O
IS -X- _ O
) -X- _ O
according -X- _ O
to -X- _ O
whether -X- _ O
the -X- _ O
involved -X- _ O
event -X- _ O
expressions -X- _ O
are -X- _ O
intrinsically -X- _ O
connected -X- _ O
and -X- _ O
what -X- _ O
connector -X- _ O
between -X- _ O
them -X- _ O
can -X- _ O
correspond -X- _ O
to -X- _ O
the -X- _ O
expected -X- _ O
meanings -X- _ O
. -X- _ O
In -X- _ O
order -X- _ O
to -X- _ O
enhance -X- _ O
the -X- _ O
generality -X- _ O
of -X- _ O
the -X- _ O
IS -X- _ O
as -X- _ O
much -X- _ O
as -X- _ O
possible -X- _ O
, -X- _ O
we -X- _ O
do -X- _ O
not -X- _ O
restrict -X- _ O
the -X- _ O
specific -X- _ O
semantic -X- _ O
representations -X- _ O
of -X- _ O
involved -X- _ O
events -X- _ O
, -X- _ O
but -X- _ O
only -X- _ O
focus -X- _ O
on -X- _ O
the -X- _ O
key -X- _ O
knowledge -X- _ O
that -X- _ O
they -X- _ O
can -X- _ O
provide -X- _ O
. -X- _ O
The -X- _ O
6 -X- _ O
IS -X- _ O
are -X- _ O
presented -X- _ O
as -X- _ O
follows -X- _ O
. -X- _ O

IS-1 -X- _ O
Comparison -X- _ O
structure -X- _ O

This -X- _ O
structure -X- _ O
interprets -X- _ O
VC-1 -X- _ O
and -X- _ O
RC -X- _ O
, -X- _ O
where -X- _ O
• -X- _ O
denotes -X- _ O
algebraic -X- _ O
predicate -X- _ O
for -X- _ O
time -X- _ O
values -X- _ O
( -X- _ O
Allen -X- _ O
, -X- _ O
1983 -X- _ O
; -X- _ O
Jia -X- _ O
et -X- _ O
al -X- _ O
. -X- _ O
, -X- _ O
2018b -X- _ O
) -X- _ O
. -X- _ O
Specifically -X- _ O
, -X- _ O
the -X- _ O
predicate -X- _ O
• -X- _ O
is -X- _ O
required -X- _ O
to -X- _ O
be -X- _ O
EQUAL -X- _ O
in -X- _ O
VC-1 -X- _ O
and -X- _ O
is -X- _ O
determined -X- _ O
according -X- _ O
to -X- _ O
the -X- _ O
identified -X- _ O
type -X- _ O
T -X- _ O
r -X- _ O
in -X- _ O
RC -X- _ O
. -X- _ O
This -X- _ O
structure -X- _ O
supposes -X- _ O
that -X- _ O
the -X- _ O
involved -X- _ O
events -X- _ O
provides -X- _ O
certain -X- _ O
time -X- _ O
values -X- _ O
. -X- _ O

For -X- _ O
example -X- _ O
, -X- _ O
the -X- _ O
question -X- _ O
: -X- _ O
" -X- _ O
Which -X- _ O
movie -X- _ O
did -X- _ O
Alfred -X- _ O
Hitchcock -X- _ O

[ -X- _ O
Event -X- _ O
1 -X- _ O
direct -X- _ O
] -X- _ O
[ -X- _ O
Signal -X- _ O
1 -X- _ O
in -X- _ O
] -X- _ O
[ -X- _ O
Time -X- _ O
1 -X- _ O

1960 -X- _ O
] -X- _ O
? -X- _ O
" -X- _ O
corresponds -X- _ O
to -X- _ O
the -X- _ O
following -X- _ O
constraint -X- _ O
and -X- _ O
KG -X- _ O
facts -X- _ O
, -X- _ O
where -X- _ O
the -X- _ O
" -X- _ O
direct -X- _ O
" -X- _ O
event -X- _ O
provides -X- _ O
the -X- _ O
value -X- _ O
" -X- _ O
1960 -X- _ O
- -X- _ O
10 -X- _ O
- -X- _ O
7 -X- _ O
" -X- _ O
. -X- _ O
COMPARE⟨INCLUDES -X- _ O
, -X- _ O
time -X- _ O
( -X- _ O
" -X- _ O
direct -X- _ O
" -X- _ O
) -X- _ O
, -X- _ O
" -X- _ O
1960 -X- _ O
" -X- _ O
⟩ -X- _ O

This -X- _ O
structure -X- _ O
interprets -X- _ O
VC-2 -X- _ O
by -X- _ O
ordering -X- _ O
entities -X- _ O
( -X- _ O
or -X- _ O
facts -X- _ O
) -X- _ O
that -X- _ O
are -X- _ O
described -X- _ O
by -X- _ O
E -X- _ O
1 -X- _ O
. -X- _ O
It -X- _ O
supposes -X- _ O
that -X- _ O
E -X- _ O
1 -X- _ O
describes -X- _ O
a -X- _ O
common -X- _ O
attribute -X- _ O
of -X- _ O
certain -X- _ O
objects -X- _ O
to -X- _ O
be -X- _ O
ordered -X- _ O
. -X- _ O
For -X- _ O
example -X- _ O
, -X- _ O
the -X- _ O
question -X- _ O
: -X- _ O
" -X- _ O
When -X- _ O
did -X- _ O
Henry -X- _ O
the -X- _ O
VIII -X- _ O
[ -X- _ O
Event -X- _ O
1 -X- _ O
marry -X- _ O
] -X- _ O
his -X- _ O
[ -X- _ O
Ordinal -X- _ O
1 -X- _ O
first -X- _ O
] -X- _ O
wife -X- _ O
? -X- _ O
" -X- _ O
corresponds -X- _ O
to -X- _ O
ORDER⟨attr -X- _ O
( -X- _ O
" -X- _ O
marry -X- _ O
" -X- _ O
) -X- _ O
, -X- _ O
" -X- _ O
first -X- _ O
" -X- _ O
⟩ -X- _ O

In -X- _ O
some -X- _ O
cases -X- _ O
, -X- _ O
the -X- _ O
expected -X- _ O
values -X- _ O
are -X- _ O
directly -X- _ O
represented -X- _ O
in -X- _ O
KG -X- _ O
facts -X- _ O
. -X- _ O
This -X- _ O
structure -X- _ O
interprets -X- _ O
VC -X- _ O
by -X- _ O
directly -X- _ O
finding -X- _ O
the -X- _ O
expected -X- _ O
value -X- _ O
X -X- _ O
in -X- _ O
certain -X- _ O
attributes -X- _ O
of -X- _ O
some -X- _ O
related -X- _ O
entity -X- _ O
. -X- _ O
It -X- _ O
supposes -X- _ O
that -X- _ O
the -X- _ O
entity -X- _ O
is -X- _ O
related -X- _ O
to -X- _ O
the -X- _ O
mentioned -X- _ O
event -X- _ O
E -X- _ O
1 -X- _ O
. -X- _ O

For -X- _ O
example -X- _ O
, -X- _ O
the -X- _ O
description -X- _ O
: -X- _ O
" -X- _ O
. -X- _ O
. -X- _ O
. -X- _ O
did -X- _ O
the -X- _ O

IS-4 -X- _ O
Same -X- _ O
Entity -X- _ O
Structure -X- _ O

This -X- _ O
structure -X- _ O
interprets -X- _ O
simultaneous -X- _ O
cases -X- _ O
of -X- _ O
RC-2 -X- _ O
. -X- _ O
It -X- _ O
supposes -X- _ O
that -X- _ O
the -X- _ O
events -X- _ O
should -X- _ O
be -X- _ O
attributes -X- _ O
of -X- _ O
a -X- _ O
certain -X- _ O
entity -X- _ O
e -X- _ O
. -X- _ O

This -X- _ O
structure -X- _ O
interprets -X- _ O
including -X- _ O
cases -X- _ O
of -X- _ O
RC-2 -X- _ O
. -X- _ O
It -X- _ O
does -X- _ O
not -X- _ O
restrict -X- _ O
the -X- _ O
representation -X- _ O
of -X- _ O
events -X- _ O
E -X- _ O
1 -X- _ O
and -X- _ O
E -X- _ O
2 -X- _ O
in -X- _ O
KG -X- _ O
, -X- _ O
but -X- _ O
requires -X- _ O
that -X- _ O
their -X- _ O
representation -X- _ O
must -X- _ O
be -X- _ O
connected -X- _ O
by -X- _ O
a -X- _ O
relation -X- _ O
r -X- _ O
p -X- _ O
which -X- _ O
implies -X- _ O
" -X- _ O
part -X- _ O
- -X- _ O
of -X- _ O
" -X- _ O
. -X- _ O

For -X- _ O
example -X- _ O
, -X- _ O
the -X- _ O
question -X- _ O
" -X- _ O
What -X- _ O
award -X- _ O
did -X- _ O
Laurence -X- _ O
Fishburne -X- _ O
[ -X- _ O
Event -X- _ O
1 -X- _ O
received -X- _ O
] -X- _ O
[ -X- _ O
Signal -X- _ O
1 -X- _ O
at -X- _ O
] -X- _ O
[ -X- _ O
Event -X- _ O
2 -X- _ O
the -X- _ O
46th -X- _ O
Tony -X- _ O
Awards -X- _ O
] -X- _ O
? -X- _ O
" -X- _ O
corresponds -X- _ O
to -X- _ O
the -X- _ O
following -X- _ O
representation -X- _ O
and -X- _ O
KG -X- _ O
facts -X- _ O
, -X- _ O
where -X- _ O
E -X- _ O
1 -X- _ O
corresponds -X- _ O
to -X- _ O
a -X- _ O
statement -X- _ O
2 -X- _ O
and -X- _ O
E -X- _ O
2 -X- _ O
corresponds -X- _ O
to -X- _ O
a -X- _ O
named -X- _ O
entity -X- _ O
. -X- _ O
PARTOF⟨r -X- _ O
p -X- _ O
, -X- _ O
" -X- _ O
received -X- _ O
" -X- _ O
, -X- _ O
" -X- _ O
. -X- _ O
. -X- _ O
. -X- _ O
Awards -X- _ O
" -X- _ O
⟩ -X- _ O

Laurence_Fishburne -X- _ O
Best_Featured_Actor -X- _ O
( -X- _ O
ANS -X- _ O
) -X- _ O
award_received -X- _ O
E -X- _ O
1 -X- _ O
46th_Tony_Awards -X- _ O
( -X- _ O
E2 -X- _ O
) -X- _ O
. -X- _ O
. -X- _ O
. -X- _ O
subject_of -X- _ O
( -X- _ O
rp -X- _ O
) -X- _ O
IS-6 -X- _ O
Sequent -X- _ O
Structure -X- _ O
RELATION -X- _ O
( -X- _ O
T -X- _ O
r -X- _ O
, -X- _ O
E -X- _ O
1 -X- _ O
, -X- _ O
E -X- _ O
2 -X- _ O
) -X- _ O
⇒ -X- _ O
SEQUENT⟨r -X- _ O
≺ -X- _ O
, -X- _ O
ent -X- _ O
( -X- _ O
E -X- _ O
1 -X- _ O
) -X- _ O
, -X- _ O
ent -X- _ O
( -X- _ O
E -X- _ O
2 -X- _ O
) -X- _ O
⟩ -X- _ O

This -X- _ O
structure -X- _ O
interprets -X- _ O
before -X- _ O
/ -X- _ O
after -X- _ O
cases -X- _ O
of -X- _ O
RC-2 -X- _ O
. -X- _ O
It -X- _ O
supposes -X- _ O
the -X- _ O
events -X- _ O
make -X- _ O
a -X- _ O
pair -X- _ O
of -X- _ O
related -X- _ O
entities -X- _ O
to -X- _ O
be -X- _ O
sequential -X- _ O
in -X- _ O
KG -X- _ O
, -X- _ O
where -X- _ O
the -X- _ O
entities -X- _ O
are -X- _ O
involved -X- _ O
in -X- _ O
E -X- _ O
1 -X- _ O
and -X- _ O
E -X- _ O
2 -X- _ O
respectively -X- _ O
and -X- _ O
they -X- _ O
must -X- _ O
be -X- _ O
connected -X- _ O
by -X- _ O
a -X- _ O
relation -X- _ O
r -X- _ O
≺ -X- _ O
which -X- _ O
indicates -X- _ O
a -X- _ O
preceding -X- _ O
( -X- _ O
or -X- _ O
succeeding -X- _ O
) -X- _ O
relation -X- _ O
. -X- _ O
In -X- _ O
summary -X- _ O
, -X- _ O
IS -X- _ O
1 -X- _ O
to -X- _ O
3 -X- _ O
interpret -X- _ O
the -X- _ O
temporal -X- _ O
constraints -X- _ O
via -X- _ O
temporal -X- _ O
facts -X- _ O
with -X- _ O
explicit -X- _ O
quantitative -X- _ O
values -X- _ O
. -X- _ O
IS -X- _ O
4 -X- _ O
to -X- _ O
6 -X- _ O
model -X- _ O
the -X- _ O
intrinsic -X- _ O
connections -X- _ O
that -X- _ O
can -X- _ O
make -X- _ O
events -X- _ O
temporally -X- _ O
related -X- _ O
. -X- _ O
It -X- _ O
is -X- _ O
worth -X- _ O
noting -X- _ O
that -X- _ O
SF -X- _ O
- -X- _ O
TCons -X- _ O
only -X- _ O
expresses -X- _ O
the -X- _ O
expected -X- _ O
form -X- _ O
of -X- _ O
corresponding -X- _ O
knowledge -X- _ O
, -X- _ O
how -X- _ O
to -X- _ O
obtain -X- _ O
the -X- _ O
specific -X- _ O
knowledge -X- _ O
is -X- _ O
left -X- _ O
to -X- _ O
the -X- _ O
implementation -X- _ O
of -X- _ O
question -X- _ O
- -X- _ O
answering -X- _ O
systems -X- _ O
. -X- _ O

3 -X- _ O
Semantic -X- _ B-MethodName
- -X- _ I-MethodName
Framework -X- _ I-MethodName
- -X- _ I-MethodName
Based -X- _ I-MethodName
Temporal -X- _ I-MethodName
Question -X- _ I-MethodName
Answering -X- _ I-MethodName

Figure -X- _ O
1 -X- _ O
illustrates -X- _ O
the -X- _ O
question -X- _ O
- -X- _ O
answering -X- _ O
process -X- _ O
of -X- _ O
the -X- _ O
semantic -X- _ B-MethodName
- -X- _ I-MethodName
framework -X- _ I-MethodName
- -X- _ I-MethodName
Based -X- _ I-MethodName
temporal -X- _ I-MethodName
question -X- _ I-MethodName
answering -X- _ I-MethodName
method -X- _ O
, -X- _ O
SF -X- _ B-MethodName
- -X- _ I-MethodName
TQA -X- _ I-MethodName
. -X- _ O
The -X- _ O
query -X- _ O
generation -X- _ O
consists -X- _ O
of -X- _ O
two -X- _ O
steps -X- _ O
, -X- _ O
1 -X- _ O
) -X- _ O
evoking -X- _ O
the -X- _ O
constraints -X- _ O
and -X- _ O
their -X- _ O
possible -X- _ O
interpretations -X- _ O
( -X- _ O
i.e. -X- _ O
, -X- _ O
constraint -X- _ O
evocation -X- _ O
) -X- _ O
and -X- _ O
2 -X- _ O
) -X- _ O
grounding -X- _ O
the -X- _ O
constraints -X- _ O
by -X- _ O
exploring -X- _ O
the -X- _ O
relevant -X- _ O
KG -X- _ O
facts -X- _ O
( -X- _ O
i.e. -X- _ O
, -X- _ O
constraint -X- _ O
grounding -X- _ O
) -X- _ O
. -X- _ O
The -X- _ O
generated -X- _ O
candidate -X- _ O
queries -X- _ O
will -X- _ O
be -X- _ O
ranked -X- _ O
by -X- _ O
a -X- _ O
BERT -X- _ O
model -X- _ O
, -X- _ O
and -X- _ O
the -X- _ O
execution -X- _ O
results -X- _ O
of -X- _ O
the -X- _ O
highest -X- _ O
- -X- _ O
scored -X- _ O
query -X- _ O
will -X- _ O
be -X- _ O
considered -X- _ O
as -X- _ O
answers -X- _ O
. -X- _ O

Constraint -X- _ O
Evocation -X- _ O

The -X- _ O
first -X- _ O
step -X- _ O
of -X- _ O
SF -X- _ B-MethodName
- -X- _ I-MethodName
TQA -X- _ I-MethodName
is -X- _ O
to -X- _ O
determine -X- _ O
the -X- _ O
possible -X- _ O
constraints -X- _ O
. -X- _ O
We -X- _ O
fine -X- _ O
- -X- _ O
tune -X- _ O
a -X- _ O
BERT -X- _ O
model -X- _ O
to -X- _ O
annotate -X- _ O
the -X- _ O
temporal -X- _ O
elements -X- _ O
. -X- _ O
The -X- _ O
corresponding -X- _ O
constraints -X- _ O
and -X- _ O
interpretation -X- _ O
structures -X- _ O
are -X- _ O
evoked -X- _ O
according -X- _ O
to -X- _ O
recognized -X- _ O
signals -X- _ O
. -X- _ O
The -X- _ O
elements -X- _ O
that -X- _ O
involve -X- _ O
certain -X- _ O
constraints -X- _ O
are -X- _ O
determined -X- _ O
by -X- _ O
TimeML -X- _ O
relations -X- _ O
or -X- _ O
by -X- _ O
simply -X- _ O
taking -X- _ O
the -X- _ O
temporal -X- _ O
elements -X- _ O
that -X- _ O
are -X- _ O
directly -X- _ O
described -X- _ O
by -X- _ O
the -X- _ O
signals -X- _ O
( -X- _ O
i.e. -X- _ O
, -X- _ O
the -X- _ O
nearest -X- _ O
neighbor -X- _ O
of -X- _ O
the -X- _ O
corresponding -X- _ O
signals -X- _ O
) -X- _ O
. -X- _ O
The -X- _ O
algebraic -X- _ O
predicates -X- _ O
in -X- _ O
the -X- _ O
comparison -X- _ O
structure -X- _ O
are -X- _ O
determined -X- _ O
by -X- _ O
normalizing -X- _ O
the -X- _ O
TimeML -X- _ O
relation -X- _ O
types -X- _ O
, -X- _ O
while -X- _ O
other -X- _ O
implicit -X- _ O
elements -X- _ O
are -X- _ O
left -X- _ O
to -X- _ O
the -X- _ O
grounding -X- _ O
phase -X- _ O
. -X- _ O

Constraint -X- _ O
Grounding -X- _ O

In -X- _ O
general -X- _ O
query -X- _ O
graph -X- _ O
generation -X- _ O
, -X- _ O
basic -X- _ O
query -X- _ O
graphs -X- _ O
are -X- _ O
constructed -X- _ O
as -X- _ O
1 -X- _ O
or -X- _ O
2 -X- _ O
hop -X- _ O
paths -X- _ O
from -X- _ O
mentioned -X- _ O
entities -X- _ O
to -X- _ O
answers -X- _ O
, -X- _ O
and -X- _ O
they -X- _ O
are -X- _ O
extended -X- _ O
by -X- _ O
pre -X- _ O
- -X- _ O
defined -X- _ O
expanding -X- _ O
action -X- _ O
( -X- _ O
Yih -X- _ O
et -X- _ O
al -X- _ O
. -X- _ O
, -X- _ O
2015 -X- _ O
) -X- _ O
or -X- _ O
fixed -X- _ O
interpretation -X- _ O
structures -X- _ O
of -X- _ O
constraints -X- _ O
( -X- _ O
Bao -X- _ O
et -X- _ O
al -X- _ O
. -X- _ O
, -X- _ O
2016 -X- _ O
) -X- _ O
. -X- _ O
In -X- _ O
temporal -X- _ B-TaskName
KGQA -X- _ I-TaskName
, -X- _ O
the -X- _ O
main -X- _ O
issue -X- _ O
is -X- _ O
that -X- _ O
events -X- _ O
could -X- _ O
have -X- _ O
various -X- _ O
representations -X- _ O
in -X- _ O
KG -X- _ O
. -X- _ O
As -X- _ O
illustrated -X- _ O
by -X- _ O
the -X- _ O
examples -X- _ O
in -X- _ O
Section -X- _ O
2.2 -X- _ O
, -X- _ O
they -X- _ O
could -X- _ O
be -X- _ O
represented -X- _ O
by -X- _ O
named -X- _ O
entities -X- _ O
, -X- _ O
triplet -X- _ O
facts -X- _ O
, -X- _ O
or -X- _ O
attributes -X- _ O
of -X- _ O
their -X- _ O
participants -X- _ O
. -X- _ O
Therefore -X- _ O
, -X- _ O
we -X- _ O
treat -X- _ O
the -X- _ O
generation -X- _ O
of -X- _ O
query -X- _ O
graphs -X- _ O
as -X- _ O
grounding -X- _ O
the -X- _ O
temporal -X- _ O
elements -X- _ O
in -X- _ O
the -X- _ O
interpretations -X- _ O
of -X- _ O
SF -X- _ O
- -X- _ O
TCons -X- _ O
. -X- _ O
We -X- _ O
divide -X- _ O
the -X- _ O
descriptions -X- _ O
of -X- _ O
events -X- _ O
into -X- _ O
nominal -X- _ O
and -X- _ O
predicative -X- _ O
. -X- _ O
We -X- _ O
suppose -X- _ O
that -X- _ O
nominal -X- _ O
descriptions -X- _ O
could -X- _ O
be -X- _ O
the -X- _ O
event -X- _ O
themselves -X- _ O
, -X- _ O
and -X- _ O
predicative -X- _ O
descriptions -X- _ O
reflect -X- _ O
certain -X- _ O
aspects -X- _ O
of -X- _ O
the -X- _ O
events -X- _ O
, -X- _ O
such -X- _ O
as -X- _ O
their -X- _ O
participants -X- _ O
or -X- _ O
their -X- _ O
post -X- _ O
- -X- _ O
effect -X- _ O
. -X- _ O
Therefore -X- _ O
, -X- _ O
nominal -X- _ O
events -X- _ O
could -X- _ O
be -X- _ O
linked -X- _ O
entities -X- _ O
and -X- _ O
others -X- _ O
correspond -X- _ O
to -X- _ O
the -X- _ O
neighboring -X- _ O
nodes -X- _ O
or -X- _ O
facts -X- _ O
of -X- _ O
the -X- _ O
explored -X- _ O
subgraph -X- _ O
( -X- _ O
s -X- _ O
) -X- _ O
or -X- _ O
linked -X- _ O
entities -X- _ O
. -X- _ O
The -X- _ O
corresponding -X- _ O
nodes -X- _ O
or -X- _ O
facts -X- _ O
must -X- _ O
provide -X- _ O
the -X- _ O
knowledge -X- _ O
required -X- _ O
by -X- _ O
corresponding -X- _ O
interpolation -X- _ O
structures -X- _ O
. -X- _ O

We -X- _ O
illustrate -X- _ O
the -X- _ O
above -X- _ O
process -X- _ O
by -X- _ O
the -X- _ O
example -X- _ O
in -X- _ O
Figure -X- _ O
2 -X- _ O
. -X- _ O
In -X- _ O
this -X- _ O
example -X- _ O
, -X- _ O
the -X- _ O
entity -X- _ O
linking -X- _ O
module -X- _ O
will -X- _ O
provide -X- _ O
John_Lennon -X- _ O
as -X- _ O
a -X- _ O
linked -X- _ O
entity -X- _ O
, -X- _ O
and -X- _ O
the -X- _ O
grounding -X- _ O
start -X- _ O
with -X- _ O
the -X- _ O
" -X- _ O
shot -X- _ O
" -X- _ O
event -X- _ O
which -X- _ O
contains -X- _ O
the -X- _ O
only -X- _ O
linked -X- _ O
entity -X- _ O
. -X- _ O
We -X- _ O
will -X- _ O
explore -X- _ O
all -X- _ O
the -X- _ O
neighboring -X- _ O
facts -X- _ O
of -X- _ O
John_Lennon -X- _ O
( -X- _ O
as -X- _ O
illustrated -X- _ O
in -X- _ O
Figure -X- _ O
2 -X- _ O
) -X- _ O
as -X- _ O
candidates -X- _ O
for -X- _ O
the -X- _ O
event -X- _ O
. -X- _ O
Since -X- _ O
" -X- _ O
shot -X- _ O
" -X- _ O
is -X- _ O
a -X- _ O
predicative -X- _ O
event -X- _ O
and -X- _ O
the -X- _ O
SAME_ENTITY -X- _ O
constraint -X- _ O
requires -X- _ O
it -X- _ O
to -X- _ O
provide -X- _ O
an -X- _ O
attribute -X- _ O
, -X- _ O
we -X- _ O
will -X- _ O
find -X- _ O
a -X- _ O
triplet -X- _ O
that -X- _ O
contains -X- _ O
John_Lennon -X- _ O
and -X- _ O
take -X- _ O
the -X- _ O
other -X- _ O
entity -X- _ O
in -X- _ O
it -X- _ O
( -X- _ O
i.e. -X- _ O
, -X- _ O
Murder_of_John_Lennon -X- _ O
) -X- _ O
as -X- _ O
the -X- _ O
expected -X- _ O
e. -X- _ O
Similarly -X- _ O
, -X- _ O
we -X- _ O
explore -X- _ O
the -X- _ O
neighboring -X- _ O
facts -X- _ O
and -X- _ O
select -X- _ O
one -X- _ O
relation -X- _ O
that -X- _ O
matches -X- _ O
with -X- _ O
the -X- _ O
question -X- _ O
meaning -X- _ O
( -X- _ O
i.e. -X- _ O
, -X- _ O
location -X- _ O
for -X- _ O
" -X- _ O
standing -X- _ O
" -X- _ O
) -X- _ O
. -X- _ O
When -X- _ O
there -X- _ O
are -X- _ O
multiple -X- _ O
candidate -X- _ O
relations -X- _ O
, -X- _ O
we -X- _ O
will -X- _ O
rank -X- _ O
the -X- _ O
candidates -X- _ O
by -X- _ O
scoring -X- _ O
their -X- _ O
serializations -X- _ O
with -X- _ O
a -X- _ O
BERT -X- _ O
model -X- _ O
. -X- _ O
The -X- _ O
highest -X- _ O
- -X- _ O
scored -X- _ O
one -X- _ O
will -X- _ O
be -X- _ O
filled -X- _ O
in -X- _ O
the -X- _ O
corresponding -X- _ O
slot -X- _ O
. -X- _ O

In -X- _ O
the -X- _ O
specific -X- _ O
implementation -X- _ O
, -X- _ O
which -X- _ O
candidates -X- _ O
satisfy -X- _ O
the -X- _ O
question -X- _ O
meanings -X- _ O
best -X- _ O
are -X- _ O
determined -X- _ O
by -X- _ O
neural -X- _ O
models -X- _ O
. -X- _ O
In -X- _ O
the -X- _ O
training -X- _ O
process -X- _ O
, -X- _ O
we -X- _ O
take -X- _ O
relations -X- _ O
that -X- _ O
appear -X- _ O
on -X- _ O
shortest -X- _ O
paths -X- _ O
between -X- _ O
mentioned -X- _ O
entities -X- _ O
and -X- _ O
answers -X- _ O
as -X- _ O
positive -X- _ O
samples -X- _ O
. -X- _ O
In -X- _ O
particular -X- _ O
, -X- _ O
the -X- _ O
relation -X- _ O
that -X- _ O
entails -X- _ O
part -X- _ O
of -X- _ O
or -X- _ O
precedes -X- _ O
are -X- _ O
filtered -X- _ O
according -X- _ O
to -X- _ O
the -X- _ O
KG -X- _ O
schema -X- _ O
in -X- _ O
the -X- _ O
training -X- _ O
process -X- _ O
and -X- _ O
are -X- _ O
predicted -X- _ O
by -X- _ O
neural -X- _ O
models -X- _ O
during -X- _ O
the -X- _ O
test -X- _ O
process -X- _ O
. -X- _ O
Queries -X- _ O
for -X- _ O
the -X- _ O
questions -X- _ O
of -X- _ O
multiple -X- _ O
constraints -X- _ O
are -X- _ O
the -X- _ O
conjunction -X- _ O
of -X- _ O
the -X- _ O
grounding -X- _ O
result -X- _ O
of -X- _ O
each -X- _ O
constraint -X- _ O
and -X- _ O
queries -X- _ O
for -X- _ O
the -X- _ O
questions -X- _ O
with -X- _ O
no -X- _ O
temporal -X- _ O
constraints -X- _ O
are -X- _ O
unrestricted -X- _ O
basic -X- _ O
query -X- _ O
graphs -X- _ O
. -X- _ O

Query -X- _ O
Ranking -X- _ O

SF -X- _ B-MethodName
- -X- _ I-MethodName
TQA -X- _ I-MethodName
usually -X- _ O
generates -X- _ O
multiple -X- _ O
candidate -X- _ O
queries -X- _ O
for -X- _ O
one -X- _ O
question -X- _ O
. -X- _ O
We -X- _ O
select -X- _ O
one -X- _ O
of -X- _ O
the -X- _ O
candidates -X- _ O
via -X- _ O
neural -X- _ O
ranking -X- _ O
models -X- _ O
. -X- _ O
Specifically -X- _ O
, -X- _ O
we -X- _ O
express -X- _ O
the -X- _ O
generated -X- _ O
queries -X- _ O
via -X- _ O
SPARQL -X- _ O
3 -X- _ O
and -X- _ O
serialize -X- _ O
the -X- _ O
queries -X- _ O
by -X- _ O
dropping -X- _ O
auxiliary -X- _ O
symbols -X- _ O
( -X- _ O
e.g. -X- _ O
, -X- _ O
" -X- _ O
{ -X- _ O
" -X- _ O
) -X- _ O
. -X- _ O
We -X- _ O
use -X- _ O
the -X- _ O
BERT -X- _ O
model -X- _ O
with -X- _ O
crossentropy -X- _ O
loss -X- _ O
to -X- _ O
score -X- _ O
the -X- _ O
pair -X- _ O
of -X- _ O
the -X- _ O
input -X- _ O
question -X- _ O
and -X- _ O
serialized -X- _ O
queries -X- _ O
. -X- _ O
For -X- _ O
each -X- _ O
question -X- _ O
, -X- _ O
we -X- _ O
use -X- _ O
the -X- _ O
candidate -X- _ O
queries -X- _ O
with -X- _ O
the -X- _ O
highest -X- _ O
F -X- _ B-MetricName
1 -X- _ I-MetricName
score -X- _ O
as -X- _ O
the -X- _ O
positive -X- _ O
samples -X- _ O
and -X- _ O
select -X- _ O
k -X- _ O
others -X- _ O
as -X- _ O
negative -X- _ O
samples -X- _ O
. -X- _ O
In -X- _ O
order -X- _ O
to -X- _ O
make -X- _ O
our -X- _ O
model -X- _ O
more -X- _ O
robust -X- _ O
, -X- _ O
we -X- _ O
classify -X- _ O
the -X- _ O
negatives -X- _ O
samples -X- _ O
as -X- _ O
confusing -X- _ O
queries -X- _ O
and -X- _ O
irrelevant -X- _ O
queries -X- _ O
. -X- _ O
Confusing -X- _ O
queries -X- _ O
are -X- _ O
those -X- _ O
that -X- _ O
can -X- _ O
find -X- _ O
partial -X- _ O
answers -X- _ O
but -X- _ O
of -X- _ O
lower -X- _ O
F -X- _ B-MetricName
1 -X- _ I-MetricName
scores -X- _ O
than -X- _ O
the -X- _ O
positive -X- _ O
samples -X- _ O
. -X- _ O
Irrelevant -X- _ O
queries -X- _ O
are -X- _ O
those -X- _ O
whose -X- _ O
outputs -X- _ O
have -X- _ O
no -X- _ O
intersection -X- _ O
with -X- _ O
the -X- _ O
correct -X- _ O
answers -X- _ O
. -X- _ O
The -X- _ O
ratio -X- _ O
of -X- _ O
confusing -X- _ O
queries -X- _ O
to -X- _ O
irrelevant -X- _ O
queries -X- _ O
is -X- _ O
1 -X- _ O
: -X- _ O
1 -X- _ O
. -X- _ O
The -X- _ O
necessity -X- _ O
of -X- _ O
classifying -X- _ O
the -X- _ O
negative -X- _ O
sample -X- _ O
is -X- _ O
presented -X- _ O
in -X- _ O
Appendix -X- _ O
A -X- _ O
. -X- _ O

Evaluation -X- _ O

Datasets -X- _ O

We -X- _ O
evaluate -X- _ O
our -X- _ O
method -X- _ O
on -X- _ O
TempQuestions -X- _ B-DatasetName
( -X- _ O
Jia -X- _ O
et -X- _ O
al -X- _ O
. -X- _ O
, -X- _ O
2018a -X- _ O
) -X- _ O

We -X- _ O
report -X- _ O
the -X- _ O
Hit -X- _ B-MetricName
@ -X- _ I-MetricName
1 -X- _ I-MetricName
( -X- _ O
denoted -X- _ O
as -X- _ O
H -X- _ B-MetricName
@ -X- _ I-MetricName
1 -X- _ I-MetricName
) -X- _ O
, -X- _ O
Precision -X- _ B-MetricName
( -X- _ O
denoted -X- _ O
as -X- _ O
P -X- _ B-MetricName
r -X- _ I-MetricName
) -X- _ O
, -X- _ O
Recall -X- _ B-MetricName
( -X- _ O
denoted -X- _ O
as -X- _ O
Re -X- _ B-MetricName
) -X- _ O
and -X- _ O
F -X- _ B-MetricName
1 -X- _ I-MetricName
score -X- _ O
of -X- _ O
the -X- _ O
evaluation -X- _ O
results -X- _ O
. -X- _ O
Our -X- _ O
computation -X- _ O
follows -X- _ O
Jia -X- _ O
et -X- _ O
al -X- _ O
. -X- _ O
's -X- _ O
( -X- _ O
2021 -X- _ O
) -X- _ O
6 -X- _ O
, -X- _ O
where -X- _ O
the -X- _ O
precision -X- _ B-MetricName
is -X- _ O
considered -X- _ O
1 -X- _ O
if -X- _ O
the -X- _ O
output -X- _ O
of -X- _ O
a -X- _ O
question -X- _ O
is -X- _ O
empty -X- _ O
and -X- _ O
the -X- _ O
F -X- _ B-MetricName
1 -X- _ I-MetricName
score -X- _ O
on -X- _ O
a -X- _ O
dataset -X- _ O
is -X- _ O
computed -X- _ O
as -X- _ O
the -X- _ O
average -X- _ O
of -X- _ O
the -X- _ O
scores -X- _ O
of -X- _ O
each -X- _ O
question -X- _ O
. -X- _ O

Compared -X- _ O
Methods -X- _ O

On -X- _ O
TempQuestions -X- _ B-DatasetName
, -X- _ O
we -X- _ O
compare -X- _ O
our -X- _ O
results -X- _ O
with -X- _ O
general -X- _ O
KGQA -X- _ B-TaskName
methods -X- _ O
AQQU -X- _ B-MethodName
( -X- _ O
Bast -X- _ O
and -X- _ O
Haussmann -X- _ O
, -X- _ O
2015 -X- _ O
) -X- _ O
, -X- _ O
QUINT -X- _ B-MethodName
( -X- _ O
Abujabal -X- _ O
et -X- _ O
al -X- _ O
. -X- _ O
, -X- _ O
2017 -X- _ O
) -X- _ O
and -X- _ O
their -X- _ O
improved -X- _ O
version -X- _ O
( -X- _ O
Jia -X- _ O
et -X- _ O
al -X- _ O
. -X- _ O
, -X- _ O
2018b -X- _ O
) -X- _ O
by -X- _ O
incorporating -X- _ O
the -X- _ O
temporal -X- _ O
question -X- _ O
decomposition -X- _ O
method -X- _ O
TEQUILA -X- _ B-MethodName
, -X- _ O
QUINT+TEQUILA -X- _ B-MethodName
and -X- _ O
AQQU+TEQUILA -X- _ B-MethodName
. -X- _ O
On -X- _ O
TimeQuestions -X- _ B-DatasetName
, -X- _ O
we -X- _ O
compare -X- _ O
our -X- _ O
results -X- _ O
with -X- _ O
general -X- _ O
KGQA -X- _ B-TaskName
methods -X- _ O
Pull -X- _ B-MethodName
- -X- _ I-MethodName
Net -X- _ I-MethodName
( -X- _ O
Sun -X- _ O
et -X- _ O
al -X- _ O
. -X- _ O
, -X- _ O
2019 -X- _ O
) -X- _ O
, -X- _ O
GraftNet -X- _ B-MethodName
( -X- _ O
Sun -X- _ O
et -X- _ O
al -X- _ O
. -X- _ O
, -X- _ O
2018 -X- _ O
) -X- _ O
, -X- _ O
5 -X- _ O
https -X- _ O
: -X- _ O
/ -X- _ O
/ -X- _ O
archive.org -X- _ O
/ -X- _ O
download -X- _ O
/ -X- _ O
wikibase -X- _ O
- -X- _ O
wikidatawiki-20190128 -X- _ O

6 -X- _ O
Their -X- _ O
script -X- _ O
could -X- _ O
be -X- _ O
downloaded -X- _ O
from -X- _ O
here -X- _ O
. -X- _ O

UNIQORN -X- _ B-MethodName
and -X- _ O
the -X- _ O
temporal -X- _ B-TaskName
KGQA -X- _ I-TaskName
method -X- _ O
EXAQT -X- _ B-MethodName
( -X- _ O
Jia -X- _ O
et -X- _ O
al -X- _ O
. -X- _ O
, -X- _ O
2021 -X- _ O
) -X- _ O
. -X- _ O

Implementation -X- _ O
Details -X- _ O

Our -X- _ O
results -X- _ O
are -X- _ O
obtained -X- _ O
on -X- _ O
a -X- _ O
workstation -X- _ O
with -X- _ O
an -X- _ O
Intel -X- _ O
Xeon -X- _ O
Gold -X- _ O
5222 -X- _ O
CPU -X- _ O
, -X- _ O
32 -X- _ O
GB -X- _ O
of -X- _ O
RAM -X- _ O
, -X- _ O
and -X- _ O
NVIDIA -X- _ O
RTX3090 -X- _ O
GPUs -X- _ O
. -X- _ O
The -X- _ O
hyper -X- _ O
- -X- _ O
parameters -X- _ O
of -X- _ O
the -X- _ O
ranking -X- _ O
models -X- _ O
are -X- _ O
listed -X- _ O
in -X- _ O
Table -X- _ O
2 -X- _ O
. -X- _ O
They -X- _ O
are -X- _ O
determined -X- _ O
according -X- _ O
to -X- _ O
the -X- _ O
F -X- _ B-MetricName
1 -X- _ I-MetricName
scores -X- _ O
on -X- _ O
the -X- _ O
development -X- _ O
sets -X- _ O
. -X- _ O
We -X- _ O
use -X- _ O
ELQ -X- _ B-MethodName
( -X- _ O
Li -X- _ O
et -X- _ O
al -X- _ O
. -X- _ O
, -X- _ O
2020 -X- _ O
) -X- _ O
results -X- _ O
on -X- _ O
both -X- _ O
two -X- _ O
benchmarks -X- _ O
. -X- _ O
Specially -X- _ O
, -X- _ O
we -X- _ O
improve -X- _ O
the -X- _ O
F -X- _ B-MetricName
1 -X- _ I-MetricName
scores -X- _ O
by -X- _ O
+3.6 -X- _ B-MetricValue
and -X- _ O
+7.1 -X- _ B-MetricValue
points -X- _ O
on -X- _ O
TempQuestions -X- _ B-DatasetName
and -X- _ O
TimeQuestions -X- _ B-DatasetName
respectively -X- _ O
. -X- _ O
On -X- _ O
TempQuestions -X- _ B-DatasetName
, -X- _ O
SF -X- _ B-MethodName
- -X- _ I-MethodName
TQA -X- _ I-MethodName
improves -X- _ O
the -X- _ O
Hit -X- _ B-MetricName
@ -X- _ I-MetricName
1 -X- _ I-MetricName
and -X- _ O
precision -X- _ O
by -X- _ O
+5.0 -X- _ B-MetricValue
and -X- _ O
+1.9 -X- _ B-MetricValue
respectively -X- _ O
. -X- _ O
On -X- _ O
TimeQuestions -X- _ B-DatasetName
, -X- _ O
SF -X- _ B-MethodName
- -X- _ I-MethodName
TQA -X- _ I-MethodName
achieves -X- _ O
better -X- _ O
recall -X- _ B-MetricName
( -X- _ O
5.2 -X- _ B-MetricValue
points -X- _ O
higher -X- _ O
) -X- _ O
while -X- _ O
EXAQT -X- _ B-MethodName
achieves -X- _ O
better -X- _ O
precision -X- _ B-MetricName
( -X- _ O
4.2 -X- _ B-MetricValue
points -X- _ O
higher -X- _ O
) -X- _ O
. -X- _ O
The -X- _ O
reason -X- _ O
could -X- _ O
be -X- _ O
the -X- _ O
different -X- _ O
strategies -X- _ O
when -X- _ O
dealing -X- _ O
with -X- _ O
unsolvable -X- _ O
problems -X- _ O
. -X- _ O
EXAQT -X- _ B-MethodName
tends -X- _ O
to -X- _ O
output -X- _ O
empty -X- _ O
answers -X- _ O
( -X- _ O
which -X- _ O
correspond -X- _ O
to -X- _ O
1 -X- _ O
in -X- _ O
precision -X- _ B-MetricName
) -X- _ O
and -X- _ O
SF -X- _ B-MethodName
- -X- _ I-MethodName
TQA -X- _ I-MethodName
degrades -X- _ O
to -X- _ O
the -X- _ O
unrestricted -X- _ O
generation -X- _ O
of -X- _ O
basic -X- _ O
query -X- _ O
graphs -X- _ O
( -X- _ O
which -X- _ O
capture -X- _ O
incomplete -X- _ O
question -X- _ O
meanings -X- _ O
) -X- _ O
. -X- _ O
The -X- _ O
Hit -X- _ B-MetricName
@ -X- _ I-MetricName
1 -X- _ I-MetricName
of -X- _ O
SF -X- _ B-MethodName
- -X- _ I-MethodName
TQA -X- _ I-MethodName
is -X- _ O
2.6 -X- _ B-MetricValue
points -X- _ O
lower -X- _ O
than -X- _ O
EXAQT -X- _ B-MethodName
might -X- _ O
because -X- _ O
EXAQT -X- _ B-MethodName
ranks -X- _ O
all -X- _ O
candidate -X- _ O
answers -X- _ O
while -X- _ O
SF -X- _ B-MethodName
- -X- _ I-MethodName
TQA -X- _ I-MethodName
just -X- _ O
randomly -X- _ O
returns -X- _ O
one -X- _ O
candidate -X- _ O
that -X- _ O
satisfies -X- _ O
the -X- _ O
generated -X- _ O
query -X- _ O
. -X- _ O

Main -X- _ O
Results -X- _ O

Ablation -X- _ O
Studies -X- _ O

We -X- _ O
conduct -X- _ O
ablations -X- _ O
on -X- _ O
the -X- _ O
necessity -X- _ O
of -X- _ O
interpretations -X- _ O
for -X- _ O
intrinsic -X- _ O
connections -X- _ O
( -X- _ O
i.e. -X- _ O
, -X- _ O
IS-4 -X- _ O
to -X- _ O
6 -X- _ O
) -X- _ O
. -X- _ O
We -X- _ O
analyze -X- _ O
the -X- _ O
result -X- _ O
on -X- _ O
questions -X- _ O
with -X- _ O
only -X- _ O
relation -X- _ O
constraints -X- _ O
. -X- _ O
The -X- _ O
ablation -X- _ O
results -X- _ O
are -X- _ O
illustrated -X- _ O
in -X- _ O
Table -X- _ O
5 -X- _ O
. -X- _ O
The -X- _ O
2nd -X- _ O
row -X- _ O
shows -X- _ O
that -X- _ O
without -X- _ O
IS -X- _ O
4 -X- _ O
to -X- _ O
6 -X- _ O
the -X- _ O
F -X- _ B-MetricName
1 -X- _ I-MetricName
scores -X- _ O
drop -X- _ O
1.5 -X- _ B-MetricValue
and -X- _ O
3.8 -X- _ B-MetricValue
points -X- _ O
respectively -X- _ O
on -X- _ O
the -X- _ O
benchmarks -X- _ O
. -X- _ O
The -X- _ O
3rd -X- _ O
row -X- _ O
shows -X- _ O
that -X- _ O
results -X- _ O
obtained -X- _ O
by -X- _ O
generating -X- _ O
only -X- _ O
basic -X- _ O
query -X- _ O
and -X- _ O
the -X- _ O
reported -X- _ O
results -X- _ O
of -X- _ O
compared -X- _ O
methods -X- _ O
on -X- _ O
TimeQuestions -X- _ B-DatasetName
are -X- _ O
provided -X- _ O
by -X- _ O
the -X- _ O
authors -X- _ O
of -X- _ O
EXAQT -X- _ B-MethodName
( -X- _ O
Jia -X- _ O
et -X- _ O
al -X- _ O
. -X- _ O
, -X- _ O
2021 -X- _ O
) -X- _ O
. -X- _ O

graphs -X- _ O
without -X- _ O
any -X- _ O
restriction -X- _ O
will -X- _ O
decrease -X- _ O
the -X- _ O
F -X- _ B-MetricName
1 -X- _ I-MetricName
scores -X- _ O
by -X- _ O
14.1 -X- _ B-MetricValue
and -X- _ O
4.7 -X- _ B-MetricValue
points -X- _ O
respectively -X- _ O
. -X- _ O
The -X- _ O
differences -X- _ O
between -X- _ O
the -X- _ O
results -X- _ O
on -X- _ O
the -X- _ O
two -X- _ O
benchmarks -X- _ O
might -X- _ O
reflect -X- _ O
the -X- _ O
differences -X- _ O
between -X- _ O
underlying -X- _ O
KGs -X- _ O
. -X- _ O
SF -X- _ B-MethodName
- -X- _ I-MethodName
TQA -X- _ I-MethodName
without -X- _ O
IS -X- _ O
4 -X- _ O
to -X- _ O
6 -X- _ O
achieves -X- _ O
acceptable -X- _ O
results -X- _ O
on -X- _ O
TempQuestions -X- _ B-DatasetName
, -X- _ O
which -X- _ O
might -X- _ O
indicate -X- _ O
that -X- _ O
Freebase -X- _ O
can -X- _ O
provide -X- _ O
sufficient -X- _ O
temporal -X- _ O
facts -X- _ O
for -X- _ O
comparisons -X- _ O
. -X- _ O
SF -X- _ B-MethodName
- -X- _ I-MethodName
TQA -X- _ I-MethodName
with -X- _ O
only -X- _ O
basic -X- _ O
query -X- _ O
graphs -X- _ O
on -X- _ O
TimeQuestions -X- _ B-DatasetName
performs -X- _ O
much -X- _ O
better -X- _ O
than -X- _ O
on -X- _ O
TempQuestions -X- _ B-DatasetName
, -X- _ O
which -X- _ O
might -X- _ O
indicate -X- _ O
that -X- _ O
Wikidata -X- _ O
provides -X- _ O
richer -X- _ O
and -X- _ O
finer -X- _ O
relations -X- _ O
between -X- _ O
entities -X- _ O
, -X- _ O
thus -X- _ O
the -X- _ O
connections -X- _ O
between -X- _ O
mentioned -X- _ O
entities -X- _ O
and -X- _ O
answers -X- _ O
are -X- _ O
more -X- _ O
likely -X- _ O
to -X- _ O
be -X- _ O
satisfied -X- _ O
via -X- _ O
simple -X- _ O
relation -X- _ O
paths -X- _ O
. -X- _ O

Error -X- _ O
Analysis -X- _ O

We -X- _ O
analyze -X- _ O
the -X- _ O
main -X- _ O
errors -X- _ O
of -X- _ O
100 -X- _ O
questions -X- _ O
of -X- _ O
which -X- _ O
the -X- _ O
F -X- _ B-MetricName
1 -X- _ I-MetricName
scores -X- _ O
are -X- _ O
less -X- _ O
than -X- _ O
1 -X- _ O
. -X- _ O
The -X- _ O
results -X- _ O
are -X- _ O
illustrated -X- _ O
in -X- _ O
Table -X- _ O
6 -X- _ O
. -X- _ O

Main -X- _ O
Error -X- _ O

TempQ. -X- _ B-DatasetName
TimeQ. -X- _ B-DatasetName
The -X- _ O
1st -X- _ O
row -X- _ O
counts -X- _ O
the -X- _ O
questions -X- _ O
with -X- _ O
incorrectly -X- _ O
recognized -X- _ O
entities -X- _ O
or -X- _ O
temporal -X- _ O
constraints -X- _ O
, -X- _ O
which -X- _ O
reveals -X- _ O
that -X- _ O
SF -X- _ B-MethodName
- -X- _ I-MethodName
TQA -X- _ I-MethodName
severely -X- _ O
suffers -X- _ O
from -X- _ O
error -X- _ O
propagations -X- _ O
on -X- _ O
TimeQuestions -X- _ B-DatasetName
. -X- _ O
The -X- _ O
2nd -X- _ O
row -X- _ O
counts -X- _ O
the -X- _ O
questions -X- _ O
whose -X- _ O
meaning -X- _ O
can -X- _ O
not -X- _ O
be -X- _ O
perfectly -X- _ O
expressed -X- _ O
by -X- _ O
generated -X- _ O
constraints -X- _ O
( -X- _ O
e.g. -X- _ O
, -X- _ O
questions -X- _ O
with -X- _ O
multi -X- _ O
- -X- _ O
hop -X- _ O
non -X- _ O
- -X- _ O
temporal -X- _ O
property -X- _ O
paths -X- _ O
like -X- _ O
" -X- _ O
wife -X- _ O
of -X- _ O
the -X- _ O
actor -X- _ O
who -X- _ O
played -X- _ O
in -X- _ O
the -X- _ O
movie -X- _ O
pinball -X- _ O
wizard -X- _ O
" -X- _ O
) -X- _ O
. -X- _ O
The -X- _ O
3rd -X- _ O
row -X- _ O
shows -X- _ O
that -X- _ O
our -X- _ O
ranking -X- _ O
model -X- _ O
is -X- _ O
hard -X- _ O
to -X- _ O
train -X- _ O
with -X- _ O
limited -X- _ O
data -X- _ O
( -X- _ O
TempQuestions -X- _ B-DatasetName
contains -X- _ O
less -X- _ O
than -X- _ O
1,000 -X- _ O
training -X- _ O
samples -X- _ O
) -X- _ O
. -X- _ O
Besides -X- _ O
, -X- _ O
data -X- _ O
quality -X- _ O
appears -X- _ O
to -X- _ O
be -X- _ O
an -X- _ O
important -X- _ O
issue -X- _ O
. -X- _ O
In -X- _ O
about -X- _ O
10 -X- _ O
% -X- _ O
of -X- _ O
the -X- _ O
sample -X- _ O
questions -X- _ O
, -X- _ O
the -X- _ O
provided -X- _ O
answers -X- _ O
are -X- _ O
inconsistent -X- _ O
with -X- _ O
the -X- _ O
knowledge -X- _ O
in -X- _ O
the -X- _ O
given -X- _ O
KG -X- _ O
. -X- _ O
For -X- _ O
example -X- _ O
, -X- _ O
TimeQuestions -X- _ B-DatasetName
annotate -X- _ O
2010_F1_Championship -X- _ O
( -X- _ O
wd -X- _ O
: -X- _ O
Q69934 -X- _ O
) -X- _ O
as -X- _ O
the -X- _ O
answer -X- _ O
of -X- _ O
" -X- _ O
Who -X- _ O
won -X- _ O
the -X- _ O
2010 -X- _ O
f1 -X- _ O
championship -X- _ O
? -X- _ O
" -X- _ O
. -X- _ O
For -X- _ O
over -X- _ O
1 -X- _ O
/ -X- _ O
3 -X- _ O
of -X- _ O
the -X- _ O
sampled -X- _ O
questions -X- _ O
, -X- _ O
KG -X- _ O
can -X- _ O
not -X- _ O
provide -X- _ O
sufficient -X- _ O
evidence -X- _ O
( -X- _ O
e.g. -X- _ O
, -X- _ O
occurrence -X- _ O
times -X- _ O
of -X- _ O
the -X- _ O
corresponding -X- _ O
facts -X- _ O
are -X- _ O
not -X- _ O
provided -X- _ O
) -X- _ O
for -X- _ O
obtaining -X- _ O
all -X- _ O
answers -X- _ O
. -X- _ O

Related -X- _ O
work -X- _ O

Temporal -X- _ O
Information -X- _ O
in -X- _ O
Natural -X- _ O
Language -X- _ O
. -X- _ O
Temporal -X- _ O
information -X- _ O
has -X- _ O
attracted -X- _ O
the -X- _ O
attention -X- _ O
of -X- _ O
AI -X- _ O
and -X- _ O
linguistics -X- _ O
communities -X- _ O
for -X- _ O
a -X- _ O
long -X- _ O
time -X- _ O
. -X- _ O
Allen -X- _ O
presents -X- _ O
an -X- _ O
interval -X- _ O
- -X- _ O
based -X- _ O
temporal -X- _ O
logic -X- _ O
for -X- _ O
reasoning -X- _ O
the -X- _ O
relation -X- _ O
between -X- _ O
time -X- _ O
duration -X- _ O
( -X- _ O
Allen -X- _ O
, -X- _ O
1983 -X- _ O
) -X- _ O
and -X- _ O
a -X- _ O
computation -X- _ O
theory -X- _ O
for -X- _ O
action -X- _ O
and -X- _ O
time -X- _ O
( -X- _ O
Allen -X- _ O
, -X- _ O
1984 -X- _ O
) -X- _ O
. -X- _ O
He -X- _ O
concludes -X- _ O
13 -X- _ O
possible -X- _ O
interval -X- _ O
relations -X- _ O
with -X- _ O
their -X- _ O
transitivity -X- _ O
table -X- _ O
. -X- _ O
Mani -X- _ O
and -X- _ O
Wilson -X- _ O
( -X- _ O
2000 -X- _ O
) -X- _ O
introduces -X- _ O
an -X- _ O
annotation -X- _ O
scheme -X- _ O
for -X- _ O
temporal -X- _ O
expression -X- _ O
in -X- _ O
news -X- _ O
and -X- _ O
discusses -X- _ O
its -X- _ O
possible -X- _ O
application -X- _ O
in -X- _ O
event -X- _ O
ordering -X- _ O
and -X- _ O
event -X- _ O
time -X- _ O
alignment -X- _ O
. -X- _ O
TimeML -X- _ O
( -X- _ O
Pustejovsky -X- _ O
et -X- _ O
al -X- _ O
. -X- _ O
, -X- _ O
2003 -X- _ O
( -X- _ O
Pustejovsky -X- _ O
et -X- _ O
al -X- _ O
. -X- _ O
, -X- _ O
, -X- _ O
2010 -X- _ O
) -X- _ O
is -X- _ O
a -X- _ O
specification -X- _ O
for -X- _ O
annotating -X- _ O
temporal -X- _ O
information -X- _ O
from -X- _ O
narratives -X- _ O
. -X- _ O
TimeML -X- _ O
has -X- _ O
become -X- _ O
the -X- _ O
de -X- _ O
facto -X- _ O
standard -X- _ O
in -X- _ O
the -X- _ O
NLP -X- _ O
community -X- _ O
. -X- _ O
It -X- _ O
annotates -X- _ O
time -X- _ O
expressions -X- _ O
, -X- _ O
events -X- _ O
, -X- _ O
the -X- _ O
relations -X- _ O
between -X- _ O
them -X- _ O
, -X- _ O
and -X- _ O
the -X- _ O
signals -X- _ O
that -X- _ O
trigger -X- _ O
the -X- _ O
relations -X- _ O
in -X- _ O
XML -X- _ O
form -X- _ O
. -X- _ O

Temporal -X- _ B-TaskName
KGQA -X- _ I-TaskName
. -X- _ O
Early -X- _ O
KGQA -X- _ B-TaskName
systems -X- _ O
usually -X- _ O
do -X- _ O
not -X- _ O
handle -X- _ O
temporal -X- _ O
constraints -X- _ O
( -X- _ O
e.g. -X- _ O
, -X- _ O
Berant -X- _ O
and -X- _ O
Liang -X- _ O
, -X- _ O
2014 -X- _ O
) -X- _ O
or -X- _ O
apply -X- _ O
simple -X- _ O
heuristics -X- _ O
about -X- _ O
their -X- _ O
surface -X- _ O
forms -X- _ O
( -X- _ O
Berant -X- _ O
et -X- _ O
al -X- _ O
. -X- _ O
, -X- _ O
2013 -X- _ O
; -X- _ O
Bast -X- _ O
and -X- _ O
Haussmann -X- _ O
, -X- _ O
2015 -X- _ O
; -X- _ O
Bao -X- _ O
et -X- _ O
al -X- _ O
. -X- _ O
, -X- _ O
2016 -X- _ O
) -X- _ O
. -X- _ O
Some -X- _ O
benchmarks -X- _ O
that -X- _ O
specifically -X- _ O
focus -X- _ O
on -X- _ O
temporal -X- _ O
intents -X- _ O
in -X- _ O
KGQA -X- _ B-TaskName
emerge -X- _ O
in -X- _ O
recent -X- _ O
years -X- _ O
, -X- _ O
including -X- _ O
Tem -X- _ B-DatasetName
- -X- _ I-DatasetName
pQuestions -X- _ I-DatasetName
( -X- _ O
Jia -X- _ O
et -X- _ O
al -X- _ O
. -X- _ O
, -X- _ O
2018b -X- _ O
) -X- _ O
, -X- _ O
TimeQuestions -X- _ B-DatasetName
( -X- _ O
Jia -X- _ O
et -X- _ O
al -X- _ O
. -X- _ O
, -X- _ O
2021 -X- _ O
) -X- _ O
and -X- _ O
TempQA -X- _ B-DatasetName
- -X- _ I-DatasetName
WD -X- _ I-DatasetName
( -X- _ O
Neelam -X- _ O
et -X- _ O
al -X- _ O
. -X- _ O
, -X- _ O
2022 -X- _ O
) -X- _ O
. -X- _ O
In -X- _ O
terms -X- _ O
of -X- _ O
the -X- _ O
technologies -X- _ O
for -X- _ O
temporal -X- _ B-TaskName
KGQA -X- _ I-TaskName
, -X- _ O
Jia -X- _ O
et -X- _ O
al -X- _ O
. -X- _ O
( -X- _ O
2018a -X- _ O
) -X- _ O
proposes -X- _ O
TEQUILA -X- _ B-MethodName
. -X- _ O
It -X- _ O
relies -X- _ O
on -X- _ O
limited -X- _ O
hand -X- _ O
- -X- _ O
crafted -X- _ O
rules -X- _ O
to -X- _ O
decompose -X- _ O
complex -X- _ O
temporal -X- _ O
relations -X- _ O
and -X- _ O
solves -X- _ O
composed -X- _ O
simple -X- _ O
questions -X- _ O
via -X- _ O
underlying -X- _ O
general -X- _ O
KGQA -X- _ B-TaskName
systems -X- _ O
. -X- _ O
EXAQT -X- _ B-MethodName
( -X- _ O
Jia -X- _ O
et -X- _ O
al -X- _ O
. -X- _ O
, -X- _ O
2021 -X- _ O
) -X- _ O
uses -X- _ O
Group -X- _ O
Steiner -X- _ O
Trees -X- _ O
to -X- _ O
anchor -X- _ O
a -X- _ O
KG -X- _ O
sub -X- _ O
- -X- _ O
graph -X- _ O
for -X- _ O
each -X- _ O
question -X- _ O
, -X- _ O
retrieving -X- _ O
answers -X- _ O
in -X- _ O
the -X- _ O
sub -X- _ O
- -X- _ O
graph -X- _ O
with -X- _ O
augmented -X- _ O
temporal -X- _ O
facts -X- _ O
by -X- _ O
an -X- _ O
RGCN -X- _ O
model -X- _ O
. -X- _ O
Besides -X- _ O
, -X- _ O
there -X- _ O
are -X- _ O
also -X- _ O
some -X- _ O
researches -X- _ O
specifically -X- _ O
focus -X- _ O
on -X- _ O
question -X- _ O
event -X- _ O
- -X- _ O
centric -X- _ O
or -X- _ O
temporal -X- _ O
knowledge -X- _ O
graphs -X- _ O
. -X- _ O
Costa -X- _ O
et -X- _ O
al -X- _ O
. -X- _ O
( -X- _ O
2020 -X- _ O
) -X- _ O
proposes -X- _ O
a -X- _ O
question -X- _ O
answering -X- _ O
benchmark -X- _ O
Event -X- _ O
- -X- _ O
QA -X- _ O
over -X- _ O
EventKG -X- _ O
Demidova -X- _ O
, -X- _ O
2018 -X- _ O
, -X- _ O
2019 -X- _ O
) -X- _ O
. -X- _ O
Saxena -X- _ O
et -X- _ O
al -X- _ O
. -X- _ O
( -X- _ O
2021 -X- _ O
) -X- _ O
proposes -X- _ O
CronQuestion -X- _ O
over -X- _ O
a -X- _ O
sub -X- _ O
- -X- _ O
graph -X- _ O
of -X- _ O
Wikidata -X- _ O
with -X- _ O
a -X- _ O
limited -X- _ O
subset -X- _ O
of -X- _ O
relations -X- _ O
for -X- _ O
evaluating -X- _ O
temporal -X- _ O
KG -X- _ O
embeddings -X- _ O
. -X- _ O

In -X- _ O
summary -X- _ O
, -X- _ O
existing -X- _ O
temporal -X- _ B-TaskName
KGQA -X- _ I-TaskName
methods -X- _ O
either -X- _ O
analyze -X- _ O
only -X- _ O
the -X- _ O
surface -X- _ O
form -X- _ O
of -X- _ O
temporal -X- _ O
constraints -X- _ O
or -X- _ O
rely -X- _ O
on -X- _ O
end -X- _ O
- -X- _ O
to -X- _ O
- -X- _ O
end -X- _ O
neural -X- _ O
models -X- _ O
. -X- _ O
While -X- _ O
neural -X- _ O
models -X- _ O
might -X- _ O
be -X- _ O
robust -X- _ O
to -X- _ O
diversified -X- _ O
representations -X- _ O
of -X- _ O
knowledge -X- _ O
, -X- _ O
they -X- _ O
are -X- _ O
hard -X- _ O
to -X- _ O
characterize -X- _ O
the -X- _ O
clear -X- _ O
boundaries -X- _ O
of -X- _ O
temporal -X- _ O
constraints -X- _ O
( -X- _ O
e.g. -X- _ O
, -X- _ O
accurately -X- _ O
filtering -X- _ O
all -X- _ O
events -X- _ O
that -X- _ O
occur -X- _ O
before -X- _ O
2022 -X- _ O
) -X- _ O
. -X- _ O

KGQA -X- _ B-TaskName
via -X- _ O
Query -X- _ O
Graph -X- _ O
Generation -X- _ O
. -X- _ O
Constructing -X- _ O
queries -X- _ O
via -X- _ O
exploring -X- _ O
the -X- _ O
relevant -X- _ O
facts -X- _ O
of -X- _ O
mentioned -X- _ O
entities -X- _ O
is -X- _ O
a -X- _ O
common -X- _ O
practice -X- _ O
in -X- _ O
KGQA -X- _ B-TaskName
, -X- _ O
especially -X- _ O
in -X- _ O
the -X- _ O
situations -X- _ O
where -X- _ O
only -X- _ O
questionanswers -X- _ O
pairs -X- _ O
are -X- _ O
provided -X- _ O
. -X- _ O
Yih -X- _ O
et -X- _ O
al -X- _ O
. -X- _ O
( -X- _ O
2015 -X- _ O
) -X- _ O
defines -X- _ O
query -X- _ O
graphs -X- _ O
that -X- _ O
can -X- _ O
be -X- _ O
straightforwardly -X- _ O
mapped -X- _ O
to -X- _ O
an -X- _ O
executable -X- _ O
logical -X- _ O
query -X- _ O
. -X- _ O
They -X- _ O
model -X- _ O
the -X- _ O
generation -X- _ O
of -X- _ O
query -X- _ O
graphs -X- _ O
as -X- _ O
a -X- _ O
staged -X- _ O
search -X- _ O
problem -X- _ O
, -X- _ O
where -X- _ O
the -X- _ O
query -X- _ O
graphs -X- _ O
are -X- _ O
expanded -X- _ O
by -X- _ O
exploring -X- _ O
legitimate -X- _ O
predicate -X- _ O
sequences -X- _ O
starting -X- _ O
from -X- _ O
mentioned -X- _ O
entities -X- _ O
. -X- _ O
Bao -X- _ O
et -X- _ O
al -X- _ O
. -X- _ O
( -X- _ O
2016 -X- _ O
) -X- _ O
expands -X- _ O
basic -X- _ O
query -X- _ O
graphs -X- _ O
with -X- _ O
6 -X- _ O
kinds -X- _ O
of -X- _ O
manually -X- _ O
designed -X- _ O
constraints -X- _ O
including -X- _ O
quantitative -X- _ O
temporal -X- _ O
and -X- _ O
ordinal -X- _ O
constraints -X- _ O
. -X- _ O
Luo -X- _ O
et -X- _ O
al -X- _ O
. -X- _ O
( -X- _ O
2018 -X- _ O
) -X- _ O
encodes -X- _ O
query -X- _ O
graphs -X- _ O
of -X- _ O
complex -X- _ O
structures -X- _ O
into -X- _ O
a -X- _ O
uniform -X- _ O
vector -X- _ O
representation -X- _ O
for -X- _ O
complex -X- _ O
questions -X- _ O
. -X- _ O
Lan -X- _ O
and -X- _ O
Jiang -X- _ O
( -X- _ O
2020 -X- _ O
) -X- _ O
prunes -X- _ O
the -X- _ O
search -X- _ O
space -X- _ O
via -X- _ O
early -X- _ O
incorporation -X- _ O
of -X- _ O
constraints -X- _ O
. -X- _ O

The -X- _ O
existing -X- _ O
query -X- _ O
graph -X- _ O
generation -X- _ O
methods -X- _ O
are -X- _ O
not -X- _ O
specifically -X- _ O
designed -X- _ O
for -X- _ O
temporal -X- _ O
constraints -X- _ O
, -X- _ O
they -X- _ O
simply -X- _ O
suppose -X- _ O
that -X- _ O
temporal -X- _ O
or -X- _ O
ordinal -X- _ O
signals -X- _ O
correspond -X- _ O
to -X- _ O
quantitative -X- _ O
constraints -X- _ O
. -X- _ O
Specifically -X- _ O
, -X- _ O
Bao -X- _ O
et -X- _ O
al -X- _ O
. -X- _ O
( -X- _ O
2016 -X- _ O
) -X- _ O
, -X- _ O
Luo -X- _ O
et -X- _ O
al -X- _ O
. -X- _ O
( -X- _ O
2018 -X- _ O
) -X- _ O
, -X- _ O
and -X- _ O
Lan -X- _ O
and -X- _ O
Jiang -X- _ O
( -X- _ O
2020 -X- _ O
) -X- _ O
recognize -X- _ O
time -X- _ O
constraints -X- _ O
via -X- _ O
syntax -X- _ O
signals -X- _ O
and -X- _ O
simply -X- _ O
interpret -X- _ O
them -X- _ O
as -X- _ O
general -X- _ O
aggregation -X- _ O
functions -X- _ O
( -X- _ O
e.g. -X- _ O
, -X- _ O
greater -X- _ O
than -X- _ O
X -X- _ O
, -X- _ O
max -X- _ O
at -X- _ O
N -X- _ O
) -X- _ O
, -X- _ O
i.e. -X- _ O
, -X- _ O
their -X- _ O
interpretations -X- _ O
of -X- _ O
temporal -X- _ O
constraints -X- _ O
are -X- _ O
similar -X- _ O
to -X- _ O
" -X- _ O
SF -X- _ B-MethodName
- -X- _ I-MethodName
TQA -X- _ I-MethodName
w -X- _ O
/ -X- _ O
o -X- _ O
IS-4 -X- _ O
to -X- _ O
6 -X- _ O
" -X- _ O
( -X- _ O
referring -X- _ O
to -X- _ O
Table -X- _ O
5 -X- _ O
) -X- _ O
. -X- _ O
In -X- _ O
contrast -X- _ O
, -X- _ O
we -X- _ O
systematically -X- _ O
analyze -X- _ O
the -X- _ O
interpretation -X- _ O
structure -X- _ O
of -X- _ O
temporal -X- _ O
constraints -X- _ O
, -X- _ O
including -X- _ O
the -X- _ O
analysis -X- _ O
of -X- _ O
what -X- _ O
kind -X- _ O
of -X- _ O
intrinsic -X- _ O
connection -X- _ O
can -X- _ O
make -X- _ O
events -X- _ O
temporally -X- _ O
related -X- _ O
. -X- _ O

Conclusion -X- _ O
and -X- _ O
Future -X- _ O
work -X- _ O

In -X- _ O
this -X- _ O
paper -X- _ O
, -X- _ O
we -X- _ O
study -X- _ O
the -X- _ O
logical -X- _ O
constraint -X- _ O
that -X- _ O
corresponds -X- _ O
to -X- _ O
temporal -X- _ O
intents -X- _ O
in -X- _ O
questions -X- _ O
. -X- _ O
Our -X- _ O
main -X- _ O
contributions -X- _ O
can -X- _ O
be -X- _ O
summarized -X- _ O
as -X- _ O
follows -X- _ O
: -X- _ O

• -X- _ O
We -X- _ O
propose -X- _ O
the -X- _ O
idea -X- _ O
of -X- _ O
analyzing -X- _ O
temporal -X- _ O
intents -X- _ O
via -X- _ O
possible -X- _ O
interpretation -X- _ O
structures -X- _ O
. -X- _ O
We -X- _ O
conclude -X- _ O
the -X- _ O
interpretation -X- _ O
structures -X- _ O
as -X- _ O
SF -X- _ O
- -X- _ O
TCons -X- _ O
, -X- _ O
which -X- _ O
allows -X- _ O
one -X- _ O
constraint -X- _ O
expression -X- _ O
has -X- _ O
various -X- _ O
interpretations -X- _ O
. -X- _ O

• -X- _ O
We -X- _ O
propose -X- _ O
the -X- _ O
semantic -X- _ B-MethodName
- -X- _ I-MethodName
framework -X- _ I-MethodName
- -X- _ I-MethodName
based -X- _ I-MethodName
temporal -X- _ I-MethodName
question -X- _ I-MethodName
answering -X- _ I-MethodName
method -X- _ O
, -X- _ O
SF -X- _ B-MethodName
- -X- _ I-MethodName
TQA -X- _ I-MethodName
. -X- _ O
SF -X- _ B-MethodName
- -X- _ I-MethodName
TQA -X- _ I-MethodName
mitigates -X- _ O
the -X- _ O
heterogeneity -X- _ O
between -X- _ O
expressions -X- _ O
of -X- _ O
temporal -X- _ O
intents -X- _ O
and -X- _ O
KG -X- _ O
facts -X- _ O
. -X- _ O
It -X- _ O
enhances -X- _ O
the -X- _ O
query -X- _ O
generation -X- _ O
via -X- _ O
structural -X- _ O
restrictions -X- _ O
provided -X- _ O
by -X- _ O
SF -X- _ O
- -X- _ O
TCons -X- _ O
. -X- _ O

• -X- _ O
Our -X- _ O
implementation -X- _ O
of -X- _ O
SF -X- _ B-MethodName
- -X- _ I-MethodName
TQA -X- _ I-MethodName
establishes -X- _ O
new -X- _ O
SOTAs -X- _ O
on -X- _ O
two -X- _ O
benchmarks -X- _ O
and -X- _ O
improves -X- _ O
the -X- _ O
F -X- _ B-MetricName
1 -X- _ I-MetricName
scores -X- _ O
by -X- _ O
+3.6 -X- _ B-MetricValue
and -X- _ O
+7.1 -X- _ B-MetricValue
points -X- _ O
respectively -X- _ O
. -X- _ O

In -X- _ O
the -X- _ O
near -X- _ O
future -X- _ O
, -X- _ O
it -X- _ O
is -X- _ O
worth -X- _ O
exploring -X- _ O
to -X- _ O
alleviate -X- _ O
the -X- _ O
possible -X- _ O
knowledge -X- _ O
incompleteness -X- _ O
in -X- _ O
practical -X- _ O
KG -X- _ O
by -X- _ O
developing -X- _ O
a -X- _ O
hybrid -X- _ O
questionanswering -X- _ O
method -X- _ O
on -X- _ O
both -X- _ O
knowledge -X- _ O
graphs -X- _ O
and -X- _ O
web -X- _ O
texts -X- _ O
. -X- _ O
In -X- _ O
addition -X- _ O
, -X- _ O
this -X- _ O
paper -X- _ O
focuses -X- _ O
only -X- _ O
on -X- _ O
temporal -X- _ O
intent -X- _ O
, -X- _ O
while -X- _ O
problems -X- _ O
in -X- _ O
real -X- _ O
configurations -X- _ O
may -X- _ O
contain -X- _ O
both -X- _ O
complex -X- _ O
non -X- _ O
- -X- _ O
temporal -X- _ O
and -X- _ O
temporal -X- _ O
intents -X- _ O
. -X- _ O
Therefore -X- _ O
, -X- _ O
it -X- _ O
would -X- _ O
be -X- _ O
helpful -X- _ O
to -X- _ O
combine -X- _ O
SF -X- _ O
- -X- _ O
TCons -X- _ O
with -X- _ O
general -X- _ O
KGQA -X- _ B-TaskName
systems -X- _ O
for -X- _ O
complex -X- _ O
questions -X- _ O
. -X- _ O

Limitations -X- _ O

• -X- _ O
Due -X- _ O
to -X- _ O
the -X- _ O
compositionality -X- _ O
of -X- _ O
natural -X- _ O
language -X- _ O
, -X- _ O
a -X- _ O
temporal -X- _ O
question -X- _ O
could -X- _ O
be -X- _ O
very -X- _ O
complex -X- _ O
, -X- _ O
which -X- _ O
is -X- _ O
beyond -X- _ O
the -X- _ O
ability -X- _ O
of -X- _ O
our -X- _ O
implemented -X- _ O
QA -X- _ O
system -X- _ O
. -X- _ O
For -X- _ O
example -X- _ O
, -X- _ O
The -X- _ O
following -X- _ O
question -X- _ O
is -X- _ O
syntactically -X- _ O
legitimate -X- _ O
but -X- _ O
can -X- _ O
not -X- _ O
be -X- _ O
handled -X- _ O
by -X- _ O
SF -X- _ B-MethodName
- -X- _ I-MethodName
TQA -X- _ I-MethodName
: -X- _ O
" -X- _ O
What -X- _ O
year -X- _ O
did -X- _ O
the -X- _ O
second -X- _ O
president -X- _ O
of -X- _ O
the -X- _ O
United -X- _ O
States -X- _ O
, -X- _ O
elected -X- _ O
after -X- _ O
the -X- _ O
last -X- _ O
spouse -X- _ O
of -X- _ O
the -X- _ O
author -X- _ O
of -X- _ O
' -X- _ O
Wish -X- _ O
Tree -X- _ O
for -X- _ O
Washington -X- _ O
, -X- _ O
DC -X- _ O
' -X- _ O
was -X- _ O
shot -X- _ O
, -X- _ O
marry -X- _ O
his -X- _ O
wife -X- _ O
? -X- _ O
" -X- _ O

• -X- _ O
While -X- _ O
the -X- _ O
linguistic -X- _ O
and -X- _ O
entity -X- _ O
annotations -X- _ O
help -X- _ O
SF -X- _ B-MethodName
- -X- _ I-MethodName
TQA -X- _ I-MethodName
alleviate -X- _ O
the -X- _ O
lack -X- _ O
of -X- _ O
structured -X- _ O
supervision -X- _ O
, -X- _ O
they -X- _ O
make -X- _ O
it -X- _ O
hard -X- _ O
to -X- _ O
apply -X- _ O
SF -X- _ B-MethodName
- -X- _ I-MethodName
TQA -X- _ I-MethodName
to -X- _ O
low -X- _ O
- -X- _ O
resource -X- _ O
languages -X- _ O
or -X- _ O
questions -X- _ O
with -X- _ O
no -X- _ O
named -X- _ O
entities -X- _ O
( -X- _ O
e.g. -X- _ O
, -X- _ O
" -X- _ O
What -X- _ O
are -X- _ O
the -X- _ O
important -X- _ O
events -X- _ O
that -X- _ O
will -X- _ O
happen -X- _ O
at -X- _ O
the -X- _ O
turn -X- _ O
of -X- _ O
the -X- _ O
century -X- _ O
? -X- _ O
" -X- _ O
) -X- _ O
. -X- _ O
Besides -X- _ O
, -X- _ O
as -X- _ O
a -X- _ O
pipeline -X- _ O
method -X- _ O
, -X- _ O
SF -X- _ B-MethodName
- -X- _ I-MethodName
TQA -X- _ I-MethodName
suffers -X- _ O
from -X- _ O
possible -X- _ O
error -X- _ O
propagations -X- _ O
. -X- _ O

Acknowledgements -X- _ O

This -X- _ O
work -X- _ O
was -X- _ O
supported -X- _ O
by -X- _ O
the -X- _ O
National -X- _ O
Natural -X- _ O
Science -X- _ O
Foundation -X- _ O
of -X- _ O
China -X- _ O
( -X- _ O
NSFC -X- _ O
) -X- _ O
under -X- _ O
Grant -X- _ O
No -X- _ O
. -X- _ O
62072224 -X- _ O
. -X- _ O
and -X- _ O
the -X- _ O
Program -X- _ O
B -X- _ O
for -X- _ O
Outstanding -X- _ O
PhD -X- _ O
candidate -X- _ O
of -X- _ O
Nanjing -X- _ O
University -X- _ O
. -X- _ O
The -X- _ O
authors -X- _ O
would -X- _ O
like -X- _ O
to -X- _ O
thank -X- _ O
all -X- _ O
the -X- _ O
participants -X- _ O
of -X- _ O
this -X- _ O
work -X- _ O
and -X- _ O
anonymous -X- _ O
reviewers -X- _ O
. -X- _ O

A -X- _ O
Appendix -X- _ O
for -X- _ O
Different -X- _ O
Training -X- _ O
Strategies -X- _ O

We -X- _ O
also -X- _ O
evaluated -X- _ O
the -X- _ O
effects -X- _ O
of -X- _ O
different -X- _ O
training -X- _ O
strategies -X- _ O
as -X- _ O
illustrated -X- _ O
in -X- _ O
Table -X- _ O
7 -X- _ O
. -X- _ O
The -X- _ O
results -X- _ O
in -X- _ O
2 -X- _ O
to -X- _ O
4 -X- _ O
rows -X- _ O
are -X- _ O
obtained -X- _ O
by -X- _ O
simply -X- _ O
using -X- _ O
the -X- _ O
irrelevant -X- _ O
negatives -X- _ O
, -X- _ O
confusing -X- _ O
negatives -X- _ O
or -X- _ O
randomly -X- _ O
sampling -X- _ O
negatives -X- _ O
without -X- _ O
classification -X- _ O
respectively -X- _ O
. -X- _ O
The -X- _ O
results -X- _ O
show -X- _ O
that -X- _ O
both -X- _ O
of -X- _ O
the -X- _ O
two -X- _ O
types -X- _ O
of -X- _ O
negative -X- _ O
sample -X- _ O
are -X- _ O
needed -X- _ O
for -X- _ O
training -X- _ O
. -X- _ O
The -X- _ O
balanced -X- _ O
sampling -X- _ O
of -X- _ O
the -X- _ O
two -X- _ O
types -X- _ O
effectively -X- _ O
improves -X- _ O
SF -X- _ B-MethodName
- -X- _ I-MethodName
TQA -X- _ I-MethodName
on -X- _ O
the -X- _ O
smaller -X- _ O
dataset -X- _ O
, -X- _ O
TempQuestions -X- _ B-DatasetName
. -X- _ O

Leaner -X- _ O
and -X- _ O
Faster -X- _ O
: -X- _ O
Two -X- _ B-MethodName
- -X- _ I-MethodName
Stage -X- _ I-MethodName
Model -X- _ I-MethodName
Compression -X- _ I-MethodName
for -X- _ O
Lightweight -X- _ O
Text -X- _ B-TaskName
- -X- _ I-TaskName
Image -X- _ I-TaskName
Retrieval -X- _ I-TaskName

Current -X- _ O
text -X- _ O
- -X- _ O
image -X- _ O
approaches -X- _ O
( -X- _ O
e.g. -X- _ O
, -X- _ O
CLIP -X- _ B-MethodName
) -X- _ O
typically -X- _ O
adopt -X- _ O
dual -X- _ O
- -X- _ O
encoder -X- _ O
architecture -X- _ O
using -X- _ O
pre -X- _ O
- -X- _ O
trained -X- _ O
vision -X- _ O
- -X- _ O
language -X- _ O
representation -X- _ O
. -X- _ O
However -X- _ O
, -X- _ O
these -X- _ O
models -X- _ O
still -X- _ O
pose -X- _ O
non -X- _ O
- -X- _ O
trivial -X- _ O
memory -X- _ O
requirements -X- _ O
and -X- _ O
substantial -X- _ O
incremental -X- _ O
indexing -X- _ O
time -X- _ O
, -X- _ O
which -X- _ O
makes -X- _ O
them -X- _ O
less -X- _ O
practical -X- _ O
on -X- _ O
mobile -X- _ O
devices -X- _ O
. -X- _ O
In -X- _ O
this -X- _ O
paper -X- _ O
, -X- _ O
we -X- _ O
present -X- _ O
an -X- _ O
effective -X- _ O
two -X- _ B-MethodName
- -X- _ I-MethodName
stage -X- _ I-MethodName
framework -X- _ I-MethodName
to -X- _ O
compress -X- _ O
large -X- _ O
pre -X- _ O
- -X- _ O
trained -X- _ O
dual -X- _ O
- -X- _ O
encoder -X- _ O
for -X- _ O
lightweight -X- _ O
text -X- _ B-TaskName
- -X- _ I-TaskName
image -X- _ I-TaskName
retrieval -X- _ I-TaskName
. -X- _ O
The -X- _ O
resulting -X- _ O
model -X- _ O
is -X- _ O
smaller -X- _ O
( -X- _ O
39 -X- _ B-MetricValue
% -X- _ I-MetricValue
of -X- _ O
the -X- _ O
original -X- _ O
) -X- _ O
, -X- _ O
faster -X- _ O
( -X- _ O
1.6x -X- _ B-MetricValue
/ -X- _ O
2.9x -X- _ B-MetricValue
for -X- _ O
processing -X- _ O
image -X- _ O
/ -X- _ O
text -X- _ O
respectively -X- _ O
) -X- _ O
, -X- _ O
yet -X- _ O
performs -X- _ O
on -X- _ O
par -X- _ O
with -X- _ O
or -X- _ O
better -X- _ O
than -X- _ O
the -X- _ O
original -X- _ O
full -X- _ O
model -X- _ O
on -X- _ O
Flickr30 -X- _ B-DatasetName
K -X- _ I-DatasetName
and -X- _ O
MSCOCO -X- _ B-DatasetName
benchmarks -X- _ O
. -X- _ O
We -X- _ O
also -X- _ O
opensource -X- _ O
an -X- _ O
accompanying -X- _ O
realistic -X- _ O
mobile -X- _ O
image -X- _ O
search -X- _ O
application -X- _ O
. -X- _ O

Text -X- _ B-TaskName
- -X- _ I-TaskName
image -X- _ I-TaskName
retrieval -X- _ I-TaskName
is -X- _ O
the -X- _ O
task -X- _ O
aiming -X- _ O
at -X- _ O
retrieving -X- _ O
a -X- _ O
list -X- _ O
of -X- _ O
relevant -X- _ O
images -X- _ O
from -X- _ O
a -X- _ O
large -X- _ O
set -X- _ O
of -X- _ O
images -X- _ O
given -X- _ O
a -X- _ O
textual -X- _ O
query -X- _ O
specified -X- _ O
by -X- _ O
the -X- _ O
user -X- _ O
. -X- _ O
Recently -X- _ O
, -X- _ O
large -X- _ O
- -X- _ O
scale -X- _ O
vision -X- _ O
- -X- _ O
language -X- _ O
pretraining -X- _ O
( -X- _ O
VLP -X- _ O
) -X- _ O
has -X- _ O
spawned -X- _ O
models -X- _ O
( -X- _ O
Tan -X- _ O
and -X- _ O
Bansal -X- _ O
, -X- _ O
2019 -X- _ O
; -X- _ O
Li -X- _ O
et -X- _ O
al -X- _ O
. -X- _ O
, -X- _ O
2020 -X- _ O
; -X- _ O
Radford -X- _ O
et -X- _ O
al -X- _ O
. -X- _ O
, -X- _ O
2021 -X- _ O
) -X- _ O
that -X- _ O
established -X- _ O
state -X- _ O
- -X- _ O
of -X- _ O
- -X- _ O
the -X- _ O
- -X- _ O
art -X- _ O
results -X- _ O
in -X- _ O
various -X- _ O
vision -X- _ O
- -X- _ O
language -X- _ O
tasks -X- _ O
( -X- _ O
Antol -X- _ O
et -X- _ O
al -X- _ O
. -X- _ O
, -X- _ O
2015 -X- _ O
; -X- _ O
Suhr -X- _ O
et -X- _ O
al -X- _ O
. -X- _ O
, -X- _ O
2019 -X- _ O
) -X- _ O
, -X- _ O
including -X- _ O
text -X- _ O
- -X- _ O
image -X- _ O
retrieval -X- _ O
. -X- _ O
Existing -X- _ O
VLP -X- _ O
models -X- _ O
for -X- _ O
text -X- _ B-TaskName
- -X- _ I-TaskName
image -X- _ I-TaskName
retrieval -X- _ I-TaskName
can -X- _ O
be -X- _ O
divided -X- _ O
into -X- _ O
two -X- _ O
categories -X- _ O
: -X- _ O
cross -X- _ O
- -X- _ O
encoder -X- _ O
architecture -X- _ O
and -X- _ O
dual -X- _ O
- -X- _ O
encoder -X- _ O
architecture -X- _ O
. -X- _ O
Cross -X- _ O
- -X- _ O
encoder -X- _ O
models -X- _ O
show -X- _ O
better -X- _ O
retrieval -X- _ O
accuracy -X- _ O
by -X- _ O
allowing -X- _ O
fine -X- _ O
- -X- _ O
grained -X- _ O
cross -X- _ O
- -X- _ O
modal -X- _ O
attention -X- _ O
among -X- _ O
image -X- _ O
and -X- _ O
text -X- _ O
. -X- _ O
However -X- _ O
, -X- _ O
they -X- _ O
are -X- _ O
prohibitively -X- _ O
slow -X- _ O
to -X- _ O
apply -X- _ O
to -X- _ O
the -X- _ O
entire -X- _ O
image -X- _ O
pool -X- _ O
because -X- _ O
each -X- _ O
image -X- _ O
has -X- _ O
to -X- _ O
go -X- _ O
through -X- _ O
the -X- _ O
deep -X- _ O
Transformer -X- _ O
again -X- _ O
whenever -X- _ O
a -X- _ O
new -X- _ O
text -X- _ O
query -X- _ O
comes -X- _ O
in -X- _ O
. -X- _ O
Moreover -X- _ O
, -X- _ O
most -X- _ O
cross -X- _ O
- -X- _ O
encoder -X- _ O
models -X- _ O
rely -X- _ O
on -X- _ O
external -X- _ O
object -X- _ O
detection -X- _ O
models -X- _ O
( -X- _ O
Ren -X- _ O
et -X- _ O
al -X- _ O
. -X- _ O
, -X- _ O
2015 -X- _ O
) -X- _ O
to -X- _ O
extract -X- _ O
visual -X- _ O
* -X- _ O
The -X- _ O
corresponding -X- _ O
author -X- _ O
. -X- _ O

features -X- _ O
, -X- _ O
which -X- _ O
further -X- _ O
increase -X- _ O
memory -X- _ O
consumption -X- _ O
. -X- _ O
On -X- _ O
the -X- _ O
other -X- _ O
hand -X- _ O
, -X- _ O
dual -X- _ O
- -X- _ O
encoder -X- _ O
models -X- _ O
are -X- _ O
more -X- _ O
scalable -X- _ O
in -X- _ O
that -X- _ O
they -X- _ O
allow -X- _ O
pre -X- _ O
- -X- _ O
computing -X- _ O
image -X- _ O
representations -X- _ O
as -X- _ O
reusable -X- _ O
vectors -X- _ O
independent -X- _ O
of -X- _ O
the -X- _ O
text -X- _ O
queries -X- _ O
. -X- _ O
These -X- _ O
image -X- _ O
vectors -X- _ O
can -X- _ O
be -X- _ O
indexed -X- _ O
and -X- _ O
efficiently -X- _ O
retrieved -X- _ O
at -X- _ O
runtime -X- _ O
using -X- _ O
Approximate -X- _ O
Nearest -X- _ O
Neighbor -X- _ O
( -X- _ O
ANN -X- _ O
) -X- _ O
search -X- _ O
( -X- _ O
Johnson -X- _ O
et -X- _ O
al -X- _ O
. -X- _ O
, -X- _ O
2017 -X- _ O
) -X- _ O
. -X- _ O
As -X- _ O
long -X- _ O
as -X- _ O
the -X- _ O
image -X- _ O
pool -X- _ O
remains -X- _ O
unchanged -X- _ O
, -X- _ O
the -X- _ O
image -X- _ O
encoder -X- _ O
is -X- _ O
not -X- _ O
required -X- _ O
. -X- _ O

However -X- _ O
, -X- _ O
a -X- _ O
more -X- _ O
practical -X- _ O
scenario -X- _ O
calls -X- _ O
for -X- _ O
dynamic -X- _ O
indexing -X- _ O
of -X- _ O
new -X- _ O
images -X- _ O
into -X- _ O
the -X- _ O
pool -X- _ O
( -X- _ O
e.g. -X- _ O
, -X- _ O
private -X- _ O
photo -X- _ O
collections -X- _ O
on -X- _ O
mobile -X- _ O
devices -X- _ O
) -X- _ O
, -X- _ O
which -X- _ O
requires -X- _ O
both -X- _ O
the -X- _ O
image -X- _ O
encoder -X- _ O
and -X- _ O
the -X- _ O
text -X- _ O
encoder -X- _ O
to -X- _ O
be -X- _ O
resident -X- _ O
in -X- _ O
memory -X- _ O
. -X- _ O
This -X- _ O
makes -X- _ O
the -X- _ O
above -X- _ O
approach -X- _ O
less -X- _ O
practical -X- _ O
on -X- _ O
mobile -X- _ O
devices -X- _ O
with -X- _ O
limited -X- _ O
memory -X- _ O
and -X- _ O
processing -X- _ O
power -X- _ O
. -X- _ O
Unfortunately -X- _ O
, -X- _ O
little -X- _ O
attention -X- _ O
has -X- _ O
been -X- _ O
paid -X- _ O
to -X- _ O
fulfill -X- _ O
this -X- _ O
need -X- _ O
. -X- _ O
In -X- _ O
this -X- _ O
paper -X- _ O
, -X- _ O
we -X- _ O
show -X- _ O
that -X- _ O
a -X- _ O
large -X- _ O
dualencoder -X- _ O
model -X- _ O
can -X- _ O
be -X- _ O
compressed -X- _ O
into -X- _ O
a -X- _ O
much -X- _ O
smaller -X- _ O
and -X- _ O
faster -X- _ O
counterpart -X- _ O
while -X- _ O
retaining -X- _ O
its -X- _ O
retrieval -X- _ O
accuracy -X- _ B-MetricValue
using -X- _ O
a -X- _ O
novel -X- _ O
two -X- _ B-MethodName
- -X- _ I-MethodName
stage -X- _ I-MethodName
compression -X- _ I-MethodName
framework -X- _ I-MethodName
. -X- _ O
In -X- _ O
the -X- _ O
first -X- _ O
stage -X- _ O
, -X- _ O
we -X- _ O
make -X- _ O
use -X- _ O
of -X- _ O
abundant -X- _ O
non -X- _ O
- -X- _ O
paired -X- _ O
texts -X- _ O
/ -X- _ O
images -X- _ O
to -X- _ O
separately -X- _ O
compress -X- _ O
text -X- _ O
or -X- _ O
image -X- _ O
encoder -X- _ O
with -X- _ O
an -X- _ O
effective -X- _ O
intra -X- _ O
- -X- _ O
modal -X- _ O
contrastive -X- _ O
knowledge -X- _ O
distillation -X- _ O
scheme -X- _ O
. -X- _ O
In -X- _ O
the -X- _ O
second -X- _ O
stage -X- _ O
, -X- _ O
we -X- _ O
sequentially -X- _ O
fine -X- _ O
- -X- _ O
tune -X- _ O
the -X- _ O
distilled -X- _ O
image -X- _ O
or -X- _ O
text -X- _ O
encoder -X- _ O
on -X- _ O
paired -X- _ O
text -X- _ O
- -X- _ O
image -X- _ O
data -X- _ O
with -X- _ O
comprehensive -X- _ O
learning -X- _ O
objectives -X- _ O
. -X- _ O
Using -X- _ O
CLIP -X- _ B-MethodName
( -X- _ O
Radford -X- _ O
et -X- _ O
al -X- _ O
. -X- _ O
, -X- _ O
2021 -X- _ O
) -X- _ O
as -X- _ O
the -X- _ O
target -X- _ O
model -X- _ O
, -X- _ O
our -X- _ O
compressed -X- _ O
models -X- _ O
deliver -X- _ O
comparable -X- _ O
performance -X- _ O
on -X- _ O
MSCOCO -X- _ B-DatasetName
and -X- _ O
Flickr30 -X- _ B-DatasetName
K -X- _ O
while -X- _ O
being -X- _ O
just -X- _ O
39 -X- _ B-MetricValue
% -X- _ I-MetricValue
of -X- _ O
the -X- _ O
original -X- _ O
size -X- _ O
and -X- _ O
1.6x -X- _ B-MetricValue
/ -X- _ O
2.9x -X- _ B-MetricValue
times -X- _ O
faster -X- _ O
for -X- _ O
processing -X- _ O
image -X- _ O
/ -X- _ O
text -X- _ O
. -X- _ O
Detailed -X- _ O
ablation -X- _ O
study -X- _ O
shows -X- _ O
the -X- _ O
effectiveness -X- _ O
of -X- _ O
each -X- _ O
component -X- _ O
in -X- _ O
the -X- _ O
compression -X- _ O
framework -X- _ O
and -X- _ O
their -X- _ O
synergistic -X- _ O
effects -X- _ O
. -X- _ O

Our -X- _ O
contributions -X- _ O
are -X- _ O
three -X- _ O
- -X- _ O
folds -X- _ O
: -X- _ O
1 -X- _ O
) -X- _ O
an -X- _ O
effective -X- _ O
compression -X- _ O
framework -X- _ O
tailored -X- _ O
for -X- _ O
lightweight -X- _ O
text -X- _ B-TaskName
- -X- _ I-TaskName
image -X- _ I-TaskName
retrieval -X- _ I-TaskName
; -X- _ O
2 -X- _ O
) -X- _ O
a -X- _ O
leaner -X- _ O
and -X- _ O
faster -X- _ O
model -X- _ O
with -X- _ O
competitive -X- _ O
accuracy -X- _ O
; -X- _ O
3 -X- _ O
) -X- _ O
open -X- _ O
- -X- _ O
sourced -X- _ O
models -X- _ O
and -X- _ O
text -X- _ O
- -X- _ O
to -X- _ O
- -X- _ O
image -X- _ O
search -X- _ O
mobile -X- _ O
applications -X- _ O

Related -X- _ O
Work -X- _ O

Cross -X- _ O
- -X- _ O
encoder -X- _ O
. -X- _ O
Cross -X- _ O
- -X- _ O
encoder -X- _ O
architecture -X- _ O
( -X- _ O
Tan -X- _ O
and -X- _ O
Bansal -X- _ O
, -X- _ O
2019 -X- _ O
; -X- _ O
Li -X- _ O
et -X- _ O
al -X- _ O
. -X- _ O
, -X- _ O
2020 -X- _ O
) -X- _ O
adopts -X- _ O
a -X- _ O
single -X- _ O
Transformer -X- _ O
network -X- _ O
( -X- _ O
Vaswani -X- _ O
et -X- _ O
al -X- _ O
. -X- _ O
, -X- _ O
2017 -X- _ O
) -X- _ O
which -X- _ O
is -X- _ O
able -X- _ O
to -X- _ O
process -X- _ O
inputs -X- _ O
from -X- _ O
different -X- _ O
modalities -X- _ O
, -X- _ O
e.g. -X- _ O
, -X- _ O
images -X- _ O
and -X- _ O
texts -X- _ O
. -X- _ O
Benefitting -X- _ O
from -X- _ O
the -X- _ O
self -X- _ O
- -X- _ O
attention -X- _ O
mechanism -X- _ O
, -X- _ O
the -X- _ O
hidden -X- _ O
states -X- _ O
of -X- _ O
images -X- _ O
and -X- _ O
texts -X- _ O
interact -X- _ O
with -X- _ O
each -X- _ O
other -X- _ O
at -X- _ O
the -X- _ O
patch -X- _ O
/ -X- _ O
token -X- _ O
- -X- _ O
level -X- _ O
, -X- _ O
therefore -X- _ O
yielding -X- _ O
state -X- _ O
- -X- _ O
ofthe -X- _ O
- -X- _ O
art -X- _ O
retrieval -X- _ O
accuracy -X- _ O
. -X- _ O
Though -X- _ O
effective -X- _ O
, -X- _ O
these -X- _ O
models -X- _ O
suffer -X- _ O
from -X- _ O
huge -X- _ O
memory -X- _ O
consumption -X- _ O
and -X- _ O
inference -X- _ O
latency -X- _ O
, -X- _ O
making -X- _ O
them -X- _ O
inpractical -X- _ O
in -X- _ O
timesensitive -X- _ O
real -X- _ O
- -X- _ O
world -X- _ O
scenarios -X- _ O
. -X- _ O

Dual -X- _ O
- -X- _ O
encoder -X- _ O
. -X- _ O
In -X- _ O
contrast -X- _ O
to -X- _ O
cross -X- _ O
- -X- _ O
encoder -X- _ O
, -X- _ O
dual -X- _ O
- -X- _ O
encoder -X- _ O
architecture -X- _ O
( -X- _ O
Radford -X- _ O
et -X- _ O
al -X- _ O
. -X- _ O
, -X- _ O
2021 -X- _ O
; -X- _ O
Jia -X- _ O
et -X- _ O
al -X- _ O
. -X- _ O
, -X- _ O
2021 -X- _ O
) -X- _ O
trains -X- _ O
two -X- _ O
seperate -X- _ O
encoders -X- _ O
for -X- _ O
vision -X- _ O
and -X- _ O
language -X- _ O
modalities -X- _ O
. -X- _ O
The -X- _ O
exact -X- _ O
choices -X- _ O
of -X- _ O
encoder -X- _ O
architecture -X- _ O
may -X- _ O
be -X- _ O
different -X- _ O
. -X- _ O
For -X- _ O
example -X- _ O
, -X- _ O
CLIP -X- _ B-MethodName
utilizes -X- _ O
Transformers -X- _ O
for -X- _ O
both -X- _ O
visual -X- _ O
and -X- _ O
text -X- _ O
encoders -X- _ O
, -X- _ O
while -X- _ O
ALIGN -X- _ B-MethodName
( -X- _ O
Jia -X- _ O
et -X- _ O
al -X- _ O
. -X- _ O
, -X- _ O
2021 -X- _ O
) -X- _ O
uses -X- _ O
pre -X- _ O
- -X- _ O
trained -X- _ O
BERT -X- _ O
as -X- _ O
text -X- _ O
encoder -X- _ O
and -X- _ O
Effi -X- _ O
- -X- _ O
cientNet -X- _ O
as -X- _ O
visual -X- _ O
encoder -X- _ O
. -X- _ O
In -X- _ O
dual -X- _ O
encoder -X- _ O
, -X- _ O
interactions -X- _ O
between -X- _ O
different -X- _ O
modalities -X- _ O
take -X- _ O
place -X- _ O
only -X- _ O
at -X- _ O
the -X- _ O
final -X- _ O
encoder -X- _ O
layer -X- _ O
, -X- _ O
resulting -X- _ O
in -X- _ O
slightly -X- _ O
worse -X- _ O
performance -X- _ O
compared -X- _ O
to -X- _ O
cross -X- _ O
- -X- _ O
encoders -X- _ O
. -X- _ O
Nevertheless -X- _ O
, -X- _ O
this -X- _ O
late -X- _ O
- -X- _ O
interaction -X- _ O
scheme -X- _ O
of -X- _ O
dualencoder -X- _ O
allows -X- _ O
for -X- _ O
efficient -X- _ O
similarity -X- _ O
computation -X- _ O
, -X- _ O
thus -X- _ O
rendering -X- _ O
it -X- _ O
suitable -X- _ O
for -X- _ O
prividing -X- _ O
real -X- _ O
- -X- _ O
time -X- _ O
searching -X- _ O
. -X- _ O

Approach -X- _ O

Background -X- _ O
on -X- _ O
Dual -X- _ O
- -X- _ O
Encoder -X- _ O

Dual -X- _ O
- -X- _ O
encoder -X- _ O
architecture -X- _ O
employs -X- _ O
two -X- _ O
separate -X- _ O
neural -X- _ O
networks -X- _ O
to -X- _ O
encode -X- _ O
inputs -X- _ O
from -X- _ O
different -X- _ O
modalities -X- _ O
and -X- _ O
map -X- _ O
them -X- _ O
to -X- _ O
a -X- _ O
shared -X- _ O
space -X- _ O
. -X- _ O

We -X- _ O
denote -X- _ O
the -X- _ O
image -X- _ O
encoder -X- _ O
as -X- _ O
f -X- _ O
v -X- _ O
and -X- _ O
the -X- _ O
text -X- _ O
encoder -X- _ O
as -X- _ O
f -X- _ O
t -X- _ O
in -X- _ O
the -X- _ O
context -X- _ O
of -X- _ O
text -X- _ O
- -X- _ O
image -X- _ O
retrieval -X- _ O
. -X- _ O
To -X- _ O
train -X- _ O
f -X- _ O
v -X- _ O
and -X- _ O
f -X- _ O
t -X- _ O
, -X- _ O
it -X- _ O
is -X- _ O
common -X- _ O
to -X- _ O
adopt -X- _ O
an -X- _ O
objective -X- _ O
that -X- _ O
pushes -X- _ O
the -X- _ O
embeddings -X- _ O
of -X- _ O
matched -X- _ O
text -X- _ O
- -X- _ O
image -X- _ O
pairs -X- _ O
closer -X- _ O
while -X- _ O
pushing -X- _ O
those -X- _ O
of -X- _ O
non -X- _ O
- -X- _ O
matched -X- _ O
text -X- _ O
- -X- _ O
image -X- _ O
pairs -X- _ O
apart -X- _ O
. -X- _ O
Specifically -X- _ O
, -X- _ O
Contrastive -X- _ O
Language -X- _ O
- -X- _ O
Image -X- _ O
Pretraining -X- _ O
( -X- _ O
CLIP -X- _ B-MethodName
) -X- _ O
( -X- _ O
Radford -X- _ O
et -X- _ O
al -X- _ O
. -X- _ O
, -X- _ O
2021 -X- _ O
) -X- _ O
optimizes -X- _ O
an -X- _ O
InfoNCE -X- _ O
( -X- _ O
van -X- _ O
den -X- _ O
Oord -X- _ O
et -X- _ O
al -X- _ O
. -X- _ O
, -X- _ O
2018 -X- _ O
) -X- _ O
loss -X- _ O
: -X- _ O

Here -X- _ O
, -X- _ O
f -X- _ O
t -X- _ O
( -X- _ O
x -X- _ O
i -X- _ O
) -X- _ O
and -X- _ O
f -X- _ O
v -X- _ O
( -X- _ O
y -X- _ O
j -X- _ O
) -X- _ O
are -X- _ O
the -X- _ O
L2 -X- _ O
- -X- _ O
normalized -X- _ O
embeddings -X- _ O
of -X- _ O
text -X- _ O
in -X- _ O
the -X- _ O
i -X- _ O
- -X- _ O
th -X- _ O
pair -X- _ O
and -X- _ O
image -X- _ O
in -X- _ O
the -X- _ O
j -X- _ O
- -X- _ O
th -X- _ O
pair -X- _ O
. -X- _ O
N -X- _ O
is -X- _ O
the -X- _ O
mini -X- _ O
- -X- _ O
batch -X- _ O
size -X- _ O
and -X- _ O
τ -X- _ O
is -X- _ O
the -X- _ O
temperature -X- _ O
to -X- _ O
scale -X- _ O
the -X- _ O
logits -X- _ O
. -X- _ O
The -X- _ O
final -X- _ O
objective -X- _ O
is -X- _ O
the -X- _ O
sum -X- _ O
of -X- _ O
L -X- _ O
t2v -X- _ O
and -X- _ O
its -X- _ O
symmetric -X- _ O
version -X- _ O
L -X- _ O
v2 -X- _ O
t -X- _ O
. -X- _ O

Despite -X- _ O
good -X- _ O
retrieval -X- _ O
accuracy -X- _ O
, -X- _ O
models -X- _ O
like -X- _ O
CLIP -X- _ B-MethodName
still -X- _ O
pose -X- _ O
non -X- _ O
- -X- _ O
trivial -X- _ O
memory -X- _ O
footprint -X- _ O
and -X- _ O
inference -X- _ O
time -X- _ O
, -X- _ O
which -X- _ O
is -X- _ O
undesirable -X- _ O
for -X- _ O
low -X- _ O
- -X- _ O
resource -X- _ O
devices -X- _ O
such -X- _ O
as -X- _ O
smart -X- _ O
phones -X- _ O
. -X- _ O

To -X- _ O
tackle -X- _ O
this -X- _ O
issue -X- _ O
, -X- _ O
we -X- _ O
propose -X- _ O
a -X- _ O
two -X- _ B-MethodName
- -X- _ I-MethodName
stage -X- _ I-MethodName
compression -X- _ I-MethodName
framework -X- _ I-MethodName
to -X- _ O
make -X- _ O
large -X- _ O
dual -X- _ O
- -X- _ O
encoder -X- _ O
model -X- _ O
smaller -X- _ O
and -X- _ O
faster -X- _ O
while -X- _ O
retaining -X- _ O
its -X- _ O
accuracy -X- _ B-MetricName
. -X- _ O
A -X- _ O
schematic -X- _ O
overview -X- _ O
is -X- _ O
illustrated -X- _ O
in -X- _ O
Figure -X- _ O
1 -X- _ O
. -X- _ O
The -X- _ O
first -X- _ O
stage -X- _ O
is -X- _ O
task -X- _ O
- -X- _ O
agnostic -X- _ O
, -X- _ O
where -X- _ O
we -X- _ O
leverage -X- _ O
massively -X- _ O
available -X- _ O
non -X- _ O
- -X- _ O
paired -X- _ O
texts -X- _ O
/ -X- _ O
images -X- _ O
to -X- _ O
separately -X- _ O
compress -X- _ O
the -X- _ O
text -X- _ O
/ -X- _ O
image -X- _ O
encoder -X- _ O
using -X- _ O
an -X- _ O
intra -X- _ O
- -X- _ O
modal -X- _ O
contrastive -X- _ O
knowledge -X- _ O
distillation -X- _ O
scheme -X- _ O
. -X- _ O
The -X- _ O
second -X- _ O
stage -X- _ O
is -X- _ O
task -X- _ O
- -X- _ O
specific -X- _ O
, -X- _ O
where -X- _ O
we -X- _ O
sequentially -X- _ O
fine -X- _ O
- -X- _ O
tune -X- _ O
the -X- _ O
distilled -X- _ O
image -X- _ O
and -X- _ O
text -X- _ O
encoder -X- _ O
using -X- _ O
a -X- _ O
combination -X- _ O
of -X- _ O
multiple -X- _ O
techniques -X- _ O
. -X- _ O
We -X- _ O
denote -X- _ O
the -X- _ O
image -X- _ O
and -X- _ O
text -X- _ O
encoder -X- _ O
of -X- _ O
the -X- _ O
large -X- _ O
dual -X- _ O
- -X- _ O
encoder -X- _ O
as -X- _ O
f -X- _ O
T -X- _ O
v -X- _ O
and -X- _ O
f -X- _ O
T -X- _ O
t -X- _ O
and -X- _ O
those -X- _ O
of -X- _ O
the -X- _ O
compressed -X- _ O
model -X- _ O
as -X- _ O
f -X- _ O
S -X- _ O
v -X- _ O
and -X- _ O
f -X- _ O
S -X- _ O
t -X- _ O
. -X- _ O

The -X- _ O
extremely -X- _ O
large -X- _ O
scale -X- _ O
of -X- _ O
text -X- _ O
- -X- _ O
image -X- _ O
pairs -X- _ O
( -X- _ O
e.g. -X- _ O
, -X- _ O
400 -X- _ O
million -X- _ O
used -X- _ O
to -X- _ O
train -X- _ O
CLIP -X- _ B-MethodName
) -X- _ O
makes -X- _ O
it -X- _ O
possible -X- _ O
to -X- _ O
make -X- _ O
up -X- _ O
for -X- _ O
the -X- _ O
noise -X- _ O
in -X- _ O
data -X- _ O
and -X- _ O
train -X- _ O
overparametrized -X- _ O
large -X- _ O
dual -X- _ O
- -X- _ O
encoder -X- _ O
( -X- _ O
i.e. -X- _ O
, -X- _ O
f -X- _ O
T -X- _ O
v -X- _ O
and -X- _ O
f -X- _ O
T -X- _ O
t -X- _ O
) -X- _ O
from -X- _ O
scratch -X- _ O
to -X- _ O
learn -X- _ O
aligned -X- _ O
visual -X- _ O
and -X- _ O
language -X- _ O
representations -X- _ O
. -X- _ O
However -X- _ O
, -X- _ O
it -X- _ O
is -X- _ O
difficult -X- _ O
to -X- _ O
train -X- _ O
small -X- _ O
model -X- _ O
( -X- _ O
i.e. -X- _ O
, -X- _ O
f -X- _ O
S -X- _ O
v -X- _ O
and -X- _ O
f -X- _ O
S -X- _ O
t -X- _ O
) -X- _ O
with -X- _ O
lower -X- _ O
capacity -X- _ O
using -X- _ O
the -X- _ O
same -X- _ O
inter -X- _ O
- -X- _ O
modal -X- _ O
learning -X- _ O
scheme -X- _ O
. -X- _ O

To -X- _ O
circumvent -X- _ O
this -X- _ O
issue -X- _ O
, -X- _ O
we -X- _ O
propose -X- _ O
to -X- _ O
exploit -X- _ O
massively -X- _ O
available -X- _ O
non -X- _ O
- -X- _ O
paired -X- _ O
data -X- _ O
from -X- _ O
the -X- _ O
web -X- _ O
and -X- _ O
optimize -X- _ O
an -X- _ O
intra -X- _ O
- -X- _ O
modal -X- _ O
contrastive -X- _ O
objective -X- _ O
that -X- _ O
aligns -X- _ O
the -X- _ O
output -X- _ O
embeddings -X- _ O
of -X- _ O
f -X- _ O
S -X- _ O
and -X- _ O
pretrained -X- _ O
f -X- _ O
T -X- _ O
, -X- _ O
which -X- _ O
can -X- _ O
be -X- _ O
seen -X- _ O
as -X- _ O
a -X- _ O
form -X- _ O
of -X- _ O
knowledge -X- _ O
distillation -X- _ O
( -X- _ O
Hinton -X- _ O
et -X- _ O
al -X- _ O
. -X- _ O
, -X- _ O
2015 -X- _ O
) -X- _ O
. -X- _ O
Here -X- _ O
we -X- _ O
take -X- _ O
visual -X- _ O
modality -X- _ O
as -X- _ O
an -X- _ O
example -X- _ O
. -X- _ O
Given -X- _ O
a -X- _ O
collection -X- _ O
of -X- _ O
images -X- _ O
{ -X- _ O
y -X- _ O
i -X- _ O
} -X- _ O
N -X- _ O
i=1 -X- _ O
, -X- _ O
we -X- _ O
feed -X- _ O
them -X- _ O
to -X- _ O
both -X- _ O
f -X- _ O
S -X- _ O
v -X- _ O
and -X- _ O
f -X- _ O
T -X- _ O
v -X- _ O
to -X- _ O
produce -X- _ O
two -X- _ O
sets -X- _ O
of -X- _ O
image -X- _ O
embeddings -X- _ O
{ -X- _ O
f -X- _ O
S -X- _ O
v -X- _ O
( -X- _ O
y -X- _ O
i -X- _ O
) -X- _ O
} -X- _ O
N -X- _ O
i=1 -X- _ O
and -X- _ O
{ -X- _ O
f -X- _ O
T -X- _ O
v -X- _ O
( -X- _ O
y -X- _ O
i -X- _ O
) -X- _ O
} -X- _ O
N -X- _ O
i=1 -X- _ O
. -X- _ O
Then -X- _ O
we -X- _ O
optimize -X- _ O
the -X- _ O
following -X- _ O
contrastive -X- _ O
objective -X- _ O
for -X- _ O
updating -X- _ O
f -X- _ O
S -X- _ O
v -X- _ O
: -X- _ O

The -X- _ O
same -X- _ O
formulation -X- _ O
is -X- _ O
symmetrically -X- _ O
applied -X- _ O
to -X- _ O
language -X- _ O
modality -X- _ O
to -X- _ O
obtain -X- _ O
L -X- _ O
t2 -X- _ O
t -X- _ O
for -X- _ O
updating -X- _ O
f -X- _ O
S -X- _ O
t -X- _ O
: -X- _ O

Essentially -X- _ O
, -X- _ O
f -X- _ O
S -X- _ O
v -X- _ O
/ -X- _ O
f -X- _ O
S -X- _ O
t -X- _ O
is -X- _ O
trained -X- _ O
to -X- _ O
recover -X- _ O
the -X- _ O
representation -X- _ O
power -X- _ O
of -X- _ O
f -X- _ O
T -X- _ O
v -X- _ O
/ -X- _ O
f -X- _ O
T -X- _ O
t -X- _ O
in -X- _ O
a -X- _ O
decoupled -X- _ O
manner -X- _ O
. -X- _ O

After -X- _ O
training -X- _ O
f -X- _ O
S -X- _ O
v -X- _ O
and -X- _ O
f -X- _ O
S -X- _ O
t -X- _ O
using -X- _ O
general -X- _ O
- -X- _ O
domain -X- _ O
data -X- _ O
, -X- _ O
it -X- _ O
is -X- _ O
necessary -X- _ O
to -X- _ O
adapt -X- _ O
the -X- _ O
learned -X- _ O
representations -X- _ O
to -X- _ O
downstream -X- _ O
tasks -X- _ O
using -X- _ O
in -X- _ O
- -X- _ O
domain -X- _ O
data -X- _ O
. -X- _ O
First -X- _ O
, -X- _ O
we -X- _ O
fine -X- _ O
- -X- _ O
tune -X- _ O
f -X- _ O
T -X- _ O
v -X- _ O
and -X- _ O
f -X- _ O
T -X- _ O
t -X- _ O
on -X- _ O
paired -X- _ O
text -X- _ O
- -X- _ O
image -X- _ O
data -X- _ O
D -X- _ O
= -X- _ O
{ -X- _ O
( -X- _ O
x -X- _ O
i -X- _ O
, -X- _ O
y -X- _ O
i -X- _ O
) -X- _ O
} -X- _ O
N -X- _ O
i=1 -X- _ O
using -X- _ O
standard -X- _ O
InfoNCE -X- _ O
loss -X- _ O
( -X- _ O
Section -X- _ O
3.1 -X- _ O
) -X- _ O
. -X- _ O
In -X- _ O
the -X- _ O
experiments -X- _ O
, -X- _ O
we -X- _ O
found -X- _ O
that -X- _ O
jointly -X- _ O
fine -X- _ O
- -X- _ O
tuning -X- _ O
image -X- _ O
and -X- _ O
text -X- _ O
encoder -X- _ O
results -X- _ O
in -X- _ O
retrieval -X- _ B-TaskName
performance -X- _ O
even -X- _ O
worse -X- _ O
than -X- _ O
no -X- _ O
fine -X- _ O
- -X- _ O
tuning -X- _ O
at -X- _ O
all -X- _ O
. -X- _ O
Therefore -X- _ O
, -X- _ O
we -X- _ O
choose -X- _ O
to -X- _ O
sequentially -X- _ O
fine -X- _ O
- -X- _ O
tune -X- _ O
f -X- _ O
T -X- _ O
v -X- _ O
/ -X- _ O
f -X- _ O
T -X- _ O
t -X- _ O
by -X- _ O
fixing -X- _ O
the -X- _ O
other -X- _ O
one -X- _ O
. -X- _ O
The -X- _ O
resulting -X- _ O
fine -X- _ O
- -X- _ O
tuned -X- _ O
encoders -X- _ O
are -X- _ O
denoted -X- _ O
as -X- _ O
f -X- _ O
T -X- _ O
v -X- _ O
and -X- _ O
f -X- _ O
T -X- _ O
t -X- _ O
and -X- _ O
are -X- _ O
henceforth -X- _ O
kept -X- _ O
fixed -X- _ O
. -X- _ O
Next -X- _ O
, -X- _ O
for -X- _ O
training -X- _ O
f -X- _ O
S -X- _ O
v -X- _ O
and -X- _ O
f -X- _ O
S -X- _ O
t -X- _ O
, -X- _ O
we -X- _ O
propose -X- _ O
several -X- _ O
techniques -X- _ O
essential -X- _ O
to -X- _ O
successful -X- _ O
compression -X- _ O
: -X- _ O
Knowledge -X- _ O
Distillation -X- _ O
( -X- _ O
KD -X- _ O
) -X- _ O
. -X- _ O
In -X- _ O
addition -X- _ O
to -X- _ O
the -X- _ O
standard -X- _ O
InfoNCE -X- _ O
loss -X- _ O
, -X- _ O
we -X- _ O
design -X- _ O
two -X- _ O
kinds -X- _ O
of -X- _ O
knowledge -X- _ O
distillation -X- _ O
objectives -X- _ O
to -X- _ O
learn -X- _ O
from -X- _ O
f -X- _ O
T -X- _ O
v -X- _ O
and -X- _ O
f -X- _ O
T -X- _ O
t -X- _ O
. -X- _ O
One -X- _ O
is -X- _ O
the -X- _ O
Kullback -X- _ O
- -X- _ O
Leibler -X- _ O
divergence -X- _ O
between -X- _ O
image -X- _ O
- -X- _ O
text -X- _ O
matching -X- _ O
distribution -X- _ O
predicted -X- _ O
by -X- _ O
f -X- _ O
T -X- _ O
v -X- _ O
and -X- _ O
f -X- _ O
T -X- _ O
t -X- _ O
and -X- _ O
the -X- _ O
one -X- _ O
predicted -X- _ O
by -X- _ O
f -X- _ O
S -X- _ O
v -X- _ O
and -X- _ O
f -X- _ O
S -X- _ O
t -X- _ O
. -X- _ O
This -X- _ O
resembles -X- _ O
previous -X- _ O
response -X- _ O
- -X- _ O
based -X- _ O
knowledge -X- _ O
distillation -X- _ O
( -X- _ O
Hinton -X- _ O
et -X- _ O
al -X- _ O
. -X- _ O
, -X- _ O
2015 -X- _ O
) -X- _ O
. -X- _ O
The -X- _ O
other -X- _ O
is -X- _ O
the -X- _ O
same -X- _ O
contrastive -X- _ O
objective -X- _ O
defined -X- _ O
in -X- _ O
Section -X- _ O
3.2.1 -X- _ O
. -X- _ O
It -X- _ O
indirectly -X- _ O
encourages -X- _ O
the -X- _ O
alingment -X- _ O
between -X- _ O
visual -X- _ O
and -X- _ O
language -X- _ O
representations -X- _ O
. -X- _ O
Sequential -X- _ O
Finetuning -X- _ O
( -X- _ O
SF -X- _ O
) -X- _ O
. -X- _ O
Similar -X- _ O
to -X- _ O
how -X- _ O
we -X- _ O
get -X- _ O
f -X- _ O
T -X- _ O
v -X- _ O
and -X- _ O
f -X- _ O
T -X- _ O
t -X- _ O
, -X- _ O
we -X- _ O
also -X- _ O
fine -X- _ O
- -X- _ O
tune -X- _ O
f -X- _ O
S -X- _ O
v -X- _ O
and -X- _ O
f -X- _ O
S -X- _ O
t -X- _ O
in -X- _ O
a -X- _ O
sequential -X- _ O
manner -X- _ O
. -X- _ O
Concretely -X- _ O
, -X- _ O
we -X- _ O
first -X- _ O
let -X- _ O
the -X- _ O
compressed -X- _ O
model -X- _ O
share -X- _ O
the -X- _ O
same -X- _ O
text -X- _ O
encoder -X- _ O
with -X- _ O
the -X- _ O
target -X- _ O
dual -X- _ O
- -X- _ O
encoder -X- _ O
and -X- _ O
only -X- _ O
fine -X- _ O
- -X- _ O
tune -X- _ O
its -X- _ O
image -X- _ O
encoder -X- _ O
. -X- _ O
After -X- _ O
that -X- _ O
, -X- _ O
we -X- _ O
then -X- _ O
fix -X- _ O
the -X- _ O
image -X- _ O
encoder -X- _ O
and -X- _ O
fine -X- _ O
- -X- _ O
tune -X- _ O
its -X- _ O
text -X- _ O
encoder -X- _ O
in -X- _ O
the -X- _ O
same -X- _ O
way -X- _ O
. -X- _ O
Hard -X- _ O
Negative -X- _ O
Mining -X- _ O
( -X- _ O
HN -X- _ O
) -X- _ O
. -X- _ O
Prior -X- _ O
works -X- _ O
on -X- _ O
contrastive -X- _ O
representation -X- _ O
learning -X- _ O
( -X- _ O
Chen -X- _ O
et -X- _ O
al -X- _ O
. -X- _ O
, -X- _ O
2020 -X- _ O
; -X- _ O
Gao -X- _ O
et -X- _ O
al -X- _ O
. -X- _ O
, -X- _ O
2021 -X- _ O
) -X- _ O
typically -X- _ O
exploit -X- _ O
in -X- _ O
- -X- _ O
batch -X- _ O
negative -X- _ O
samples -X- _ O
. -X- _ O
Though -X- _ O
efficient -X- _ O
, -X- _ O
image -X- _ O
- -X- _ O
text -X- _ O
pairs -X- _ O
in -X- _ O
a -X- _ O
batch -X- _ O
are -X- _ O
randomly -X- _ O
sampled -X- _ O
and -X- _ O
are -X- _ O
likely -X- _ O
to -X- _ O
be -X- _ O
trivially -X- _ O
unrelated -X- _ O
. -X- _ O
Models -X- _ O
trained -X- _ O
in -X- _ O
such -X- _ O
a -X- _ O
way -X- _ O
may -X- _ O
fail -X- _ O
in -X- _ O
cases -X- _ O
where -X- _ O
candidates -X- _ O
are -X- _ O
similar -X- _ O
. -X- _ O
To -X- _ O
achieve -X- _ O
more -X- _ O
accurate -X- _ O
retrieval -X- _ B-TaskName
, -X- _ O
we -X- _ O
mine -X- _ O
hard -X- _ O
negatives -X- _ O
from -X- _ O
the -X- _ O
entire -X- _ O
corpus -X- _ O
. -X- _ O
In -X- _ O
our -X- _ O
sequential -X- _ O
fine -X- _ O
- -X- _ O
tuning -X- _ O
setting -X- _ O
, -X- _ O
we -X- _ O
first -X- _ O
use -X- _ O
f -X- _ O
T -X- _ O
t -X- _ O
to -X- _ O
compute -X- _ O
embeddings -X- _ O
of -X- _ O
all -X- _ O
texts -X- _ O
in -X- _ O
the -X- _ O
corpus -X- _ O
and -X- _ O
index -X- _ O
them -X- _ O
with -X- _ O
Faiss -X- _ O
( -X- _ O
Johnson -X- _ O
et -X- _ O
al -X- _ O
. -X- _ O
, -X- _ O
2017 -X- _ O
) -X- _ O
. -X- _ O
During -X- _ O
training -X- _ O
f -X- _ O
S -X- _ O
v -X- _ O
, -X- _ O
for -X- _ O
each -X- _ O
image -X- _ O
y -X- _ O
i -X- _ O
we -X- _ O
use -X- _ O
f -X- _ O
S -X- _ O
v -X- _ O
( -X- _ O
y -X- _ O
i -X- _ O
) -X- _ O
as -X- _ O
query -X- _ O
to -X- _ O
the -X- _ O
index -X- _ O
and -X- _ O
obtain -X- _ O
its -X- _ O
top -X- _ O
- -X- _ O
k -X- _ O
texts -X- _ O
as -X- _ O
negative -X- _ O
samples -X- _ O
. -X- _ O
Afterward -X- _ O
, -X- _ O
we -X- _ O
use -X- _ O
the -X- _ O
trained -X- _ O
f -X- _ O
S -X- _ O
v -X- _ O
to -X- _ O
compute -X- _ O
embeddings -X- _ O
of -X- _ O
all -X- _ O
images -X- _ O
in -X- _ O
the -X- _ O
corpus -X- _ O
and -X- _ O
build -X- _ O
the -X- _ O
index -X- _ O
. -X- _ O
During -X- _ O
training -X- _ O
f -X- _ O
S -X- _ O
t -X- _ O
, -X- _ O
for -X- _ O
each -X- _ O
text -X- _ O
x -X- _ O
i -X- _ O
we -X- _ O
use -X- _ O
f -X- _ O
S -X- _ O
t -X- _ O
( -X- _ O
x -X- _ O
i -X- _ O
) -X- _ O
as -X- _ O
query -X- _ O
to -X- _ O
the -X- _ O
index -X- _ O
and -X- _ O
get -X- _ O
its -X- _ O
top -X- _ O
- -X- _ O
k -X- _ O
images -X- _ O
as -X- _ O
negative -X- _ O
samples -X- _ O
. -X- _ O

The -X- _ O
complete -X- _ O
training -X- _ O
objective -X- _ O
of -X- _ O
stage-2 -X- _ O
is -X- _ O
defined -X- _ O
as -X- _ O
L -X- _ O
= -X- _ O
L -X- _ O
t2v -X- _ O
+ -X- _ O
L -X- _ O
v2 -X- _ O
t -X- _ O
+ -X- _ O
L -X- _ O
KD -X- _ O
+ -X- _ O
L -X- _ O
HN -X- _ O
. -X- _ O

Experiment -X- _ O

Setup -X- _ O

Implementation -X- _ O
Detail -X- _ O
. -X- _ O
In -X- _ O
stage-1 -X- _ O
, -X- _ O
we -X- _ O
train -X- _ O
1 -X- _ B-HyperparameterValue
epoch -X- _ B-HyperparameterName
using -X- _ O
AdamW -X- _ O
( -X- _ O
Loshchilov -X- _ O
and -X- _ O
Hutter -X- _ O
, -X- _ O
2017 -X- _ O
) -X- _ O
with -X- _ O
a -X- _ O
batch -X- _ B-HyperparameterName
size -X- _ I-HyperparameterName
of -X- _ O
84 -X- _ B-HyperparameterValue
for -X- _ O
both -X- _ O
images -X- _ O
and -X- _ O
texts -X- _ O
, -X- _ O
learning -X- _ B-HyperparameterName
rate -X- _ I-HyperparameterName
of -X- _ O
3e-4 -X- _ B-HyperparameterValue
, -X- _ O
and -X- _ O
weight -X- _ B-HyperparameterName
decay -X- _ I-HyperparameterName
of -X- _ O
0.1 -X- _ B-HyperparameterValue
. -X- _ O
In -X- _ O
stage-2 -X- _ O
, -X- _ O
we -X- _ O
use -X- _ O
the -X- _ O
same -X- _ O
optimization -X- _ O
setting -X- _ O
except -X- _ O
that -X- _ O
we -X- _ O
train -X- _ O
with -X- _ O
batch -X- _ B-HyperparameterName
size -X- _ I-HyperparameterName
96 -X- _ B-HyperparameterValue
for -X- _ O
5 -X- _ B-HyperparameterValue
epochs -X- _ B-HyperparameterName
. -X- _ O
We -X- _ O
employ -X- _ O
a -X- _ O
cosine -X- _ O
learning -X- _ O
rate -X- _ O
scheduler -X- _ O
with -X- _ O
10,000 -X- _ B-HyperparameterValue
warm -X- _ B-HyperparameterName
- -X- _ I-HyperparameterName
up -X- _ I-HyperparameterName
steps -X- _ I-HyperparameterName
for -X- _ O
both -X- _ O
stages -X- _ O
. -X- _ O
All -X- _ O
reported -X- _ O
results -X- _ O
are -X- _ O
calculated -X- _ O
on -X- _ O
the -X- _ O
test -X- _ O
set -X- _ O
using -X- _ O
checkpoints -X- _ O
with -X- _ O
the -X- _ O
highest -X- _ O
validation -X- _ O
performance -X- _ O
. -X- _ O

Results -X- _ O

Main -X- _ O
Results -X- _ O
. -X- _ O
Table -X- _ O
1 -X- _ O
summarizes -X- _ O
the -X- _ O
main -X- _ O
results -X- _ O
. -X- _ O
As -X- _ O
can -X- _ O
be -X- _ O
observed -X- _ O
, -X- _ O
the -X- _ O
pre -X- _ O
- -X- _ O
trained -X- _ O
CLIP -X- _ B-MethodName
model -X- _ O
can -X- _ O
already -X- _ O
deliver -X- _ O
moderately -X- _ O
good -X- _ O
retrieval -X- _ B-TaskName
performance -X- _ O
. -X- _ O
The -X- _ O
performance -X- _ O
is -X- _ O
further -X- _ O
improved -X- _ O
after -X- _ O
fine -X- _ O
- -X- _ O
tuning -X- _ O
. -X- _ O
Fine -X- _ O
- -X- _ O
tuning -X- _ O
pre -X- _ O
- -X- _ O
trained -X- _ O
ViT -X- _ B-MethodName
- -X- _ I-MethodName
S -X- _ I-MethodName
/ -X- _ I-MethodName
16 -X- _ I-MethodName
and -X- _ I-MethodName
TinyBERT -X- _ I-MethodName
underperforms -X- _ O
the -X- _ O
zeroshot -X- _ O
CLIP -X- _ B-MethodName
, -X- _ O
showing -X- _ O
that -X- _ O
training -X- _ O
with -X- _ O
inter -X- _ O
- -X- _ O
modal -X- _ O
InfoNCE -X- _ O
is -X- _ O
not -X- _ O
effective -X- _ O
without -X- _ O
extremely -X- _ O
largescale -X- _ O
paired -X- _ O
data -X- _ O
. -X- _ O
On -X- _ O
most -X- _ O
evaluation -X- _ O
metrics -X- _ O
, -X- _ O
models -X- _ O
compressed -X- _ O
by -X- _ O
our -X- _ O
proposed -X- _ O
two -X- _ B-MethodName
- -X- _ I-MethodName
stage -X- _ I-MethodName
pipeline -X- _ I-MethodName
perform -X- _ O
on -X- _ O
par -X- _ O
with -X- _ O
or -X- _ O
better -X- _ O
than -X- _ O
the -X- _ O
fine -X- _ O
- -X- _ O
tuned -X- _ O
target -X- _ O
model -X- _ O
. -X- _ O
We -X- _ O
also -X- _ O
found -X- _ O
that -X- _ O
the -X- _ O
capacity -X- _ O
of -X- _ O
text -X- _ O
encoder -X- _ O
has -X- _ O
limited -X- _ O
affect -X- _ O
on -X- _ O
the -X- _ O
performance -X- _ O
. -X- _ O

Ablation -X- _ O
Study -X- _ O
. -X- _ O
We -X- _ O
perform -X- _ O
extensive -X- _ O
ablations -X- _ O
to -X- _ O
study -X- _ O
the -X- _ O
importance -X- _ O
of -X- _ O
each -X- _ O
proposed -X- _ O
technique -X- _ O
. -X- _ O
Due -X- _ O
to -X- _ O
the -X- _ O
computational -X- _ O
budget -X- _ O
, -X- _ O
we -X- _ O
only -X- _ O
conduct -X- _ O
ablation -X- _ O
on -X- _ O
the -X- _ O
image -X- _ O
encoder -X- _ O
and -X- _ O
fix -X- _ O
the -X- _ O
text -X- _ O
encoder -X- _ O
as -X- _ O
f -X- _ O
T -X- _ O
t -X- _ O
. -X- _ O
We -X- _ O
evaluate -X- _ O
w -X- _ O
/ -X- _ O
o -X- _ O
stage-1 -X- _ O
, -X- _ O
stage-1 -X- _ O
M -X- _ O
SE -X- _ O
( -X- _ O
mean -X- _ O
- -X- _ O
square -X- _ O
- -X- _ O
error -X- _ O
between -X- _ O
f -X- _ O
S -X- _ O
v -X- _ O
and -X- _ O
f -X- _ O
T -X- _ O
v -X- _ O
) -X- _ O
, -X- _ O
and -X- _ O
stage-1 -X- _ O
Inf -X- _ O
oN -X- _ O
CE -X- _ O
( -X- _ O
identical -X- _ O
to -X- _ O
the -X- _ O
loss -X- _ O
in -X- _ O
Section -X- _ O
3.1 -X- _ O
) -X- _ O
for -X- _ O
stage-1 -X- _ O
ablation -X- _ O
. -X- _ O
We -X- _ O
also -X- _ O
study -X- _ O
the -X- _ O
effectiveness -X- _ O
of -X- _ O
KD -X- _ O
/ -X- _ O
SF -X- _ O
/ -X- _ O
HN -X- _ O
by -X- _ O
removing -X- _ O
them -X- _ O
separately -X- _ O
or -X- _ O
together -X- _ O
. -X- _ O
We -X- _ O
made -X- _ O
several -X- _ O
observations -X- _ O
based -X- _ O
on -X- _ O
Table -X- _ O
2 -X- _ O
: -X- _ O
1 -X- _ O
) -X- _ O
SF -X- _ O
makes -X- _ O
fine -X- _ O
- -X- _ O
tuning -X- _ O
stable -X- _ O
and -X- _ O
is -X- _ O
essential -X- _ O
for -X- _ O
convergence -X- _ O
. -X- _ O
2 -X- _ O
) -X- _ O
both -X- _ O
KD -X- _ O
and -X- _ O
HN -X- _ O
improve -X- _ O
retrieval -X- _ O
accuracy -X- _ O
and -X- _ O
are -X- _ O
complementary -X- _ O
to -X- _ O
each -X- _ O
other -X- _ O
. -X- _ O
3 -X- _ O
) -X- _ O
intra -X- _ O
- -X- _ O
modal -X- _ O
contrastive -X- _ O
distillation -X- _ O
helps -X- _ O
when -X- _ O
image -X- _ O
- -X- _ O
text -X- _ O
pairs -X- _ O
are -X- _ O
noisy -X- _ O
and -X- _ O
outperforms -X- _ O
inter -X- _ O
- -X- _ O
modal -X- _ O
infoNCE -X- _ O
loss -X- _ O
. -X- _ O

Efficiency -X- _ O
. -X- _ O
In -X- _ O
Table -X- _ O
3 -X- _ O
, -X- _ O
we -X- _ O
compare -X- _ O
the -X- _ O
disk -X- _ B-MetricName
space -X- _ I-MetricName
and -X- _ O
QSP -X- _ B-MetricName
used -X- _ O
by -X- _ O
models -X- _ O
on -X- _ O
a -X- _ O
RTX -X- _ O
2080Ti -X- _ O
of -X- _ O
12 -X- _ O
GB -X- _ O
memroy -X- _ O
. -X- _ O
The -X- _ O
compressed -X- _ O
image -X- _ O
encoder -X- _ O
f -X- _ O
S -X- _ O
v -X- _ O
takes -X- _ O
85 -X- _ B-MetricValue
MB -X- _ I-MetricValue
disk -X- _ O
space -X- _ O
( -X- _ O
39 -X- _ B-MetricValue
% -X- _ I-MetricValue
of -X- _ O
f -X- _ O
T -X- _ O
v -X- _ O
) -X- _ O
meanwhile -X- _ O
being -X- _ O
1.51x -X- _ B-MetricValue
times -X- _ O
faster -X- _ O
. -X- _ O
Our -X- _ O
compressed -X- _ O
text -X- _ O
encoder -X- _ O
can -X- _ O
achieve -X- _ O
up -X- _ O
to -X- _ O
x2.77 -X- _ B-MetricValue
inference -X- _ O
speed -X- _ O
- -X- _ O
up -X- _ O
and -X- _ O
40 -X- _ B-MetricValue
% -X- _ I-MetricValue
size -X- _ O
reduction -X- _ O
( -X- _ O
from -X- _ O
243 -X- _ O
MB -X- _ O
to -X- _ O
146 -X- _ B-MetricValue
MB -X- _ I-MetricValue
) -X- _ O
. -X- _ O
We -X- _ O
further -X- _ O
benchmark -X- _ O
models -X- _ O
' -X- _ O
memory -X- _ O
and -X- _ O
runtime -X- _ O
performance -X- _ O
on -X- _ O
a -X- _ O
real -X- _ O
iPhone -X- _ O
X -X- _ O
with -X- _ O
1,000 -X- _ O
images -X- _ O
in -X- _ O
the -X- _ O
gallery -X- _ O
for -X- _ O
testing -X- _ O
. -X- _ O
It -X- _ O
takes -X- _ O
870 -X- _ O
MB -X- _ O
and -X- _ O
295 -X- _ B-MetricValue
MB -X- _ I-MetricValue
for -X- _ O
loading -X- _ O
CLIP -X- _ B-MethodName
and -X- _ O
our -X- _ O
compressed -X- _ O
model -X- _ O
into -X- _ O
main -X- _ O
memory -X- _ O
respectively -X- _ O
. -X- _ O
After -X- _ O
indexing -X- _ O
, -X- _ O
the -X- _ O
response -X- _ B-MetricName
time -X- _ I-MetricName
for -X- _ O
a -X- _ O
single -X- _ O
text -X- _ O
query -X- _ O
is -X- _ O
0.4s -X- _ O
for -X- _ O
CLIP -X- _ B-MethodName
while -X- _ O
it -X- _ O
is -X- _ O
only -X- _ O
0.1s -X- _ B-MetricValue
for -X- _ O
our -X- _ O
compressed -X- _ O
model -X- _ O
. -X- _ O
Although -X- _ O
the -X- _ O
results -X- _ O
are -X- _ O
hardwarddependent -X- _ O
, -X- _ O
our -X- _ O
compressed -X- _ O
model -X- _ O
still -X- _ O
shows -X- _ O
an -X- _ O
evident -X- _ O
improvement -X- _ O
in -X- _ O
efficiency -X- _ O
. -X- _ O

Conclusion -X- _ O

In -X- _ O
this -X- _ O
paper -X- _ O
, -X- _ O
we -X- _ O
present -X- _ O
a -X- _ O
two -X- _ B-MethodName
- -X- _ I-MethodName
stage -X- _ I-MethodName
framework -X- _ I-MethodName
for -X- _ O
lightweight -X- _ O
text -X- _ B-TaskName
- -X- _ I-TaskName
image -X- _ I-TaskName
retrieval -X- _ I-TaskName
. -X- _ O
Experiments -X- _ O
on -X- _ O
two -X- _ O
benchmarks -X- _ O
show -X- _ O
the -X- _ O
effectiveness -X- _ O
of -X- _ O
each -X- _ O
component -X- _ O
in -X- _ O
the -X- _ O
framework -X- _ O
and -X- _ O
the -X- _ O
best -X- _ O
performance -X- _ O
is -X- _ O
achieved -X- _ O
when -X- _ O
combining -X- _ O
them -X- _ O
together -X- _ O
. -X- _ O
It -X- _ O
holds -X- _ O
the -X- _ O
merit -X- _ O
of -X- _ O
reducing -X- _ O
model -X- _ O
size -X- _ O
and -X- _ O
accelerating -X- _ O
inference -X- _ O
time -X- _ O
, -X- _ O
making -X- _ O
memory -X- _ O
/ -X- _ O
responsesensitive -X- _ O
applications -X- _ O
more -X- _ O
practical -X- _ O
. -X- _ O

Acknowledgement -X- _ O

This -X- _ O
research -X- _ O
is -X- _ O
partially -X- _ O
supported -X- _ O
by -X- _ O
NSFC -X- _ O
Grant -X- _ O
No -X- _ O
. -X- _ O
91646205 -X- _ O
, -X- _ O
and -X- _ O
SJTU -X- _ O
- -X- _ O
CMBCC -X- _ O
Joint -X- _ O
Research -X- _ O
Scheme -X- _ O

Enhancing -X- _ O
Dialogue -X- _ B-TaskName
Generation -X- _ I-TaskName
via -X- _ O
Dynamic -X- _ B-MethodName
Graph -X- _ I-MethodName
Knowledge -X- _ I-MethodName
Aggregation -X- _ I-MethodName

Incorporating -X- _ O
external -X- _ O
graph -X- _ O
knowledge -X- _ O
into -X- _ O
neural -X- _ O
chatbot -X- _ O
models -X- _ O
has -X- _ O
been -X- _ O
proven -X- _ O
effective -X- _ O
for -X- _ O
enhancing -X- _ O
dialogue -X- _ B-TaskName
generation -X- _ I-TaskName
. -X- _ O
However -X- _ O
, -X- _ O
in -X- _ O
conventional -X- _ B-MethodName
graph -X- _ I-MethodName
neural -X- _ I-MethodName
networks -X- _ I-MethodName
( -X- _ O
GNNs -X- _ B-MethodName
) -X- _ O
, -X- _ O
message -X- _ O
passing -X- _ O
on -X- _ O
a -X- _ O
graph -X- _ O
is -X- _ O
independent -X- _ O
from -X- _ O
text -X- _ O
, -X- _ O
resulting -X- _ O
in -X- _ O
the -X- _ O
graph -X- _ O
representation -X- _ O
hidden -X- _ O
space -X- _ O
differing -X- _ O
from -X- _ O
that -X- _ O
of -X- _ O
the -X- _ O
text -X- _ O
. -X- _ O
This -X- _ O
training -X- _ O
regime -X- _ O
of -X- _ O
existing -X- _ O
models -X- _ O
therefore -X- _ O
leads -X- _ O
to -X- _ O
a -X- _ O
semantic -X- _ O
gap -X- _ O
between -X- _ O
graph -X- _ O
knowledge -X- _ O
and -X- _ O
text -X- _ O
. -X- _ O
In -X- _ O
this -X- _ O
study -X- _ O
, -X- _ O
we -X- _ O
propose -X- _ O
a -X- _ O
novel -X- _ O
framework -X- _ O
for -X- _ O
knowledge -X- _ O
graph -X- _ O
enhanced -X- _ O
dialogue -X- _ B-TaskName
generation -X- _ I-TaskName
. -X- _ O
We -X- _ O
dynamically -X- _ O
construct -X- _ O
a -X- _ O
multi -X- _ O
- -X- _ O
hop -X- _ O
knowledge -X- _ O
graph -X- _ O
with -X- _ O
pseudo -X- _ O
nodes -X- _ O
to -X- _ O
involve -X- _ O
the -X- _ O
language -X- _ O
model -X- _ O
in -X- _ O
feature -X- _ O
aggregation -X- _ O
within -X- _ O
the -X- _ O
graph -X- _ O
at -X- _ O
all -X- _ O
steps -X- _ O
. -X- _ O
To -X- _ O
avoid -X- _ O
the -X- _ O
semantic -X- _ O
biases -X- _ O
caused -X- _ O
by -X- _ O
learning -X- _ O
on -X- _ O
vanilla -X- _ O
subgraphs -X- _ O
, -X- _ O
the -X- _ O
proposed -X- _ O
framework -X- _ O
applies -X- _ O
hierarchical -X- _ O
graph -X- _ O
attention -X- _ O
to -X- _ O
aggregate -X- _ O
graph -X- _ O
features -X- _ O
on -X- _ O
pseudo -X- _ O
nodes -X- _ O
and -X- _ O
then -X- _ O
attains -X- _ O
a -X- _ O
global -X- _ O
feature -X- _ O
. -X- _ O
Therefore -X- _ O
, -X- _ O
the -X- _ O
framework -X- _ O
can -X- _ O
better -X- _ O
utilise -X- _ O
the -X- _ O
heterogeneous -X- _ O
features -X- _ O
from -X- _ O
both -X- _ O
the -X- _ O
post -X- _ O
and -X- _ O
external -X- _ O
graph -X- _ O
knowledge -X- _ O
. -X- _ O
Extensive -X- _ O
experiments -X- _ O
demonstrate -X- _ O
that -X- _ O
our -X- _ O
framework -X- _ O
outperforms -X- _ O
state -X- _ O
- -X- _ O
of -X- _ O
- -X- _ O
the -X- _ O
- -X- _ O
art -X- _ O
( -X- _ O
SOTA -X- _ O
) -X- _ O
baselines -X- _ O
on -X- _ O
dialogue -X- _ B-TaskName
generation -X- _ I-TaskName
. -X- _ O
Further -X- _ O
analysis -X- _ O
also -X- _ O
shows -X- _ O
that -X- _ O
our -X- _ O
representation -X- _ O
learning -X- _ O
framework -X- _ O
can -X- _ O
fill -X- _ O
the -X- _ O
semantic -X- _ O
gap -X- _ O
by -X- _ O
coagulating -X- _ O
representations -X- _ O
of -X- _ O
both -X- _ O
text -X- _ O
and -X- _ O
graph -X- _ O
knowledge -X- _ O
. -X- _ O
Moreover -X- _ O
, -X- _ O
the -X- _ O
language -X- _ O
model -X- _ O
also -X- _ O
learns -X- _ O
how -X- _ O
to -X- _ O
better -X- _ O
select -X- _ O
knowledge -X- _ O
triples -X- _ O
for -X- _ O
a -X- _ O
more -X- _ O
informative -X- _ O
response -X- _ O
via -X- _ O
exploiting -X- _ O
subgraph -X- _ O
patterns -X- _ O
within -X- _ O
our -X- _ O
feature -X- _ O
aggregation -X- _ O
process -X- _ O
. -X- _ O
Our -X- _ O
code -X- _ O
and -X- _ O
resources -X- _ O
are -X- _ O
available -X- _ O
at -X- _ O
https -X- _ O
: -X- _ O
/ -X- _ O
/ -X- _ O
github.com -X- _ O
/ -X- _ O
tangg555 -X- _ O
/ -X- _ O
SaBART -X- _ O
. -X- _ O

Introduction -X- _ O

Recent -X- _ O
years -X- _ O
have -X- _ O
seen -X- _ O
a -X- _ O
surge -X- _ O
of -X- _ O
interest -X- _ O
in -X- _ O
developing -X- _ O
chatbots -X- _ O
with -X- _ O
the -X- _ O
facilitation -X- _ O
of -X- _ O
large -X- _ O
- -X- _ O
scale -X- _ O
knowledge -X- _ O
( -X- _ O
Ni -X- _ O
et -X- _ O
al -X- _ O
. -X- _ O
, -X- _ O
2022 -X- _ O
) -X- _ O
. -X- _ O
As -X- _ O
a -X- _ O
highly -X- _ O
expressive -X- _ O
data -X- _ O
format -X- _ O
, -X- _ O
Knowledge -X- _ O
Graphs -X- _ O
( -X- _ O
e.g. -X- _ O
ConceptNet -X- _ O
and -X- _ O
DBpedia -X- _ O
) -X- _ O
, -X- _ O
which -X- _ O
include -X- _ O
world -X- _ O
facts -X- _ O
, -X- _ O
are -X- _ O
considered -X- _ O
to -X- _ O
be -X- _ O
a -X- _ O
key -X- _ O
factor -X- _ O
in -X- _ O
building -X- _ O
an -X- _ O
effective -X- _ O
* -X- _ O
Corresponding -X- _ O
author -X- _ O
. -X- _ O
dialogue -X- _ B-TaskName
generation -X- _ I-TaskName
system -X- _ O
( -X- _ O
Zhou -X- _ O
et -X- _ O
al -X- _ O
. -X- _ O
, -X- _ O
2018 -X- _ O
) -X- _ O
. -X- _ O
In -X- _ O
order -X- _ O
to -X- _ O
incorporate -X- _ O
graph -X- _ O
- -X- _ O
structured -X- _ O
knowledge -X- _ O
, -X- _ O
a -X- _ O
range -X- _ O
of -X- _ O
Graph -X- _ O
Neural -X- _ O
Networks -X- _ O
such -X- _ O
as -X- _ O
Graph -X- _ B-MethodName
Attention -X- _ I-MethodName
Networks -X- _ I-MethodName
( -X- _ O
GATs -X- _ B-MethodName
) -X- _ O
( -X- _ O
Velickovic -X- _ O
et -X- _ O
al -X- _ O
. -X- _ O
, -X- _ O
2017 -X- _ O
; -X- _ O
Brody -X- _ O
et -X- _ O
al -X- _ O
. -X- _ O
, -X- _ O
2021 -X- _ O
) -X- _ O
and -X- _ O
Graph -X- _ B-MethodName
Convolutional -X- _ I-MethodName
Networks -X- _ I-MethodName
( -X- _ O
GCNs -X- _ B-MethodName
) -X- _ O
( -X- _ O
Kipf -X- _ O
and -X- _ O
Welling -X- _ O
, -X- _ O
2016 -X- _ O
) -X- _ O
have -X- _ O
been -X- _ O
proposed -X- _ O
to -X- _ O
learn -X- _ O
representations -X- _ O
of -X- _ O
the -X- _ O
topological -X- _ O
structure -X- _ O
of -X- _ O
the -X- _ O
knowledge -X- _ O
graph -X- _ O
via -X- _ O
message -X- _ O
passing -X- _ O
between -X- _ O
entities -X- _ O
. -X- _ O
In -X- _ O
open -X- _ O
- -X- _ O
domain -X- _ O
dialogue -X- _ B-TaskName
generation -X- _ I-TaskName
, -X- _ O
these -X- _ O
GNNs -X- _ B-MethodName
are -X- _ O
further -X- _ O
embedded -X- _ O
into -X- _ O
generative -X- _ O
frameworks -X- _ O
to -X- _ O
feed -X- _ O
graph -X- _ O
knowledge -X- _ O
features -X- _ O
into -X- _ O
the -X- _ O
language -X- _ B-MethodName
models -X- _ I-MethodName
( -X- _ O
LMs -X- _ B-MethodName
) -X- _ O
. -X- _ O

Despite -X- _ O
prior -X- _ O
success -X- _ O
in -X- _ O
leveraging -X- _ O
graph -X- _ O
knowledge -X- _ O
with -X- _ O
graph -X- _ O
neural -X- _ O
networks -X- _ O
( -X- _ O
GNN -X- _ B-MethodName
) -X- _ O
( -X- _ O
Zhou -X- _ O
et -X- _ O
al -X- _ O
. -X- _ O
, -X- _ O
2018 -X- _ O
; -X- _ O
Zhang -X- _ O
et -X- _ O
al -X- _ O
. -X- _ O
, -X- _ O
2020 -X- _ O
) -X- _ O
, -X- _ O
current -X- _ O
generative -X- _ O
frameworks -X- _ O
are -X- _ O
still -X- _ O
hindered -X- _ O
by -X- _ O
the -X- _ O
representation -X- _ O
gap -X- _ O
in -X- _ O
the -X- _ O
hidden -X- _ O
space -X- _ O
between -X- _ O
the -X- _ O
LMs -X- _ B-MethodName
and -X- _ O
GNNs -X- _ B-MethodName
, -X- _ O
which -X- _ O
poses -X- _ O
significant -X- _ O
challenges -X- _ O
in -X- _ O
exploiting -X- _ O
graph -X- _ O
knowledge -X- _ O
in -X- _ O
the -X- _ O
subsequent -X- _ O
text -X- _ O
decoding -X- _ O
process -X- _ O
. -X- _ O
As -X- _ O
illustrated -X- _ O
in -X- _ O
Figure -X- _ O
1 -X- _ O
, -X- _ O
prior -X- _ O
works -X- _ O
using -X- _ O
GNNs -X- _ B-MethodName
( -X- _ O
Zhu -X- _ O
et -X- _ O
al -X- _ O
. -X- _ O
, -X- _ O
2017 -X- _ O
; -X- _ O
Ghazvininejad -X- _ O
et -X- _ O
al -X- _ O
. -X- _ O
, -X- _ O
2018 -X- _ O
; -X- _ O
Zhou -X- _ O
et -X- _ O
al -X- _ O
. -X- _ O
, -X- _ O
2018 -X- _ O
; -X- _ O
Zhang -X- _ O
et -X- _ O
al -X- _ O
. -X- _ O
, -X- _ O
2020 -X- _ O
) -X- _ O
tend -X- _ O
to -X- _ O
fuse -X- _ O
the -X- _ O
graph -X- _ O
features -X- _ O
by -X- _ O
transforming -X- _ O
them -X- _ O
into -X- _ O
text -X- _ O
form -X- _ O
and -X- _ O
then -X- _ O
feeding -X- _ O
them -X- _ O
into -X- _ O
the -X- _ O
language -X- _ O
model -X- _ O
, -X- _ O
which -X- _ O
acts -X- _ O
as -X- _ O
a -X- _ O
" -X- _ O
copy -X- _ O
" -X- _ O
mechanism -X- _ O
. -X- _ O
In -X- _ O
other -X- _ O
words -X- _ O
, -X- _ O
these -X- _ O
networks -X- _ O
run -X- _ O
as -X- _ O
a -X- _ O
pipeline -X- _ O
where -X- _ O
the -X- _ O
graph -X- _ O
knowledge -X- _ O
is -X- _ O
firstly -X- _ O
transformed -X- _ O
into -X- _ O
additional -X- _ O
text -X- _ O
to -X- _ O
avoid -X- _ O
the -X- _ O
problem -X- _ O
of -X- _ O
language -X- _ O
model -X- _ O
encoding -X- _ O
brought -X- _ O
about -X- _ O
by -X- _ O
the -X- _ O
heterogeneous -X- _ O
graph -X- _ O
features -X- _ O
. -X- _ O
However -X- _ O
, -X- _ O
these -X- _ O
separate -X- _ O
encoding -X- _ O
stages -X- _ O
result -X- _ O
in -X- _ O
neural -X- _ O
networks -X- _ O
learning -X- _ O
suboptimal -X- _ O
representations -X- _ O
of -X- _ O
graph -X- _ O
knowledge -X- _ O
, -X- _ O
which -X- _ O
leads -X- _ O
to -X- _ O
information -X- _ O
loss -X- _ O
. -X- _ O
With -X- _ O
large -X- _ O
- -X- _ O
scale -X- _ O
pretrained -X- _ O
models -X- _ O
such -X- _ O
as -X- _ O
GPT-2 -X- _ B-MethodName
( -X- _ O
Radford -X- _ O
et -X- _ O
al -X- _ O
. -X- _ O
, -X- _ O
2019 -X- _ O
) -X- _ O
, -X- _ O
BART -X- _ B-MethodName
( -X- _ O
Lewis -X- _ O
et -X- _ O
al -X- _ O
. -X- _ O
, -X- _ O
2020 -X- _ O
) -X- _ O
and -X- _ O
T5 -X- _ B-MethodName
( -X- _ O
Raffel -X- _ O
et -X- _ O
al -X- _ O
. -X- _ O
, -X- _ O
2020 -X- _ O
) -X- _ O
being -X- _ O
widely -X- _ O
adopted -X- _ O
in -X- _ O
recent -X- _ O
advances -X- _ O
in -X- _ O
dialogue -X- _ B-TaskName
generation -X- _ I-TaskName
, -X- _ O
the -X- _ O
drawbacks -X- _ O
that -X- _ O
arise -X- _ O
from -X- _ O
incompatibility -X- _ O
between -X- _ O
GNNs -X- _ B-MethodName
and -X- _ O
LMs -X- _ B-MethodName
becomes -X- _ O
a -X- _ O
more -X- _ O
severe -X- _ O
problem -X- _ O
, -X- _ O
prohibiting -X- _ O
chatbot -X- _ O
systems -X- _ O
from -X- _ O
leveraging -X- _ O
graph -X- _ O
structured -X- _ O
data -X- _ O
effectively -X- _ O
. -X- _ O

In -X- _ O
order -X- _ O
to -X- _ O
address -X- _ O
the -X- _ O
aforementioned -X- _ O
challenges -X- _ O
, -X- _ O
we -X- _ O
propose -X- _ O
a -X- _ O
novel -X- _ O
representation -X- _ O
learning -X- _ O
framework -X- _ O
to -X- _ O
facilitate -X- _ O
language -X- _ O
understanding -X- _ O
and -X- _ O
generation -X- _ O
, -X- _ O
which -X- _ O
permits -X- _ O
effective -X- _ O
incorporation -X- _ O
of -X- _ O
heterogeneous -X- _ O
features -X- _ O
via -X- _ O
a -X- _ O
dynamic -X- _ B-MethodName
graph -X- _ I-MethodName
knowledge -X- _ I-MethodName
aggregation -X- _ I-MethodName
mechanism -X- _ O
. -X- _ O
In -X- _ O
contrast -X- _ O
to -X- _ O
existing -X- _ O
works -X- _ O
( -X- _ O
Zhu -X- _ O
et -X- _ O
al -X- _ O
. -X- _ O
, -X- _ O
2017 -X- _ O
; -X- _ O
Ghazvininejad -X- _ O
et -X- _ O
al -X- _ O
. -X- _ O
, -X- _ O
2018 -X- _ O
; -X- _ O
Zhou -X- _ O
et -X- _ O
al -X- _ O
. -X- _ O
, -X- _ O
2018 -X- _ O
; -X- _ O
Zhang -X- _ O
et -X- _ O
al -X- _ O
. -X- _ O
, -X- _ O
2020 -X- _ O
) -X- _ O
which -X- _ O
incorporate -X- _ O
graph -X- _ O
knowledge -X- _ O
with -X- _ O
conventional -X- _ O
GNNs -X- _ B-MethodName
( -X- _ O
causing -X- _ O
inadequacies -X- _ O
in -X- _ O
representation -X- _ O
learning -X- _ O
) -X- _ O
, -X- _ O
we -X- _ O
propose -X- _ O
to -X- _ O
involve -X- _ O
language -X- _ B-MethodName
models -X- _ I-MethodName
in -X- _ O
both -X- _ O
text -X- _ O
and -X- _ O
graph -X- _ O
knowledge -X- _ O
incorporation -X- _ O
at -X- _ O
all -X- _ O
steps -X- _ O
via -X- _ O
hierarchically -X- _ O
aggregating -X- _ O
knowledge -X- _ O
on -X- _ O
a -X- _ O
dynamic -X- _ O
pseudo -X- _ O
graph -X- _ O
. -X- _ O
During -X- _ O
the -X- _ O
knowledge -X- _ O
aggregation -X- _ O
process -X- _ O
, -X- _ O
knowledge -X- _ O
triples -X- _ O
are -X- _ O
reorganised -X- _ O
as -X- _ O
shown -X- _ O
in -X- _ O
Figure -X- _ O
1 -X- _ O
( -X- _ O
b -X- _ O
) -X- _ O
, -X- _ O
where -X- _ O
pseudo -X- _ O
nodes -X- _ O
are -X- _ O
created -X- _ O
to -X- _ O
learn -X- _ O
conceptual -X- _ O
representations -X- _ O
from -X- _ O
original -X- _ O
knowledge -X- _ O
triples -X- _ O
. -X- _ O
Conceptual -X- _ O
semantics -X- _ O
are -X- _ O
forced -X- _ O
to -X- _ O
coagulate -X- _ O
into -X- _ O
pseudo -X- _ O
nodes -X- _ O
, -X- _ O
and -X- _ O
finally -X- _ O
merge -X- _ O
into -X- _ O
a -X- _ O
condensed -X- _ O
feature -X- _ O
vector -X- _ O
to -X- _ O
fill -X- _ O
the -X- _ O
semantic -X- _ O
gap -X- _ O
of -X- _ O
the -X- _ O
encoded -X- _ O
text -X- _ O
features -X- _ O
. -X- _ O
Our -X- _ O
approach -X- _ O
for -X- _ O
incorporating -X- _ O
text -X- _ O
and -X- _ O
graph -X- _ O
knowledge -X- _ O
features -X- _ O
can -X- _ O
be -X- _ O
adapted -X- _ O
to -X- _ O
all -X- _ O
language -X- _ O
models -X- _ O
with -X- _ O
an -X- _ O
encoder -X- _ O
- -X- _ O
decoder -X- _ O
architecture -X- _ O
. -X- _ O
In -X- _ O
this -X- _ O
study -X- _ O
, -X- _ O
we -X- _ O
choose -X- _ O
BART -X- _ B-MethodName
( -X- _ O
Lewis -X- _ O
et -X- _ O
al -X- _ O
. -X- _ O
, -X- _ O
2020 -X- _ O
) -X- _ O
, -X- _ O
a -X- _ O
SOTA -X- _ O
language -X- _ O
model -X- _ O
for -X- _ O
generation -X- _ O
, -X- _ O
as -X- _ O
our -X- _ O
language -X- _ O
model -X- _ O
in -X- _ O
our -X- _ O
experiments -X- _ O
. -X- _ O
This -X- _ O
framework -X- _ O
will -X- _ O
hereinafter -X- _ O
be -X- _ O
referred -X- _ O
to -X- _ O
as -X- _ O
SaBART -X- _ B-MethodName
( -X- _ O
Subgraph -X- _ B-MethodName
- -X- _ I-MethodName
Aggregation -X- _ I-MethodName
BART -X- _ I-MethodName
) -X- _ O
. -X- _ O

During -X- _ O
subgraph -X- _ O
knowledge -X- _ O
aggregation -X- _ O
, -X- _ O
the -X- _ O
language -X- _ O
model -X- _ O
is -X- _ O
involved -X- _ O
in -X- _ O
learning -X- _ O
three -X- _ O
levels -X- _ O
of -X- _ O
features -X- _ O
: -X- _ O
( -X- _ O
1 -X- _ O
) -X- _ O
Subword -X- _ O
- -X- _ O
level -X- _ O
, -X- _ O
where -X- _ O
conceptual -X- _ O
embeddings -X- _ O
are -X- _ O
connected -X- _ O
to -X- _ O
entity -X- _ O
mentions -X- _ O
within -X- _ O
text -X- _ O
; -X- _ O
( -X- _ O
2 -X- _ O
) -X- _ O
Knowledge -X- _ O
- -X- _ O
level -X- _ O
, -X- _ O
where -X- _ O
original -X- _ O
triples -X- _ O
are -X- _ O
transformed -X- _ O
by -X- _ O
language -X- _ O
encoding -X- _ O
; -X- _ O
and -X- _ O

( -X- _ O
3 -X- _ O
) -X- _ O
Semantic -X- _ O
- -X- _ O
level -X- _ O
, -X- _ O
where -X- _ O
the -X- _ O
context -X- _ O
vector -X- _ O
encoded -X- _ O
from -X- _ O
text -X- _ O
is -X- _ O
involved -X- _ O
in -X- _ O
knowledge -X- _ O
aggregation -X- _ O
. -X- _ O
This -X- _ O
implies -X- _ O
that -X- _ O
the -X- _ O
neural -X- _ O
networks -X- _ O
are -X- _ O
able -X- _ O
to -X- _ O
access -X- _ O
both -X- _ O
the -X- _ O
text -X- _ O
and -X- _ O
graph -X- _ O
features -X- _ O
during -X- _ O
representation -X- _ O
learning -X- _ O
. -X- _ O
The -X- _ O
text -X- _ O
and -X- _ O
graph -X- _ O
unified -X- _ O
encoding -X- _ O
process -X- _ O
also -X- _ O
avoids -X- _ O
the -X- _ O
information -X- _ O
loss -X- _ O
caused -X- _ O
by -X- _ O
the -X- _ O
representation -X- _ O
shift -X- _ O
in -X- _ O
vanilla -X- _ B-MethodName
GNNs -X- _ I-MethodName
, -X- _ O
thus -X- _ O
improving -X- _ O
efficiency -X- _ O
and -X- _ O
efficacy -X- _ O
. -X- _ O
Extensive -X- _ O
experiments -X- _ O
demonstrate -X- _ O
that -X- _ O
our -X- _ O
proposed -X- _ O
framework -X- _ O
significantly -X- _ O
outperforms -X- _ O
current -X- _ O
SOTA -X- _ O
baselines -X- _ O
in -X- _ O
dialogue -X- _ B-TaskName
generation -X- _ I-TaskName
. -X- _ O
We -X- _ O
also -X- _ O
conduct -X- _ O
in -X- _ O
- -X- _ O
depth -X- _ O
analysis -X- _ O
into -X- _ O
the -X- _ O
underlying -X- _ O
mechanism -X- _ O
of -X- _ O
why -X- _ O
our -X- _ O
proposed -X- _ O
approach -X- _ O
better -X- _ O
incorporates -X- _ O
heterogeneous -X- _ O
features -X- _ O
. -X- _ O
Our -X- _ O
contributions -X- _ O
can -X- _ O
be -X- _ O
summarised -X- _ O
as -X- _ O
follows -X- _ O
: -X- _ O

• -X- _ O
We -X- _ O
propose -X- _ O
a -X- _ O
novel -X- _ O
representation -X- _ O
learning -X- _ O
framework -X- _ O
where -X- _ O
graph -X- _ O
and -X- _ O
text -X- _ O
features -X- _ O
can -X- _ O
be -X- _ O
effectively -X- _ O
aggregated -X- _ O
via -X- _ O
hierarchical -X- _ O
knowledge -X- _ O
aggregation -X- _ O
on -X- _ O
a -X- _ O
dynamically -X- _ O
constructed -X- _ O
pseudo -X- _ O
graph -X- _ O
; -X- _ O

• -X- _ O
We -X- _ O
conduct -X- _ O
a -X- _ O
comprehensive -X- _ O
set -X- _ O
of -X- _ O
experiments -X- _ O
to -X- _ O
demonstrate -X- _ O
the -X- _ O
effectiveness -X- _ O
of -X- _ O
our -X- _ O
proposed -X- _ O
approach -X- _ O
, -X- _ O
where -X- _ O
our -X- _ O
framework -X- _ O
achieves -X- _ O
SOTA -X- _ O
performance -X- _ O
on -X- _ O
the -X- _ O
commonsense -X- _ O
knowledge -X- _ O
graph -X- _ O
enhanced -X- _ O
dialogue -X- _ B-TaskName
generation -X- _ I-TaskName
dataset -X- _ O
; -X- _ O

• -X- _ O
We -X- _ O
conduct -X- _ O
in -X- _ O
- -X- _ O
depth -X- _ O
experiments -X- _ O
to -X- _ O
analyse -X- _ O
the -X- _ O
improvement -X- _ O
of -X- _ O
representation -X- _ O
learning -X- _ O
on -X- _ O
both -X- _ O
graph -X- _ O
and -X- _ O
text -X- _ O
knowledge -X- _ O
, -X- _ O
and -X- _ O
investigate -X- _ O
the -X- _ O
mechanism -X- _ O
to -X- _ O
address -X- _ O
this -X- _ O
representation -X- _ O
gap -X- _ O
problem -X- _ O
of -X- _ O
learning -X- _ O
heterogeneous -X- _ O
features -X- _ O
. -X- _ O

Related -X- _ O
Works -X- _ O

In -X- _ O
this -X- _ O
section -X- _ O
, -X- _ O
we -X- _ O
introduce -X- _ O
related -X- _ O
works -X- _ O
by -X- _ O
summarising -X- _ O
recent -X- _ O
advances -X- _ O
in -X- _ O
the -X- _ O
knowledge -X- _ B-TaskName
enhanced -X- _ I-TaskName
dialogue -X- _ I-TaskName
generation -X- _ I-TaskName
task -X- _ O
, -X- _ O
as -X- _ O
well -X- _ O
as -X- _ O
the -X- _ O
SOTA -X- _ O
approaches -X- _ O
for -X- _ O
injecting -X- _ O
graph -X- _ O
knowledge -X- _ O
into -X- _ O
generative -X- _ O
frameworks -X- _ O
. -X- _ O

Knowledge -X- _ B-TaskName
Enhanced -X- _ O
Dialogue -X- _ O
Generation -X- _ O

As -X- _ O
a -X- _ O
data -X- _ O
- -X- _ O
driven -X- _ O
approach -X- _ O
, -X- _ O
deep -X- _ O
learning -X- _ O
based -X- _ O
chatbots -X- _ O
rely -X- _ O
on -X- _ O
access -X- _ O
to -X- _ O
large -X- _ O
amounts -X- _ O
of -X- _ O
knowledge -X- _ O
( -X- _ O
Zhao -X- _ O
et -X- _ O
al -X- _ O
. -X- _ O
, -X- _ O
2020 -X- _ O
) -X- _ O
to -X- _ O
generate -X- _ O
interesting -X- _ O
and -X- _ O
informative -X- _ O
dialogues -X- _ O
like -X- _ O
humans -X- _ O
. -X- _ O
In -X- _ O
order -X- _ O
to -X- _ O
realise -X- _ O
a -X- _ O
commonsense -X- _ O
- -X- _ O
aware -X- _ O
and -X- _ O
semantic -X- _ O
- -X- _ O
aware -X- _ O
chatbot -X- _ O
, -X- _ O
more -X- _ O
and -X- _ O
more -X- _ O
studies -X- _ O
( -X- _ O
Yu -X- _ O
et -X- _ O
al -X- _ O
. -X- _ O
, -X- _ O
2022 -X- _ O
; -X- _ O
Huang -X- _ O
et -X- _ O
al -X- _ O
. -X- _ O
, -X- _ O
2022 -X- _ O
; -X- _ O
Tang -X- _ O
et -X- _ O
al -X- _ O
. -X- _ O
, -X- _ O
2022b -X- _ O
) -X- _ O

Figure -X- _ O
2 -X- _ O
: -X- _ O
The -X- _ O
overall -X- _ O
framework -X- _ O
of -X- _ O
SaBART -X- _ B-MethodName
. -X- _ O
We -X- _ O
split -X- _ O
the -X- _ O
whole -X- _ O
framework -X- _ O
into -X- _ O
four -X- _ O
parts -X- _ O
, -X- _ O
which -X- _ O
contain -X- _ O
codependencies -X- _ O
. -X- _ O
For -X- _ O
instance -X- _ O
, -X- _ O
the -X- _ O
concepts -X- _ O
and -X- _ O
relations -X- _ O
will -X- _ O
create -X- _ O
new -X- _ O
sub -X- _ O
- -X- _ O
word -X- _ O
embedding -X- _ O
placeholders -X- _ O
in -X- _ O
language -X- _ O
models -X- _ O
after -X- _ O
flattening -X- _ O
into -X- _ O
text -X- _ O
sequences -X- _ O
to -X- _ O
make -X- _ O
the -X- _ O
graph -X- _ O
and -X- _ O
language -X- _ O
models -X- _ O
share -X- _ O
low -X- _ O
- -X- _ O
dimensional -X- _ O
representations -X- _ O
. -X- _ O

the -X- _ O
performance -X- _ O
of -X- _ O
neural -X- _ O
frameworks -X- _ O
through -X- _ O
using -X- _ O
additional -X- _ O
knowledge -X- _ O
graphs -X- _ O
as -X- _ O
external -X- _ O
resources -X- _ O
. -X- _ O
Therefore -X- _ O
, -X- _ O
studies -X- _ O
with -X- _ O
external -X- _ O
knowledge -X- _ O
other -X- _ O
than -X- _ O
knowledge -X- _ O
graphs -X- _ O
, -X- _ O
such -X- _ O
as -X- _ O
content -X- _ O
planning -X- _ O
( -X- _ O
Tang -X- _ O
et -X- _ O
al -X- _ O
. -X- _ O
, -X- _ O
2022c -X- _ O
) -X- _ O
, -X- _ O
retrieved -X- _ O
documents -X- _ O
( -X- _ O
Yu -X- _ O
et -X- _ O
al -X- _ O
. -X- _ O
, -X- _ O
2022 -X- _ O
) -X- _ O
, -X- _ O
and -X- _ O
mixed -X- _ O
resources -X- _ O
( -X- _ O
Wu -X- _ O
et -X- _ O
al -X- _ O
. -X- _ O
, -X- _ O
2022 -X- _ O
) -X- _ O
, -X- _ O
are -X- _ O
not -X- _ O
directly -X- _ O
compared -X- _ O
in -X- _ O
this -X- _ O
paper -X- _ O
. -X- _ O
We -X- _ O
believe -X- _ O
our -X- _ O
learning -X- _ O
pattern -X- _ O
for -X- _ O
handling -X- _ O
heterogeneous -X- _ O
features -X- _ O
can -X- _ O
provide -X- _ O
inspiration -X- _ O
to -X- _ O
other -X- _ O
types -X- _ O
of -X- _ O
knowledge -X- _ O
grounded -X- _ O
conversational -X- _ O
systems -X- _ O
as -X- _ O
well -X- _ O
. -X- _ O

Injecting -X- _ O
Graph -X- _ O
Knowledge -X- _ O
into -X- _ O
Generative -X- _ O
Frameworks -X- _ O
With -X- _ O
pre -X- _ O
- -X- _ O
training -X- _ O
techniques -X- _ O
being -X- _ O
widely -X- _ O
adopted -X- _ O
, -X- _ O
large -X- _ O
- -X- _ O
scale -X- _ O
language -X- _ O
models -X- _ O
such -X- _ O
as -X- _ O
UniLM -X- _ B-MethodName
( -X- _ O
Dong -X- _ O
et -X- _ O
al -X- _ O
. -X- _ O
, -X- _ O
2019 -X- _ O
) -X- _ O
, -X- _ O
GPT-2 -X- _ B-MethodName
( -X- _ O
Radford -X- _ O
et -X- _ O
al -X- _ O
. -X- _ O
, -X- _ O
2019 -X- _ O
) -X- _ O
, -X- _ O
and -X- _ O
BART -X- _ B-MethodName
( -X- _ O
Lewis -X- _ O
et -X- _ O
al -X- _ O
. -X- _ O
, -X- _ O
2020 -X- _ O
) -X- _ O
have -X- _ O
become -X- _ O
the -X- _ O
base -X- _ O
models -X- _ O
for -X- _ O
various -X- _ O
dialogue -X- _ B-TaskName
generation -X- _ I-TaskName
systems -X- _ O
. -X- _ O
However -X- _ O
, -X- _ O
these -X- _ O
language -X- _ O
models -X- _ O
generally -X- _ O
input -X- _ O
only -X- _ O
sequence -X- _ O
formatted -X- _ O
text -X- _ O
, -X- _ O
and -X- _ O
can -X- _ O
not -X- _ O
directly -X- _ O
incorporate -X- _ O
features -X- _ O
of -X- _ O
graph -X- _ O
knowledge -X- _ O
. -X- _ O
Usually -X- _ O
graph -X- _ O
knowledge -X- _ O
has -X- _ O
to -X- _ O
firstly -X- _ O
be -X- _ O
flattened -X- _ O
into -X- _ O
a -X- _ O
sequence -X- _ O
of -X- _ O
tokens -X- _ O
( -X- _ O
Tang -X- _ O
et -X- _ O
al -X- _ O
. -X- _ O
, -X- _ O
2022a -X- _ O
) -X- _ O
, -X- _ O
or -X- _ O
encoded -X- _ O
as -X- _ O
feature -X- _ O
vectors -X- _ O
( -X- _ O
Zhao -X- _ O
et -X- _ O
al -X- _ O
. -X- _ O
, -X- _ O
2020 -X- _ O
) -X- _ O
before -X- _ O
being -X- _ O
fed -X- _ O
into -X- _ O
a -X- _ O
language -X- _ O
model -X- _ O
. -X- _ O
Zhou -X- _ O
et -X- _ O
al -X- _ O
. -X- _ O
( -X- _ O
2018 -X- _ O
) -X- _ O
uses -X- _ O
GRUs -X- _ O
and -X- _ O
two -X- _ O
graph -X- _ O
attention -X- _ O
modules -X- _ O
to -X- _ O
select -X- _ O
appropriate -X- _ O
triples -X- _ O
to -X- _ O
incorporate -X- _ O
into -X- _ O
responses -X- _ O
. -X- _ O
In -X- _ O
order -X- _ O
to -X- _ O
exploit -X- _ O
the -X- _ O
benefits -X- _ O
of -X- _ O
multi -X- _ O
- -X- _ O
hop -X- _ O
knowledge -X- _ O
, -X- _ O
Zhang -X- _ O
et -X- _ O
al -X- _ O
. -X- _ O
( -X- _ O
2020 -X- _ O
) -X- _ O
adds -X- _ O
an -X- _ O
attention -X- _ O
mechanism -X- _ O
in -X- _ O
a -X- _ O
similar -X- _ O
way -X- _ O
to -X- _ O
filter -X- _ O
the -X- _ O
appropriate -X- _ O
knowledge -X- _ O
. -X- _ O
Finally -X- _ O
, -X- _ O
Tuan -X- _ O
et -X- _ O
al -X- _ O
. -X- _ O
( -X- _ O
2019 -X- _ O
) -X- _ O
propose -X- _ O
a -X- _ O
model -X- _ O
which -X- _ O
selects -X- _ O
the -X- _ O
output -X- _ O
from -X- _ O
a -X- _ O
sequence -X- _ O
- -X- _ O
to -X- _ O
- -X- _ O
sequence -X- _ O
model -X- _ O
and -X- _ O
a -X- _ O
multi -X- _ O
- -X- _ O
hop -X- _ O
reasoning -X- _ O
model -X- _ O
at -X- _ O
each -X- _ O
time -X- _ O
step -X- _ O
. -X- _ O

Methods -X- _ O

Task -X- _ O
Definition -X- _ O

In -X- _ O
our -X- _ O
task -X- _ O
, -X- _ O
the -X- _ O
given -X- _ O
input -X- _ O
includes -X- _ O
a -X- _ O
textual -X- _ O
post -X- _ O
X -X- _ O
= -X- _ O
{ -X- _ O
x -X- _ O
1 -X- _ O
, -X- _ O
x -X- _ O
2 -X- _ O
, -X- _ O
... -X- _ O
, -X- _ O
x -X- _ O
n -X- _ O
} -X- _ O
where -X- _ O
x -X- _ O
n -X- _ O
denotes -X- _ O
the -X- _ O
n -X- _ O
- -X- _ O
th -X- _ O
token -X- _ O
, -X- _ O
and -X- _ O
a -X- _ O
graph -X- _ O
knowledge -X- _ O
base -X- _ O
G -X- _ O
= -X- _ O
{ -X- _ O
τ -X- _ O
1 -X- _ O
, -X- _ O
τ -X- _ O
2 -X- _ O
, -X- _ O
... -X- _ O
, -X- _ O
τ -X- _ O
k -X- _ O
} -X- _ O
. -X- _ O
τ -X- _ O
denotes -X- _ O
a -X- _ O
triple -X- _ O
{ -X- _ O
h -X- _ O
, -X- _ O
r -X- _ O
, -X- _ O
t -X- _ O
} -X- _ O
, -X- _ O
where -X- _ O
h -X- _ O
, -X- _ O
r -X- _ O
, -X- _ O
and -X- _ O
t -X- _ O
refer -X- _ O
to -X- _ O
the -X- _ O
head -X- _ O
entity -X- _ O
, -X- _ O
the -X- _ O
relation -X- _ O
, -X- _ O
and -X- _ O
the -X- _ O
tail -X- _ O
entity -X- _ O
, -X- _ O
respectively -X- _ O
. -X- _ O
These -X- _ O
triples -X- _ O
represent -X- _ O
the -X- _ O
entities -X- _ O
contained -X- _ O
in -X- _ O
the -X- _ O
posts -X- _ O
and -X- _ O
reference -X- _ O
responses -X- _ O
, -X- _ O
and -X- _ O
the -X- _ O
relations -X- _ O
between -X- _ O
them -X- _ O
. -X- _ O
Provided -X- _ O
with -X- _ O
these -X- _ O
two -X- _ O
kinds -X- _ O
of -X- _ O
input -X- _ O
, -X- _ O
the -X- _ O
generation -X- _ O
model -X- _ O
is -X- _ O
required -X- _ O
to -X- _ O
generate -X- _ O
a -X- _ O
response -X- _ O
Y -X- _ O
= -X- _ O
{ -X- _ O
y -X- _ O
1 -X- _ O
, -X- _ O
y -X- _ O
2 -X- _ O
, -X- _ O
... -X- _ O
, -X- _ O
y -X- _ O
m -X- _ O
} -X- _ O
by -X- _ O
modeling -X- _ O
the -X- _ O
conditional -X- _ O
probability -X- _ O
distribution -X- _ O
P -X- _ O
( -X- _ O
Y -X- _ O
|X -X- _ O
, -X- _ O
G -X- _ O
) -X- _ O
. -X- _ O

where -X- _ O
triples -X- _ O
τ -X- _ O
containing -X- _ O
the -X- _ O
same -X- _ O
conceptual -X- _ O
entity -X- _ O
ent -X- _ O
i -X- _ O
are -X- _ O
grouped -X- _ O
as -X- _ O
a -X- _ O
subgraph -X- _ O
g -X- _ O
i -X- _ O
for -X- _ O
the -X- _ O
post -X- _ O
. -X- _ O
In -X- _ O
contrast -X- _ O
to -X- _ O
existing -X- _ O
works -X- _ O
( -X- _ O
Zhu -X- _ O
et -X- _ O
al -X- _ O
. -X- _ O
, -X- _ O
2017 -X- _ O
; -X- _ O
Ghazvininejad -X- _ O
et -X- _ O
al -X- _ O
. -X- _ O
, -X- _ O
2018 -X- _ O
; -X- _ O
Zhou -X- _ O
et -X- _ O
al -X- _ O
. -X- _ O
, -X- _ O
2018 -X- _ O
; -X- _ O
Zhang -X- _ O
et -X- _ O
al -X- _ O
. -X- _ O
, -X- _ O
2020 -X- _ O
) -X- _ O
that -X- _ O
encode -X- _ O
knowledge -X- _ O
and -X- _ O
select -X- _ O
triples -X- _ O
on -X- _ O
separate -X- _ O
subgraphs -X- _ O
( -X- _ O
leading -X- _ O
to -X- _ O
biased -X- _ O
and -X- _ O
incomplete -X- _ O
feature -X- _ O
learning -X- _ O
) -X- _ O
, -X- _ O
we -X- _ O
propose -X- _ O
to -X- _ O
reconstruct -X- _ O
G -X- _ O
with -X- _ O
pseudo -X- _ O
nodes -X- _ O
, -X- _ O
so -X- _ O
that -X- _ O
pseudo -X- _ O
nodes -X- _ O
can -X- _ O
dynamically -X- _ O
connect -X- _ O
each -X- _ O
g -X- _ O
i -X- _ O
to -X- _ O
form -X- _ O
a -X- _ O
global -X- _ O
graph -X- _ O
: -X- _ O

Here -X- _ O
pseu -X- _ O
G -X- _ O
∈ -X- _ O
R -X- _ O
W -X- _ O
C -X- _ O
is -X- _ O
the -X- _ O
root -X- _ O
node -X- _ O
representing -X- _ O
the -X- _ O
features -X- _ O
of -X- _ O
the -X- _ O
whole -X- _ O
graph -X- _ O
G -X- _ O
′ -X- _ O
. -X- _ O
pseu -X- _ O
G -X- _ O
as -X- _ O
the -X- _ O
new -X- _ O
pseudo -X- _ O
knowledge -X- _ O
graph -X- _ O
is -X- _ O
the -X- _ O
set -X- _ O
of -X- _ O
the -X- _ O
aforementioned -X- _ O
pseudo -X- _ O
triples -X- _ O
transformed -X- _ O
from -X- _ O
the -X- _ O
original -X- _ O
triples -X- _ O
. -X- _ O

Instead -X- _ O
of -X- _ O
learning -X- _ O
graph -X- _ O
features -X- _ O
by -X- _ O
message -X- _ O
passing -X- _ O
on -X- _ O
graph -X- _ O
nodes -X- _ O
, -X- _ O
we -X- _ O
implement -X- _ O
a -X- _ O
novel -X- _ O
representation -X- _ O
learning -X- _ O
framework -X- _ O
, -X- _ O
where -X- _ O
we -X- _ O
train -X- _ O
the -X- _ O
neural -X- _ O
network -X- _ O
to -X- _ O
learn -X- _ O
the -X- _ O
global -X- _ O
features -X- _ O
from -X- _ O
the -X- _ O
whole -X- _ O
graph -X- _ O
by -X- _ O
hierarchically -X- _ O
aggregating -X- _ O
features -X- _ O
through -X- _ O
pseudo -X- _ O
nodes -X- _ O
as -X- _ O
shown -X- _ O
in -X- _ O
Figure -X- _ O
2 -X- _ O
( -X- _ O
c -X- _ O
) -X- _ O
. -X- _ O
Firstly -X- _ O
, -X- _ O
we -X- _ O
encode -X- _ O
features -X- _ O
of -X- _ O
the -X- _ O
post -X- _ O
to -X- _ O
obtain -X- _ O
a -X- _ O
semantic -X- _ O
vector -X- _ O
H -X- _ O
CLS -X- _ O
∈ -X- _ O
R -X- _ O
1×E -X- _ O
, -X- _ O
and -X- _ O
the -X- _ O
embeddings -X- _ O
of -X- _ O
input -X- _ O
tokens -X- _ O
H -X- _ O
X -X- _ O
: -X- _ O

where -X- _ O
the -X- _ O
context -X- _ O
information -X- _ O
of -X- _ O
the -X- _ O
post -X- _ O
H -X- _ O
CLS -X- _ O
will -X- _ O
be -X- _ O
used -X- _ O
as -X- _ O
context -X- _ O
from -X- _ O
the -X- _ O
post -X- _ O
, -X- _ O
and -X- _ O
involved -X- _ O
in -X- _ O
aggregating -X- _ O
features -X- _ O
on -X- _ O
graph -X- _ O
knowledge -X- _ O
( -X- _ O
as -X- _ O
the -X- _ O
query -X- _ O
vector -X- _ O
in -X- _ O
the -X- _ O
attention -X- _ O
mechanism -X- _ O
) -X- _ O
. -X- _ O
Subsequently -X- _ O
, -X- _ O
a -X- _ O
series -X- _ O
of -X- _ O
feature -X- _ O
incorporation -X- _ O
procedures -X- _ O
will -X- _ O
be -X- _ O
conducted -X- _ O
on -X- _ O
our -X- _ O
constructed -X- _ O
graph -X- _ O
of -X- _ O
pseudo -X- _ O
nodes -X- _ O
. -X- _ O

In -X- _ O
§ -X- _ O
3.2 -X- _ O
, -X- _ O
the -X- _ O
original -X- _ O
retrieved -X- _ O
triples -X- _ O
have -X- _ O
been -X- _ O
transformed -X- _ O
into -X- _ O
the -X- _ O
set -X- _ O
of -X- _ O
pseudo -X- _ O
nodes -X- _ O
pseu -X- _ O
τ -X- _ O
j -X- _ O
. -X- _ O

To -X- _ O
obtain -X- _ O
the -X- _ O
representation -X- _ O
of -X- _ O
the -X- _ O
graph -X- _ O
, -X- _ O
we -X- _ O
directly -X- _ O
aggregate -X- _ O
the -X- _ O
node -X- _ O
features -X- _ O
by -X- _ O
calculating -X- _ O
their -X- _ O
mean -X- _ O
value -X- _ O
, -X- _ O
which -X- _ O
is -X- _ O
inspired -X- _ O
by -X- _ O
the -X- _ O
work -X- _ O
of -X- _ O
Tang -X- _ O
et -X- _ O
al -X- _ O
. -X- _ O
( -X- _ O
2021 -X- _ O
) -X- _ O
in -X- _ O
calculating -X- _ O
global -X- _ O
representations -X- _ O
. -X- _ O

) -X- _ O

First -X- _ O
Forward -X- _ O
Layer -X- _ O
. -X- _ O
In -X- _ O
the -X- _ O
first -X- _ O
step -X- _ O
, -X- _ O
we -X- _ O
calculate -X- _ O
the -X- _ O
features -X- _ O
of -X- _ O
pseu -X- _ O
g -X- _ O
i -X- _ O
∈ -X- _ O
g -X- _ O
i -X- _ O
: -X- _ O

Update -X- _ O
( -X- _ O
pseu -X- _ O
g -X- _ O
i -X- _ O
) -X- _ O
= -X- _ O
|g -X- _ O
′ -X- _ O
i -X- _ O
| -X- _ O
j=1 -X- _ O
a -X- _ O
g -X- _ O
′ -X- _ O
i -X- _ O
ji -X- _ O
pseu -X- _ O
τ -X- _ O
j -X- _ O
( -X- _ O
12 -X- _ O
) -X- _ O
a -X- _ O
g -X- _ O
′ -X- _ O
i -X- _ O
ji -X- _ O
= -X- _ O
exp -X- _ O
( -X- _ O
β -X- _ O
g -X- _ O
′ -X- _ O
i -X- _ O
ji -X- _ O
) -X- _ O
|g -X- _ O
′ -X- _ O
i -X- _ O
| -X- _ O
j=1 -X- _ O
exp -X- _ O
( -X- _ O
β -X- _ O
g -X- _ O
′ -X- _ O
i -X- _ O
ji -X- _ O
) -X- _ O
( -X- _ O
13 -X- _ O
) -X- _ O

where -X- _ O
τ -X- _ O
′ -X- _ O
j -X- _ O
∈ -X- _ O
g -X- _ O
′ -X- _ O
i -X- _ O
all -X- _ O
include -X- _ O
pseu -X- _ O
g -X- _ O
i -X- _ O
as -X- _ O
the -X- _ O
tail -X- _ O
node -X- _ O
( -X- _ O
cf -X- _ O
. -X- _ O
Equation -X- _ O
6 -X- _ O
) -X- _ O
; -X- _ O
i -X- _ O
denotes -X- _ O
the -X- _ O
i -X- _ O
- -X- _ O
th -X- _ O
entity -X- _ O
mention -X- _ O
in -X- _ O
the -X- _ O
post -X- _ O
; -X- _ O
and -X- _ O
j -X- _ O
denotes -X- _ O
the -X- _ O
j -X- _ O
- -X- _ O
th -X- _ O
triple -X- _ O
related -X- _ O
to -X- _ O
the -X- _ O
mention -X- _ O
. -X- _ O
W -X- _ O
g -X- _ O
′ -X- _ O
i -X- _ O
∈ -X- _ O
R -X- _ O
1× -X- _ O
( -X- _ O
W -X- _ O
+1 -X- _ O
) -X- _ O
E -X- _ O
is -X- _ O
a -X- _ O
trainable -X- _ O
parameter -X- _ O
multiplying -X- _ O
the -X- _ O
concatenation -X- _ O
of -X- _ O
the -X- _ O
node -X- _ O
representation -X- _ O
and -X- _ O
the -X- _ O
context -X- _ O
feature -X- _ O
vector -X- _ O
. -X- _ O
a -X- _ O

Second -X- _ O
Forward -X- _ O
Layer -X- _ O
. -X- _ O
Similarly -X- _ O
, -X- _ O
when -X- _ O
our -X- _ O
model -X- _ O
attends -X- _ O
to -X- _ O
G -X- _ O
′ -X- _ O
, -X- _ O
we -X- _ O
update -X- _ O
the -X- _ O
features -X- _ O
with -X- _ O
pseu -X- _ O
g -X- _ O
k -X- _ O
obtained -X- _ O
in -X- _ O
the -X- _ O
first -X- _ O
step -X- _ O
: -X- _ O

Update -X- _ O
( -X- _ O
pseu -X- _ O
G -X- _ O
) -X- _ O
= -X- _ O
|G -X- _ O
′ -X- _ O
| -X- _ O
k=1 -X- _ O
a -X- _ O
G -X- _ O
′ -X- _ O
k -X- _ O
pseu -X- _ O
g -X- _ O
k -X- _ O
( -X- _ O
17 -X- _ O

where -X- _ O
aggregated -X- _ O
by -X- _ O
G. -X- _ O
The -X- _ O
feature -X- _ O
vector -X- _ O
q -X- _ O
is -X- _ O
the -X- _ O
same -X- _ O
as -X- _ O
the -X- _ O
one -X- _ O
in -X- _ O
the -X- _ O
first -X- _ O
forward -X- _ O
layer -X- _ O
, -X- _ O
which -X- _ O
acts -X- _ O
as -X- _ O
the -X- _ O
global -X- _ O
context -X- _ O
of -X- _ O
both -X- _ O
the -X- _ O
post -X- _ O
and -X- _ O
static -X- _ O
knowledge -X- _ O
graph -X- _ O
. -X- _ O

Inference -X- _ O
and -X- _ O
Training -X- _ O

where -X- _ O
N -X- _ O
denotes -X- _ O
the -X- _ O
size -X- _ O
of -X- _ O
the -X- _ O
test -X- _ O
data -X- _ O
, -X- _ O
and -X- _ O
L -X- _ O
is -X- _ O
the -X- _ O
cross -X- _ O
entropy -X- _ O
of -X- _ O
predicted -X- _ O
response -X- _ O
tokens -X- _ O
and -X- _ O
those -X- _ O
of -X- _ O
the -X- _ O
golden -X- _ O
responses -X- _ O
. -X- _ O
( -X- _ O
Zhou -X- _ O
et -X- _ O
al -X- _ O
. -X- _ O
, -X- _ O
2018 -X- _ O
) -X- _ O
, -X- _ O
and -X- _ O
Concept -X- _ B-MethodName
- -X- _ I-MethodName
Flow -X- _ I-MethodName
( -X- _ O
Zhang -X- _ O
et -X- _ O
al -X- _ O
. -X- _ O
, -X- _ O
2020 -X- _ O
) -X- _ O
. -X- _ O
In -X- _ O
particular -X- _ O
, -X- _ O
UniLM -X- _ B-MethodName
and -X- _ O
BART -X- _ B-MethodName
are -X- _ O
SOTA -X- _ O
pre -X- _ O
- -X- _ O
trained -X- _ O
models -X- _ O
for -X- _ O
generation -X- _ O
tasks -X- _ O
, -X- _ O
whilst -X- _ O
ConceptFlow -X- _ B-MethodName
is -X- _ O
the -X- _ O
SOTA -X- _ O
model -X- _ O
for -X- _ O
our -X- _ O
task -X- _ O
. -X- _ O
3 -X- _ O
Evaluation -X- _ O
Metrics -X- _ O
. -X- _ O
We -X- _ O
adopt -X- _ O
the -X- _ O
metrics -X- _ O
of -X- _ O
BLEU -X- _ B-MetricName
( -X- _ O
Papineni -X- _ O
et -X- _ O
al -X- _ O
. -X- _ O
, -X- _ O
2002 -X- _ O
) -X- _ O
, -X- _ O
NIST -X- _ B-MetricName
( -X- _ O
Doddington -X- _ O
, -X- _ O
2002 -X- _ O
) -X- _ O
, -X- _ O
METEOR -X- _ B-MetricName
( -X- _ O
Lavie -X- _ O
and -X- _ O
Agarwal -X- _ O
, -X- _ O
2007 -X- _ O
) -X- _ O
, -X- _ O
Dist -X- _ B-MetricName
, -X- _ O
and -X- _ O
Ent -X- _ B-MetricName
( -X- _ O
Zhang -X- _ O
et -X- _ O
al -X- _ O
. -X- _ O
, -X- _ O
2018 -X- _ O
) -X- _ O
for -X- _ O
evaluation -X- _ O
. -X- _ O
BLEU -X- _ B-MetricName
, -X- _ O
NIST -X- _ B-MetricName
, -X- _ O
and -X- _ O
METEOR -X- _ B-MetricName
are -X- _ O
calculated -X- _ O
between -X- _ O
generated -X- _ O
responses -X- _ O
and -X- _ O
golden -X- _ O
responses -X- _ O
, -X- _ O
whilst -X- _ O
Dist -X- _ B-MetricName
and -X- _ O
Ent -X- _ B-MetricName
( -X- _ O
calculating -X- _ O
word -X- _ O
distinction -X- _ O
by -X- _ O
n -X- _ O
- -X- _ O
grams -X- _ O
) -X- _ O
are -X- _ O
calculated -X- _ O
within -X- _ O
generated -X- _ O
responses -X- _ O
. -X- _ O
We -X- _ O
also -X- _ O
conduct -X- _ O
further -X- _ O
experiments -X- _ O
to -X- _ O
evaluate -X- _ O
the -X- _ O
efficiency -X- _ O
and -X- _ O
efficacy -X- _ O
of -X- _ O
incorporating -X- _ O
external -X- _ O
knowledge -X- _ O
by -X- _ O
counting -X- _ O
the -X- _ O
entities -X- _ O
from -X- _ O
the -X- _ O
post -X- _ O
used -X- _ O
in -X- _ O
2 -X- _ O
We -X- _ O
follow -X- _ O
prior -X- _ O
work -X- _ O
( -X- _ O
Zhang -X- _ O
et -X- _ O
al -X- _ O
. -X- _ O
, -X- _ O
2020 -X- _ O
) -X- _ O
in -X- _ O
using -X- _ O
the -X- _ O
original -X- _ O
validation -X- _ O
dataset -X- _ O
as -X- _ O
the -X- _ O
test -X- _ O
set -X- _ O
for -X- _ O
the -X- _ O
convenience -X- _ O
of -X- _ O
comparison -X- _ O
. -X- _ O

3 -X- _ O
To -X- _ O
our -X- _ O
knowledge -X- _ O
, -X- _ O
ConceptFlow -X- _ B-MethodName
is -X- _ O
the -X- _ O
SOTA -X- _ O
model -X- _ O
for -X- _ O
this -X- _ O
task -X- _ O
( -X- _ O
where -X- _ O
text -X- _ O
and -X- _ O
knowledge -X- _ O
graphs -X- _ O
are -X- _ O
used -X- _ O
as -X- _ O
the -X- _ O
input -X- _ O
) -X- _ O
. -X- _ O
There -X- _ O
are -X- _ O
some -X- _ O
other -X- _ O
similar -X- _ O
works -X- _ O
( -X- _ O
Yu -X- _ O
et -X- _ O
al -X- _ O
. -X- _ O
, -X- _ O
2022 -X- _ O
; -X- _ O
Wu -X- _ O
et -X- _ O
al -X- _ O
. -X- _ O
, -X- _ O
2022 -X- _ O
) -X- _ O
in -X- _ O
commonsense -X- _ B-TaskName
dialogue -X- _ I-TaskName
generation -X- _ I-TaskName
, -X- _ O
but -X- _ O
they -X- _ O
generate -X- _ O
dialogues -X- _ O
with -X- _ O
additional -X- _ O
documents -X- _ O
or -X- _ O
other -X- _ O
kind -X- _ O
of -X- _ O
inputs -X- _ O
. -X- _ O
Due -X- _ O
to -X- _ O
the -X- _ O
different -X- _ O
input -X- _ O
formats -X- _ O
, -X- _ O
they -X- _ O
can -X- _ O
not -X- _ O
be -X- _ O
considered -X- _ O
as -X- _ O
baselines -X- _ O
in -X- _ O
our -X- _ O
task -X- _ O
. -X- _ O
the -X- _ O
generated -X- _ O
responses -X- _ O
. -X- _ O

Implementation -X- _ O
Details -X- _ O

Our -X- _ O
framework -X- _ O
is -X- _ O
mainly -X- _ O
implemented -X- _ O
with -X- _ O
Pytorch -X- _ O
4 -X- _ O
and -X- _ O
Pytorch -X- _ O
- -X- _ O
lightning -X- _ O
, -X- _ O
and -X- _ O
we -X- _ O
select -X- _ O
BART -X- _ B-MethodName
( -X- _ O
Lewis -X- _ O
et -X- _ O
al -X- _ O
. -X- _ O
, -X- _ O
2020 -X- _ O
) -X- _ O
as -X- _ O
the -X- _ O
base -X- _ O
language -X- _ O
model -X- _ O
. -X- _ O
We -X- _ O
use -X- _ O
a -X- _ O
publicly -X- _ O
available -X- _ O
checkpoint -X- _ O
5 -X- _ O
from -X- _ O
Huggingface -X- _ O
, -X- _ O
and -X- _ O
fine -X- _ O
- -X- _ O
tune -X- _ O
it -X- _ O
with -X- _ O
our -X- _ O
dynamic -X- _ O
graph -X- _ O
knowledge -X- _ O
aggregation -X- _ O
framework -X- _ O
. -X- _ O
The -X- _ O
random -X- _ O
seed -X- _ O
is -X- _ O
fixed -X- _ O
to -X- _ O
42 -X- _ O
for -X- _ O
ease -X- _ O
of -X- _ O
reproducibility -X- _ O
. -X- _ O
Our -X- _ O
language -X- _ O
model -X- _ O
has -X- _ O
12 -X- _ B-HyperparameterValue
attention -X- _ B-HyperparameterName
heads -X- _ I-HyperparameterName
and -X- _ O
6 -X- _ B-HyperparameterValue
hidden -X- _ B-HyperparameterName
layers -X- _ I-HyperparameterName
in -X- _ O
each -X- _ O
encoder -X- _ O
and -X- _ O
decoder -X- _ O
, -X- _ O
leading -X- _ O
to -X- _ O
a -X- _ O
total -X- _ O
of -X- _ O
157 -X- _ B-HyperparameterValue
M -X- _ I-HyperparameterValue
parameters -X- _ B-HyperparameterName
. -X- _ O
The -X- _ O
maximum -X- _ B-HyperparameterName
sequence -X- _ I-HyperparameterName
length -X- _ I-HyperparameterName
is -X- _ O
limited -X- _ O
to -X- _ O
512 -X- _ B-HyperparameterValue
; -X- _ O
the -X- _ O
batch -X- _ B-HyperparameterName
size -X- _ I-HyperparameterName
is -X- _ O
set -X- _ O
to -X- _ O
64 -X- _ B-HyperparameterValue
; -X- _ O
and -X- _ O
the -X- _ O
learning -X- _ B-HyperparameterName
rate -X- _ I-HyperparameterName
is -X- _ O
1e-4 -X- _ B-HyperparameterValue
. -X- _ O
We -X- _ O
use -X- _ O
Adam -X- _ O
( -X- _ O
Kingma -X- _ O
and -X- _ O
Ba -X- _ O
, -X- _ O
2014 -X- _ O
) -X- _ O
as -X- _ O
the -X- _ O
optimiser -X- _ O
and -X- _ O
set -X- _ O
its -X- _ O
parameter -X- _ O
to -X- _ O
1e-8 -X- _ B-HyperparameterValue
. -X- _ O
The -X- _ O
whole -X- _ O
training -X- _ O
process -X- _ O
lasts -X- _ O
for -X- _ O
5 -X- _ B-HyperparameterValue
epochs -X- _ B-HyperparameterName
. -X- _ O
We -X- _ O
train -X- _ O
on -X- _ O
an -X- _ O
Nvidia -X- _ O
RTX -X- _ O
A100 -X- _ O
GPU -X- _ O
node -X- _ O
, -X- _ O
which -X- _ O
has -X- _ O
120 -X- _ O
GB -X- _ O
of -X- _ O
system -X- _ O
memory -X- _ O
and -X- _ O
80 -X- _ O
GB -X- _ O
of -X- _ O
VRAM -X- _ O
, -X- _ O
and -X- _ O
takes -X- _ O
two -X- _ O
days -X- _ O
to -X- _ O
train -X- _ O
. -X- _ O

Automatic -X- _ O
Evaluation -X- _ O

Table -X- _ O
2 -X- _ O
shows -X- _ O
reference -X- _ O
- -X- _ O
based -X- _ O
automatic -X- _ O
evaluation -X- _ O
results -X- _ O
, -X- _ O
which -X- _ O
demonstrate -X- _ O
our -X- _ O
proposed -X- _ O
framework -X- _ O
substantially -X- _ O
outperforms -X- _ O
all -X- _ O
baselines -X- _ O
on -X- _ O
all -X- _ O
referenced -X- _ O
metrics -X- _ O
. -X- _ O
In -X- _ O
comparison -X- _ O
to -X- _ O
the -X- _ O
SOTA -X- _ O
model -X- _ O
ConceptFlow -X- _ B-MethodName
, -X- _ O
our -X- _ O
model -X- _ O
doubles -X- _ O
( -X- _ O
e.g. -X- _ O
BLEU-2 -X- _ B-MetricName
, -X- _ O
NIST-2 -X- _ B-MetricName
, -X- _ O
METEOR -X- _ B-MetricName
) -X- _ O
or -X- _ O
triples -X- _ O
( -X- _ O
e.g. -X- _ O
BLEU-3 -X- _ B-MetricName
, -X- _ O
BLEU-4 -X- _ B-MetricName
) -X- _ O
performance -X- _ O
on -X- _ O
most -X- _ O
metrics -X- _ O
. -X- _ O

Considering -X- _ O
the -X- _ O
performance -X- _ O
of -X- _ O
-w -X- _ O
/ -X- _ O
o -X- _ O
kg -X- _ O
( -X- _ O
equivalent -X- _ O
to -X- _ O
vanilla -X- _ B-MethodName
BART -X- _ I-MethodName
) -X- _ O
, -X- _ O
it -X- _ O
can -X- _ O
be -X- _ O
inferred -X- _ O
that -X- _ O
the -X- _ O
enhanced -X- _ O
performance -X- _ O
of -X- _ O
our -X- _ O
model -X- _ O
is -X- _ O
primarily -X- _ O
attributable -X- _ O
to -X- _ O
incorporating -X- _ O
external -X- _ O
knowledge -X- _ O
. -X- _ O

Comparing -X- _ O
to -X- _ O
other -X- _ O
GNN -X- _ B-MethodName
models -X- _ O
( -X- _ O
e.g. -X- _ O
Concept -X- _ B-MethodName
- -X- _ I-MethodName
Flow -X- _ I-MethodName
and -X- _ O
CCM -X- _ B-MethodName
) -X- _ O
, -X- _ O
our -X- _ O
model -X- _ O
is -X- _ O
superior -X- _ O
in -X- _ O
handling -X- _ O
the -X- _ O
heterogeneous -X- _ O
features -X- _ O
from -X- _ O
the -X- _ O
text -X- _ O
and -X- _ O
graph -X- _ O
knowledge -X- _ O
, -X- _ O
leading -X- _ O
to -X- _ O
a -X- _ O
better -X- _ O
capturing -X- _ O
of -X- _ O
the -X- _ O
global -X- _ O
context -X- _ O
contained -X- _ O
in -X- _ O
both -X- _ O
the -X- _ O
post -X- _ O
and -X- _ O
knowledge -X- _ O
graph -X- _ O
. -X- _ O
In -X- _ O
terms -X- _ O
of -X- _ O
unreferenced -X- _ O
metrics -X- _ O
, -X- _ O
the -X- _ O
results -X- _ O
in -X- _ O
Table -X- _ O
3 -X- _ O
also -X- _ O
show -X- _ O
that -X- _ O
our -X- _ O
model -X- _ O
achieves -X- _ O
a -X- _ O
substantial -X- _ O
improvement -X- _ O
in -X- _ O
diversity -X- _ O
. -X- _ O
It -X- _ O
can -X- _ O
be -X- _ O
observed -X- _ O
that -X- _ O
our -X- _ O
model -X- _ O
performance -X- _ O
on -X- _ O
Dist-1 -X- _ B-MetricName
and -X- _ O
Dist-2 -X- _ B-MetricName
are -X- _ O
more -X- _ O
than -X- _ O
twice -X- _ O
that -X- _ O
of -X- _ O
the -X- _ O
SOTA -X- _ O
model -X- _ O
ConceptFlow -X- _ B-MethodName
. -X- _ O
Our -X- _ O
improvement -X- _ O
on -X- _ O
both -X- _ O
unreferenced -X- _ O
and -X- _ O
referenced -X- _ O
metrics -X- _ O
further -X- _ O
demonstrates -X- _ O
that -X- _ O
the -X- _ O
gain -X- _ O
comes -X- _ O
from -X- _ O
incorporat -X- _ O
- -X- _ O
ing -X- _ O
knowledge -X- _ O
to -X- _ O
generate -X- _ O
human -X- _ O
- -X- _ O
like -X- _ O
responses -X- _ O
, -X- _ O
rather -X- _ O
than -X- _ O
metric -X- _ O
- -X- _ O
oriented -X- _ O
training -X- _ O
( -X- _ O
i.e. -X- _ O
, -X- _ O
no -X- _ O
metricoriented -X- _ O
reward -X- _ O
is -X- _ O
used -X- _ O
here -X- _ O
) -X- _ O
. -X- _ O
In -X- _ O
addition -X- _ O
, -X- _ O
the -X- _ O
ablation -X- _ O
results -X- _ O
of -X- _ O
-w -X- _ O
/ -X- _ O
o -X- _ O
dy -X- _ O
- -X- _ O
agg -X- _ O
and -X- _ O
-w -X- _ O
/ -X- _ O
o -X- _ O
st -X- _ O
- -X- _ O
agg -X- _ O
also -X- _ O
prove -X- _ O
the -X- _ O
hierarchical -X- _ O
layers -X- _ O
of -X- _ O
graph -X- _ O
knowledge -X- _ O
aggregation -X- _ O
benefit -X- _ O
the -X- _ O
semantic -X- _ O
understanding -X- _ O
of -X- _ O
graph -X- _ O
knowledge -X- _ O
. -X- _ O
The -X- _ O
aggregation -X- _ O
of -X- _ O
static -X- _ O
graph -X- _ O
features -X- _ O
forms -X- _ O
the -X- _ O
representation -X- _ O
learning -X- _ O
of -X- _ O
lowerlevel -X- _ O
semantics -X- _ O
, -X- _ O
whilst -X- _ O
the -X- _ O
dynamic -X- _ O
aggregation -X- _ O
contributes -X- _ O
to -X- _ O
the -X- _ O
representation -X- _ O
of -X- _ O
higher -X- _ O
- -X- _ O
level -X- _ O
semantics -X- _ O
. -X- _ O
Therefore -X- _ O
, -X- _ O
combining -X- _ O
the -X- _ O
two -X- _ O
kinds -X- _ O
of -X- _ O
semantics -X- _ O
leads -X- _ O
to -X- _ O
a -X- _ O
substantial -X- _ O
performance -X- _ O
improvement -X- _ O
on -X- _ O
both -X- _ O
referenced -X- _ O
and -X- _ O
unreferenced -X- _ O
metrics -X- _ O
. -X- _ O

In -X- _ O
- -X- _ O
Depth -X- _ O
Analysis -X- _ O

Furthermore -X- _ O
, -X- _ O
we -X- _ O
present -X- _ O
two -X- _ O
experiments -X- _ O
to -X- _ O
analyse -X- _ O
whether -X- _ O
the -X- _ O
external -X- _ O
knowledge -X- _ O
is -X- _ O
better -X- _ O
exploited -X- _ O
in -X- _ O
our -X- _ O
framework -X- _ O
than -X- _ O
the -X- _ O
SOTA -X- _ O
model -X- _ O
( -X- _ O
ConceptFlow -X- _ B-MethodName
) -X- _ O
, -X- _ O
as -X- _ O
well -X- _ O
as -X- _ O
why -X- _ O
our -X- _ O
framework -X- _ O
learns -X- _ O
representations -X- _ O
more -X- _ O
efficiently -X- _ O
and -X- _ O
effectively -X- _ O
. -X- _ O

As -X- _ O
the -X- _ O
number -X- _ O
of -X- _ O
retrieved -X- _ O
entities -X- _ O
increases -X- _ O
, -X- _ O
the -X- _ O
curve -X- _ O
in -X- _ O
( -X- _ O
c -X- _ O
) -X- _ O
maintains -X- _ O
a -X- _ O
steady -X- _ O
slope -X- _ O
to -X- _ O
incorporate -X- _ O
entities -X- _ O
, -X- _ O
indicating -X- _ O
that -X- _ O
our -X- _ O
model -X- _ O
maintains -X- _ O
the -X- _ O
incorporation -X- _ O
efficacy -X- _ O
even -X- _ O
with -X- _ O
large -X- _ O
amounts -X- _ O
of -X- _ O
knowledge -X- _ O
as -X- _ O
input -X- _ O
. -X- _ O
We -X- _ O
argue -X- _ O
that -X- _ O
the -X- _ O
robustness -X- _ O
and -X- _ O
efficiency -X- _ O
of -X- _ O
knowledge -X- _ O
incorporation -X- _ O
result -X- _ O
from -X- _ O
the -X- _ O
globally -X- _ O
aggregated -X- _ O
features -X- _ O
from -X- _ O
the -X- _ O
dynamically -X- _ O
constructed -X- _ O
graph -X- _ O
with -X- _ O
pseudo -X- _ O
nodes -X- _ O
, -X- _ O
which -X- _ O
avoids -X- _ O
the -X- _ O
information -X- _ O
loss -X- _ O
that -X- _ O
the -X- _ O
vanilla -X- _ B-MethodName
GNN -X- _ I-MethodName
models -X- _ O
typically -X- _ O
suffer -X- _ O
. -X- _ O
This -X- _ O
also -X- _ O
leads -X- _ O
to -X- _ O
our -X- _ O
model -X- _ O
outperforming -X- _ O
other -X- _ O
baseline -X- _ O
models -X- _ O
in -X- _ O
generating -X- _ O
high -X- _ O
- -X- _ O
quality -X- _ O
responses -X- _ O
. -X- _ O

Figure -X- _ O
4 -X- _ O
shows -X- _ O
the -X- _ O
representations -X- _ O
of -X- _ O
text -X- _ O
and -X- _ O
entities -X- _ O
from -X- _ O
the -X- _ O
knowledge -X- _ O
graph -X- _ O
. -X- _ O
We -X- _ O
project -X- _ O
the -X- _ O
embeddings -X- _ O
of -X- _ O
the -X- _ O
vanilla -X- _ B-MethodName
GNN -X- _ I-MethodName
models -X- _ O
used -X- _ O
in -X- _ O
the -X- _ O
baselines -X- _ O
into -X- _ O
two -X- _ O
- -X- _ O
dimensional -X- _ O
points -X- _ O
for -X- _ O
visualisation -X- _ O
. -X- _ O
To -X- _ O
compare -X- _ O
the -X- _ O
difference -X- _ O
in -X- _ O
embeddings -X- _ O
from -X- _ O
text -X- _ O
and -X- _ O
the -X- _ O
knowledge -X- _ O
graph -X- _ O
, -X- _ O
we -X- _ O
normalise -X- _ O
by -X- _ O
mapping -X- _ O
both -X- _ O
embeddings -X- _ O
to -X- _ O
the -X- _ O
range -X- _ O
of -X- _ O
[ -X- _ O
0 -X- _ O
, -X- _ O
1 -X- _ O
] -X- _ O
. -X- _ O
It -X- _ O
can -X- _ O
be -X- _ O
observed -X- _ O
that -X- _ O
the -X- _ O
entity -X- _ O
embeddings -X- _ O
of -X- _ O
the -X- _ O
baselines -X- _ O
( -X- _ O
shown -X- _ O
in -X- _ O
Figure -X- _ O
4 -X- _ O
( -X- _ O
a -X- _ O
) -X- _ O
) -X- _ O
are -X- _ O
concentrated -X- _ O
in -X- _ O
a -X- _ O
circle -X- _ O
no -X- _ O
matter -X- _ O
what -X- _ O
post -X- _ O
is -X- _ O
given -X- _ O
( -X- _ O
i.e. -X- _ O
blue -X- _ O
points -X- _ O
) -X- _ O
. -X- _ O
This -X- _ O
suggests -X- _ O
that -X- _ O
the -X- _ O
GNN -X- _ B-MethodName
- -X- _ O
learned -X- _ O
embeddings -X- _ O
present -X- _ O
a -X- _ O
biased -X- _ O
representation -X- _ O
for -X- _ O
external -X- _ O
knowledge -X- _ O
, -X- _ O
which -X- _ O
may -X- _ O
lead -X- _ O
to -X- _ O
difficulty -X- _ O
in -X- _ O
incorporating -X- _ O
graph -X- _ O
knowledge -X- _ O
with -X- _ O
the -X- _ O
language -X- _ O
model -X- _ O
( -X- _ O
which -X- _ O
is -X- _ O
trained -X- _ O
on -X- _ O
text -X- _ O
corpora -X- _ O
) -X- _ O
. -X- _ O
In -X- _ O
comparison -X- _ O
, -X- _ O
our -X- _ O
framework -X- _ O
unifies -X- _ O
the -X- _ O
representation -X- _ O
hidden -X- _ O
space -X- _ O
of -X- _ O
both -X- _ O
text -X- _ O
and -X- _ O
graph -X- _ O
knowledge -X- _ O
, -X- _ O
which -X- _ O
makes -X- _ O
the -X- _ O
heterogeneous -X- _ O
features -X- _ O
have -X- _ O
more -X- _ O
shared -X- _ O
space -X- _ O
to -X- _ O
fit -X- _ O
the -X- _ O
dataset -X- _ O
. -X- _ O
This -X- _ O
mechanism -X- _ O
makes -X- _ O
the -X- _ O
entity -X- _ O
embeddings -X- _ O
in -X- _ O
our -X- _ O
framework -X- _ O
evenly -X- _ O
spread -X- _ O
among -X- _ O
text -X- _ O
words -X- _ O
, -X- _ O
thus -X- _ O
it -X- _ O
can -X- _ O
be -X- _ O
easily -X- _ O
exploited -X- _ O
by -X- _ O
neural -X- _ O
networks -X- _ O
. -X- _ O

Human -X- _ B-MethodName
Evaluation -X- _ I-MethodName

We -X- _ O
present -X- _ O
manual -X- _ O
pair -X- _ O
- -X- _ O
wise -X- _ O
comparisons -X- _ O
to -X- _ O
examine -X- _ O
the -X- _ O
appropriateness -X- _ B-MetricName
( -X- _ O
whether -X- _ O
the -X- _ O
response -X- _ O
is -X- _ O
appropriate -X- _ O
in -X- _ O
the -X- _ O
context -X- _ O
) -X- _ O
and -X- _ O
informativeness -X- _ B-MetricName
( -X- _ O
whether -X- _ O
the -X- _ O
response -X- _ O
contains -X- _ O
much -X- _ O
information -X- _ O
) -X- _ O
of -X- _ O
the -X- _ O
most -X- _ O
competitive -X- _ O
baseline -X- _ O
( -X- _ O
ConceptFlow -X- _ B-MethodName
) -X- _ O
, -X- _ O
our -X- _ O
model -X- _ O
( -X- _ O
SaBART -X- _ B-MethodName
) -X- _ O
, -X- _ O
as -X- _ O
well -X- _ O
as -X- _ O
two -X- _ O
ablation -X- _ O
models -X- _ O
( -X- _ O
-w -X- _ O
/ -X- _ O
o -X- _ O
dy -X- _ O
- -X- _ O
agg -X- _ O
and -X- _ O
-w -X- _ O
/ -X- _ O
o -X- _ O
st -X- _ O
- -X- _ O
agg -X- _ O
) -X- _ O
. -X- _ O
Three -X- _ O
human -X- _ O
evaluators -X- _ O
are -X- _ O
instructed -X- _ O
to -X- _ O
give -X- _ O
their -X- _ O
preferred -X- _ O
response -X- _ O
on -X- _ O
100 -X- _ O
randomly -X- _ O
sampled -X- _ O
conversational -X- _ O
pairs -X- _ O
between -X- _ O
each -X- _ O
compared -X- _ O
model -X- _ O
. -X- _ O
The -X- _ O
results -X- _ O
are -X- _ O
reported -X- _ O
in -X- _ O
Table -X- _ O
4 -X- _ O
. -X- _ O
( -X- _ O
Fleiss -X- _ O
, -X- _ O
1971 -X- _ O
) -X- _ O
, -X- _ O
which -X- _ O
indicates -X- _ O
all -X- _ O
of -X- _ O
our -X- _ O
evaluation -X- _ O
annotations -X- _ O
reach -X- _ O
a -X- _ O
fair -X- _ O
or -X- _ O
moderate -X- _ O
agreement -X- _ O
( -X- _ O
meaning -X- _ O
the -X- _ O
two -X- _ O
ablated -X- _ O
models -X- _ O
generate -X- _ O
similar -X- _ O
answers -X- _ O
to -X- _ O
SaBART -X- _ B-MethodName
) -X- _ O
. -X- _ O

When -X- _ O
summarising -X- _ O
the -X- _ O
human -X- _ B-MethodName
annotation -X- _ I-MethodName
results -X- _ O
, -X- _ O
the -X- _ O
final -X- _ O
results -X- _ O
are -X- _ O
counted -X- _ O
by -X- _ O
majority -X- _ O
voting -X- _ O
. -X- _ O
The -X- _ O
ablated -X- _ O
static -X- _ O
aggregation -X- _ O
and -X- _ O
dynamic -X- _ O
aggregation -X- _ O
play -X- _ O
different -X- _ O
roles -X- _ O
in -X- _ O
feature -X- _ O
incorporation -X- _ O
, -X- _ O
so -X- _ O
the -X- _ O
results -X- _ O
of -X- _ O
the -X- _ O
corresponding -X- _ O
ablation -X- _ O
models -X- _ O
are -X- _ O
slightly -X- _ O
lower -X- _ O
than -X- _ O
that -X- _ O
of -X- _ O
SaBART -X- _ B-MethodName
. -X- _ O
On -X- _ O
the -X- _ O
other -X- _ O
hand -X- _ O
, -X- _ O
the -X- _ O
comparison -X- _ O
with -X- _ O
ConceptFlow -X- _ B-MethodName
demonstrates -X- _ O
that -X- _ O
our -X- _ O
proposed -X- _ O
model -X- _ O
significantly -X- _ O
outperforms -X- _ O
the -X- _ O
SOTA -X- _ O
in -X- _ O
terms -X- _ O
of -X- _ O
both -X- _ O
appropriateness -X- _ B-MetricName
and -X- _ O
informativeness -X- _ B-MetricName
, -X- _ O
which -X- _ O
is -X- _ O
consistent -X- _ O
with -X- _ O
our -X- _ O
observations -X- _ O
in -X- _ O
automatic -X- _ O
evaluation -X- _ O
. -X- _ O

In -X- _ O
Table -X- _ O
5 -X- _ O
, -X- _ O
we -X- _ O
show -X- _ O
the -X- _ O
generated -X- _ O
responses -X- _ O
of -X- _ O
the -X- _ O
most -X- _ O
competitive -X- _ O
models -X- _ O
( -X- _ O
i.e. -X- _ O
, -X- _ O
two -X- _ O
ablated -X- _ O
models -X- _ O
and -X- _ O
ConceptFlow -X- _ B-MethodName
) -X- _ O
. -X- _ O
We -X- _ O
select -X- _ O
a -X- _ O
short -X- _ O
post -X- _ O
and -X- _ O
a -X- _ O
long -X- _ O
post -X- _ O
that -X- _ O
includes -X- _ O
more -X- _ O
graph -X- _ O
knowledge -X- _ O
to -X- _ O
validate -X- _ O
performance -X- _ O
. -X- _ O
It -X- _ O
can -X- _ O
be -X- _ O
observed -X- _ O
that -X- _ O
in -X- _ O
both -X- _ O
cases -X- _ O
, -X- _ O
the -X- _ O
models -X- _ O
containing -X- _ O
aggregation -X- _ O
frameworks -X- _ O
tend -X- _ O
to -X- _ O
compose -X- _ O
their -X- _ O
responses -X- _ O
with -X- _ O
more -X- _ O
unique -X- _ O
and -X- _ O
relevant -X- _ O
entities -X- _ O
. -X- _ O
When -X- _ O
a -X- _ O
short -X- _ O
post -X- _ O
is -X- _ O
given -X- _ O
, -X- _ O
the -X- _ O
knowledge -X- _ O
can -X- _ O
effectively -X- _ O
help -X- _ O
avoid -X- _ O
generating -X- _ O
overly -X- _ O
simplistic -X- _ O
utterances -X- _ O
, -X- _ O
resulting -X- _ O
in -X- _ O
a -X- _ O
more -X- _ O
appropriate -X- _ O
, -X- _ O
informative -X- _ O
, -X- _ O
and -X- _ O
engaging -X- _ O
response -X- _ O
output -X- _ O
. -X- _ O
Given -X- _ O
a -X- _ O
long -X- _ O
input -X- _ O
, -X- _ O
all -X- _ O
models -X- _ O
seem -X- _ O
good -X- _ O
at -X- _ O
generating -X- _ O
a -X- _ O
long -X- _ O
response -X- _ O
. -X- _ O
However -X- _ O
, -X- _ O
compared -X- _ O
to -X- _ O
SaBART -X- _ B-MethodName
, -X- _ O
the -X- _ O
responses -X- _ O
generated -X- _ O
by -X- _ O
the -X- _ O
baseline -X- _ O
models -X- _ O
are -X- _ O
less -X- _ O
expressive -X- _ O
due -X- _ O
to -X- _ O
the -X- _ O
sub -X- _ O
- -X- _ O
optimal -X- _ O
incorporation -X- _ O
of -X- _ O
graph -X- _ O
knowledge -X- _ O
. -X- _ O
For -X- _ O
example -X- _ O
, -X- _ O
ConceptFlow -X- _ B-MethodName
uses -X- _ O
four -X- _ O
instances -X- _ O
of -X- _ O
" -X- _ O
play -X- _ O
" -X- _ O
in -X- _ O
the -X- _ O
response -X- _ O
, -X- _ O
diluting -X- _ O
the -X- _ O

As -X- _ O
an -X- _ O
energy -X- _ O
drink -X- _ O
consumer -X- _ O
who -X- _ O
hates -X- _ O
tea -X- _ O
, -X- _ O
this -X- _ O
is -X- _ O
hilarious -X- _ O
. -X- _ O

I -X- _ O
'm -X- _ O
not -X- _ O
a -X- _ O
tea -X- _ O
drink -X- _ O
consumer -X- _ O
, -X- _ O
but -X- _ O
i -X- _ O
do -X- _ O
n't -X- _ O
think -X- _ O
it -X- _ O
's -X- _ O
hilarious -X- _ O
. -X- _ O

w -X- _ O
/ -X- _ O
o -X- _ O
st -X- _ O
- -X- _ O
agg -X- _ O
As -X- _ O
a -X- _ O
consumer -X- _ O
, -X- _ O
this -X- _ O
is -X- _ O
hilarious -X- _ O
. -X- _ O

w -X- _ O
/ -X- _ O
o -X- _ O
dy -X- _ O
- -X- _ O
agg -X- _ O
As -X- _ O
a -X- _ O
consumer -X- _ O
, -X- _ O
this -X- _ O
is -X- _ O
hilarious -X- _ O
. -X- _ O

I -X- _ O
've -X- _ O
played -X- _ O
it -X- _ O
on -X- _ O
ps3 -X- _ O
, -X- _ O
and -X- _ O
i -X- _ O
have -X- _ O
no -X- _ O
idea -X- _ O
what -X- _ O
the -X- _ O
problem -X- _ O
is -X- _ O
with -X- _ O
it -X- _ O
. -X- _ O
pc -X- _ O
is -X- _ O
really -X- _ O
suitable -X- _ O
for -X- _ O
this -X- _ O
game -X- _ O
. -X- _ O

w -X- _ O
/ -X- _ O
o -X- _ O
st -X- _ O
- -X- _ O
agg -X- _ O
It -X- _ O
's -X- _ O
not -X- _ O
suited -X- _ O
for -X- _ O
pc -X- _ O
, -X- _ O
but -X- _ O
it -X- _ O
does -X- _ O
n't -X- _ O
have -X- _ O
to -X- _ O
be -X- _ O
on -X- _ O
a -X- _ O
ps3 -X- _ O
. -X- _ O

w -X- _ O
/ -X- _ O
o -X- _ O
dy -X- _ O
- -X- _ O
agg -X- _ O
I -X- _ O
've -X- _ O
played -X- _ O
it -X- _ O
on -X- _ O
ps3 -X- _ O
, -X- _ O
and -X- _ O
it -X- _ O
's -X- _ O
not -X- _ O
really -X- _ O
suited -X- _ O
for -X- _ O
pc -X- _ O
. -X- _ O

Conclusion -X- _ O

Limitations -X- _ O

This -X- _ O
paper -X- _ O
aims -X- _ O
to -X- _ O
investigate -X- _ O
a -X- _ O
more -X- _ O
efficient -X- _ O
and -X- _ O
effective -X- _ O
framework -X- _ O
to -X- _ O
incorporate -X- _ O
the -X- _ O
heterogeneous -X- _ O
features -X- _ O
of -X- _ O
both -X- _ O
text -X- _ O
and -X- _ O
graph -X- _ O
knowledge -X- _ O
. -X- _ O

The -X- _ O
extensive -X- _ O
experiments -X- _ O
demonstrate -X- _ O
our -X- _ O
framework -X- _ O
has -X- _ O
a -X- _ O
superior -X- _ O
performance -X- _ O
in -X- _ O
capturing -X- _ O
semantics -X- _ O
of -X- _ O
input -X- _ O
knowledge -X- _ O
, -X- _ O
thus -X- _ O
beating -X- _ O
all -X- _ O
SOTA -X- _ O
models -X- _ O
. -X- _ O
However -X- _ O
, -X- _ O
due -X- _ O
to -X- _ O
the -X- _ O
time -X- _ O
and -X- _ O
resource -X- _ O
limit -X- _ O
, -X- _ O
we -X- _ O
could -X- _ O
not -X- _ O
conduct -X- _ O
further -X- _ O
experimentation -X- _ O
to -X- _ O
compare -X- _ O
with -X- _ O
promising -X- _ O
frameworks -X- _ O
in -X- _ O
similar -X- _ O
areas -X- _ O
. -X- _ O
In -X- _ O
fact -X- _ O
, -X- _ O
we -X- _ O
have -X- _ O
observed -X- _ O
some -X- _ O
other -X- _ O
techniques -X- _ O
( -X- _ O
Tang -X- _ O
et -X- _ O
al -X- _ O
. -X- _ O
, -X- _ O
2022c -X- _ O
; -X- _ O
Yu -X- _ O
et -X- _ O
al -X- _ O
. -X- _ O
, -X- _ O
2022 -X- _ O
; -X- _ O
Wu -X- _ O
et -X- _ O
al -X- _ O
. -X- _ O
, -X- _ O
2022 -X- _ O
) -X- _ O
may -X- _ O
be -X- _ O
beneficial -X- _ O
to -X- _ O
our -X- _ O
study -X- _ O
, -X- _ O
but -X- _ O
when -X- _ O
considering -X- _ O
the -X- _ O
difficulty -X- _ O
in -X- _ O
applying -X- _ O
them -X- _ O
here -X- _ O
( -X- _ O
due -X- _ O
to -X- _ O
additional -X- _ O
annotation -X- _ O
and -X- _ O
knowledge -X- _ O
being -X- _ O
required -X- _ O
) -X- _ O
, -X- _ O
we -X- _ O
have -X- _ O
to -X- _ O
leave -X- _ O
them -X- _ O
to -X- _ O
future -X- _ O
work -X- _ O
. -X- _ O
We -X- _ O
also -X- _ O
can -X- _ O
not -X- _ O
exclude -X- _ O
some -X- _ O
other -X- _ O
factors -X- _ O
which -X- _ O
may -X- _ O
affect -X- _ O
performance -X- _ O
. -X- _ O
For -X- _ O
example -X- _ O
, -X- _ O
we -X- _ O
select -X- _ O
BART -X- _ B-MethodName
as -X- _ O
the -X- _ O
base -X- _ O
language -X- _ O
model -X- _ O
in -X- _ O
this -X- _ O
paper -X- _ O
. -X- _ O
In -X- _ O
practical -X- _ O
use -X- _ O
, -X- _ O
the -X- _ O
latest -X- _ O
language -X- _ O
models -X- _ O
( -X- _ O
e.g. -X- _ O
ChatGPT -X- _ B-MethodName
) -X- _ O
may -X- _ O
have -X- _ O
better -X- _ O
performance -X- _ O
in -X- _ O
this -X- _ O
task -X- _ O
. -X- _ O
We -X- _ O
have -X- _ O
to -X- _ O
leave -X- _ O
the -X- _ O
analysis -X- _ O
of -X- _ O
these -X- _ O
factors -X- _ O
to -X- _ O
future -X- _ O
study -X- _ O
. -X- _ O

Ethics -X- _ O
Statement -X- _ O

We -X- _ O
conduct -X- _ O
the -X- _ O
experiments -X- _ O
based -X- _ O
on -X- _ O
an -X- _ O
existing -X- _ O
publicly -X- _ O
available -X- _ O
dataset -X- _ O
from -X- _ O
Zhou -X- _ O
et -X- _ O
al -X- _ O
. -X- _ O
( -X- _ O
2018 -X- _ O
) -X- _ O
which -X- _ O
is -X- _ O
a -X- _ O
large -X- _ O
- -X- _ O
scale -X- _ O
dataset -X- _ O
widely -X- _ O
used -X- _ O
to -X- _ O
study -X- _ O
commonsense -X- _ B-TaskName
dialogue -X- _ I-TaskName
generation -X- _ I-TaskName
, -X- _ O
and -X- _ O
we -X- _ O
strictly -X- _ O
follow -X- _ O
the -X- _ O
license -X- _ O
and -X- _ O
instructions -X- _ O
. -X- _ O
We -X- _ O
also -X- _ O
read -X- _ O
and -X- _ O
acknowledge -X- _ O
the -X- _ O
ACM -X- _ O
Code -X- _ O
of -X- _ O
Ethnics -X- _ O
and -X- _ O
Professional -X- _ O
Conduct -X- _ O
. -X- _ O
6 -X- _ O
We -X- _ O
take -X- _ O
our -X- _ O
professional -X- _ O
responsibilities -X- _ O
very -X- _ O
seriously -X- _ O
, -X- _ O
and -X- _ O
our -X- _ O
study -X- _ O
did -X- _ O
not -X- _ O
violate -X- _ O
any -X- _ O
ethical -X- _ O
principles -X- _ O
. -X- _ O
Additionally -X- _ O
, -X- _ O
whilst -X- _ O
our -X- _ O
work -X- _ O
concerns -X- _ O
the -X- _ O
incorporation -X- _ O
of -X- _ O
knowledge -X- _ O
from -X- _ O
knowledge -X- _ O
graphs -X- _ O
in -X- _ O
dialogue -X- _ O
systems -X- _ O
, -X- _ O
we -X- _ O
acknowledge -X- _ O
that -X- _ O
the -X- _ O
veracity -X- _ O
and -X- _ O
validity -X- _ O
of -X- _ O
the -X- _ O
knowledge -X- _ O
in -X- _ O
such -X- _ O
resources -X- _ O
should -X- _ O
be -X- _ O
assessed -X- _ O
in -X- _ O
production -X- _ O
, -X- _ O
in -X- _ O
order -X- _ O
to -X- _ O
avoid -X- _ O
the -X- _ O
perpetuation -X- _ O
of -X- _ O
misinformation -X- _ O
. -X- _ O
B3 -X- _ O
. -X- _ O
Did -X- _ O
you -X- _ O
discuss -X- _ O
if -X- _ O
your -X- _ O
use -X- _ O
of -X- _ O
existing -X- _ O
artifact -X- _ O
( -X- _ O
s -X- _ O
) -X- _ O
was -X- _ O
consistent -X- _ O
with -X- _ O
their -X- _ O
intended -X- _ O
use -X- _ O
, -X- _ O
provided -X- _ O
that -X- _ O
it -X- _ O
was -X- _ O
specified -X- _ O
? -X- _ O
For -X- _ O
the -X- _ O
artifacts -X- _ O
you -X- _ O
create -X- _ O
, -X- _ O
do -X- _ O
you -X- _ O
specify -X- _ O
intended -X- _ O
use -X- _ O
and -X- _ O
whether -X- _ O
that -X- _ O
is -X- _ O
compatible -X- _ O
with -X- _ O
the -X- _ O
original -X- _ O
access -X- _ O
conditions -X- _ O
( -X- _ O
in -X- _ O
particular -X- _ O
, -X- _ O
derivatives -X- _ O
of -X- _ O
data -X- _ O
accessed -X- _ O
for -X- _ O
research -X- _ O
purposes -X- _ O
should -X- _ O
not -X- _ O
be -X- _ O
used -X- _ O
outside -X- _ O
of -X- _ O
research -X- _ O
contexts -X- _ O
) -X- _ O
? -X- _ O
Section -X- _ O
of -X- _ O
" -X- _ O
Ethnical -X- _ O
Statement -X- _ O
" -X- _ O
B4 -X- _ O
. -X- _ O
Did -X- _ O
you -X- _ O
discuss -X- _ O
the -X- _ O
steps -X- _ O
taken -X- _ O
to -X- _ O
check -X- _ O
whether -X- _ O
the -X- _ O
data -X- _ O
that -X- _ O
was -X- _ O
collected -X- _ O
/ -X- _ O
used -X- _ O
contains -X- _ O
any -X- _ O
information -X- _ O
that -X- _ O
names -X- _ O
or -X- _ O
uniquely -X- _ O
identifies -X- _ O
individual -X- _ O
people -X- _ O
or -X- _ O
offensive -X- _ O
content -X- _ O
, -X- _ O
and -X- _ O
the -X- _ O
steps -X- _ O
taken -X- _ O
to -X- _ O
protect -X- _ O
/ -X- _ O
anonymize -X- _ O
it -X- _ O
? -X- _ O
Not -X- _ O
applicable -X- _ O
. -X- _ O
Left -X- _ O
blank -X- _ O
. -X- _ O

Chen -X- _ O
Tang -X- _ O
is -X- _ O
supported -X- _ O
by -X- _ O
the -X- _ O
China -X- _ O
Scholarship -X- _ O
Council -X- _ O
( -X- _ O
CSC -X- _ O
) -X- _ O
for -X- _ O
his -X- _ O
doctoral -X- _ O
study -X- _ O
( -X- _ O
File -X- _ O
No.202006120039 -X- _ O
) -X- _ O
. -X- _ O
Tyler -X- _ O
Loakman -X- _ O
is -X- _ O
support -X- _ O

Semi -X- _ O
- -X- _ O
parametric -X- _ O
models -X- _ O
, -X- _ O
which -X- _ O
augment -X- _ O
generation -X- _ O
with -X- _ O
retrieval -X- _ O
, -X- _ O
have -X- _ O
led -X- _ O
to -X- _ O
impressive -X- _ O
results -X- _ O
in -X- _ O
language -X- _ O
modeling -X- _ O
and -X- _ O
machine -X- _ B-TaskName
translation -X- _ I-TaskName
, -X- _ O
due -X- _ O
to -X- _ O
their -X- _ O
ability -X- _ O
to -X- _ O
retrieve -X- _ O
fine -X- _ O
- -X- _ O
grained -X- _ O
information -X- _ O
from -X- _ O
a -X- _ O
datastore -X- _ O
of -X- _ O
examples -X- _ O
. -X- _ O
One -X- _ O
of -X- _ O
the -X- _ O
most -X- _ O
prominent -X- _ O
approaches -X- _ O
, -X- _ O
kNN -X- _ B-MethodName
- -X- _ I-MethodName
MT -X- _ I-MethodName
, -X- _ O
exhibits -X- _ O
strong -X- _ O
domain -X- _ O
adaptation -X- _ O
capabilities -X- _ O
by -X- _ O
retrieving -X- _ O
tokens -X- _ O
from -X- _ O
domain -X- _ O
- -X- _ O
specific -X- _ O
datastores -X- _ O
( -X- _ O
Khandelwal -X- _ O
et -X- _ O
al -X- _ O
. -X- _ O
, -X- _ O
2021 -X- _ O
) -X- _ O
. -X- _ O
However -X- _ O
, -X- _ O
kNN -X- _ B-MethodName
- -X- _ I-MethodName
MT -X- _ I-MethodName
requires -X- _ O
an -X- _ O
expensive -X- _ O
retrieval -X- _ O
operation -X- _ O
for -X- _ O
every -X- _ O
single -X- _ O
generated -X- _ O
token -X- _ O
, -X- _ O
leading -X- _ O
to -X- _ O
a -X- _ O
very -X- _ O
low -X- _ O
decoding -X- _ O
speed -X- _ O
( -X- _ O
around -X- _ O
8 -X- _ O
times -X- _ O
slower -X- _ O
than -X- _ O
a -X- _ O
parametric -X- _ O
model -X- _ O
) -X- _ O
. -X- _ O
In -X- _ O
this -X- _ O
paper -X- _ O
, -X- _ O
we -X- _ O
introduce -X- _ O
a -X- _ O
chunk -X- _ B-MethodName
- -X- _ I-MethodName
based -X- _ I-MethodName
kNN -X- _ I-MethodName
- -X- _ I-MethodName
MT -X- _ I-MethodName
model -X- _ O
which -X- _ O
retrieves -X- _ O
chunks -X- _ O
of -X- _ O
tokens -X- _ O
from -X- _ O
the -X- _ O
datastore -X- _ O
, -X- _ O
instead -X- _ O
of -X- _ O
a -X- _ O
single -X- _ O
token -X- _ O
. -X- _ O
We -X- _ O
propose -X- _ O
several -X- _ O
strategies -X- _ O
for -X- _ O
incorporating -X- _ O
the -X- _ O
retrieved -X- _ O
chunks -X- _ O
into -X- _ O
the -X- _ O
generation -X- _ O
process -X- _ O
, -X- _ O
and -X- _ O
for -X- _ O
selecting -X- _ O
the -X- _ O
steps -X- _ O
at -X- _ O
which -X- _ O
the -X- _ O
model -X- _ O
needs -X- _ O
to -X- _ O
search -X- _ O
for -X- _ O
neighbors -X- _ O
in -X- _ O
the -X- _ O
datastore -X- _ O
. -X- _ O
Experiments -X- _ O
on -X- _ O
machine -X- _ O
translation -X- _ O
in -X- _ O
two -X- _ O
settings -X- _ O
, -X- _ O
static -X- _ O
and -X- _ O
" -X- _ O
on -X- _ O
- -X- _ O
the -X- _ O
- -X- _ O
fly -X- _ O
" -X- _ O
domain -X- _ O
adaptation -X- _ O
, -X- _ O
show -X- _ O
that -X- _ O
the -X- _ O
chunk -X- _ B-MethodName
- -X- _ I-MethodName
based -X- _ I-MethodName
kNN -X- _ I-MethodName
- -X- _ I-MethodName
MT -X- _ I-MethodName
model -X- _ O
leads -X- _ O
to -X- _ O
significant -X- _ O
speed -X- _ O
- -X- _ O
ups -X- _ O
( -X- _ O
up -X- _ O
to -X- _ O
4 -X- _ B-MetricValue
times -X- _ I-MetricValue
) -X- _ O
with -X- _ O
only -X- _ O
a -X- _ O
small -X- _ O
drop -X- _ O
in -X- _ O
translation -X- _ O
quality -X- _ O
. -X- _ O
1 -X- _ O

Machine -X- _ B-TaskName
translation -X- _ I-TaskName
has -X- _ O
seen -X- _ O
remarkable -X- _ O
advances -X- _ O
due -X- _ O
to -X- _ O
increasingly -X- _ O
powerful -X- _ O
neural -X- _ O
models -X- _ O
( -X- _ O
Sutskever -X- _ O
et -X- _ O
al -X- _ O
. -X- _ O
, -X- _ O
2014 -X- _ O
; -X- _ O
Bahdanau -X- _ O
et -X- _ O
al -X- _ O
. -X- _ O
, -X- _ O
2015 -X- _ O
; -X- _ O
Vaswani -X- _ O
et -X- _ O
al -X- _ O
. -X- _ O
, -X- _ O
2017 -X- _ O
) -X- _ O
. -X- _ O
Most -X- _ O
deployed -X- _ O
systems -X- _ O
are -X- _ O
fully -X- _ O
- -X- _ O
parametric -X- _ O
( -X- _ O
the -X- _ O
training -X- _ O
data -X- _ O
is -X- _ O
fully -X- _ O
compressed -X- _ O
into -X- _ O
the -X- _ O
parameters -X- _ O
of -X- _ O
a -X- _ O
neural -X- _ O
model -X- _ O
) -X- _ O
, -X- _ O
but -X- _ O
they -X- _ O
often -X- _ O
struggle -X- _ O
when -X- _ O
translating -X- _ O
rare -X- _ O
words -X- _ O
or -X- _ O
out -X- _ O
- -X- _ O
of -X- _ O
- -X- _ O
domain -X- _ O
sentences -X- _ O
( -X- _ O
Koehn -X- _ O
and -X- _ O
Knowles -X- _ O
, -X- _ O
2017 -X- _ O
) -X- _ O
, -X- _ O
commonly -X- _ O
requiring -X- _ O
several -X- _ O
stages -X- _ O
of -X- _ O
finetuning -X- _ O
to -X- _ O
adapt -X- _ O
to -X- _ O
data -X- _ O
drift -X- _ O
or -X- _ O
to -X- _ O
new -X- _ O
domains -X- _ O
. -X- _ O
Recently -X- _ O
, -X- _ O
semi -X- _ O
- -X- _ O
parametric -X- _ O
methods -X- _ O
have -X- _ O
shown -X- _ O
great -X- _ O
promise -X- _ O
, -X- _ O
by -X- _ O
combining -X- _ O
the -X- _ O
strengths -X- _ O
of -X- _ O
parametric -X- _ O
models -X- _ O
with -X- _ O
external -X- _ O
databases -X- _ O
of -X- _ O
parallel -X- _ O
sentences -X- _ O
, -X- _ O
such -X- _ O
as -X- _ O
translation -X- _ O
memories -X- _ O
( -X- _ O
Gu -X- _ O
et -X- _ O
al -X- _ O
. -X- _ O
, -X- _ O
2018 -X- _ O
; -X- _ O
Zhang -X- _ O
et -X- _ O
al -X- _ O
. -X- _ O
, -X- _ O
2018 -X- _ O
; -X- _ O
Bapna -X- _ O
and -X- _ O
Firat -X- _ O
, -X- _ O
2019a -X- _ O
; -X- _ O
Zheng -X- _ O
et -X- _ O
al -X- _ O
. -X- _ O
, -X- _ O
2021a -X- _ O
; -X- _ O
Jiang -X- _ O
et -X- _ O
al -X- _ O
. -X- _ O
, -X- _ O
2021 -X- _ O
; -X- _ O
Martins -X- _ O
et -X- _ O
al -X- _ O
. -X- _ O
, -X- _ O
2022 -X- _ O
) -X- _ O
. -X- _ O

One -X- _ O
of -X- _ O
the -X- _ O
most -X- _ O
prominent -X- _ O
semi -X- _ O
- -X- _ O
parametric -X- _ O
models -X- _ O
for -X- _ O
machine -X- _ B-TaskName
translation -X- _ I-TaskName
is -X- _ O
the -X- _ O
k -X- _ B-MethodName
- -X- _ I-MethodName
Nearest -X- _ I-MethodName
Neighbor -X- _ I-MethodName
Machine -X- _ I-MethodName
Translation -X- _ I-MethodName
model -X- _ O
( -X- _ O
kNN -X- _ B-MethodName
- -X- _ I-MethodName
MT -X- _ I-MethodName
) -X- _ O
( -X- _ O
Khandelwal -X- _ O
et -X- _ O
al -X- _ O
. -X- _ O
, -X- _ O
2021 -X- _ O
) -X- _ O
, -X- _ O
which -X- _ O
has -X- _ O
led -X- _ O
to -X- _ O
impressive -X- _ O
results -X- _ O
, -X- _ O
particularly -X- _ O
in -X- _ O
domain -X- _ O
adaptation -X- _ O
settings -X- _ O
, -X- _ O
without -X- _ O
requiring -X- _ O
fine -X- _ O
- -X- _ O
tuning -X- _ O
. -X- _ O
The -X- _ O
kNN -X- _ B-MethodName
- -X- _ I-MethodName
MT -X- _ I-MethodName
model -X- _ O
constructs -X- _ O
domain -X- _ O
- -X- _ O
specific -X- _ O
datastores -X- _ O
of -X- _ O
parallel -X- _ O
sentences -X- _ O
and -X- _ O
, -X- _ O
at -X- _ O
inference -X- _ O
time -X- _ O
, -X- _ O
it -X- _ O
retrieves -X- _ O
similar -X- _ O
examples -X- _ O
from -X- _ O
these -X- _ O
datastores -X- _ O
, -X- _ O
which -X- _ O
are -X- _ O
used -X- _ O
to -X- _ O
improve -X- _ O
the -X- _ O
generation -X- _ O
process -X- _ O
, -X- _ O
through -X- _ O
the -X- _ O
interpolation -X- _ O
of -X- _ O
probability -X- _ O
distributions -X- _ O
. -X- _ O
However -X- _ O
, -X- _ O
kNN -X- _ B-MethodName
- -X- _ I-MethodName
MT -X- _ I-MethodName
only -X- _ O
retrieves -X- _ O
single -X- _ O
tokens -X- _ O
- -X- _ O
this -X- _ O
is -X- _ O
inefficient -X- _ O
, -X- _ O
since -X- _ O
the -X- _ O
model -X- _ O
needs -X- _ O
to -X- _ O
consult -X- _ O
the -X- _ O
datastore -X- _ O
at -X- _ O
every -X- _ O
generation -X- _ O
step -X- _ O
, -X- _ O
an -X- _ O
expensive -X- _ O
operation -X- _ O
. -X- _ O
Consequently -X- _ O
, -X- _ O
its -X- _ O
decoding -X- _ B-MetricName
speed -X- _ I-MetricName
is -X- _ O
around -X- _ O
8 -X- _ B-MetricValue
times -X- _ I-MetricValue
slower -X- _ O
than -X- _ O
that -X- _ O
of -X- _ O
a -X- _ O
fully -X- _ O
- -X- _ O
parametric -X- _ O
model -X- _ O
. -X- _ O

Recent -X- _ O
work -X- _ O
has -X- _ O
introduced -X- _ O
several -X- _ O
techniques -X- _ O
to -X- _ O
speed -X- _ O
up -X- _ O
kNN -X- _ B-MethodName
- -X- _ I-MethodName
MT -X- _ I-MethodName
. -X- _ O
proposed -X- _ O
Fast -X- _ B-MethodName
kNN -X- _ I-MethodName
- -X- _ I-MethodName
MT -X- _ I-MethodName
, -X- _ O
which -X- _ O
constructs -X- _ O
a -X- _ O
different -X- _ O
datastore -X- _ O
for -X- _ O
each -X- _ O
example -X- _ O
, -X- _ O
by -X- _ O
first -X- _ O
searching -X- _ O
for -X- _ O
the -X- _ O
nearest -X- _ O
neighbors -X- _ O
of -X- _ O
the -X- _ O
source -X- _ O
tokens -X- _ O
. -X- _ O
introduced -X- _ O
Faster -X- _ B-MethodName
kNN -X- _ I-MethodName
- -X- _ I-MethodName
MT -X- _ I-MethodName
, -X- _ O
similar -X- _ O
to -X- _ O
Fast -X- _ B-MethodName
kNN -X- _ I-MethodName
- -X- _ I-MethodName
MT -X- _ I-MethodName
but -X- _ O
with -X- _ O
reduced -X- _ O
memory -X- _ O
requirements -X- _ O
. -X- _ O
Martins -X- _ O
et -X- _ O
al -X- _ O
. -X- _ O
( -X- _ O
2022 -X- _ O
) -X- _ O
proposed -X- _ O
pruning -X- _ O
the -X- _ O
datastore -X- _ O
, -X- _ O
reducing -X- _ O
the -X- _ O
keys -X- _ O
' -X- _ O
representation -X- _ O
size -X- _ O
, -X- _ O
and -X- _ O
using -X- _ O
a -X- _ O
cache -X- _ O
of -X- _ O
retrieval -X- _ O
distributions -X- _ O
. -X- _ O
However -X- _ O
, -X- _ O
despite -X- _ O
leading -X- _ O
to -X- _ O
some -X- _ O
decoding -X- _ O
speedups -X- _ O
, -X- _ O
these -X- _ O
methods -X- _ O
are -X- _ O
limited -X- _ O
as -X- _ O
they -X- _ O
still -X- _ O
retrieve -X- _ O
a -X- _ O
single -X- _ O
token -X- _ O
at -X- _ O
each -X- _ O
time -X- _ O
step -X- _ O
. -X- _ O

In -X- _ O
this -X- _ O
paper -X- _ O
, -X- _ O
we -X- _ O
propose -X- _ O
a -X- _ O
simple -X- _ O
and -X- _ O
efficient -X- _ O
chunk -X- _ B-MethodName
- -X- _ I-MethodName
based -X- _ I-MethodName
kNN -X- _ I-MethodName
- -X- _ I-MethodName
MT -X- _ I-MethodName
model -X- _ O
. -X- _ O
Inspired -X- _ O
by -X- _ O
RETRO -X- _ B-MethodName
( -X- _ O
Borgeaud -X- _ O
et -X- _ O
al -X- _ O
. -X- _ O
, -X- _ O
2021 -X- _ O
) -X- _ O
, -X- _ O
the -X- _ O
chunk -X- _ B-MethodName
- -X- _ I-MethodName
based -X- _ I-MethodName
kNN -X- _ I-MethodName
- -X- _ I-MethodName
MT -X- _ I-MethodName
model -X- _ O
retrieves -X- _ O
chunks -X- _ O
of -X- _ O
tokens -X- _ O
, -X- _ O
instead -X- _ O
of -X- _ O
single -X- _ O
tokens -X- _ O
. -X- _ O
But -X- _ O
, -X- _ O
similarly -X- _ O
to -X- _ O
kNN -X- _ B-MethodName
- -X- _ I-MethodName
MT -X- _ I-MethodName
and -X- _ O
unlike -X- _ O
RETRO -X- _ B-MethodName
, -X- _ O
it -X- _ O
does -X- _ O
not -X- _ O
require -X- _ O
any -X- _ O
training -X- _ O
or -X- _ O
finetuning -X- _ O
of -X- _ O
the -X- _ O
parametric -X- _ O
component -X- _ O
: -X- _ O
it -X- _ O
simply -X- _ O
uses -X- _ O
a -X- _ O
combination -X- _ O
of -X- _ O
caching -X- _ O
and -X- _ O
interpolation -X- _ O
of -X- _ O
probability -X- _ O
distributions -X- _ O
to -X- _ O
incorporate -X- _ O
the -X- _ O
retrieved -X- _ O
tokens -X- _ O
. -X- _ O
By -X- _ O
doing -X- _ O
this -X- _ O
, -X- _ O
the -X- _ O
model -X- _ O
leads -X- _ O
to -X- _ O
a -X- _ O
similar -X- _ O
translation -X- _ B-TaskName
quality -X- _ O
while -X- _ O
having -X- _ O
to -X- _ O
search -X- _ O
for -X- _ O
neighbors -X- _ O
in -X- _ O
the -X- _ O
datastore -X- _ O
less -X- _ O
often -X- _ O
. -X- _ O
This -X- _ O
leads -X- _ O
to -X- _ O
decoding -X- _ B-MetricName
speeds -X- _ I-MetricName
up -X- _ O
to -X- _ O
4 -X- _ B-MetricValue
times -X- _ I-MetricValue
faster -X- _ O
than -X- _ O
the -X- _ O
ones -X- _ O
achieved -X- _ O
using -X- _ O
the -X- _ O
vanilla -X- _ O
kNN -X- _ B-MethodName
- -X- _ I-MethodName
MT -X- _ I-MethodName
model -X- _ O
and -X- _ O
only -X- _ O
twice -X- _ B-MetricValue
as -X- _ O
slow -X- _ O
as -X- _ O
a -X- _ O
fully -X- _ O
- -X- _ O
parametric -X- _ O
model -X- _ O
, -X- _ O
but -X- _ O
with -X- _ O
considerably -X- _ O
higher -X- _ O
translation -X- _ B-TaskName
quality -X- _ O
. -X- _ O

In -X- _ O
sum -X- _ O
, -X- _ O
our -X- _ O
main -X- _ O
contributions -X- _ O
are -X- _ O
: -X- _ O

• -X- _ O
We -X- _ O
introduce -X- _ O
a -X- _ O
chunk -X- _ B-MethodName
- -X- _ I-MethodName
based -X- _ I-MethodName
kNN -X- _ I-MethodName
- -X- _ I-MethodName
MT -X- _ I-MethodName
model -X- _ O
, -X- _ O
which -X- _ O
retrieves -X- _ O
chunks -X- _ O
of -X- _ O
tokens -X- _ O
from -X- _ O
a -X- _ O
datastore -X- _ O
of -X- _ O
examples -X- _ O
. -X- _ O

• -X- _ O
We -X- _ O
propose -X- _ O
and -X- _ O
compare -X- _ O
several -X- _ O
approaches -X- _ O
to -X- _ O
deal -X- _ O
with -X- _ O
the -X- _ O
retrieved -X- _ O
chunks -X- _ O
' -X- _ O
tokens -X- _ O
and -X- _ O
to -X- _ O
select -X- _ O
the -X- _ O
steps -X- _ O
in -X- _ O
which -X- _ O
the -X- _ O
model -X- _ O
performs -X- _ O
retrieval -X- _ O
from -X- _ O
the -X- _ O
datastore -X- _ O
. -X- _ O

• -X- _ O
We -X- _ O
compare -X- _ O
the -X- _ O
translation -X- _ B-TaskName
quality -X- _ O
and -X- _ O
decoding -X- _ O
efficiency -X- _ O
on -X- _ O
domain -X- _ O
adaptation -X- _ O
, -X- _ O
which -X- _ O
shows -X- _ O
the -X- _ O
benefits -X- _ O
of -X- _ O
chunk -X- _ B-MethodName
- -X- _ I-MethodName
based -X- _ I-MethodName
kNN -X- _ I-MethodName
- -X- _ I-MethodName
MT -X- _ I-MethodName
. -X- _ O

• -X- _ O
We -X- _ O
propose -X- _ O
using -X- _ O
chunk -X- _ B-MethodName
- -X- _ I-MethodName
based -X- _ I-MethodName
kNN -X- _ I-MethodName
- -X- _ I-MethodName
MT -X- _ I-MethodName
for -X- _ O
on -X- _ O
- -X- _ O
the -X- _ O
- -X- _ O
fly -X- _ O
adaptation -X- _ O
. -X- _ O

Background -X- _ O

In -X- _ O
machine -X- _ B-TaskName
translation -X- _ I-TaskName
, -X- _ O
a -X- _ O
model -X- _ O
is -X- _ O
given -X- _ O
a -X- _ O
sentence -X- _ O
or -X- _ O
document -X- _ O
in -X- _ O
a -X- _ O
source -X- _ O
language -X- _ O
, -X- _ O
x -X- _ O
= -X- _ O
[ -X- _ O
x -X- _ O
1 -X- _ O
, -X- _ O
. -X- _ O
. -X- _ O
. -X- _ O
, -X- _ O
x -X- _ O
L -X- _ O
] -X- _ O
, -X- _ O
and -X- _ O
the -X- _ O
goal -X- _ O
is -X- _ O
to -X- _ O
output -X- _ O
a -X- _ O
translation -X- _ O
in -X- _ O
a -X- _ O
target -X- _ O
language -X- _ O
, -X- _ O
y -X- _ O
= -X- _ O
[ -X- _ O
y -X- _ O
1 -X- _ O
, -X- _ O
. -X- _ O
. -X- _ O
. -X- _ O
, -X- _ O
y -X- _ O
N -X- _ O
] -X- _ O
. -X- _ O
This -X- _ O
is -X- _ O
commonly -X- _ O
done -X- _ O
using -X- _ O
a -X- _ O
parametric -X- _ O
sequence -X- _ O
- -X- _ O
tosequence -X- _ O
model -X- _ O
( -X- _ O
Sutskever -X- _ O
et -X- _ O
al -X- _ O
. -X- _ O
, -X- _ O
2014 -X- _ O
; -X- _ O
Bahdanau -X- _ O
et -X- _ O
al -X- _ O
. -X- _ O
, -X- _ O
2015 -X- _ O
; -X- _ O
Vaswani -X- _ O
et -X- _ O
al -X- _ O
. -X- _ O
, -X- _ O
2017 -X- _ O
) -X- _ O
, -X- _ O
in -X- _ O
which -X- _ O
the -X- _ O
encoder -X- _ O
receives -X- _ O
the -X- _ O
source -X- _ O
sentence -X- _ O
as -X- _ O
input -X- _ O
and -X- _ O
outputs -X- _ O
a -X- _ O
set -X- _ O
of -X- _ O
hidden -X- _ O
states -X- _ O
. -X- _ O
Then -X- _ O
, -X- _ O
at -X- _ O
each -X- _ O
step -X- _ O
t -X- _ O
, -X- _ O
the -X- _ O
decoder -X- _ O
attends -X- _ O
to -X- _ O
these -X- _ O
hidden -X- _ O
states -X- _ O
and -X- _ O
outputs -X- _ O
a -X- _ O
probability -X- _ O
distribution -X- _ O
over -X- _ O
the -X- _ O
vocabulary -X- _ O
, -X- _ O
p -X- _ O
NMT -X- _ O
( -X- _ O
y -X- _ O
t -X- _ O
|y -X- _ O
< -X- _ O
t -X- _ O
, -X- _ O
x -X- _ O
) -X- _ O
. -X- _ O
Finally -X- _ O
, -X- _ O
these -X- _ O
probability -X- _ O
distributions -X- _ O
are -X- _ O
used -X- _ O
in -X- _ O
a -X- _ O
search -X- _ O
procedure -X- _ O
to -X- _ O
generate -X- _ O
the -X- _ O
translation -X- _ O
, -X- _ O
typically -X- _ O
using -X- _ O
beam -X- _ O
search -X- _ O
( -X- _ O
Reddy -X- _ O
, -X- _ O
1977 -X- _ O
) -X- _ O
. -X- _ O
Khandelwal -X- _ O
et -X- _ O
al -X- _ O
. -X- _ O
( -X- _ O
2021 -X- _ O
) -X- _ O
introduced -X- _ O
a -X- _ O
semiparametric -X- _ O
model -X- _ O
called -X- _ O
k -X- _ B-MethodName
- -X- _ I-MethodName
nearest -X- _ I-MethodName
neighbor -X- _ I-MethodName
machine -X- _ I-MethodName
translation -X- _ I-MethodName
( -X- _ O
kNN -X- _ B-MethodName
- -X- _ I-MethodName
MT -X- _ I-MethodName
) -X- _ O
. -X- _ O
kNN -X- _ B-MethodName
- -X- _ I-MethodName
MT -X- _ I-MethodName
is -X- _ O
composed -X- _ O
of -X- _ O
a -X- _ O
parametric -X- _ O
component -X- _ O
that -X- _ O
outputs -X- _ O
a -X- _ O
probability -X- _ O
distribution -X- _ O
over -X- _ O
the -X- _ O
vocabulary -X- _ O
as -X- _ O
above -X- _ O
, -X- _ O
p -X- _ O
NMT -X- _ O
( -X- _ O
y -X- _ O
t -X- _ O
|y -X- _ O
< -X- _ O
t -X- _ O
, -X- _ O
x -X- _ O
) -X- _ O
, -X- _ O
enhanced -X- _ O
with -X- _ O
an -X- _ O
approximate -X- _ O
nearest -X- _ O
neighbor -X- _ O
retrieval -X- _ O
mechanism -X- _ O
, -X- _ O
which -X- _ O
allows -X- _ O
direct -X- _ O
access -X- _ O
to -X- _ O
a -X- _ O
datastore -X- _ O
of -X- _ O
examples -X- _ O
. -X- _ O

The -X- _ O
kNN -X- _ B-MethodName
- -X- _ I-MethodName
MT -X- _ I-MethodName
's -X- _ O
datastore -X- _ O
D -X- _ O
consists -X- _ O
of -X- _ O
a -X- _ O
keyvalue -X- _ O
memory -X- _ O
, -X- _ O
where -X- _ O
each -X- _ O
key -X- _ O
is -X- _ O
the -X- _ O
decoder -X- _ O
's -X- _ O
output -X- _ O
representation -X- _ O
, -X- _ O
f -X- _ O
( -X- _ O
x -X- _ O
, -X- _ O
y -X- _ O
< -X- _ O
t -X- _ O
) -X- _ O
∈ -X- _ O
R -X- _ O
d -X- _ O
, -X- _ O
and -X- _ O
the -X- _ O
value -X- _ O
is -X- _ O
the -X- _ O
corresponding -X- _ O
target -X- _ O
token -X- _ O
y -X- _ O
t -X- _ O
∈ -X- _ O
V -X- _ O
: -X- _ O

where -X- _ O
S -X- _ O
denotes -X- _ O
a -X- _ O
set -X- _ O
of -X- _ O
parallel -X- _ O
sentences -X- _ O
. -X- _ O
Then -X- _ O
, -X- _ O
at -X- _ O
inference -X- _ O
time -X- _ O
, -X- _ O
the -X- _ O
model -X- _ O
searches -X- _ O
the -X- _ O
datastore -X- _ O
to -X- _ O
( -X- _ O
approximately -X- _ O
) -X- _ O
retrieve -X- _ O
the -X- _ O
set -X- _ O
of -X- _ O
k -X- _ O
nearest -X- _ O
neighbors -X- _ O
N -X- _ O
. -X- _ O
The -X- _ O
retrieval -X- _ O
distribution -X- _ O
, -X- _ O
p -X- _ O
kNN -X- _ O
( -X- _ O
y -X- _ O
t -X- _ O
|y -X- _ O
< -X- _ O
t -X- _ O
, -X- _ O
x -X- _ O
) -X- _ O
, -X- _ O
is -X- _ O
computed -X- _ O
, -X- _ O
using -X- _ O
the -X- _ O
neighbors -X- _ O
' -X- _ O
distance -X- _ O
to -X- _ O
the -X- _ O
current -X- _ O
decoder -X- _ O
's -X- _ O
output -X- _ O
representation -X- _ O
, -X- _ O
d -X- _ O
( -X- _ O
f -X- _ O
( -X- _ O
x -X- _ O
, -X- _ O
y -X- _ O
< -X- _ O
t -X- _ O
) -X- _ O
, -X- _ O
• -X- _ O
) -X- _ O
: -X- _ O

We -X- _ O
now -X- _ O
describe -X- _ O
our -X- _ O
chunk -X- _ B-MethodName
- -X- _ I-MethodName
based -X- _ I-MethodName
kNN -X- _ I-MethodName
- -X- _ I-MethodName
MT -X- _ I-MethodName
model -X- _ O
, -X- _ O
illustrated -X- _ O
in -X- _ O
Figure -X- _ O
1 -X- _ O
. -X- _ O
We -X- _ O
first -X- _ O
describe -X- _ O
the -X- _ O
datastore -X- _ O
creation -X- _ O
( -X- _ O
§ -X- _ O
3.1 -X- _ O
) -X- _ O
and -X- _ O
how -X- _ O
we -X- _ O
can -X- _ O
retrieve -X- _ O
chunks -X- _ O
of -X- _ O
tokens -X- _ O
from -X- _ O
it -X- _ O
( -X- _ O
§ -X- _ O
3.2 -X- _ O
) -X- _ O
, -X- _ O
describing -X- _ O
how -X- _ O
they -X- _ O
are -X- _ O
used -X- _ O
by -X- _ O
the -X- _ O
model -X- _ O
( -X- _ O
§ -X- _ O
3.2.2 -X- _ O
) -X- _ O
. -X- _ O
Finally -X- _ O
, -X- _ O
we -X- _ O
describe -X- _ O
how -X- _ O
to -X- _ O
select -X- _ O
the -X- _ O
steps -X- _ O
in -X- _ O
which -X- _ O
the -X- _ O
model -X- _ O
performs -X- _ O
retrieval -X- _ O
( -X- _ O
§ -X- _ O
3.3 -X- _ O
) -X- _ O
. -X- _ O

Building -X- _ O
the -X- _ O
datastore -X- _ O

For -X- _ O
the -X- _ O
model -X- _ O
to -X- _ O
retrieve -X- _ O
a -X- _ O
chunk -X- _ O
of -X- _ O
tokens -X- _ O
of -X- _ O
size -X- _ O
c -X- _ O
instead -X- _ O
of -X- _ O
a -X- _ O
single -X- _ O
token -X- _ O
, -X- _ O
we -X- _ O
first -X- _ O
need -X- _ O
to -X- _ O
build -X- _ O
a -X- _ O
datastore -X- _ O
D -X- _ O
which -X- _ O
also -X- _ O
consists -X- _ O
of -X- _ O
a -X- _ O
key -X- _ O
- -X- _ O
value -X- _ O
memory -X- _ O
, -X- _ O
where -X- _ O
each -X- _ O
entry -X- _ O
key -X- _ O
is -X- _ O
the -X- _ O
decoder -X- _ O
's -X- _ O
output -X- _ O
representation -X- _ O
f -X- _ O
( -X- _ O
x -X- _ O
, -X- _ O
y -X- _ O
< -X- _ O
t -X- _ O
) -X- _ O
, -X- _ O
but -X- _ O
the -X- _ O
value -X- _ O
is -X- _ O
now -X- _ O
a -X- _ O
chunk -X- _ O
of -X- _ O
target -X- _ O
tokens -X- _ O
y -X- _ O
t -X- _ O
: -X- _ O
( -X- _ O
t+c−1 -X- _ O
) -X- _ O
: -X- _ O
2 -X- _ O
D -X- _ O
= -X- _ O
{ -X- _ O
( -X- _ O
f -X- _ O
( -X- _ O
x -X- _ O
, -X- _ O
y -X- _ O
< -X- _ O
t -X- _ O
) -X- _ O
, -X- _ O
y -X- _ O
t -X- _ O
: -X- _ O
( -X- _ O
t+c−1 -X- _ O
) -X- _ O
) -X- _ O
∀ -X- _ O
t -X- _ O
| -X- _ O
( -X- _ O
x -X- _ O
, -X- _ O
y -X- _ O
) -X- _ O
∈ -X- _ O
S -X- _ O
} -X- _ O
. -X- _ O
Note -X- _ O
that -X- _ O
the -X- _ O
chunks -X- _ O
are -X- _ O
sliding -X- _ O
windows -X- _ O
, -X- _ O
i.e. -X- _ O
, -X- _ O
they -X- _ O
overlap -X- _ O
. -X- _ O

Retrieving -X- _ O
chunks -X- _ O
of -X- _ O
tokens -X- _ O

At -X- _ O
inference -X- _ O
time -X- _ O
, -X- _ O
when -X- _ O
performing -X- _ O
retrieval -X- _ O
, -X- _ O
the -X- _ O
model -X- _ O
searches -X- _ O
the -X- _ O
datastore -X- _ O
and -X- _ O
retrieves -X- _ O
the -X- _ O
set -X- _ O
of -X- _ O
k -X- _ O
nearest -X- _ O
neighbors -X- _ O
N -X- _ O
, -X- _ O
for -X- _ O
each -X- _ O
beam -X- _ O
hypothesis -X- _ O
and -X- _ O
example -X- _ O
in -X- _ O
the -X- _ O
current -X- _ O
batch -X- _ O
. -X- _ O
We -X- _ O
now -X- _ O
describe -X- _ O
several -X- _ O
strategies -X- _ O
to -X- _ O
manipulate -X- _ O
the -X- _ O
retrieved -X- _ O
chunks -X- _ O
of -X- _ O
tokens -X- _ O
during -X- _ O
generation -X- _ O
. -X- _ O

Since -X- _ O
in -X- _ O
the -X- _ O
original -X- _ O
sentences -X- _ O
used -X- _ O
to -X- _ O
build -X- _ O
the -X- _ O
datastore -X- _ O
each -X- _ O
chunk -X- _ O
is -X- _ O
composed -X- _ O
of -X- _ O
an -X- _ O
ordered -X- _ O
sequence -X- _ O
of -X- _ O
tokens -X- _ O
, -X- _ O
the -X- _ O
simplest -X- _ O
way -X- _ O
for -X- _ O
the -X- _ O
model -X- _ O
to -X- _ O
use -X- _ O
the -X- _ O
retrieved -X- _ O
tokens -X- _ O
is -X- _ O
to -X- _ O
consider -X- _ O
them -X- _ O
in -X- _ O
the -X- _ O
same -X- _ O
order -X- _ O
. -X- _ O
For -X- _ O
this -X- _ O
, -X- _ O
we -X- _ O
simply -X- _ O
need -X- _ O
to -X- _ O
compute -X- _ O
a -X- _ O
retrieval -X- _ O
distribution -X- _ O
for -X- _ O
each -X- _ O
token -X- _ O
in -X- _ O
the -X- _ O
chunk -X- _ O
, -X- _ O
always -X- _ O
using -X- _ O
the -X- _ O
same -X- _ O
retrieval -X- _ O
distances -X- _ O
but -X- _ O
aligning -X- _ O
the -X- _ O
chunk -X- _ O
tokens -X- _ O
with -X- _ O
the -X- _ O
corresponding -X- _ O
time -X- _ O
step -X- _ O
, -X- _ O
i.e. -X- _ O
at -X- _ O
the -X- _ O
retrieval -X- _ O
step -X- _ O
we -X- _ O
consider -X- _ O
the -X- _ O
first -X- _ O
token -X- _ O
of -X- _ O
each -X- _ O
neighbor -X- _ O
chunk -X- _ O
, -X- _ O
at -X- _ O
the -X- _ O
following -X- _ O
step -X- _ O
we -X- _ O
consider -X- _ O
the -X- _ O
second -X- _ O
token -X- _ O
, -X- _ O
and -X- _ O
so -X- _ O
on -X- _ O
. -X- _ O
We -X- _ O
can -X- _ O
compute -X- _ O
this -X- _ O
retrieval -X- _ O
distribution -X- _ O
as -X- _ O
it -X- _ O
is -X- _ O
done -X- _ O
for -X- _ O
the -X- _ O
kNN -X- _ B-MethodName
- -X- _ I-MethodName
MT -X- _ I-MethodName
, -X- _ O
in -X- _ O
Eq -X- _ O
. -X- _ O
2 -X- _ O
, -X- _ O
just -X- _ O
modifying -X- _ O
the -X- _ O
token -X- _ O
indices -X- _ O
according -X- _ O
to -X- _ O
the -X- _ O
step -X- _ O
. -X- _ O
However -X- _ O
, -X- _ O
by -X- _ O
doing -X- _ O
this -X- _ O
, -X- _ O
we -X- _ O
are -X- _ O
ignoring -X- _ O
the -X- _ O
remaining -X- _ O
tokens -X- _ O
in -X- _ O
the -X- _ O
chunk -X- _ O
, -X- _ O
which -X- _ O
can -X- _ O
also -X- _ O
contain -X- _ O
relevant -X- _ O
information -X- _ O
for -X- _ O
the -X- _ O
current -X- _ O
prediction -X- _ O
. -X- _ O
Also -X- _ O
, -X- _ O
the -X- _ O
tokens -X- _ O
that -X- _ O
are -X- _ O
generated -X- _ O
in -X- _ O
the -X- _ O
previous -X- _ O
steps -X- _ O
t -X- _ O
, -X- _ O
. -X- _ O
. -X- _ O
. -X- _ O
, -X- _ O
t -X- _ O
+ -X- _ O
j -X- _ O
− -X- _ O
1 -X- _ O
might -X- _ O
not -X- _ O
be -X- _ O
well -X- _ O
" -X- _ O
aligned -X- _ O
" -X- _ O
with -X- _ O
the -X- _ O
next -X- _ O
tokens -X- _ O
in -X- _ O
the -X- _ O
jth -X- _ O
position -X- _ O
of -X- _ O
the -X- _ O
chunk -X- _ O
for -X- _ O
all -X- _ O
neighbors -X- _ O
. -X- _ O

To -X- _ O
avoid -X- _ O
the -X- _ O
limitation -X- _ O
stated -X- _ O
above -X- _ O
, -X- _ O
we -X- _ O
propose -X- _ O
using -X- _ O
a -X- _ O
neighbors -X- _ O
' -X- _ O
cache -X- _ O
instead -X- _ O
. -X- _ O
We -X- _ O
keep -X- _ O
the -X- _ O
tokens -X- _ O
of -X- _ O
the -X- _ O
retrieved -X- _ O
chunks -X- _ O
in -X- _ O
this -X- _ O
cache -X- _ O
, -X- _ O
so -X- _ O
that -X- _ O
the -X- _ O
model -X- _ O
has -X- _ O
a -X- _ O
higher -X- _ O
flexibility -X- _ O
about -X- _ O
which -X- _ O
tokens -X- _ O
to -X- _ O
select -X- _ O
for -X- _ O
the -X- _ O
current -X- _ O
step -X- _ O
: -X- _ O
it -X- _ O
has -X- _ O
access -X- _ O
to -X- _ O
all -X- _ O
the -X- _ O
tokens -X- _ O
present -X- _ O
in -X- _ O
the -X- _ O
retrieved -X- _ O
chunks -X- _ O
. -X- _ O
The -X- _ O
neighbors -X- _ O
' -X- _ O
cache -X- _ O
, -X- _ O
M -X- _ O
, -X- _ O
consists -X- _ O
of -X- _ O
a -X- _ O
key -X- _ O
- -X- _ O
value -X- _ O
memory -X- _ O
, -X- _ O
where -X- _ O
a -X- _ O
key -X- _ O
is -X- _ O
the -X- _ O
decoder -X- _ O
's -X- _ O
output -X- _ O
representation -X- _ O
, -X- _ O
f -X- _ O
( -X- _ O
x -X- _ O
, -X- _ O
y -X- _ O
< -X- _ O
t -X- _ O
) -X- _ O
, -X- _ O
and -X- _ O
a -X- _ O
value -X- _ O
is -X- _ O
the -X- _ O
corresponding -X- _ O
target -X- _ O
token -X- _ O
y -X- _ O
t -X- _ O
, -X- _ O
as -X- _ O
in -X- _ O
the -X- _ O
datastore -X- _ O
: -X- _ O

Note -X- _ O
, -X- _ O
however -X- _ O
, -X- _ O
that -X- _ O
this -X- _ O
cache -X- _ O
requires -X- _ O
having -X- _ O
the -X- _ O
decoder -X- _ O
state -X- _ O
for -X- _ O
every -X- _ O
token -X- _ O
in -X- _ O
the -X- _ O
chunk -X- _ O
, -X- _ O
not -X- _ O
just -X- _ O
for -X- _ O
the -X- _ O
first -X- _ O
one -X- _ O
. -X- _ O
Therefore -X- _ O
, -X- _ O
we -X- _ O
need -X- _ O
to -X- _ O
have -X- _ O
this -X- _ O
information -X- _ O
available -X- _ O
in -X- _ O
the -X- _ O
datastore -X- _ O
: -X- _ O

Considering -X- _ O
batch -X- _ O
- -X- _ O
beam -X- _ O
- -X- _ O
level -X- _ O
neighbors -X- _ O
. -X- _ O
By -X- _ O
building -X- _ O
this -X- _ O
neighbors -X- _ O
' -X- _ O
cache -X- _ O
, -X- _ O
the -X- _ O
model -X- _ O
can -X- _ O
use -X- _ O
all -X- _ O
the -X- _ O
tokens -X- _ O
in -X- _ O
the -X- _ O
retrieved -X- _ O
chunks -X- _ O
that -X- _ O
correspond -X- _ O
to -X- _ O
each -X- _ O
beam -X- _ O
hypothesis -X- _ O
of -X- _ O
the -X- _ O
sentence -X- _ O
being -X- _ O
translated -X- _ O
. -X- _ O
However -X- _ O
, -X- _ O
it -X- _ O
still -X- _ O
ignores -X- _ O
the -X- _ O
chunks -X- _ O
of -X- _ O
tokens -X- _ O
corresponding -X- _ O
to -X- _ O
the -X- _ O
other -X- _ O
beam -X- _ O
hypotheses -X- _ O
, -X- _ O
which -X- _ O
are -X- _ O
often -X- _ O
quite -X- _ O
similar -X- _ O
, -X- _ O
and -X- _ O
the -X- _ O
other -X- _ O
sentences -X- _ O
being -X- _ O
translated -X- _ O
in -X- _ O
the -X- _ O
same -X- _ O
batch -X- _ O
, -X- _ O
which -X- _ O
can -X- _ O
contain -X- _ O
relevant -X- _ O
contextual -X- _ O
information -X- _ O
if -X- _ O
they -X- _ O
belong -X- _ O
to -X- _ O
the -X- _ O
same -X- _ O
document -X- _ O
. -X- _ O

To -X- _ O
also -X- _ O
leverage -X- _ O
these -X- _ O
, -X- _ O
we -X- _ O
propose -X- _ O
increasing -X- _ O
the -X- _ O
number -X- _ O
of -X- _ O
tokens -X- _ O
that -X- _ O
the -X- _ O
model -X- _ O
has -X- _ O
access -X- _ O
to -X- _ O
, -X- _ O
by -X- _ O
combining -X- _ O
the -X- _ O
chunks -X- _ O
retrieved -X- _ O
for -X- _ O
the -X- _ O
different -X- _ O
beam -X- _ O
hypotheses -X- _ O
and -X- _ O
the -X- _ O
different -X- _ O
examples -X- _ O
of -X- _ O
the -X- _ O
same -X- _ O
batch -X- _ O
. -X- _ O
To -X- _ O
do -X- _ O
so -X- _ O
, -X- _ O
we -X- _ O
simply -X- _ O
need -X- _ O
to -X- _ O
build -X- _ O
a -X- _ O
single -X- _ O
neighbors -X- _ O
' -X- _ O
cache -X- _ O
for -X- _ O
the -X- _ O
current -X- _ O
batch -X- _ O
, -X- _ O
to -X- _ O
which -X- _ O
we -X- _ O
feed -X- _ O
all -X- _ O
the -X- _ O
retrieved -X- _ O
chunks -X- _ O
' -X- _ O
tokens -X- _ O
. -X- _ O

We -X- _ O
empirically -X- _ O
compare -X- _ O
these -X- _ O
different -X- _ O
proposed -X- _ O
approaches -X- _ O
in -X- _ O
§ -X- _ O
4.1.3 -X- _ O
. -X- _ O

As -X- _ O
the -X- _ O
need -X- _ O
to -X- _ O
perform -X- _ O
retrieval -X- _ O
slows -X- _ O
down -X- _ O
decoding -X- _ O
considerably -X- _ O
, -X- _ O
having -X- _ O
an -X- _ O
efficient -X- _ O
retrieval -X- _ O
schedule -X- _ O
is -X- _ O
key -X- _ O
to -X- _ O
achieve -X- _ O
decoding -X- _ O
speedups -X- _ O
. -X- _ O
The -X- _ O
simplest -X- _ O
scheduling -X- _ O
option -X- _ O
corresponds -X- _ O
to -X- _ O
performing -X- _ O
retrieval -X- _ O
every -X- _ O
i -X- _ O
steps -X- _ O
. -X- _ O
However -X- _ O
, -X- _ O
we -X- _ O
noticed -X- _ O
empirically -X- _ O
that -X- _ O
it -X- _ O
is -X- _ O
beneficial -X- _ O
to -X- _ O
perform -X- _ O
retrieval -X- _ O
steps -X- _ O
more -X- _ O
frequently -X- _ O
at -X- _ O
the -X- _ O
beginning -X- _ O
of -X- _ O
the -X- _ O
sentence -X- _ O
, -X- _ O
as -X- _ O
we -X- _ O
will -X- _ O
see -X- _ O
in -X- _ O
Table -X- _ O
3 -X- _ O
of -X- _ O
§ -X- _ O
4.1.4 -X- _ O
. -X- _ O
To -X- _ O
leverage -X- _ O
this -X- _ O
, -X- _ O
we -X- _ O
introduce -X- _ O
the -X- _ O
following -X- _ O
schedule -X- _ O
. -X- _ O

Having -X- _ O
k -X- _ O
∈ -X- _ O
{ -X- _ O
1 -X- _ O
, -X- _ O
2 -X- _ O
, -X- _ O
. -X- _ O
. -X- _ O
. -X- _ O
} -X- _ O
as -X- _ O
the -X- _ O
retrieval -X- _ O
step -X- _ O
's -X- _ O
index -X- _ O
and -X- _ O
t -X- _ O
k -X- _ O
as -X- _ O
the -X- _ O
corresponding -X- _ O
time -X- _ O
step -X- _ O
, -X- _ O
( -X- _ O
i.e. -X- _ O
t -X- _ O
k -X- _ O
is -X- _ O
the -X- _ O
position -X- _ O
of -X- _ O
the -X- _ O
token -X- _ O
generated -X- _ O
after -X- _ O
the -X- _ O
k -X- _ O
th -X- _ O
retrieval -X- _ O
step -X- _ O
) -X- _ O
, -X- _ O
we -X- _ O
propose -X- _ O
using -X- _ O
a -X- _ O
geometric -X- _ O
progression -X- _ O
to -X- _ O
compute -X- _ O
the -X- _ O
interval -X- _ O
( -X- _ O
in -X- _ O
tokens -X- _ O
) -X- _ O
between -X- _ O
the -X- _ O
k -X- _ O
th -X- _ O
and -X- _ O
( -X- _ O
k -X- _ O
+ -X- _ O
1 -X- _ O
) -X- _ O
th -X- _ O
retrieval -X- _ O
steps -X- _ O
, -X- _ O
i -X- _ O
k -X- _ O
= -X- _ O
t -X- _ O
k+1 -X- _ O
− -X- _ O
t -X- _ O
k -X- _ O
: -X- _ O

where -X- _ O
i -X- _ B-HyperparameterName
max -X- _ I-HyperparameterName
and -X- _ O
i -X- _ B-HyperparameterName
min -X- _ I-HyperparameterName
are -X- _ O
hyperparameters -X- _ O
that -X- _ O
define -X- _ O
the -X- _ O
maximum -X- _ B-HyperparameterName
and -X- _ O
minimum -X- _ B-HyperparameterName
interval -X- _ I-HyperparameterName
between -X- _ I-HyperparameterName
retrieval -X- _ I-HyperparameterName
steps -X- _ I-HyperparameterName
, -X- _ O
the -X- _ O
rate -X- _ O
at -X- _ O
which -X- _ O
the -X- _ O
interval -X- _ O
increases -X- _ O
is -X- _ O
defined -X- _ O
as -X- _ O
r -X- _ O
= -X- _ O
1 -X- _ O
2 -X- _ O
i -X- _ O
max -X- _ O
/ -X- _ O
|x| -X- _ O
where -X- _ O
|x| -X- _ O
is -X- _ O
the -X- _ O
source -X- _ O
sentence -X- _ O
size -X- _ O
, -X- _ O
and -X- _ O
⌊•⌋ -X- _ O
denotes -X- _ O
the -X- _ O
floor -X- _ O
function -X- _ O
. -X- _ O
5 -X- _ O
By -X- _ O
using -X- _ O
this -X- _ O
progression -X- _ O
, -X- _ O
the -X- _ O
frequency -X- _ O
with -X- _ O
which -X- _ O
the -X- _ O
model -X- _ O
performs -X- _ O
retrieval -X- _ O
decays -X- _ O
along -X- _ O
the -X- _ O
generation -X- _ O
, -X- _ O
until -X- _ O
the -X- _ O
interval -X- _ O
between -X- _ O
retrieval -X- _ O
steps -X- _ O
reaches -X- _ O
i -X- _ O
max -X- _ O
. -X- _ O
For -X- _ O
example -X- _ O
, -X- _ O
with -X- _ O
i -X- _ O
min -X- _ O
= -X- _ O
2 -X- _ O
, -X- _ O
i -X- _ O
max -X- _ O
= -X- _ O
16 -X- _ O
, -X- _ O
and -X- _ O
|x| -X- _ O
= -X- _ O
20 -X- _ O
the -X- _ O
model -X- _ O
performs -X- _ O
retrieval -X- _ O
at -X- _ O
steps -X- _ O
: -X- _ O
{ -X- _ O
1 -X- _ O
, -X- _ O
3 -X- _ O
, -X- _ O
7 -X- _ O
, -X- _ O
20 -X- _ O
, -X- _ O
36 -X- _ O
, -X- _ O
52 -X- _ O
, -X- _ O
. -X- _ O
. -X- _ O
. -X- _ O
} -X- _ O
. -X- _ O
Note -X- _ O
that -X- _ O
the -X- _ O
chunk -X- _ O
size -X- _ O
, -X- _ O
c -X- _ O
, -X- _ O
is -X- _ O
independent -X- _ O
of -X- _ O
the -X- _ O
interval -X- _ O
between -X- _ O
retrieval -X- _ O
steps -X- _ O
. -X- _ O

To -X- _ O
understand -X- _ O
if -X- _ O
the -X- _ O
chunk -X- _ B-MethodName
- -X- _ I-MethodName
based -X- _ I-MethodName
kNN -X- _ I-MethodName
- -X- _ I-MethodName
MT -X- _ I-MethodName
is -X- _ O
able -X- _ O
to -X- _ O
maintain -X- _ O
the -X- _ O
translation -X- _ O
quality -X- _ O
while -X- _ O
speedingup -X- _ O
decoding -X- _ O
, -X- _ O
we -X- _ O
performed -X- _ O
experiments -X- _ O
on -X- _ O
domain -X- _ O
adaptation -X- _ O
( -X- _ O
§ -X- _ O
4.1 -X- _ O
) -X- _ O
and -X- _ O
on -X- _ O
- -X- _ O
the -X- _ O
- -X- _ O
fly -X- _ O
adaptation -X- _ O
( -X- _ O
§ -X- _ O
4.2 -X- _ O
) -X- _ O
. -X- _ O

For -X- _ O
the -X- _ O
fine -X- _ O
- -X- _ O
tuned -X- _ O
model -X- _ O
, -X- _ O
we -X- _ O
perform -X- _ O
fine -X- _ O
- -X- _ O
tuning -X- _ O
for -X- _ O
a -X- _ O
maximum -X- _ O
of -X- _ O
20 -X- _ B-HyperparameterValue
epochs -X- _ B-HyperparameterName
on -X- _ O
each -X- _ O
domain -X- _ O
. -X- _ O
We -X- _ O
perform -X- _ O
grid -X- _ O
search -X- _ O
on -X- _ O
the -X- _ O
validation -X- _ O
set -X- _ O
, -X- _ O
using -X- _ O
different -X- _ O
learning -X- _ B-HyperparameterName
rates -X- _ I-HyperparameterName
, -X- _ O
η -X- _ B-HyperparameterName
∈ -X- _ O
{ -X- _ O
5 -X- _ O
× -X- _ O
10 -X- _ O
−6 -X- _ O
, -X- _ O
1 -X- _ O
× -X- _ O
10 -X- _ O
−5 -X- _ O
, -X- _ O
5 -X- _ O
× -X- _ O
10 -X- _ O
−5 -X- _ O
, -X- _ O
1 -X- _ O
× -X- _ O
10 -X- _ O
−4 -X- _ O
} -X- _ O
and -X- _ O
two -X- _ O
different -X- _ O
learning -X- _ O
rate -X- _ O
schedules -X- _ O
( -X- _ O
reducing -X- _ O
learning -X- _ O
rate -X- _ O
on -X- _ O
plateau -X- _ O
and -X- _ O
by -X- _ O
the -X- _ O
inverse -X- _ O
square -X- _ O
root -X- _ O
) -X- _ O
with -X- _ O
and -X- _ O
without -X- _ O
warmup -X- _ O
during -X- _ O
1 -X- _ O
epoch -X- _ O
. -X- _ O
The -X- _ O
selected -X- _ O
hyperparameters -X- _ O
are -X- _ O
stated -X- _ O
in -X- _ O
Table -X- _ O
11 -X- _ O
of -X- _ O
App -X- _ O
. -X- _ O
D -X- _ O
. -X- _ O

Computational -X- _ O
infrastructure -X- _ O
. -X- _ O
All -X- _ O
experiments -X- _ O
were -X- _ O
performed -X- _ O
on -X- _ O
a -X- _ O
server -X- _ O
with -X- _ O
3 -X- _ O
RTX -X- _ O
2080 -X- _ O
Ti -X- _ O
( -X- _ O
11 -X- _ O
GB -X- _ O
) -X- _ O
, -X- _ O
12 -X- _ O
AMD -X- _ O
Ryzen -X- _ O
2920X -X- _ O
CPUs -X- _ O
( -X- _ O
24 -X- _ O
cores -X- _ O
) -X- _ O
, -X- _ O
and -X- _ O
128 -X- _ O
Gb -X- _ O
of -X- _ O
RAM -X- _ O
. -X- _ O
For -X- _ O
the -X- _ O
decoding -X- _ O
speed -X- _ O
measurements -X- _ O
, -X- _ O
we -X- _ O
ran -X- _ O
each -X- _ O
model -X- _ O
on -X- _ O
a -X- _ O
single -X- _ O
GPU -X- _ O
while -X- _ O
no -X- _ O
other -X- _ O
process -X- _ O
was -X- _ O
running -X- _ O
on -X- _ O
the -X- _ O
server -X- _ O
, -X- _ O
to -X- _ O
have -X- _ O
a -X- _ O
controlled -X- _ O
environment -X- _ O
. -X- _ O
The -X- _ O
nearest -X- _ O
neighbor -X- _ O
search -X- _ O
in -X- _ O
the -X- _ O
datastore -X- _ O
is -X- _ O
performed -X- _ O
on -X- _ O
the -X- _ O
CPUs -X- _ O
, -X- _ O
since -X- _ O
not -X- _ O
all -X- _ O
datastores -X- _ O
fit -X- _ O
into -X- _ O
GPU -X- _ O
memory -X- _ O
. -X- _ O

The -X- _ O
translation -X- _ B-TaskName
scores -X- _ O
are -X- _ O
reported -X- _ O
in -X- _ O
of -X- _ O
semi -X- _ O
- -X- _ O
parametric -X- _ O
models -X- _ O
, -X- _ O
the -X- _ O
results -X- _ O
are -X- _ O
not -X- _ O
conclusive -X- _ O
: -X- _ O
in -X- _ O
terms -X- _ O
of -X- _ O
BLEU -X- _ B-MetricName
, -X- _ O
the -X- _ O
semi -X- _ O
- -X- _ O
parametric -X- _ O
models -X- _ O
lead -X- _ O
to -X- _ O
better -X- _ O
translations -X- _ B-TaskName
, -X- _ O
but -X- _ O
according -X- _ O
to -X- _ O
COMET -X- _ B-MetricName
this -X- _ O
is -X- _ O
not -X- _ O
the -X- _ O
case -X- _ O
. -X- _ O
We -X- _ O
present -X- _ O
translation -X- _ B-TaskName
examples -X- _ O
for -X- _ O
the -X- _ O
different -X- _ O
domains -X- _ O
in -X- _ O
App -X- _ O
. -X- _ O
F -X- _ O
. -X- _ O

As -X- _ O
can -X- _ O
be -X- _ O
seen -X- _ O
in -X- _ O
Figure -X- _ O
2 -X- _ O
, -X- _ O
the -X- _ O
chunk -X- _ B-MethodName
- -X- _ I-MethodName
based -X- _ I-MethodName
kNN -X- _ I-MethodName
- -X- _ I-MethodName
MT -X- _ I-MethodName
model -X- _ O
leads -X- _ O
to -X- _ O
a -X- _ O
decoding -X- _ B-MetricName
speed -X- _ I-MetricName
up -X- _ O
to -X- _ O
two -X- _ B-MetricValue
times -X- _ I-MetricValue
higher -X- _ O
than -X- _ O
the -X- _ O
decoding -X- _ O
speed -X- _ O
of -X- _ O
the -X- _ O
efficient -X- _ B-MethodName
kNN -X- _ I-MethodName
- -X- _ I-MethodName
MT -X- _ I-MethodName
model -X- _ O
of -X- _ O
Martins -X- _ O
et -X- _ O
al -X- _ O
. -X- _ O
( -X- _ O
2022 -X- _ O
) -X- _ O
and -X- _ O
up -X- _ O
to -X- _ O
four -X- _ O
times -X- _ O
higher -X- _ O
than -X- _ O
that -X- _ O
of -X- _ O
the -X- _ O
vanilla -X- _ O
kNN -X- _ B-MethodName
- -X- _ I-MethodName
MT -X- _ I-MethodName
model -X- _ O
of -X- _ O
Khandelwal -X- _ O
et -X- _ O
al -X- _ O
. -X- _ O
( -X- _ O
2021 -X- _ O
) -X- _ O
. -X- _ O
The -X- _ O
chunk -X- _ B-MethodName
- -X- _ I-MethodName
based -X- _ I-MethodName
kNN -X- _ I-MethodName
- -X- _ I-MethodName
MT -X- _ I-MethodName
model -X- _ O
is -X- _ O
also -X- _ O
able -X- _ O
to -X- _ O
reduce -X- _ O
the -X- _ O
decoding -X- _ B-MetricName
speed -X- _ I-MetricName
gap -X- _ O
to -X- _ O
the -X- _ O
base -X- _ B-MethodName
MT -X- _ I-MethodName
model -X- _ O
to -X- _ O
a -X- _ O
factor -X- _ O
of -X- _ O
two -X- _ B-MetricValue
, -X- _ O
compared -X- _ O
to -X- _ O
a -X- _ O
factor -X- _ O
of -X- _ O
four -X- _ B-MetricValue
from -X- _ O
previous -X- _ O
work -X- _ O
. -X- _ O
Moreover -X- _ O
, -X- _ O
according -X- _ O
to -X- _ O
the -X- _ O
results -X- _ O
on -X- _ O
Table -X- _ O
1 -X- _ O
this -X- _ O
speed -X- _ O
- -X- _ O
up -X- _ O
comes -X- _ O
without -X- _ O
substantially -X- _ O
harming -X- _ O
the -X- _ O
model -X- _ O
's -X- _ O
translation -X- _ B-TaskName
quality -X- _ O
. -X- _ O

What -X- _ O
is -X- _ O
the -X- _ O
best -X- _ O
way -X- _ O
to -X- _ O
incorporate -X- _ O
the -X- _ O
retrieved -X- _ O
tokens -X- _ O
? -X- _ O

Models -X- _ O
. -X- _ O

Figure -X- _ O
4 -X- _ O
contains -X- _ O
the -X- _ O
results -X- _ O
of -X- _ O
the -X- _ O
on -X- _ O
- -X- _ O
the -X- _ O
- -X- _ O
fly -X- _ O
adaptation -X- _ O
experiments -X- _ O
on -X- _ O
the -X- _ O
medical -X- _ O
domain -X- _ O
. -X- _ O
On -X- _ O
the -X- _ O
top -X- _ O
left -X- _ O
plot -X- _ O
, -X- _ O
we -X- _ O
see -X- _ O
that -X- _ O
both -X- _ O
the -X- _ O
kNN -X- _ B-MethodName
- -X- _ I-MethodName
MT -X- _ I-MethodName
and -X- _ O
the -X- _ O
chunk -X- _ B-MethodName
- -X- _ I-MethodName
based -X- _ I-MethodName
kNN -X- _ I-MethodName
- -X- _ I-MethodName
MT -X- _ I-MethodName
lead -X- _ O
to -X- _ O
higher -X- _ O
BLEU -X- _ B-MetricName
scores -X- _ O
than -X- _ O
the -X- _ O
fine -X- _ O
- -X- _ O
tuned -X- _ O
models -X- _ O
. -X- _ O
Also -X- _ O
, -X- _ O
on -X- _ O
the -X- _ O
top -X- _ O
right -X- _ O
, -X- _ O
we -X- _ O
see -X- _ O
that -X- _ O
the -X- _ O
time -X- _ O
needed -X- _ O
to -X- _ O
add -X- _ O
examples -X- _ O
to -X- _ O
the -X- _ O
datastore -X- _ O
is -X- _ O
much -X- _ O
shorter -X- _ O
than -X- _ O
the -X- _ O
time -X- _ O
needed -X- _ O
to -X- _ O
fine -X- _ O
- -X- _ O
tune -X- _ O
the -X- _ O
model -X- _ O
. -X- _ O
This -X- _ O
comes -X- _ O
at -X- _ O
the -X- _ O
cost -X- _ O
of -X- _ O
a -X- _ O
higher -X- _ O
inference -X- _ O
time -X- _ O
( -X- _ O
bottom -X- _ O
left -X- _ O
) -X- _ O
. -X- _ O
However -X- _ O
, -X- _ O
we -X- _ O
can -X- _ O
see -X- _ O
that -X- _ O
the -X- _ O
chunk -X- _ B-MethodName
- -X- _ I-MethodName
based -X- _ I-MethodName
kNN -X- _ I-MethodName
- -X- _ I-MethodName
MT -X- _ I-MethodName
model -X- _ O
is -X- _ O
able -X- _ O
to -X- _ O
substantially -X- _ O
reduce -X- _ O
the -X- _ O
inference -X- _ B-MetricName
time -X- _ I-MetricName
gap -X- _ O
to -X- _ O
the -X- _ O
fully -X- _ O
- -X- _ O
parametric -X- _ O
models -X- _ O
. -X- _ O
Also -X- _ O
, -X- _ O
the -X- _ O
bottom -X- _ O
right -X- _ O
plot -X- _ O
shows -X- _ O
that -X- _ O
the -X- _ O
chunk -X- _ B-MethodName
- -X- _ I-MethodName
based -X- _ I-MethodName
kNN -X- _ I-MethodName
- -X- _ I-MethodName
MT -X- _ I-MethodName
has -X- _ O
a -X- _ O
shorter -X- _ O
total -X- _ B-MetricName
time -X- _ I-MetricName
than -X- _ O
kNN -X- _ B-MethodName
- -X- _ I-MethodName
MT -X- _ I-MethodName
and -X- _ O
the -X- _ O
models -X- _ O
fine -X- _ O
- -X- _ O
tuned -X- _ O
every -X- _ O
32,000 -X- _ O
and -X- _ O
64,000 -X- _ O
steps -X- _ O
. -X- _ O
Concerning -X- _ O
the -X- _ O
fine -X- _ O
- -X- _ O
tuned -X- _ O
models -X- _ O
, -X- _ O
there -X- _ O
is -X- _ O
a -X- _ O
BLEU -X- _ B-MetricName
increase -X- _ O
when -X- _ O
the -X- _ O
model -X- _ O
is -X- _ O
fine -X- _ O
- -X- _ O
tuned -X- _ O
more -X- _ O
often -X- _ O
. -X- _ O
However -X- _ O
, -X- _ O
this -X- _ O
leads -X- _ O
to -X- _ O
a -X- _ O
substantially -X- _ O
higher -X- _ O
training -X- _ O
time -X- _ O
. -X- _ O
On -X- _ O
the -X- _ O
other -X- _ O
hand -X- _ O
, -X- _ O
increasing -X- _ O
the -X- _ O
datastore -X- _ O
updates -X- _ O
frequency -X- _ O
leads -X- _ O
to -X- _ O
small -X- _ O
BLEU -X- _ B-MetricName
improvements -X- _ O
and -X- _ O
small -X- _ O
increases -X- _ O
in -X- _ O
training -X- _ O
time -X- _ O
. -X- _ O
The -X- _ O
results -X- _ O
on -X- _ O
the -X- _ O
law -X- _ O
domain -X- _ O
show -X- _ O
similar -X- _ O
results -X- _ O
( -X- _ O
App -X- _ O
. -X- _ O
E -X- _ O
) -X- _ O
. -X- _ O

Related -X- _ O
Work -X- _ O

Semi -X- _ O
- -X- _ O
parametric -X- _ O
models -X- _ O
. -X- _ O
Semi -X- _ O
- -X- _ O
parametric -X- _ O
models -X- _ O
, -X- _ O
which -X- _ O
augment -X- _ O
a -X- _ O
parametric -X- _ O
model -X- _ O
with -X- _ O
a -X- _ O
retrieval -X- _ O
component -X- _ O
, -X- _ O
have -X- _ O
been -X- _ O
shown -X- _ O
to -X- _ O
be -X- _ O
effective -X- _ O
on -X- _ O
several -X- _ O
text -X- _ O
generation -X- _ O
tasks -X- _ O
. -X- _ O
For -X- _ O
language -X- _ O
modeling -X- _ O
, -X- _ O
Khandelwal -X- _ O
et -X- _ O
al -X- _ O
. -X- _ O
( -X- _ O
2019 -X- _ O
) -X- _ O
proposed -X- _ O
the -X- _ O
k -X- _ B-MethodName
- -X- _ I-MethodName
nearest -X- _ I-MethodName
neighbor -X- _ I-MethodName
language -X- _ I-MethodName
( -X- _ O
kNN -X- _ B-MethodName
- -X- _ I-MethodName
LM -X- _ I-MethodName
) -X- _ O
, -X- _ O
in -X- _ O
which -X- _ O
a -X- _ O
language -X- _ O
model -X- _ O
is -X- _ O
augmented -X- _ O
with -X- _ O
token -X- _ O
- -X- _ O
based -X- _ O
retrieval -X- _ O
and -X- _ O
uses -X- _ O
probability -X- _ O
interpolation -X- _ O
to -X- _ O
incorporate -X- _ O
these -X- _ O
tokens -X- _ O
. -X- _ O
Yogatama -X- _ O
et -X- _ O
al -X- _ O
. -X- _ O
( -X- _ O
2021 -X- _ O
) -X- _ O
proposed -X- _ O
to -X- _ O
integrate -X- _ O
the -X- _ O
retrieved -X- _ O
tokens -X- _ O
with -X- _ O
a -X- _ O
gating -X- _ O
mechanism -X- _ O
. -X- _ O
Borgeaud -X- _ O
et -X- _ O
al -X- _ O
. -X- _ O
( -X- _ O
2021 -X- _ O
) -X- _ O
proposed -X- _ O
to -X- _ O
retrieve -X- _ O
chunks -X- _ O
of -X- _ O
tokens -X- _ O
and -X- _ O
incorporate -X- _ O
them -X- _ O
with -X- _ O
cross -X- _ O
- -X- _ O
attention -X- _ O
, -X- _ O
using -X- _ O
datastores -X- _ O
with -X- _ O
trillions -X- _ O
of -X- _ O
tokens -X- _ O
. -X- _ O
To -X- _ O
increase -X- _ O
the -X- _ O
kNN -X- _ B-MethodName
- -X- _ I-MethodName
LM -X- _ I-MethodName
's -X- _ O
decoding -X- _ B-MetricName
speed -X- _ I-MetricName
, -X- _ O
He -X- _ O
et -X- _ O
al -X- _ O
. -X- _ O
( -X- _ O
2021 -X- _ O
) -X- _ O
proposed -X- _ O
a -X- _ O
range -X- _ O
of -X- _ O
techniques -X- _ O
, -X- _ O
such -X- _ O
as -X- _ O
datastore -X- _ O
pruning -X- _ O
, -X- _ O
dimension -X- _ O
reduction -X- _ O
, -X- _ O
and -X- _ O
adaptive -X- _ O
retrieval -X- _ O
. -X- _ O
Alon -X- _ O
et -X- _ O
al -X- _ O
. -X- _ O
( -X- _ O
2022 -X- _ O
) -X- _ O
proposed -X- _ O
adding -X- _ O
pointers -X- _ O
to -X- _ O
the -X- _ O
next -X- _ O
token -X- _ O
on -X- _ O
the -X- _ O
original -X- _ O
corpus -X- _ O
to -X- _ O
the -X- _ O
datastore -X- _ O
entries -X- _ O
, -X- _ O
so -X- _ O
that -X- _ O
the -X- _ O
model -X- _ O
can -X- _ O
consider -X- _ O
the -X- _ O
pointed -X- _ O
entries -X- _ O
instead -X- _ O
of -X- _ O
performing -X- _ O
retrieval -X- _ O
. -X- _ O
Similarly -X- _ O
to -X- _ O
our -X- _ O
approach -X- _ O
, -X- _ O
this -X- _ O
saves -X- _ O
retrieval -X- _ O
steps -X- _ O
by -X- _ O
leveraging -X- _ O
the -X- _ O
original -X- _ O
corpus -X- _ O
sequences -X- _ O
, -X- _ O
but -X- _ O
in -X- _ O
our -X- _ O
case -X- _ O
, -X- _ O
we -X- _ O
do -X- _ O
not -X- _ O
limit -X- _ O
the -X- _ O
candidate -X- _ O
tokens -X- _ O
to -X- _ O
be -X- _ O
the -X- _ O
following -X- _ O
ones -X- _ O
and -X- _ O
consider -X- _ O
the -X- _ O
succeeding -X- _ O
tokens -X- _ O
even -X- _ O
if -X- _ O
the -X- _ O
model -X- _ O
has -X- _ O
not -X- _ O
generated -X- _ O
the -X- _ O
same -X- _ O
prefix -X- _ O
token -X- _ O
( -X- _ O
s -X- _ O
) -X- _ O
. -X- _ O

For -X- _ O
machine -X- _ B-TaskName
translation -X- _ I-TaskName
, -X- _ O
Gu -X- _ O
et -X- _ O
al -X- _ O
. -X- _ O
( -X- _ O
2018 -X- _ O
) -X- _ O
introduced -X- _ O
a -X- _ O
semi -X- _ O
- -X- _ O
parametric -X- _ O
model -X- _ O
which -X- _ O
uses -X- _ O
an -X- _ O
outof -X- _ O
- -X- _ O
the -X- _ O
- -X- _ O
box -X- _ O
search -X- _ O
engine -X- _ O
to -X- _ O
retrieve -X- _ O
similar -X- _ O
sentence -X- _ O
pairs -X- _ O
, -X- _ O
and -X- _ O
incorporate -X- _ O
them -X- _ O
with -X- _ O
shallow -X- _ O
and -X- _ O
deep -X- _ O
fusion -X- _ O
. -X- _ O
Zhang -X- _ O
et -X- _ O
al -X- _ O
. -X- _ O
( -X- _ O
2018 -X- _ O
) -X- _ O
proposed -X- _ O
to -X- _ O
retrieve -X- _ O
n -X- _ O
- -X- _ O
grams -X- _ O
and -X- _ O
use -X- _ O
them -X- _ O
to -X- _ O
up -X- _ O
- -X- _ O
weight -X- _ O
token -X- _ O
probabilities -X- _ O
. -X- _ O
Bapna -X- _ O
and -X- _ O
Firat -X- _ O
( -X- _ O
2019a -X- _ O
) -X- _ O
proposed -X- _ O
to -X- _ O
retrieve -X- _ O
sentences -X- _ O
similar -X- _ O
to -X- _ O
the -X- _ O
source -X- _ O
's -X- _ O
n -X- _ O
- -X- _ O
grams -X- _ O
, -X- _ O
and -X- _ O
incorporate -X- _ O
them -X- _ O
with -X- _ O
attention -X- _ O
. -X- _ O
More -X- _ O
recently -X- _ O
, -X- _ O
Khandelwal -X- _ O
et -X- _ O
al -X- _ O
. -X- _ O
( -X- _ O
2021 -X- _ O
) -X- _ O
proposed -X- _ O
the -X- _ O
kNN -X- _ B-MethodName
- -X- _ I-MethodName
MT -X- _ I-MethodName
model -X- _ I-MethodName
which -X- _ O
Zheng -X- _ O
et -X- _ O
al -X- _ O
. -X- _ O
( -X- _ O
2021a -X- _ O
) -X- _ O
extended -X- _ O
with -X- _ O
a -X- _ O
network -X- _ O
that -X- _ O
determines -X- _ O
the -X- _ O
number -X- _ O
of -X- _ O
retrieved -X- _ O
tokens -X- _ O
to -X- _ O
consider -X- _ O
and -X- _ O
Zheng -X- _ O
et -X- _ O
al -X- _ O
. -X- _ O
( -X- _ O
2021b -X- _ O
) -X- _ O
pro -X- _ O
- -X- _ O
posed -X- _ O
building -X- _ O
the -X- _ O
datastore -X- _ O
using -X- _ O
monolingual -X- _ O
sentences -X- _ O
. -X- _ O
As -X- _ O
kNN -X- _ B-MethodName
- -X- _ I-MethodName
MT -X- _ I-MethodName
can -X- _ O
be -X- _ O
up -X- _ O
to -X- _ O
two -X- _ O
orders -X- _ O
of -X- _ O
magnitude -X- _ O
slower -X- _ O
than -X- _ O
a -X- _ O
fully -X- _ O
- -X- _ O
parametric -X- _ O
model -X- _ O
, -X- _ O
methods -X- _ O
that -X- _ O
improve -X- _ O
its -X- _ O
efficiency -X- _ O
have -X- _ O
been -X- _ O
proposed -X- _ O
. -X- _ O
and -X- _ O
proposed -X- _ O
the -X- _ O
Fast -X- _ B-MethodName
and -X- _ O
Faster -X- _ B-MethodName
kNN -X- _ I-MethodName
- -X- _ I-MethodName
MT -X- _ I-MethodName
, -X- _ O
in -X- _ O
which -X- _ O
the -X- _ O
model -X- _ O
has -X- _ O
a -X- _ O
higher -X- _ O
decoding -X- _ B-MetricName
speed -X- _ I-MetricName
, -X- _ O
by -X- _ O
creating -X- _ O
a -X- _ O
different -X- _ O
datastore -X- _ O
, -X- _ O
based -X- _ O
on -X- _ O
the -X- _ O
source -X- _ O
sentence -X- _ O
, -X- _ O
for -X- _ O
each -X- _ O
example -X- _ O
. -X- _ O
Martins -X- _ O
et -X- _ O
al -X- _ O
. -X- _ O
( -X- _ O
2022 -X- _ O
) -X- _ O
propose -X- _ O
efficient -X- _ O
kNN -X- _ B-MethodName
- -X- _ I-MethodName
MT -X- _ I-MethodName
, -X- _ O
which -X- _ O
we -X- _ O
use -X- _ O
as -X- _ O
baseline -X- _ O
( -X- _ O
§ -X- _ O
4.1 -X- _ O
) -X- _ O
, -X- _ O
by -X- _ O
adapting -X- _ O
the -X- _ O
methods -X- _ O
introduced -X- _ O
by -X- _ O
He -X- _ O
et -X- _ O
al -X- _ O
. -X- _ O
( -X- _ O
2021 -X- _ O
) -X- _ O
to -X- _ O
machine -X- _ B-TaskName
translation -X- _ I-TaskName
and -X- _ O
introducing -X- _ O
a -X- _ O
retrieval -X- _ O
distributions -X- _ O
cache -X- _ O
to -X- _ O
speed -X- _ O
- -X- _ O
up -X- _ O
decoding -X- _ O
. -X- _ O
In -X- _ O
this -X- _ O
paper -X- _ O
, -X- _ O
we -X- _ O
show -X- _ O
that -X- _ O
the -X- _ O
chunk -X- _ B-MethodName
- -X- _ I-MethodName
based -X- _ I-MethodName
kNN -X- _ I-MethodName
- -X- _ I-MethodName
MT -X- _ I-MethodName
model -X- _ O
can -X- _ O
further -X- _ O
speed -X- _ O
- -X- _ O
up -X- _ O
decoding -X- _ O
, -X- _ O
by -X- _ O
retrieving -X- _ O
chunks -X- _ O
of -X- _ O
tokens -X- _ O
instead -X- _ O
of -X- _ O
a -X- _ O
single -X- _ O
token -X- _ O
. -X- _ O

Domain -X- _ O
adaptation -X- _ O
consists -X- _ O
of -X- _ O
adapting -X- _ O
generic -X- _ O
models -X- _ O
to -X- _ O
domain -X- _ O
- -X- _ O
specific -X- _ O
data -X- _ O
. -X- _ O
The -X- _ O
most -X- _ O
common -X- _ O
method -X- _ O
for -X- _ O
domain -X- _ O
adaptation -X- _ O
in -X- _ O
machine -X- _ B-TaskName
translation -X- _ I-TaskName
is -X- _ O
fine -X- _ O
- -X- _ O
tuning -X- _ O
the -X- _ O
model -X- _ O
on -X- _ O
each -X- _ O
domain -X- _ O
, -X- _ O
but -X- _ O
this -X- _ O
can -X- _ O
be -X- _ O
expensive -X- _ O
and -X- _ O
often -X- _ O
leads -X- _ O
to -X- _ O
catastrophic -X- _ O
forgetting -X- _ O
( -X- _ O
Saunders -X- _ O
, -X- _ O
2021 -X- _ O
) -X- _ O
. -X- _ O
To -X- _ O
simplify -X- _ O
this -X- _ O
, -X- _ O
some -X- _ O
work -X- _ O
has -X- _ O
proposed -X- _ O
fine -X- _ O
- -X- _ O
tuning -X- _ O
only -X- _ O
part -X- _ O
of -X- _ O
the -X- _ O
model -X- _ O
( -X- _ O
Wuebker -X- _ O
et -X- _ O
al -X- _ O
. -X- _ O
, -X- _ O
2018 -X- _ O
; -X- _ O
Bapna -X- _ O
and -X- _ O
Firat -X- _ O
, -X- _ O
2019b -X- _ O
; -X- _ O
Lin -X- _ O
et -X- _ O
al -X- _ O
. -X- _ O
, -X- _ O
2021 -X- _ O
; -X- _ O
Liang -X- _ O
et -X- _ O
al -X- _ O
. -X- _ O
, -X- _ O
2021 -X- _ O
) -X- _ O
. -X- _ O
Farajian -X- _ O
et -X- _ O
al -X- _ O
. -X- _ O
( -X- _ O
2017 -X- _ O
) -X- _ O
performed -X- _ O
on -X- _ O
- -X- _ O
the -X- _ O
- -X- _ O
fly -X- _ O
adaptation -X- _ O
, -X- _ O
by -X- _ O
fine -X- _ O
- -X- _ O
tuning -X- _ O
the -X- _ O
model -X- _ O
on -X- _ O
a -X- _ O
set -X- _ O
of -X- _ O
retrieved -X- _ O
examples -X- _ O
for -X- _ O
each -X- _ O
source -X- _ O
sentence -X- _ O
. -X- _ O
However -X- _ O
, -X- _ O
this -X- _ O
still -X- _ O
requires -X- _ O
fine -X- _ O
- -X- _ O
tuning -X- _ O
model -X- _ O
parameters -X- _ O
. -X- _ O

In -X- _ O
this -X- _ O
paper -X- _ O
, -X- _ O
we -X- _ O
propose -X- _ O
a -X- _ O
chunk -X- _ B-MethodName
- -X- _ I-MethodName
based -X- _ I-MethodName
kNN -X- _ I-MethodName
- -X- _ I-MethodName
MT -X- _ I-MethodName
model -X- _ O
, -X- _ O
which -X- _ O
retrieves -X- _ O
chunks -X- _ O
of -X- _ O
tokens -X- _ O
from -X- _ O
a -X- _ O
datastore -X- _ O
, -X- _ O
instead -X- _ O
of -X- _ O
a -X- _ O
single -X- _ O
token -X- _ O
. -X- _ O
To -X- _ O
do -X- _ O
so -X- _ O
, -X- _ O
we -X- _ O
proposed -X- _ O
several -X- _ O
alternatives -X- _ O
to -X- _ O
explore -X- _ O
the -X- _ O
re -X- _ O
- -X- _ O
trieved -X- _ O
chunks -X- _ O
' -X- _ O
tokens -X- _ O
: -X- _ O
keeping -X- _ O
the -X- _ O
original -X- _ O
order -X- _ O
or -X- _ O
building -X- _ O
a -X- _ O
neighbors -X- _ O
' -X- _ O
cache -X- _ O
. -X- _ O
We -X- _ O
also -X- _ O
analyzed -X- _ O
two -X- _ O
approaches -X- _ O
to -X- _ O
select -X- _ O
the -X- _ O
retrieval -X- _ O
steps -X- _ O
: -X- _ O
every -X- _ O
i -X- _ O
steps -X- _ O
or -X- _ O
using -X- _ O
a -X- _ O
geometric -X- _ O
progression -X- _ O
heuristic -X- _ O
to -X- _ O
define -X- _ O
the -X- _ O
interval -X- _ O
between -X- _ O
retrieval -X- _ O
steps -X- _ O
. -X- _ O
Through -X- _ O
experiments -X- _ O
on -X- _ O
domain -X- _ O
adaptation -X- _ O
, -X- _ O
we -X- _ O
showed -X- _ O
that -X- _ O
chunk -X- _ B-MethodName
- -X- _ I-MethodName
based -X- _ I-MethodName
kNN -X- _ I-MethodName
- -X- _ I-MethodName
MT -X- _ I-MethodName
leads -X- _ O
to -X- _ O
a -X- _ O
considerable -X- _ O
speed -X- _ O
- -X- _ O
up -X- _ O
without -X- _ O
substantially -X- _ O
compromising -X- _ O
the -X- _ O
translation -X- _ B-TaskName
quality -X- _ O
. -X- _ O
Experiments -X- _ O
on -X- _ O
onthe -X- _ O
- -X- _ O
fly -X- _ O
adaptation -X- _ O
showed -X- _ O
that -X- _ O
chunk -X- _ B-MethodName
- -X- _ I-MethodName
based -X- _ I-MethodName
kNN -X- _ I-MethodName
- -X- _ I-MethodName
MT -X- _ I-MethodName
leads -X- _ O
to -X- _ O
high -X- _ O
quality -X- _ O
translations -X- _ O
while -X- _ O
being -X- _ O
more -X- _ O
efficient -X- _ O
than -X- _ O
previously -X- _ O
proposed -X- _ O
methods -X- _ O
. -X- _ O

Limitations -X- _ O

The -X- _ O
scope -X- _ O
of -X- _ O
this -X- _ O
paper -X- _ O
is -X- _ O
limited -X- _ O
to -X- _ O
the -X- _ O
usage -X- _ O
of -X- _ O
small -X- _ O
to -X- _ O
medium -X- _ O
size -X- _ O
datastores -X- _ O
, -X- _ O
due -X- _ O
to -X- _ O
the -X- _ O
memory -X- _ O
requirements -X- _ O
needed -X- _ O
for -X- _ O
big -X- _ O
size -X- _ O
datastores -X- _ O
, -X- _ O
for -X- _ O
which -X- _ O
the -X- _ O
proposed -X- _ O
model -X- _ O
could -X- _ O
be -X- _ O
even -X- _ O
more -X- _ O
beneficial -X- _ O
. -X- _ O
Additionally -X- _ O
, -X- _ O
we -X- _ O
use -X- _ O
the -X- _ O
decoding -X- _ B-MetricName
speed -X- _ I-MetricName
( -X- _ O
tokens -X- _ O
per -X- _ O
second -X- _ O
) -X- _ O
, -X- _ O
training -X- _ B-MetricName
time -X- _ I-MetricName
( -X- _ O
in -X- _ O
minutes -X- _ O
) -X- _ O
, -X- _ O
and -X- _ O
inference -X- _ B-MetricName
time -X- _ I-MetricName
( -X- _ O
in -X- _ O
minutes -X- _ O
) -X- _ O
to -X- _ O
compare -X- _ O
the -X- _ O
efficiency -X- _ O
of -X- _ O
the -X- _ O
different -X- _ O
models -X- _ O
. -X- _ O
However -X- _ O
, -X- _ O
these -X- _ O
metrics -X- _ O
depend -X- _ O
on -X- _ O
the -X- _ O
computational -X- _ O
infrastructure -X- _ O
used -X- _ O
, -X- _ O
and -X- _ O
, -X- _ O
consequently -X- _ O
, -X- _ O
the -X- _ O
speed -X- _ O
- -X- _ O
up -X- _ O
gains -X- _ O
can -X- _ O
vary -X- _ O
when -X- _ O
using -X- _ O
different -X- _ O
hardware -X- _ O
. -X- _ O

We -X- _ O
report -X- _ O
the -X- _ O
results -X- _ O
of -X- _ O
the -X- _ O
on -X- _ O
- -X- _ O
the -X- _ O
- -X- _ O
fly -X- _ O
adaptation -X- _ O
experiment -X- _ O
, -X- _ O
on -X- _ O
the -X- _ O
law -X- _ O
domain -X- _ O
, -X- _ O
on -X- _ O
Figure -X- _ O
5 -X- _ O
. -X- _ O
In -X- _ O
a -X- _ O
similar -X- _ O
way -X- _ O
as -X- _ O
in -X- _ O
the -X- _ O
medical -X- _ O
domain -X- _ O
, -X- _ O
the -X- _ O
top -X- _ O
left -X- _ O
plot -X- _ O
shows -X- _ O
that -X- _ O
the -X- _ O
kNN -X- _ B-MethodName
- -X- _ I-MethodName
MT -X- _ I-MethodName
and -X- _ O
the -X- _ O
chunk -X- _ B-MethodName
- -X- _ I-MethodName
based -X- _ I-MethodName
kNN -X- _ I-MethodName
- -X- _ I-MethodName
MT -X- _ I-MethodName
models -X- _ O
lead -X- _ O
to -X- _ O
higher -X- _ O
BLEU -X- _ B-MetricValue
scores -X- _ O
than -X- _ O
the -X- _ O
fine -X- _ O
- -X- _ O
tuned -X- _ O
models -X- _ O
. -X- _ O
We -X- _ O
can -X- _ O
also -X- _ O
see -X- _ O
, -X- _ O
on -X- _ O
the -X- _ O
top -X- _ O
right -X- _ O
plot -X- _ O
, -X- _ O
that -X- _ O
the -X- _ O
time -X- _ O
the -X- _ O
models -X- _ O
take -X- _ O
to -X- _ O
add -X- _ O
examples -X- _ O
to -X- _ O
the -X- _ O
datastore -X- _ O
along -X- _ O
the -X- _ O
generation -X- _ O
is -X- _ O
much -X- _ O
shorter -X- _ O
than -X- _ O
the -X- _ O
time -X- _ O
needed -X- _ O
to -X- _ O
fine -X- _ O
- -X- _ O
tune -X- _ O
the -X- _ O
model -X- _ O
. -X- _ O
This -X- _ O
comes -X- _ O
at -X- _ O
the -X- _ O
cost -X- _ O
of -X- _ O
a -X- _ O
higher -X- _ O
inference -X- _ B-MetricName
time -X- _ I-MetricName
( -X- _ O
as -X- _ O
shown -X- _ O
on -X- _ O
the -X- _ O
bottom -X- _ O
left -X- _ O
plot -X- _ O
) -X- _ O
. -X- _ O
However -X- _ O
, -X- _ O
we -X- _ O
can -X- _ O
see -X- _ O
that -X- _ O
the -X- _ O
chunk -X- _ B-MethodName
- -X- _ I-MethodName
based -X- _ I-MethodName
kNN -X- _ I-MethodName
- -X- _ I-MethodName
MT -X- _ I-MethodName
model -X- _ O
is -X- _ O
able -X- _ O
to -X- _ O
substantially -X- _ O
reduce -X- _ O
the -X- _ O
inference -X- _ O
time -X- _ O
gap -X- _ O
between -X- _ O
fully -X- _ O
- -X- _ O
parametric -X- _ O
and -X- _ O
semi -X- _ O
- -X- _ O
parametric -X- _ O
models -X- _ O
, -X- _ O
having -X- _ O
a -X- _ O
shorter -X- _ O
total -X- _ B-MetricName
time -X- _ I-MetricName
than -X- _ O
the -X- _ O
kNN -X- _ B-MethodName
- -X- _ I-MethodName
MT -X- _ I-MethodName
and -X- _ O
the -X- _ O
models -X- _ O
fine -X- _ O
- -X- _ O
tuned -X- _ O
every -X- _ O
32,000 -X- _ O
and -X- _ O
64,000 -X- _ O
steps -X- _ O
( -X- _ O
bottom -X- _ O
right -X- _ O
plot -X- _ O
) -X- _ O
. -X- _ O
Concerning -X- _ O
the -X- _ O
fine -X- _ O
- -X- _ O
tuned -X- _ O
models -X- _ O
, -X- _ O
fine -X- _ O
- -X- _ O
tuning -X- _ O
more -X- _ O
often -X- _ O
leads -X- _ O
to -X- _ O
a -X- _ O
slightly -X- _ O
better -X- _ O
BLEU -X- _ B-MetricName
score -X- _ O
. -X- _ O
However -X- _ O
, -X- _ O
this -X- _ O
also -X- _ O
leads -X- _ O
to -X- _ O
a -X- _ O
substantially -X- _ O
higher -X- _ O
training -X- _ B-MetricName
time -X- _ I-MetricName
. -X- _ O

We -X- _ O
report -X- _ O
some -X- _ O
translation -X- _ O
examples -X- _ O
on -X- _ O
the -X- _ O
medical -X- _ O
domain -X- _ O
in -X- _ O
Figures -X- _ O
6 -X- _ O
and -X- _ O
7 -X- _ O
, -X- _ O
on -X- _ O
the -X- _ O
law -X- _ O
domain -X- _ O
in -X- _ O
Figure -X- _ O
8 -X- _ O
, -X- _ O
and -X- _ O
on -X- _ O
the -X- _ O
IT -X- _ O
domain -X- _ O
in -X- _ O
Figure -X- _ O
9 -X- _ O
. -X- _ O
To -X- _ O
simplify -X- _ O
the -X- _ O
examples -X- _ O
, -X- _ O
we -X- _ O
use -X- _ O
a -X- _ O
batch -X- _ O
size -X- _ O
of -X- _ O
1 -X- _ O
and -X- _ O
a -X- _ O
beam -X- _ O
size -X- _ O
of -X- _ O
1 -X- _ O
. -X- _ O

Figure -X- _ O
8 -X- _ O
: -X- _ O
Example -X- _ O
of -X- _ O
translation -X- _ B-TaskName
from -X- _ O
the -X- _ O
law -X- _ O
domain -X- _ O
. -X- _ O
The -X- _ O
tokens -X- _ O
generated -X- _ O
at -X- _ O
the -X- _ O
retrieval -X- _ O
steps -X- _ O
are -X- _ O
highlighted -X- _ O
in -X- _ O
the -X- _ O
same -X- _ O
color -X- _ O
as -X- _ O
the -X- _ O
retrieved -X- _ O
chunks -X- _ O
of -X- _ O
tokens -X- _ O
. -X- _ O
These -X- _ O
chunks -X- _ O
of -X- _ O
tokens -X- _ O
are -X- _ O
added -X- _ O
to -X- _ O
the -X- _ O
neighbors -X- _ O
' -X- _ O
cache -X- _ O
, -X- _ O
after -X- _ O
being -X- _ O
retrieved -X- _ O
. -X- _ O
The -X- _ O
retrieved -X- _ O
tokens -X- _ O
which -X- _ O
are -X- _ O
present -X- _ O
in -X- _ O
the -X- _ O
translation -X- _ B-TaskName
are -X- _ O
bolded -X- _ O
. -X- _ O

Acknowledgments -X- _ O

Due -X- _ O
to -X- _ O
the -X- _ O
rapid -X- _ O
upgrade -X- _ O
of -X- _ O
social -X- _ O
platforms -X- _ O
, -X- _ O
most -X- _ O
of -X- _ O
today -X- _ O
's -X- _ O
fake -X- _ O
news -X- _ O
is -X- _ O
published -X- _ O
and -X- _ O
spread -X- _ O
in -X- _ O
a -X- _ O
multi -X- _ O
- -X- _ O
modal -X- _ O
form -X- _ O
. -X- _ O
Most -X- _ O
existing -X- _ O
multi -X- _ B-TaskName
- -X- _ I-TaskName
modal -X- _ I-TaskName
fake -X- _ I-TaskName
news -X- _ I-TaskName
detection -X- _ I-TaskName
methods -X- _ O
neglect -X- _ O
the -X- _ O
fact -X- _ O
that -X- _ O
some -X- _ O
label -X- _ O
- -X- _ O
specific -X- _ O
features -X- _ O
learned -X- _ O
from -X- _ O
the -X- _ O
training -X- _ O
set -X- _ O
can -X- _ O
not -X- _ O
generalize -X- _ O
well -X- _ O
to -X- _ O
the -X- _ O
testing -X- _ O
set -X- _ O
, -X- _ O
thus -X- _ O
inevitably -X- _ O
suffering -X- _ O
from -X- _ O
the -X- _ O
harm -X- _ O
caused -X- _ O
by -X- _ O
the -X- _ O
latent -X- _ O
data -X- _ O
bias -X- _ O
. -X- _ O
In -X- _ O
this -X- _ O
paper -X- _ O
, -X- _ O
we -X- _ O
analyze -X- _ O
and -X- _ O
identify -X- _ O
the -X- _ O
psycholinguistic -X- _ O
bias -X- _ O
in -X- _ O
the -X- _ O
text -X- _ O
and -X- _ O
the -X- _ O
bias -X- _ O
of -X- _ O
inferring -X- _ O
news -X- _ O
label -X- _ O
based -X- _ O
on -X- _ O
only -X- _ O
image -X- _ O
features -X- _ O
. -X- _ O
We -X- _ O
mitigate -X- _ O
these -X- _ O
biases -X- _ O
from -X- _ O
a -X- _ O
causality -X- _ O
perspective -X- _ O
and -X- _ O
propose -X- _ O
a -X- _ O
Causal -X- _ B-MethodName
intervention -X- _ I-MethodName
and -X- _ I-MethodName
Counterfactual -X- _ I-MethodName
reasoning -X- _ I-MethodName
based -X- _ I-MethodName
Debiasing -X- _ I-MethodName
framework -X- _ I-MethodName
( -X- _ O
CCD -X- _ B-MethodName
) -X- _ O
for -X- _ O
multi -X- _ B-TaskName
- -X- _ I-TaskName
modal -X- _ I-TaskName
fake -X- _ I-TaskName
news -X- _ I-TaskName
detection -X- _ I-TaskName
. -X- _ O
To -X- _ O
achieve -X- _ O
our -X- _ O
goal -X- _ O
, -X- _ O
we -X- _ O
first -X- _ O
utilize -X- _ O
causal -X- _ O
intervention -X- _ O
to -X- _ O
remove -X- _ O
the -X- _ O
psycholinguistic -X- _ O
bias -X- _ O
which -X- _ O
introduces -X- _ O
the -X- _ O
spurious -X- _ O
correlations -X- _ O
between -X- _ O
text -X- _ O
features -X- _ O
and -X- _ O
news -X- _ O
label -X- _ O
. -X- _ O
And -X- _ O
then -X- _ O
, -X- _ O
we -X- _ O
apply -X- _ O
counterfactual -X- _ O
reasoning -X- _ O
by -X- _ O
imagining -X- _ O
a -X- _ O
counterfactual -X- _ O
world -X- _ O
where -X- _ O
each -X- _ O
news -X- _ O
has -X- _ O
only -X- _ O
image -X- _ O
features -X- _ O
for -X- _ O
estimating -X- _ O
the -X- _ O
direct -X- _ O
effect -X- _ O
of -X- _ O
the -X- _ O
image -X- _ O
. -X- _ O
Therefore -X- _ O
we -X- _ O
can -X- _ O
eliminate -X- _ O
the -X- _ O
image -X- _ O
- -X- _ O
only -X- _ O
bias -X- _ O
by -X- _ O
deducting -X- _ O
the -X- _ O
direct -X- _ O
effect -X- _ O
of -X- _ O
the -X- _ O
image -X- _ O
from -X- _ O
the -X- _ O
total -X- _ O
effect -X- _ O
on -X- _ O
labels -X- _ O
. -X- _ O
Extensive -X- _ O
experiments -X- _ O
on -X- _ O
two -X- _ O
real -X- _ O
- -X- _ O
world -X- _ O
benchmark -X- _ O
datasets -X- _ O
demonstrate -X- _ O
the -X- _ O
effectiveness -X- _ O
of -X- _ O
our -X- _ O
framework -X- _ O
for -X- _ O
improving -X- _ O
multi -X- _ B-TaskName
- -X- _ I-TaskName
modal -X- _ I-TaskName
fake -X- _ I-TaskName
news -X- _ I-TaskName
detection -X- _ I-TaskName
. -X- _ O

Today -X- _ O
, -X- _ O
most -X- _ O
existing -X- _ O
methods -X- _ O
train -X- _ O
on -X- _ O
known -X- _ O
fake -X- _ O
news -X- _ O
instances -X- _ O
expecting -X- _ O
to -X- _ O
capture -X- _ O
the -X- _ O
labelspecific -X- _ O
features -X- _ O
for -X- _ O
judging -X- _ O
the -X- _ O
authenticity -X- _ O
of -X- _ O
unseen -X- _ O
news -X- _ O
( -X- _ O
Singhal -X- _ O
et -X- _ O
al -X- _ O
. -X- _ O
, -X- _ O
2020 -X- _ O
; -X- _ O
Wu -X- _ O
et -X- _ O
al -X- _ O
. -X- _ O
, -X- _ O
Qian -X- _ O
et -X- _ O
al -X- _ O
. -X- _ O
, -X- _ O
2021b -X- _ O
; -X- _ O
Qi -X- _ O
et -X- _ O
al -X- _ O
. -X- _ O
, -X- _ O
2021 -X- _ O
) -X- _ O
. -X- _ O
However -X- _ O
, -X- _ O
such -X- _ O
label -X- _ O
- -X- _ O
specific -X- _ O
features -X- _ O
may -X- _ O
expose -X- _ O
the -X- _ O
models -X- _ O
to -X- _ O
hidden -X- _ O
data -X- _ O
bias -X- _ O
when -X- _ O
confronted -X- _ O
with -X- _ O
unseen -X- _ O
fake -X- _ O
news -X- _ O
samples -X- _ O
( -X- _ O
Wang -X- _ O
et -X- _ O
al -X- _ O
. -X- _ O
, -X- _ O
2018 -X- _ O
; -X- _ O
Cheng -X- _ O
et -X- _ O
al -X- _ O
. -X- _ O
, -X- _ O
2021 -X- _ O
; -X- _ O
Zhu -X- _ O
et -X- _ O
al -X- _ O
. -X- _ O
, -X- _ O
2022 -X- _ O
) -X- _ O
. -X- _ O
To -X- _ O
address -X- _ O
the -X- _ O
problem -X- _ O
, -X- _ O
we -X- _ O
investigate -X- _ O
the -X- _ O
biases -X- _ O
underlying -X- _ O
the -X- _ O
multi -X- _ B-TaskName
- -X- _ I-TaskName
modal -X- _ I-TaskName
fake -X- _ I-TaskName
news -X- _ I-TaskName
detection -X- _ I-TaskName
data -X- _ O
and -X- _ O
identify -X- _ O
the -X- _ O
psycholinguistic -X- _ O
bias -X- _ O
in -X- _ O
the -X- _ O
text -X- _ O
and -X- _ O
the -X- _ O
bias -X- _ O
of -X- _ O
inferring -X- _ O
news -X- _ O
label -X- _ O
based -X- _ O
on -X- _ O
image -X- _ O
features -X- _ O
only -X- _ O
( -X- _ O
i.e. -X- _ O
image -X- _ O
- -X- _ O
only -X- _ O
bias -X- _ O
) -X- _ O
. -X- _ O
These -X- _ O
biases -X- _ O
could -X- _ O
lead -X- _ O
to -X- _ O
spurious -X- _ O
correlations -X- _ O
between -X- _ O
the -X- _ O
news -X- _ O
and -X- _ O
labels -X- _ O
, -X- _ O
thus -X- _ O
impairing -X- _ O
the -X- _ O
model -X- _ O
performance -X- _ O
on -X- _ O
testing -X- _ O
data -X- _ O
. -X- _ O

For -X- _ O
the -X- _ O
T -X- _ O
→ -X- _ O
Y -X- _ O
branch -X- _ O
, -X- _ O
we -X- _ O
observe -X- _ O
that -X- _ O
the -X- _ O
linguistic -X- _ O
characteristics -X- _ O
of -X- _ O
the -X- _ O
text -X- _ O
have -X- _ O
obvious -X- _ O
emotional -X- _ O
preferences -X- _ O
, -X- _ O
such -X- _ O
as -X- _ O
the -X- _ O
usage -X- _ O
of -X- _ O
psycholin- -X- _ O
guistic -X- _ O
words -X- _ O
" -X- _ O
crazy -X- _ O
" -X- _ O
and -X- _ O
" -X- _ O
amazing -X- _ O
" -X- _ O
, -X- _ O
which -X- _ O
play -X- _ O
a -X- _ O
critical -X- _ O
role -X- _ O
in -X- _ O
fake -X- _ B-TaskName
news -X- _ I-TaskName
detection -X- _ I-TaskName
. -X- _ O
To -X- _ O
deeply -X- _ O
analyze -X- _ O
the -X- _ O
linguistic -X- _ O
characteristics -X- _ O
of -X- _ O
the -X- _ O
text -X- _ O
, -X- _ O
we -X- _ O
present -X- _ O
a -X- _ O
mathematical -X- _ O
analysis -X- _ O
of -X- _ O
the -X- _ O
psycholinguistic -X- _ O
word -X- _ O
distribution -X- _ O
of -X- _ O
real -X- _ O
news -X- _ O
and -X- _ O
fake -X- _ O
news -X- _ O
based -X- _ O
on -X- _ O
the -X- _ O
LIWC -X- _ O
2015 -X- _ O
dictionary -X- _ O
( -X- _ O
Pennebaker -X- _ O
et -X- _ O
al -X- _ O
. -X- _ O
, -X- _ O
2015 -X- _ O
) -X- _ O
. -X- _ O
Take -X- _ O
the -X- _ O
Twitter -X- _ B-DatasetName
dataset -X- _ O
as -X- _ O
an -X- _ O
example -X- _ O
, -X- _ O
as -X- _ O
shown -X- _ O
in -X- _ O
Figure -X- _ O
1 -X- _ O
, -X- _ O
we -X- _ O
can -X- _ O
observe -X- _ O
that -X- _ O
the -X- _ O
word -X- _ O
frequency -X- _ O
distribution -X- _ O
of -X- _ O
fake -X- _ O
news -X- _ O
is -X- _ O
quite -X- _ O
different -X- _ O
from -X- _ O
that -X- _ O
of -X- _ O
real -X- _ O
news -X- _ O
, -X- _ O
especially -X- _ O
for -X- _ O
words -X- _ O
expressing -X- _ O
anxiety -X- _ O
, -X- _ O
negative -X- _ O
emotions -X- _ O
, -X- _ O
positive -X- _ O
emotions -X- _ O
, -X- _ O
tentative -X- _ O
, -X- _ O
and -X- _ O
netspeak -X- _ O
. -X- _ O
It -X- _ O
seems -X- _ O
that -X- _ O
we -X- _ O
can -X- _ O
draw -X- _ O
a -X- _ O
conclusion -X- _ O
that -X- _ O
fake -X- _ O
news -X- _ O
prefers -X- _ O
to -X- _ O
use -X- _ O
loaded -X- _ O
language -X- _ O
to -X- _ O
stir -X- _ O
up -X- _ O
the -X- _ O
reader -X- _ O
's -X- _ O
emotions -X- _ O
and -X- _ O
attract -X- _ O
more -X- _ O
attention -X- _ O
. -X- _ O
Consequently -X- _ O
, -X- _ O
the -X- _ O
model -X- _ O
could -X- _ O
be -X- _ O
prone -X- _ O
to -X- _ O
relying -X- _ O
on -X- _ O
such -X- _ O
psycholinguistic -X- _ O
features -X- _ O
as -X- _ O
a -X- _ O
shortcut -X- _ O
to -X- _ O
judge -X- _ O
news -X- _ O
authenticity -X- _ O
. -X- _ O
However -X- _ O
, -X- _ O
we -X- _ O
analyze -X- _ O
the -X- _ O
training -X- _ O
set -X- _ O
and -X- _ O
testing -X- _ O
set -X- _ O
, -X- _ O
and -X- _ O
find -X- _ O
that -X- _ O
there -X- _ O
exist -X- _ O
significant -X- _ O
differences -X- _ O
in -X- _ O
the -X- _ O
frequency -X- _ O
of -X- _ O
these -X- _ O
psycholinguistic -X- _ O
words -X- _ O
. -X- _ O
The -X- _ O
manifest -X- _ O
differences -X- _ O
between -X- _ O
the -X- _ O
training -X- _ O
set -X- _ O
and -X- _ O
testing -X- _ O
set -X- _ O
have -X- _ O
proven -X- _ O
that -X- _ O
this -X- _ O
shortcut -X- _ O
appears -X- _ O
to -X- _ O
be -X- _ O
unreliable -X- _ O
evidence -X- _ O
. -X- _ O
As -X- _ O
shown -X- _ O
in -X- _ O
Figure -X- _ O
2 -X- _ O
( -X- _ O
b -X- _ O
) -X- _ O
where -X- _ O
U -X- _ O
denotes -X- _ O
the -X- _ O
confounder -X- _ O
( -X- _ O
i.e. -X- _ O
the -X- _ O
psycholinguistic -X- _ O
features -X- _ O
in -X- _ O
the -X- _ O
text -X- _ O
) -X- _ O
, -X- _ O
there -X- _ O
exist -X- _ O
a -X- _ O
backdoor -X- _ O
path -X- _ O
T -X- _ O
← -X- _ O
U -X- _ O
→ -X- _ O
Y -X- _ O
which -X- _ O
will -X- _ O
introduce -X- _ O
spurious -X- _ O
correlations -X- _ O
among -X- _ O
the -X- _ O
text -X- _ O
features -X- _ O
and -X- _ O
news -X- _ O
label -X- _ O
. -X- _ O
In -X- _ O
order -X- _ O
to -X- _ O
remove -X- _ O
the -X- _ O
psycholinguistic -X- _ O
bias -X- _ O
, -X- _ O
we -X- _ O
apply -X- _ O
causal -X- _ O
intervention -X- _ O
by -X- _ O
adopting -X- _ O
the -X- _ O
backdoor -X- _ O
adjustment -X- _ O
( -X- _ O
Glymour -X- _ O
et -X- _ O
al -X- _ O
. -X- _ O
, -X- _ O
2016 -X- _ O
) -X- _ O
with -X- _ O
do -X- _ O
- -X- _ O
calculus -X- _ O
P -X- _ O
( -X- _ O
Y -X- _ O
|do -X- _ O
( -X- _ O
T -X- _ O
) -X- _ O
) -X- _ O
to -X- _ O
calculate -X- _ O
the -X- _ O
causal -X- _ O
effect -X- _ O
in -X- _ O
the -X- _ O
training -X- _ O
stage -X- _ O
, -X- _ O
which -X- _ O
is -X- _ O
fundamentally -X- _ O
different -X- _ O
from -X- _ O
the -X- _ O
conventional -X- _ O
likelihood -X- _ O
P -X- _ O
( -X- _ O
Y -X- _ O
|T -X- _ O
) -X- _ O
. -X- _ O

We -X- _ O
instantiate -X- _ O
our -X- _ O
proposed -X- _ O
debiasing -X- _ O
framework -X- _ O
on -X- _ O
three -X- _ O
strong -X- _ O
baseline -X- _ O
models -X- _ O
that -X- _ O
can -X- _ O
handle -X- _ O
both -X- _ O
text -X- _ O
and -X- _ O
image -X- _ O
features -X- _ O
as -X- _ O
inputs -X- _ O
. -X- _ O
Extensive -X- _ O
experiments -X- _ O
on -X- _ O
two -X- _ O
widely -X- _ O
used -X- _ O
real -X- _ O
- -X- _ O
world -X- _ O
benchmark -X- _ O
datasets -X- _ O
show -X- _ O
the -X- _ O
effectiveness -X- _ O
of -X- _ O
our -X- _ O
framework -X- _ O
. -X- _ O
Overall -X- _ O
, -X- _ O
our -X- _ O
contributions -X- _ O
can -X- _ O
be -X- _ O
summarized -X- _ O
as -X- _ O
follows -X- _ O
: -X- _ O

• -X- _ O
We -X- _ O
analyze -X- _ O
each -X- _ O
modality -X- _ O
of -X- _ O
fake -X- _ O
news -X- _ O
detection -X- _ O
data -X- _ O
and -X- _ O
identify -X- _ O
the -X- _ O
underlying -X- _ O
psycholinguistic -X- _ O
bias -X- _ O
in -X- _ O
the -X- _ O
text -X- _ O
and -X- _ O
the -X- _ O
image -X- _ O
- -X- _ O
only -X- _ O
bias -X- _ O
. -X- _ O

And -X- _ O
we -X- _ O
propose -X- _ O
a -X- _ O
novel -X- _ O
Causal -X- _ B-MethodName
intervention -X- _ I-MethodName
and -X- _ I-MethodName
Counterfactual -X- _ I-MethodName
reasoning -X- _ I-MethodName
based -X- _ I-MethodName
Debiasing -X- _ I-MethodName
framework -X- _ O
( -X- _ O
CCD -X- _ B-MethodName
) -X- _ O
for -X- _ O
multi -X- _ B-TaskName
- -X- _ I-TaskName
modal -X- _ I-TaskName
fake -X- _ I-TaskName
news -X- _ I-TaskName
detection -X- _ I-TaskName
. -X- _ O

• -X- _ O
In -X- _ O
our -X- _ O
debiasing -X- _ O
framework -X- _ O
CCD -X- _ B-MethodName
, -X- _ O
we -X- _ O
conduct -X- _ O
causal -X- _ O
interventions -X- _ O
via -X- _ O
backdoor -X- _ O
adjustment -X- _ O
to -X- _ O
remove -X- _ O
spurious -X- _ O
correlations -X- _ O
introduced -X- _ O
by -X- _ O
the -X- _ O
psycholinguistic -X- _ O
confounder -X- _ O
. -X- _ O
For -X- _ O
addressing -X- _ O
the -X- _ O
image -X- _ O
- -X- _ O
only -X- _ O
bias -X- _ O
, -X- _ O
we -X- _ O
apply -X- _ O
counterfactual -X- _ O
reasoning -X- _ O
to -X- _ O
pursue -X- _ O
the -X- _ O
indirect -X- _ O
causal -X- _ O
effect -X- _ O
as -X- _ O
the -X- _ O
inference -X- _ O
prediction -X- _ O
. -X- _ O

• -X- _ O
Our -X- _ O
causal -X- _ O
framework -X- _ O
CCD -X- _ B-MethodName
can -X- _ O
be -X- _ O
applied -X- _ O
to -X- _ O
any -X- _ O
fake -X- _ B-TaskName
news -X- _ I-TaskName
detection -X- _ I-TaskName
model -X- _ I-TaskName
with -X- _ O
image -X- _ O
and -X- _ O
text -X- _ O
features -X- _ O
as -X- _ O
inputs -X- _ O
. -X- _ O
We -X- _ O
implement -X- _ O
the -X- _ O
proposed -X- _ O
framework -X- _ O
on -X- _ O
three -X- _ O
strong -X- _ O
baseline -X- _ O
models -X- _ O
, -X- _ O
and -X- _ O
conduct -X- _ O
extensive -X- _ O
experiments -X- _ O
on -X- _ O
two -X- _ O
widely -X- _ O
used -X- _ O
benchmark -X- _ O
datasets -X- _ O
, -X- _ O
validating -X- _ O
the -X- _ O
effectiveness -X- _ O
of -X- _ O
CCD -X- _ B-MethodName
. -X- _ O

Preliminaries -X- _ O

Causal -X- _ O
Graph -X- _ O

The -X- _ O
causal -X- _ O
graph -X- _ O
( -X- _ O
Glymour -X- _ O
et -X- _ O
al -X- _ O
. -X- _ O
, -X- _ O
2016 -X- _ O
) -X- _ O
is -X- _ O
a -X- _ O
probabilistic -X- _ O
graphical -X- _ O
model -X- _ O
used -X- _ O
to -X- _ O
describe -X- _ O
how -X- _ O
variables -X- _ O
interact -X- _ O
with -X- _ O
each -X- _ O
other -X- _ O
, -X- _ O
expressed -X- _ O
by -X- _ O
a -X- _ O
directed -X- _ O
acyclic -X- _ O
graph -X- _ O
G -X- _ O
= -X- _ O
{ -X- _ O
N -X- _ O
, -X- _ O
E -X- _ O
} -X- _ O
consisting -X- _ O
of -X- _ O
the -X- _ O
sets -X- _ O
of -X- _ O
variables -X- _ O
N -X- _ O
and -X- _ O
the -X- _ O
causal -X- _ O
correlations -X- _ O
E -X- _ O
between -X- _ O
two -X- _ O
nodes -X- _ O
. -X- _ O
As -X- _ O
shown -X- _ O
in -X- _ O
Figure -X- _ O
3 -X- _ O
, -X- _ O
X -X- _ O
→ -X- _ O
Y -X- _ O
denotes -X- _ O
that -X- _ O
X -X- _ O
is -X- _ O
the -X- _ O
cause -X- _ O
of -X- _ O
the -X- _ O
effect -X- _ O
Y -X- _ O
. -X- _ O
U -X- _ O
is -X- _ O
the -X- _ O
confounder -X- _ O
. -X- _ O

In -X- _ O
this -X- _ O
section -X- _ O
, -X- _ O
we -X- _ O
first -X- _ O
formulate -X- _ O
the -X- _ O
fake -X- _ B-TaskName
news -X- _ I-TaskName
detection -X- _ I-TaskName
task -X- _ O
as -X- _ O
a -X- _ O
causal -X- _ O
graph -X- _ O
to -X- _ O
clearly -X- _ O
depict -X- _ O
the -X- _ O
causal -X- _ O
effect -X- _ O
between -X- _ O
factors -X- _ O
. -X- _ O
And -X- _ O
then -X- _ O
we -X- _ O
present -X- _ O
our -X- _ O
CCD -X- _ B-MethodName
framework -X- _ O
that -X- _ O
removes -X- _ O
the -X- _ O
psycholinguistic -X- _ O
bias -X- _ O
by -X- _ O
means -X- _ O
of -X- _ O
causal -X- _ O
intervention -X- _ O
, -X- _ O
as -X- _ O
well -X- _ O
as -X- _ O
deducts -X- _ O
the -X- _ O
direct -X- _ O
causal -X- _ O
effect -X- _ O
of -X- _ O
image -X- _ O
features -X- _ O
( -X- _ O
i.e. -X- _ O
the -X- _ O
image -X- _ O
- -X- _ O
only -X- _ O
bias -X- _ O
) -X- _ O
via -X- _ O
counterfactual -X- _ O
reasoning -X- _ O
. -X- _ O

As -X- _ O
aforementioned -X- _ O
, -X- _ O
Figure -X- _ O
2 -X- _ O
( -X- _ O
a -X- _ O
) -X- _ O
depicts -X- _ O
the -X- _ O
causal -X- _ O
graph -X- _ O
of -X- _ O
the -X- _ O
fake -X- _ O
news -X- _ O
detection -X- _ O
process -X- _ O
. -X- _ O
Nodes -X- _ O
T -X- _ O
, -X- _ O
I -X- _ O
, -X- _ O
and -X- _ O
C -X- _ O
represent -X- _ O
the -X- _ O
text -X- _ O
features -X- _ O
, -X- _ O
image -X- _ O
features -X- _ O
, -X- _ O
and -X- _ O
fused -X- _ O
multi -X- _ O
- -X- _ O
modal -X- _ O
features -X- _ O
, -X- _ O
respectively -X- _ O
. -X- _ O
According -X- _ O
to -X- _ O
the -X- _ O
proposed -X- _ O
causal -X- _ O
graph -X- _ O
, -X- _ O
the -X- _ O
final -X- _ O
prediction -X- _ O
Y -X- _ O
takes -X- _ O
inputs -X- _ O
from -X- _ O
the -X- _ O
three -X- _ O
branches -X- _ O
: -X- _ O
the -X- _ O
direct -X- _ O
effect -X- _ O
of -X- _ O
the -X- _ O
input -X- _ O
T -X- _ O
and -X- _ O
I -X- _ O
on -X- _ O
Y -X- _ O
via -X- _ O
T -X- _ O
→ -X- _ O
Y -X- _ O
and -X- _ O
I -X- _ O
→ -X- _ O
Y -X- _ O
, -X- _ O
as -X- _ O
well -X- _ O
as -X- _ O
the -X- _ O
indirect -X- _ O
effect -X- _ O
of -X- _ O
the -X- _ O
input -X- _ O
T -X- _ O
and -X- _ O
I -X- _ O
on -X- _ O
Y -X- _ O
via -X- _ O
the -X- _ O
fused -X- _ O
features -X- _ O
C -X- _ O
, -X- _ O
i.e. -X- _ O
T -X- _ O
( -X- _ O
I -X- _ O
) -X- _ O
→ -X- _ O
C -X- _ O
→ -X- _ O
Y -X- _ O
. -X- _ O
Each -X- _ O
branch -X- _ O
of -X- _ O
Figure -X- _ O
2 -X- _ O
( -X- _ O
a -X- _ O
) -X- _ O
can -X- _ O
be -X- _ O
implemented -X- _ O
via -X- _ O
a -X- _ O
base -X- _ O
fake -X- _ B-TaskName
news -X- _ I-TaskName
detection -X- _ I-TaskName
model -X- _ O
( -X- _ O
Figure -X- _ O
5 -X- _ O
) -X- _ O
. -X- _ O
Formally -X- _ O
, -X- _ O
the -X- _ O
abstract -X- _ O
format -X- _ O
of -X- _ O
the -X- _ O
model -X- _ O
should -X- _ O
be -X- _ O
: -X- _ O

where -X- _ O
c -X- _ O
= -X- _ O
f -X- _ O
( -X- _ O
T -X- _ O
= -X- _ O
t -X- _ O
, -X- _ O
I -X- _ O
= -X- _ O
i -X- _ O
) -X- _ O
, -X- _ O
f -X- _ O
( -X- _ O
• -X- _ O
) -X- _ O
is -X- _ O
the -X- _ O
feature -X- _ O
aggregation -X- _ O
function -X- _ O
in -X- _ O
baseline -X- _ O
fake -X- _ B-TaskName
news -X- _ I-TaskName
detection -X- _ I-TaskName
models -X- _ O
. -X- _ O
Then -X- _ O
the -X- _ O
total -X- _ O
effect -X- _ O
( -X- _ O
TE -X- _ O
) -X- _ O
of -X- _ O
the -X- _ O
input -X- _ O
on -X- _ O
label -X- _ O
y -X- _ O
can -X- _ O
be -X- _ O
written -X- _ O
as -X- _ O
: -X- _ O

where -X- _ O
Y -X- _ O
t -X- _ O
is -X- _ O
the -X- _ O
output -X- _ O
of -X- _ O
the -X- _ O
text -X- _ O
- -X- _ O
only -X- _ O
branch -X- _ O
( -X- _ O
i.e. -X- _ O
T -X- _ O
→ -X- _ O
Y -X- _ O
) -X- _ O
, -X- _ O
Y -X- _ O
i -X- _ O
is -X- _ O
the -X- _ O
output -X- _ O
of -X- _ O
the -X- _ O
image -X- _ O
- -X- _ O
only -X- _ O
branch -X- _ O
( -X- _ O
i.e. -X- _ O
I -X- _ O
→ -X- _ O
Y -X- _ O
) -X- _ O
, -X- _ O
and -X- _ O
Y -X- _ O
c -X- _ O
= -X- _ O
Y -X- _ O
t -X- _ O
, -X- _ O
i -X- _ O
is -X- _ O
the -X- _ O
output -X- _ O
of -X- _ O
fused -X- _ O
features -X- _ O
branch -X- _ O
( -X- _ O
i.e. -X- _ O
C -X- _ O
→ -X- _ O
Y -X- _ O
) -X- _ O
as -X- _ O
shown -X- _ O
in -X- _ O
Figure -X- _ O
5 -X- _ O
. -X- _ O
F -X- _ O
( -X- _ O
• -X- _ O
) -X- _ O
is -X- _ O
the -X- _ O
fusion -X- _ O
function -X- _ O
to -X- _ O
obtain -X- _ O
the -X- _ O
final -X- _ O
prediction -X- _ O
. -X- _ O
We -X- _ O
adopt -X- _ O
a -X- _ O
non -X- _ O
- -X- _ O
linear -X- _ O
fusion -X- _ O
strategy -X- _ O
for -X- _ O
its -X- _ O
better -X- _ O
representation -X- _ O
capacity -X- _ O
. -X- _ O
Any -X- _ O
differentiable -X- _ O
arithmetic -X- _ O
binary -X- _ O
operations -X- _ O
can -X- _ O
be -X- _ O
employed -X- _ O
as -X- _ O
the -X- _ O
fusion -X- _ O
function -X- _ O
F -X- _ O
( -X- _ O
• -X- _ O
) -X- _ O
and -X- _ O
we -X- _ O
examine -X- _ O
several -X- _ O
fusion -X- _ O
alternatives -X- _ O
in -X- _ O
Table -X- _ O
4 -X- _ O
. -X- _ O

Next -X- _ O
, -X- _ O
we -X- _ O
conduct -X- _ O
deconfounded -X- _ O
training -X- _ O
in -X- _ O
T -X- _ O
→ -X- _ O
Y -X- _ O
branch -X- _ O
which -X- _ O
exploits -X- _ O
the -X- _ O
backdoor -X- _ O
adjustments -X- _ O
( -X- _ O
Glymour -X- _ O
et -X- _ O
al -X- _ O
. -X- _ O
, -X- _ O
2016 -X- _ O
) -X- _ O
with -X- _ O
do -X- _ O
- -X- _ O
calculus -X- _ O
on -X- _ O
T -X- _ O
to -X- _ O
calculate -X- _ O
the -X- _ O
corresponding -X- _ O
intervention -X- _ O
distribution -X- _ O
. -X- _ O
Since -X- _ O
the -X- _ O
edge -X- _ O
U -X- _ O
→ -X- _ O
T -X- _ O
has -X- _ O
been -X- _ O
cut -X- _ O
off -X- _ O
, -X- _ O
we -X- _ O
can -X- _ O
have -X- _ O
: -X- _ O

To -X- _ O
estimate -X- _ O
Y -X- _ O
t -X- _ O
, -X- _ O
given -X- _ O
the -X- _ O
text -X- _ O
features -X- _ O
T -X- _ O
's -X- _ O
representations -X- _ O
t -X- _ O
and -X- _ O
the -X- _ O
confounder -X- _ O
U -X- _ O
's -X- _ O
representations -X- _ O
u -X- _ O
, -X- _ O
Equation -X- _ O
( -X- _ O
9 -X- _ O
) -X- _ O
is -X- _ O
implemented -X- _ O
as -X- _ O
u -X- _ O
P -X- _ O
( -X- _ O
y|t -X- _ O
, -X- _ O
u -X- _ O
) -X- _ O
P -X- _ O
( -X- _ O
u -X- _ O
) -X- _ O
, -X- _ O
where -X- _ O
P -X- _ O
( -X- _ O
y|t -X- _ O
, -X- _ O
u -X- _ O
) -X- _ O
is -X- _ O
the -X- _ O
prediction -X- _ O
upon -X- _ O
a -X- _ O
news -X- _ O
feature -X- _ O
learning -X- _ O
model -X- _ O
g -X- _ O
( -X- _ O
• -X- _ O
) -X- _ O
: -X- _ O

Furthermore -X- _ O
, -X- _ O
the -X- _ O
removal -X- _ O
of -X- _ O
the -X- _ O
bias -X- _ O
can -X- _ O
be -X- _ O
realized -X- _ O
by -X- _ O
subtracting -X- _ O
NDE -X- _ O
from -X- _ O
the -X- _ O
total -X- _ O
effect -X- _ O
TE -X- _ O
: -X- _ O

In -X- _ O
this -X- _ O
section -X- _ O
, -X- _ O
we -X- _ O
apply -X- _ O
our -X- _ O
CCD -X- _ B-MethodName
framework -X- _ O
on -X- _ O
three -X- _ O
strong -X- _ O
baseline -X- _ O
multi -X- _ B-TaskName
- -X- _ I-TaskName
modal -X- _ I-TaskName
fake -X- _ I-TaskName
news -X- _ I-TaskName
detection -X- _ I-TaskName
models -X- _ O
on -X- _ O
two -X- _ O
real -X- _ O
- -X- _ O
world -X- _ O
datasets -X- _ O
to -X- _ O
evaluate -X- _ O
the -X- _ O
effectiveness -X- _ O
of -X- _ O
our -X- _ O
proposed -X- _ O
CCD -X- _ B-MethodName
framework -X- _ O
. -X- _ O

Experimental -X- _ O
Settings -X- _ O

We -X- _ O
conducted -X- _ O
experiments -X- _ O
on -X- _ O
two -X- _ O
datasets -X- _ O
: -X- _ O
Twitter -X- _ B-DatasetName
: -X- _ O
This -X- _ O
dataset -X- _ O
was -X- _ O
released -X- _ O
for -X- _ O
Verifying -X- _ O
Multimedia -X- _ O
Use -X- _ O
task -X- _ O
at -X- _ O
MediaEval -X- _ O
1 -X- _ O
. -X- _ O
It -X- _ O
consists -X- _ O
of -X- _ O
tweets -X- _ O
with -X- _ O
textual -X- _ O
, -X- _ O
visual -X- _ O
, -X- _ O
and -X- _ O
social -X- _ O
context -X- _ O
information -X- _ O
. -X- _ O
Since -X- _ O
our -X- _ O
framework -X- _ O
belongs -X- _ O
to -X- _ O
contentbased -X- _ O
methods -X- _ O
, -X- _ O
we -X- _ O
only -X- _ O
leverage -X- _ O
textual -X- _ O
and -X- _ O
visual -X- _ O
information -X- _ O
. -X- _ O
Pheme -X- _ B-DatasetName
: -X- _ O
This -X- _ O
dataset -X- _ O
was -X- _ O
generated -X- _ O
as -X- _ O
part -X- _ O
of -X- _ O
the -X- _ O
Pheme -X- _ O
project -X- _ O
, -X- _ O
which -X- _ O
attempts -X- _ O
to -X- _ O
detect -X- _ O
and -X- _ O
verify -X- _ O
rumors -X- _ O
spread -X- _ O
via -X- _ O
social -X- _ O
media -X- _ O
. -X- _ O
It -X- _ O
is -X- _ O
based -X- _ O
on -X- _ O
five -X- _ O
breaking -X- _ O
news -X- _ O
stories -X- _ O
, -X- _ O
each -X- _ O
of -X- _ O
which -X- _ O
comprises -X- _ O
a -X- _ O
series -X- _ O
of -X- _ O
statements -X- _ O
categorized -X- _ O
as -X- _ O
rumor -X- _ O
or -X- _ O
nonrumor -X- _ O
. -X- _ O
We -X- _ O
classified -X- _ O
rumors -X- _ O
as -X- _ O
fake -X- _ O
news -X- _ O
and -X- _ O
nonrumors -X- _ O
as -X- _ O
real -X- _ O
news -X- _ O
in -X- _ O
our -X- _ O
framework -X- _ O
. -X- _ O

The -X- _ O
CCD -X- _ B-MethodName
framework -X- _ O
can -X- _ O
be -X- _ O
applied -X- _ O
to -X- _ O
any -X- _ O
multimodal -X- _ B-TaskName
fake -X- _ I-TaskName
news -X- _ I-TaskName
detection -X- _ I-TaskName
method -X- _ O
with -X- _ O
text -X- _ O
and -X- _ O
image -X- _ O
as -X- _ O
input -X- _ O
. -X- _ O
Here -X- _ O
, -X- _ O
we -X- _ O
apply -X- _ O
our -X- _ O
framework -X- _ O
to -X- _ O
the -X- _ O
following -X- _ O
strong -X- _ O
baselines -X- _ O
: -X- _ O
1 -X- _ O
) -X- _ O
SpotFake+ -X- _ B-MethodName
( -X- _ O
Singhal -X- _ O
et -X- _ O
al -X- _ O
. -X- _ O
, -X- _ O
2020 -X- _ O
) -X- _ O
: -X- _ O
SpotFake+ -X- _ B-MethodName
concatenates -X- _ O
the -X- _ O
features -X- _ O
extracted -X- _ O
from -X- _ O
different -X- _ O
modalities -X- _ O
and -X- _ O
performs -X- _ O
multiple -X- _ O
feature -X- _ O
transformations -X- _ O
to -X- _ O
facilitate -X- _ O
multi -X- _ O
- -X- _ O
modal -X- _ O
fusion -X- _ O
. -X- _ O
2 -X- _ O
) -X- _ O
MCAN -X- _ B-MethodName
( -X- _ O
Wu -X- _ O
et -X- _ O
al -X- _ O
. -X- _ O
, -X- _ O
2021 -X- _ O
) -X- _ O
: -X- _ O
MCAN -X- _ B-MethodName
stacks -X- _ O
multiple -X- _ O
co -X- _ O
- -X- _ O
attention -X- _ O
layers -X- _ O
to -X- _ O
learn -X- _ O
dependencies -X- _ O
across -X- _ O
the -X- _ O
modalities -X- _ O
. -X- _ O
They -X- _ O
repeatedly -X- _ O
fuse -X- _ O
the -X- _ O
two -X- _ O
modalities -X- _ O
to -X- _ O
simulate -X- _ O
people -X- _ O
's -X- _ O
reading -X- _ O
process -X- _ O
. -X- _ O
3 -X- _ O
) -X- _ O
HMCAN -X- _ B-MethodName
( -X- _ O
Qian -X- _ O
et -X- _ O
al -X- _ O
. -X- _ O
, -X- _ O
2021b -X- _ O
) -X- _ O
: -X- _ O
HMCAN -X- _ B-MethodName
uses -X- _ O
a -X- _ O
hierarchical -X- _ O
multi -X- _ O
- -X- _ O
modal -X- _ O
contextual -X- _ O
attention -X- _ O
model -X- _ O
that -X- _ O
considers -X- _ O
both -X- _ O
the -X- _ O
text -X- _ O
's -X- _ O
hierarchical -X- _ O
semantics -X- _ O
and -X- _ O
multi -X- _ O
- -X- _ O
modal -X- _ O
contextual -X- _ O
data -X- _ O
. -X- _ O

We -X- _ O
use -X- _ O
the -X- _ O
Accuracy -X- _ B-MethodName
as -X- _ O
the -X- _ O
evaluation -X- _ O
metric -X- _ O
for -X- _ O
binary -X- _ O
classification -X- _ O
tasks -X- _ O
such -X- _ O
as -X- _ O
fake -X- _ B-TaskName
news -X- _ I-TaskName
detection -X- _ I-TaskName
. -X- _ O
In -X- _ O
consideration -X- _ O
of -X- _ O
the -X- _ O
imbalance -X- _ O
label -X- _ O
distributions -X- _ O
, -X- _ O
in -X- _ O
addition -X- _ O
to -X- _ O
the -X- _ O
accuracy -X- _ B-MethodName
metric -X- _ O
, -X- _ O
we -X- _ O
add -X- _ O
Precision -X- _ B-MethodName
, -X- _ O
Recall -X- _ B-MethodName
, -X- _ O
and -X- _ O
F1 -X- _ B-MethodName
- -X- _ O
score -X- _ O
as -X- _ O
complementary -X- _ O
evaluation -X- _ O
metrics -X- _ O
following -X- _ O
previous -X- _ O
works -X- _ O
( -X- _ O
Wu -X- _ O
et -X- _ O
al -X- _ O
. -X- _ O
, -X- _ O
2021 -X- _ O
; -X- _ O
Qian -X- _ O
et -X- _ O
al -X- _ O
. -X- _ O
, -X- _ O
2021b -X- _ O
) -X- _ O
. -X- _ O

Table -X- _ O
2 -X- _ O
displays -X- _ O
the -X- _ O
experimental -X- _ O
results -X- _ O
of -X- _ O
our -X- _ O
proposed -X- _ O
framework -X- _ O
CCD -X- _ B-MethodName
applied -X- _ O
to -X- _ O
the -X- _ O
baseline -X- _ O
methods -X- _ O
on -X- _ O
two -X- _ O
benchmark -X- _ O
datasets -X- _ O
. -X- _ O
The -X- _ O
results -X- _ O
of -X- _ O
the -X- _ O
baselines -X- _ O
are -X- _ O
the -X- _ O
results -X- _ O
of -X- _ O
our -X- _ O
reproductions -X- _ O
on -X- _ O
our -X- _ O
data -X- _ O
settings -X- _ O
based -X- _ O
on -X- _ O
their -X- _ O
public -X- _ O
code -X- _ O
2 -X- _ O
. -X- _ O
From -X- _ O
Table -X- _ O
2 -X- _ O
, -X- _ O
we -X- _ O
can -X- _ O
obtain -X- _ O
the -X- _ O
following -X- _ O
observations -X- _ O
: -X- _ O

Compared -X- _ O
with -X- _ O
each -X- _ O
base -X- _ O
fake -X- _ O
news -X- _ O
detection -X- _ O
model -X- _ O
( -X- _ O
i.e. -X- _ O
SpotFake+ -X- _ B-MethodName
, -X- _ O
MCAN -X- _ B-MethodName
, -X- _ O
HMCAN -X- _ B-MethodName
) -X- _ O
, -X- _ O
the -X- _ O
accuracy -X- _ B-MetricName
of -X- _ O
the -X- _ O
models -X- _ O
that -X- _ O
apply -X- _ O
the -X- _ O
proposed -X- _ O
CCD -X- _ B-MethodName
framework -X- _ O
( -X- _ O
i.e. -X- _ O
, -X- _ O
w -X- _ O
/ -X- _ O
CCD -X- _ B-MethodName
) -X- _ O
has -X- _ O
been -X- _ O
significantly -X- _ O
improved -X- _ O
by -X- _ O
around -X- _ O
7.7 -X- _ B-MetricValue
% -X- _ I-MetricValue
, -X- _ O
3.3 -X- _ B-MetricValue
% -X- _ I-MetricValue
, -X- _ O
and -X- _ O
5.2 -X- _ B-MetricValue
% -X- _ I-MetricValue
on -X- _ O
the -X- _ O
Twitter -X- _ B-DatasetName
dataset -X- _ O
, -X- _ O
and -X- _ O
improved -X- _ O
by -X- _ O
around -X- _ O
1.0 -X- _ B-MetricValue
% -X- _ I-MetricValue
, -X- _ O
0.6 -X- _ B-MetricValue
% -X- _ I-MetricValue
, -X- _ O
and -X- _ O
1.3 -X- _ B-MetricValue
% -X- _ I-MetricValue
on -X- _ O
the -X- _ O
Pheme -X- _ B-DatasetName
dataset -X- _ O
. -X- _ O
With -X- _ O
the -X- _ O
help -X- _ O
of -X- _ O
the -X- _ O
proposed -X- _ O
framework -X- _ O
, -X- _ O
all -X- _ O
of -X- _ O
the -X- _ O
base -X- _ O
models -X- _ O
show -X- _ O
significant -X- _ O
improvements -X- _ O
on -X- _ O
most -X- _ O
metrics -X- _ O
, -X- _ O
which -X- _ O
demonstrates -X- _ O
the -X- _ O
effectiveness -X- _ O
of -X- _ O
the -X- _ O
proposed -X- _ O
framework -X- _ O
. -X- _ O
We -X- _ O
believe -X- _ O
that -X- _ O
CCD -X- _ B-MethodName
benefits -X- _ O
from -X- _ O
the -X- _ O
removal -X- _ O
of -X- _ O
psycholinguistic -X- _ O
bias -X- _ O
with -X- _ O
causal -X- _ O
intervention -X- _ O
as -X- _ O
well -X- _ O
as -X- _ O
the -X- _ O
mitigation -X- _ O
of -X- _ O
the -X- _ O
image -X- _ O
- -X- _ O
only -X- _ O
bias -X- _ O
via -X- _ O
counterfactual -X- _ O
reasoning -X- _ O
. -X- _ O

The -X- _ O
performance -X- _ O
improvements -X- _ O
on -X- _ O
the -X- _ O
Twitter -X- _ B-DatasetName
dataset -X- _ O
are -X- _ O
larger -X- _ O
than -X- _ O
that -X- _ O
on -X- _ O
the -X- _ O
Pheme -X- _ B-DatasetName
dataset -X- _ O
. -X- _ O
We -X- _ O
attribute -X- _ O
such -X- _ O
a -X- _ O
difference -X- _ O
between -X- _ O
the -X- _ O
two -X- _ O
datasets -X- _ O
to -X- _ O
the -X- _ O
following -X- _ O
two -X- _ O
reasons -X- _ O
: -X- _ O
1 -X- _ O
) -X- _ O
The -X- _ O
proportion -X- _ O
of -X- _ O
psycholinguistic -X- _ O
vocabulary -X- _ O
in -X- _ O
the -X- _ O
Twitter -X- _ B-DatasetName
dataset -X- _ O
( -X- _ O
19.87 -X- _ O
% -X- _ O
) -X- _ O
is -X- _ O
higher -X- _ O
than -X- _ O
that -X- _ O
in -X- _ O
the -X- _ O
Pheme -X- _ B-DatasetName
dataset -X- _ O
( -X- _ O
16.19 -X- _ O
% -X- _ O
) -X- _ O
, -X- _ O
so -X- _ O
the -X- _ O
Twitter -X- _ B-DatasetName
dataset -X- _ O
could -X- _ O
be -X- _ O
more -X- _ O
susceptible -X- _ O
to -X- _ O
psycholinguistic -X- _ O
bias -X- _ O
. -X- _ O

2 -X- _ O
) -X- _ O
According -X- _ O
to -X- _ O
Table -X- _ O
1 -X- _ O
, -X- _ O
the -X- _ O
number -X- _ O
of -X- _ O
unique -X- _ O
images -X- _ O
in -X- _ O
the -X- _ O
Twitter -X- _ B-DatasetName
dataset -X- _ O
is -X- _ O
far -X- _ O
less -X- _ O
than -X- _ O
the -X- _ O
number -X- _ O
of -X- _ O
news -X- _ O
texts -X- _ O
, -X- _ O
which -X- _ O
means -X- _ O
that -X- _ O
there -X- _ O
's -X- _ O
a -X- _ O
serious -X- _ O
problem -X- _ O
of -X- _ O
different -X- _ O
texts -X- _ O
sharing -X- _ O
the -X- _ O
same -X- _ O
image -X- _ O
. -X- _ O
So -X- _ O
the -X- _ O
influence -X- _ O
of -X- _ O
image -X- _ O
- -X- _ O
only -X- _ O
bias -X- _ O
in -X- _ O
the -X- _ O
Twitter -X- _ B-DatasetName
dataset -X- _ O
is -X- _ O
more -X- _ O
severe -X- _ O
than -X- _ O
that -X- _ O
of -X- _ O
the -X- _ O
Pheme -X- _ B-DatasetName
dataset -X- _ O
. -X- _ O

We -X- _ O
conduct -X- _ O
experiments -X- _ O
to -X- _ O
study -X- _ O
the -X- _ O
de -X- _ O
- -X- _ O
biasing -X- _ O
effect -X- _ O
of -X- _ O
each -X- _ O
module -X- _ O
in -X- _ O
CCD -X- _ B-MethodName
using -X- _ O
the -X- _ O
strong -X- _ O
baseline -X- _ O
HMCAN -X- _ B-MethodName
on -X- _ O
Twitter -X- _ B-DatasetName
and -X- _ O
Pheme -X- _ B-DatasetName
testing -X- _ O
We -X- _ O
can -X- _ O
observe -X- _ O
that -X- _ O
if -X- _ O
we -X- _ O
remove -X- _ O
the -X- _ O
causal -X- _ O
intervention -X- _ O
part -X- _ O
, -X- _ O
the -X- _ O
performance -X- _ O
respectively -X- _ O
drops -X- _ O
by -X- _ O
around -X- _ O
3.7 -X- _ B-MetricValue
% -X- _ I-MetricValue
and -X- _ O
0.8 -X- _ B-MetricValue
% -X- _ I-MetricValue
on -X- _ O
Twitter -X- _ B-DatasetName
and -X- _ O
Pheme -X- _ B-DatasetName
, -X- _ O
demonstrating -X- _ O
the -X- _ O
effectiveness -X- _ O
of -X- _ O
eliminating -X- _ O
the -X- _ O
psycholinguistic -X- _ O
bias -X- _ O
in -X- _ O
the -X- _ O
text -X- _ O
. -X- _ O
And -X- _ O
removing -X- _ O
the -X- _ O
counterfactual -X- _ O
reasoning -X- _ O
part -X- _ O
will -X- _ O
make -X- _ O
the -X- _ O
performance -X- _ O
respectively -X- _ O
decreases -X- _ O
by -X- _ O
around -X- _ O
2.2 -X- _ B-MetricValue
% -X- _ I-MetricValue
and -X- _ O
1.0 -X- _ B-MetricValue
% -X- _ I-MetricValue
on -X- _ O
Twitter -X- _ B-DatasetName
and -X- _ O
Pheme -X- _ B-DatasetName
, -X- _ O
proving -X- _ O
that -X- _ O
CCD -X- _ B-MethodName
can -X- _ O
effectively -X- _ O
mitigate -X- _ O
the -X- _ O
image -X- _ O
- -X- _ O
only -X- _ O
bias -X- _ O
in -X- _ O
the -X- _ O
inference -X- _ O
stage -X- _ O
. -X- _ O

We -X- _ O
provide -X- _ O
a -X- _ O
qualitative -X- _ O
analysis -X- _ O
of -X- _ O
the -X- _ O
proposed -X- _ O
CCD -X- _ B-MethodName
framework -X- _ O
by -X- _ O
examining -X- _ O
the -X- _ O
fake -X- _ O
and -X- _ O
real -X- _ O
news -X- _ O
samples -X- _ O
that -X- _ O
are -X- _ O
successfully -X- _ O
detected -X- _ O
by -X- _ O
HM -X- _ B-MethodName
- -X- _ I-MethodName
CAN -X- _ I-MethodName
w -X- _ O
/ -X- _ O
CCD -X- _ B-MethodName
on -X- _ O
Pheme -X- _ B-DatasetName
datasets -X- _ O
in -X- _ O
Figure -X- _ O
7 -X- _ O
. -X- _ O
The -X- _ O
psycholinguistic -X- _ O
words -X- _ O
are -X- _ O
highlighted -X- _ O
in -X- _ O
red -X- _ O
and -X- _ O
the -X- _ O
prediction -X- _ O
results -X- _ O
before -X- _ O
( -X- _ O
Before -X- _ O
) -X- _ O
and -X- _ O
after -X- _ O
( -X- _ O
Debiased -X- _ O
) -X- _ O
counterfactual -X- _ O
reasoning -X- _ O
are -X- _ O
shown -X- _ O
in -X- _ O
the -X- _ O
charts -X- _ O
. -X- _ O
As -X- _ O
we -X- _ O
can -X- _ O
see -X- _ O
, -X- _ O
the -X- _ O
texts -X- _ O
of -X- _ O
both -X- _ O
fake -X- _ O
and -X- _ O
real -X- _ O
news -X- _ O
contain -X- _ O
words -X- _ O
expressing -X- _ O
anger -X- _ O
and -X- _ O
negative -X- _ O
emotions -X- _ O
( -X- _ O
i.e. -X- _ O
, -X- _ O
" -X- _ O
killed -X- _ O
" -X- _ O
, -X- _ O
" -X- _ O
assault -X- _ O
" -X- _ O
, -X- _ O
" -X- _ O
murdered -X- _ O
" -X- _ O
and -X- _ O
" -X- _ O
attack -X- _ O
" -X- _ O
) -X- _ O
, -X- _ O
but -X- _ O
CCD -X- _ B-MethodName
can -X- _ O
make -X- _ O
correct -X- _ O
predictions -X- _ O
based -X- _ O
on -X- _ O
the -X- _ O
text -X- _ O
features -X- _ O
( -X- _ O
Text -X- _ O
) -X- _ O
after -X- _ O
causal -X- _ O
intervention -X- _ O
. -X- _ O
In -X- _ O
addition -X- _ O
, -X- _ O
after -X- _ O
conducting -X- _ O
counterfactual -X- _ O
reasoning -X- _ O
by -X- _ O
subtracting -X- _ O
the -X- _ O
direct -X- _ O
causal -X- _ O
effect -X- _ O
of -X- _ O
the -X- _ O
image -X- _ O
( -X- _ O
Image -X- _ O
) -X- _ O
, -X- _ O
the -X- _ O
CCD -X- _ B-MethodName
is -X- _ O
able -X- _ O
to -X- _ O
make -X- _ O
correct -X- _ O
predictions -X- _ O
based -X- _ O
on -X- _ O
the -X- _ O
debiased -X- _ O
results -X- _ O
. -X- _ O
The -X- _ O
two -X- _ O
cases -X- _ O
show -X- _ O
the -X- _ O
effectiveness -X- _ O
of -X- _ O
our -X- _ O
CCD -X- _ B-MethodName
framework -X- _ O
, -X- _ O
which -X- _ O
makes -X- _ O
debiased -X- _ O
predictions -X- _ O
by -X- _ O
removing -X- _ O
the -X- _ O
psycholinguistic -X- _ O
bias -X- _ O
in -X- _ O
the -X- _ O
text -X- _ O
and -X- _ O
image -X- _ O
- -X- _ O
only -X- _ O
bias -X- _ O
. -X- _ O

Related -X- _ O
Work -X- _ O

In -X- _ O
this -X- _ O
section -X- _ O
, -X- _ O
we -X- _ O
review -X- _ O
the -X- _ O
related -X- _ O
work -X- _ O
including -X- _ O
fake -X- _ B-TaskName
news -X- _ I-TaskName
detection -X- _ I-TaskName
and -X- _ O
causal -X- _ O
inference -X- _ O
. -X- _ O

Existing -X- _ O
fake -X- _ B-TaskName
news -X- _ I-TaskName
detection -X- _ I-TaskName
work -X- _ O
generally -X- _ O
falls -X- _ O
into -X- _ O
two -X- _ O
categories -X- _ O
: -X- _ O
content -X- _ O
- -X- _ O
based -X- _ O
methods -X- _ O
and -X- _ O
propagation -X- _ O
- -X- _ O
based -X- _ O
methods -X- _ O
. -X- _ O
The -X- _ O
multi -X- _ O
- -X- _ O
modal -X- _ O
approaches -X- _ O
fall -X- _ O
into -X- _ O
the -X- _ O
former -X- _ O
category -X- _ O
. -X- _ O
Most -X- _ O
works -X- _ O
on -X- _ O
multi -X- _ B-TaskName
- -X- _ I-TaskName
modal -X- _ I-TaskName
fake -X- _ I-TaskName
news -X- _ I-TaskName
detection -X- _ I-TaskName
exert -X- _ O
efforts -X- _ O
to -X- _ O
fully -X- _ O
incorporate -X- _ O
cross -X- _ O
- -X- _ O
modal -X- _ O
features -X- _ O
. -X- _ O
For -X- _ O
instance -X- _ O
, -X- _ O
Jin -X- _ O
et -X- _ O
al -X- _ O
. -X- _ O
( -X- _ O
2017 -X- _ O
) -X- _ O
proposed -X- _ O
a -X- _ O
recurrent -X- _ O
neural -X- _ O
network -X- _ O
with -X- _ O
an -X- _ O
attention -X- _ O
mechanism -X- _ O
to -X- _ O
fuse -X- _ O
the -X- _ O
text -X- _ O
, -X- _ O
social -X- _ O
context -X- _ O
, -X- _ O
and -X- _ O
image -X- _ O
features -X- _ O
. -X- _ O
Singhal -X- _ O
et -X- _ O
al -X- _ O
. -X- _ O
( -X- _ O
2020 -X- _ O
) -X- _ O
utilized -X- _ O
pre -X- _ O
- -X- _ O
trained -X- _ O
encoders -X- _ O
and -X- _ O
applied -X- _ O
multiple -X- _ O
- -X- _ O
layer -X- _ O
feature -X- _ O
transformation -X- _ O
to -X- _ O
achieve -X- _ O
deep -X- _ O
fusion -X- _ O
. -X- _ O
Chen -X- _ O
et -X- _ O
al -X- _ O
. -X- _ O
( -X- _ O
2022b -X- _ O
) -X- _ O
calculated -X- _ O
the -X- _ O
ambiguity -X- _ O
score -X- _ O
of -X- _ O
different -X- _ O
modalities -X- _ O
to -X- _ O
control -X- _ O
the -X- _ O
contribution -X- _ O
of -X- _ O
mono -X- _ O
- -X- _ O
modal -X- _ O
features -X- _ O
and -X- _ O
inter -X- _ O
- -X- _ O
modal -X- _ O
correlations -X- _ O
to -X- _ O
the -X- _ O
final -X- _ O
prediction -X- _ O
. -X- _ O
To -X- _ O
capture -X- _ O
fine -X- _ O
- -X- _ O
grained -X- _ O
cross -X- _ O
- -X- _ O
modal -X- _ O
correlations -X- _ O
, -X- _ O
Wu -X- _ O
et -X- _ O
al -X- _ O
. -X- _ O
( -X- _ O
2021 -X- _ O
) -X- _ O
employed -X- _ O
multiple -X- _ O
rounds -X- _ O
of -X- _ O
co -X- _ O
- -X- _ O
attention -X- _ O
mechanism -X- _ O
to -X- _ O
model -X- _ O
the -X- _ O
cross -X- _ O
- -X- _ O
modal -X- _ O
interactions -X- _ O
. -X- _ O
Qian -X- _ O
et -X- _ O
al -X- _ O
. -X- _ O
( -X- _ O
2021b -X- _ O
) -X- _ O
lever -X- _ O
- -X- _ O
aged -X- _ O
a -X- _ O
contextual -X- _ O
attention -X- _ O
network -X- _ O
to -X- _ O
model -X- _ O
both -X- _ O
the -X- _ O
intra -X- _ O
- -X- _ O
and -X- _ O
inter -X- _ O
- -X- _ O
modality -X- _ O
information -X- _ O
, -X- _ O
and -X- _ O
captured -X- _ O
the -X- _ O
hierarchical -X- _ O
semantic -X- _ O
information -X- _ O
of -X- _ O
the -X- _ O
text -X- _ O
. -X- _ O
There -X- _ O
are -X- _ O
also -X- _ O
methods -X- _ O
leveraging -X- _ O
external -X- _ O
knowledge -X- _ O
to -X- _ O
provide -X- _ O
powerful -X- _ O
evidence -X- _ O
or -X- _ O
enrich -X- _ O
features -X- _ O
' -X- _ O
representations -X- _ O
( -X- _ O
Hu -X- _ O
et -X- _ O
al -X- _ O
. -X- _ O
, -X- _ O
2021 -X- _ O
; -X- _ O
Qi -X- _ O
et -X- _ O
al -X- _ O
. -X- _ O
, -X- _ O
2021 -X- _ O
) -X- _ O
. -X- _ O
For -X- _ O
example -X- _ O
, -X- _ O
Hu -X- _ O
et -X- _ O
al -X- _ O
. -X- _ O
( -X- _ O
2021 -X- _ O
) -X- _ O
compared -X- _ O
each -X- _ O
news -X- _ O
with -X- _ O
the -X- _ O
external -X- _ O
knowledge -X- _ O
base -X- _ O
through -X- _ O
entities -X- _ O
to -X- _ O
utilize -X- _ O
consistencies -X- _ O
for -X- _ O
detection -X- _ O
. -X- _ O

In -X- _ O
this -X- _ O
work -X- _ O
, -X- _ O
we -X- _ O
improve -X- _ O
fake -X- _ B-TaskName
news -X- _ I-TaskName
detection -X- _ I-TaskName
from -X- _ O
the -X- _ O
perspective -X- _ O
of -X- _ O
causality -X- _ O
and -X- _ O
propose -X- _ O
a -X- _ O
novel -X- _ O
framework -X- _ O
that -X- _ O
eliminates -X- _ O
the -X- _ O
hidden -X- _ O
biases -X- _ O
in -X- _ O
each -X- _ O
modality -X- _ O
. -X- _ O

In -X- _ O
this -X- _ O
work -X- _ O
, -X- _ O
we -X- _ O
propose -X- _ O
a -X- _ O
novel -X- _ O
causal -X- _ B-MethodName
intervention -X- _ I-MethodName
and -X- _ I-MethodName
counterfactual -X- _ I-MethodName
reasoning -X- _ I-MethodName
based -X- _ I-MethodName
debiasing -X- _ I-MethodName
framework -X- _ O
CCD -X- _ B-MethodName
that -X- _ O
eliminates -X- _ O
the -X- _ O
hidden -X- _ O
biases -X- _ O
in -X- _ O
multi -X- _ B-TaskName
- -X- _ I-TaskName
modal -X- _ I-TaskName
fake -X- _ I-TaskName
news -X- _ I-TaskName
detection -X- _ I-TaskName
. -X- _ O
We -X- _ O
analyze -X- _ O
and -X- _ O
identify -X- _ O
the -X- _ O
psycholinguistic -X- _ O
bias -X- _ O
in -X- _ O
the -X- _ O
text -X- _ O
as -X- _ O
well -X- _ O
as -X- _ O
the -X- _ O
image -X- _ O
- -X- _ O
only -X- _ O
bias -X- _ O
. -X- _ O
Then -X- _ O
, -X- _ O
we -X- _ O
formulate -X- _ O
the -X- _ O
process -X- _ O
of -X- _ O
fake -X- _ B-TaskName
news -X- _ I-TaskName
detection -X- _ I-TaskName
as -X- _ O
a -X- _ O
causal -X- _ O
graph -X- _ O
, -X- _ O
addressing -X- _ O
the -X- _ O
biases -X- _ O
from -X- _ O
the -X- _ O
causality -X- _ O
perspective -X- _ O
. -X- _ O
Specifically -X- _ O
, -X- _ O
we -X- _ O
address -X- _ O
the -X- _ O
psycholinguistic -X- _ O
bias -X- _ O
by -X- _ O
causal -X- _ O
intervention -X- _ O
with -X- _ O
backdoor -X- _ O
adjustment -X- _ O
, -X- _ O
and -X- _ O
mitigate -X- _ O
the -X- _ O
image -X- _ O
- -X- _ O
only -X- _ O
bias -X- _ O
using -X- _ O
counterfactual -X- _ O
reasoning -X- _ O
that -X- _ O
subtracts -X- _ O
the -X- _ O
direct -X- _ O
image -X- _ O
- -X- _ O
only -X- _ O
causal -X- _ O
effect -X- _ O
from -X- _ O
the -X- _ O
total -X- _ O
causal -X- _ O
ef -X- _ O
- -X- _ O
fect -X- _ O
. -X- _ O
Experiments -X- _ O
on -X- _ O
two -X- _ O
real -X- _ O
- -X- _ O
world -X- _ O
benchmark -X- _ O
datasets -X- _ O
verify -X- _ O
that -X- _ O
CCD -X- _ B-MethodName
can -X- _ O
effectively -X- _ O
eliminate -X- _ O
biases -X- _ O
and -X- _ O
improve -X- _ O
multi -X- _ B-TaskName
- -X- _ I-TaskName
modal -X- _ I-TaskName
fake -X- _ I-TaskName
news -X- _ I-TaskName
detection -X- _ I-TaskName
. -X- _ O

Answering -X- _ O
Unanswered -X- _ O
Questions -X- _ O
through -X- _ O
Semantic -X- _ B-MethodName
Reformulations -X- _ I-MethodName
in -X- _ O
Spoken -X- _ B-TaskName
QA -X- _ I-TaskName

Spoken -X- _ B-TaskName
Question -X- _ I-TaskName
Answering -X- _ I-TaskName
( -X- _ O
QA -X- _ B-TaskName
) -X- _ O
is -X- _ O
a -X- _ O
key -X- _ O
feature -X- _ O
of -X- _ O
voice -X- _ O
assistants -X- _ O
, -X- _ O
usually -X- _ O
backed -X- _ O
by -X- _ O
multiple -X- _ O
QA -X- _ B-TaskName
systems -X- _ O
. -X- _ O
Users -X- _ O
ask -X- _ O
questions -X- _ O
via -X- _ O
spontaneous -X- _ O
speech -X- _ O
which -X- _ O
can -X- _ O
contain -X- _ O
disfluencies -X- _ O
, -X- _ O
errors -X- _ O
, -X- _ O
and -X- _ O
informal -X- _ O
syntax -X- _ O
or -X- _ O
phrasing -X- _ O
. -X- _ O
This -X- _ O
is -X- _ O
a -X- _ O
major -X- _ O
challenge -X- _ O
in -X- _ O
QA -X- _ B-TaskName
, -X- _ O
causing -X- _ O
unanswered -X- _ O
questions -X- _ O
or -X- _ O
irrelevant -X- _ O
answers -X- _ O
, -X- _ O
and -X- _ O
leading -X- _ O
to -X- _ O
bad -X- _ O
user -X- _ O
experiences -X- _ O
. -X- _ O
We -X- _ O
analyze -X- _ O
failed -X- _ O
QA -X- _ B-TaskName
requests -X- _ O
to -X- _ O
identify -X- _ O
core -X- _ O
challenges -X- _ O
: -X- _ O
lexical -X- _ O
gaps -X- _ O
, -X- _ O
proposition -X- _ O
types -X- _ O
, -X- _ O
complex -X- _ O
syntactic -X- _ O
structure -X- _ O
, -X- _ O
and -X- _ O
high -X- _ O
specificity -X- _ O
. -X- _ O
We -X- _ O
propose -X- _ O
a -X- _ O
Semantic -X- _ B-MethodName
Question -X- _ I-MethodName
Reformulation -X- _ I-MethodName
( -X- _ O
SURF -X- _ B-MethodName
) -X- _ O
model -X- _ O
offering -X- _ O
three -X- _ O
linguistically -X- _ O
- -X- _ O
grounded -X- _ O
operations -X- _ O
( -X- _ O
repair -X- _ O
, -X- _ O
syntactic -X- _ O
reshaping -X- _ O
, -X- _ O
generalization -X- _ O
) -X- _ O
to -X- _ O
rewrite -X- _ O
questions -X- _ O
to -X- _ O
facilitate -X- _ O
answering -X- _ O
. -X- _ O
Offline -X- _ O
evaluation -X- _ O
on -X- _ O
1 -X- _ O
M -X- _ O
unanswered -X- _ O
questions -X- _ O
from -X- _ O
a -X- _ O
leading -X- _ O
voice -X- _ O
assistant -X- _ O
shows -X- _ O
that -X- _ O
SURF -X- _ B-MethodName
significantly -X- _ O
improves -X- _ O
answer -X- _ B-MetricName
rates -X- _ I-MetricName
: -X- _ O
up -X- _ O
to -X- _ O
24 -X- _ B-MetricValue
% -X- _ I-MetricValue
of -X- _ O
previously -X- _ O
unanswered -X- _ O
questions -X- _ O
obtain -X- _ O
relevant -X- _ O
answers -X- _ O
( -X- _ O
75 -X- _ B-MetricValue
% -X- _ I-MetricValue
) -X- _ O
. -X- _ O
Live -X- _ O
deployment -X- _ O
shows -X- _ O
positive -X- _ O
impact -X- _ O
for -X- _ O
millions -X- _ O
of -X- _ O
customers -X- _ O
with -X- _ O
unanswered -X- _ O
questions -X- _ O
; -X- _ O
explicit -X- _ O
relevance -X- _ O
feedback -X- _ O
shows -X- _ O
high -X- _ O
user -X- _ O
satisfaction -X- _ O
. -X- _ O
* -X- _ O
Work -X- _ O
done -X- _ O
during -X- _ O
an -X- _ O
internship -X- _ O
at -X- _ O
Amazon -X- _ O
. -X- _ O
Repair -X- _ O
Operation -X- _ O
( -X- _ O
disfluencies -X- _ O
, -X- _ O
syntax -X- _ O
, -X- _ O
formality -X- _ O
, -X- _ O
lexical -X- _ O
gaps -X- _ O
) -X- _ O
Q1 -X- _ O
: -X- _ O
does -X- _ O
strawberries -X- _ O
no -X- _ O
i -X- _ O
mean -X- _ O
blueberries -X- _ O
grow -X- _ O
on -X- _ O
top -X- _ O
of -X- _ O
tree -X- _ O
R1 -X- _ O
: -X- _ O
do -X- _ O
blueberries -X- _ O
grow -X- _ O
on -X- _ O
trees -X- _ O
Q2 -X- _ O
: -X- _ O
how -X- _ O
to -X- _ O
store -X- _ O
honey -X- _ O
so -X- _ O
it -X- _ O
does -X- _ O
n't -X- _ O
get -X- _ O
weird -X- _ O
R2 -X- _ O
: -X- _ O
how -X- _ O
to -X- _ O
keep -X- _ O
honey -X- _ O
freshGeneralize -X- _ O
Operation -X- _ O
( -X- _ O
relax -X- _ O
/ -X- _ O
remove -X- _ O
constraints -X- _ O
, -X- _ O
modify -X- _ O
entities -X- _ O
) -X- _ O
Q6 -X- _ O
: -X- _ O
was -X- _ O
winston -X- _ O
churchill -X- _ O
's -X- _ O
mother -X- _ O
an -X- _ O
american -X- _ O
nurse -X- _ O
R6 -X- _ O
: -X- _ O
who -X- _ O
was -X- _ O
winston -X- _ O
churchill -X- _ O
's -X- _ O
mother -X- _ O
Q4 -X- _ O
: -X- _ O
if -X- _ O
you -X- _ O
fall -X- _ O
and -X- _ O
got -X- _ O
a -X- _ O
bruised -X- _ O
thigh -X- _ O
should -X- _ O
i -X- _ O
put -X- _ O
ice -X- _ O
on -X- _ O
it -X- _ O
or -X- _ O
heat -X- _ O
R4 -X- _ O
: -X- _ O
what -X- _ O
is -X- _ O
the -X- _ O
treatment -X- _ O
for -X- _ O
a -X- _ O
bruised -X- _ O
thigh -X- _ O
Q7 -X- _ O
: -X- _ O
did -X- _ O
kamala -X- _ O
harris -X- _ O
move -X- _ O
to -X- _ O
canada -X- _ O
then -X- _ O
back -X- _ O
to -X- _ O
america -X- _ O
R7 -X- _ O
: -X- _ O
did -X- _ O
kamala -X- _ O
harris -X- _ O
move -X- _ O
to -X- _ O
canada -X- _ O
Q8 -X- _ O
: -X- _ O
what -X- _ O
is -X- _ O
the -X- _ O
maximum -X- _ O
salary -X- _ O
of -X- _ O
a -X- _ O
plumber -X- _ O
in -X- _ O
san -X- _ O
francisco -X- _ O
R8 -X- _ O
: -X- _ O
what -X- _ O
is -X- _ O
the -X- _ O
income -X- _ O
of -X- _ O
a -X- _ O
plumber -X- _ O
in -X- _ O
california -X- _ O
Q9 -X- _ O
: -X- _ O
how -X- _ O
do -X- _ O
i -X- _ O
get -X- _ O
rid -X- _ O
of -X- _ O
flies -X- _ O
that -X- _ O
keep -X- _ O
come -X- _ O
out -X- _ O
of -X- _ O
the -X- _ O
bathroom -X- _ O
R9 -X- _ O
: -X- _ O
how -X- _ O
to -X- _ O
get -X- _ O
rid -X- _ O
of -X- _ O
flies -X- _ O
Q3 -X- _ O
: -X- _ O
my -X- _ O
hamburger -X- _ O
patty -X- _ O
is -X- _ O
in -X- _ O
the -X- _ O
fridge -X- _ O
for -X- _ O
four -X- _ O
days -X- _ O
should -X- _ O
i -X- _ O
throw -X- _ O
it -X- _ O
R3 -X- _ O
: -X- _ O
how -X- _ O
long -X- _ O
can -X- _ O
hamburger -X- _ O
patty -X- _ O
be -X- _ O
refrigerated -X- _ O
Q5 -X- _ O
: -X- _ O
our -X- _ O
pet -X- _ O
dog -X- _ O
was -X- _ O
playing -X- _ O
in -X- _ O
the -X- _ O
park -X- _ O
and -X- _ O
ate -X- _ O
a -X- _ O
rat -X- _ O
is -X- _ O
that -X- _ O
safe -X- _ O
R5 -X- _ O
: -X- _ O
what -X- _ O
happens -X- _ O
if -X- _ O
a -X- _ O
dog -X- _ O
eats -X- _ O
a -X- _ O
rat -X- _ O

Question -X- _ B-TaskName
Answering -X- _ I-TaskName
( -X- _ O
QA -X- _ B-TaskName
) -X- _ O
is -X- _ O
a -X- _ O
longstanding -X- _ O
NLP -X- _ O
task -X- _ O
, -X- _ O
and -X- _ O
voice -X- _ O
assistants -X- _ O
like -X- _ O
Alexa -X- _ O
have -X- _ O
made -X- _ O
Spoken -X- _ B-TaskName
QA -X- _ I-TaskName
ubiquitous -X- _ O
. -X- _ O
Users -X- _ O
often -X- _ O
address -X- _ O
such -X- _ O
assistants -X- _ O
with -X- _ O
spontaneous -X- _ O
speech -X- _ O
, -X- _ O
as -X- _ O
they -X- _ O
would -X- _ O
a -X- _ O
human -X- _ O
. -X- _ O
However -X- _ O
, -X- _ O
differences -X- _ O
between -X- _ O
spoken -X- _ O
and -X- _ O
written -X- _ O
language -X- _ O
( -X- _ O
Chafe -X- _ O
and -X- _ O
Tannen -X- _ O
, -X- _ O
1987 -X- _ O
) -X- _ O
, -X- _ O
such -X- _ O
as -X- _ O
the -X- _ O
presence -X- _ O
of -X- _ O
disfluencies -X- _ O
, -X- _ O
informal -X- _ O
or -X- _ O
incomplete -X- _ O
speech -X- _ O
, -X- _ O
and -X- _ O
different -X- _ O
syntax -X- _ O
have -X- _ O
been -X- _ O
shown -X- _ O
to -X- _ O
pose -X- _ O
challenges -X- _ O
for -X- _ O
NLP -X- _ O
tasks -X- _ O
( -X- _ O
Ward -X- _ O
, -X- _ O
1989 -X- _ O
; -X- _ O
Shriberg -X- _ O
, -X- _ O
2005 -X- _ O
; -X- _ O
Salesky -X- _ O
et -X- _ O
al -X- _ O
. -X- _ O
, -X- _ O
2019 -X- _ O
) -X- _ O
. -X- _ O
QA -X- _ B-TaskName
system -X- _ O
mostly -X- _ O
use -X- _ O
written -X- _ O
data -X- _ O
, -X- _ O
and -X- _ O
such -X- _ O
phenomena -X- _ O
impact -X- _ O
question -X- _ O
understanding -X- _ O
and -X- _ O
answer -X- _ O
retrieval -X- _ O
( -X- _ O
Gupta -X- _ O
et -X- _ O
al -X- _ O
. -X- _ O
, -X- _ O
2021 -X- _ O
) -X- _ O
, -X- _ O
leading -X- _ O
to -X- _ O
irrelevant -X- _ O
answers -X- _ O
or -X- _ O
unanswered -X- _ O
questions -X- _ O
, -X- _ O
leaving -X- _ O
users -X- _ O
unsatisfied -X- _ O
. -X- _ O

Recently -X- _ O
, -X- _ O
language -X- _ O
generation -X- _ O
has -X- _ O
been -X- _ O
used -X- _ O
to -X- _ O
improve -X- _ O
QA -X- _ B-TaskName
through -X- _ O
Question -X- _ B-MethodName
Rewriting -X- _ I-MethodName
( -X- _ O
QR -X- _ B-MethodName
) -X- _ O
. -X- _ O
For -X- _ O
example -X- _ O
, -X- _ O
QR -X- _ B-MethodName
is -X- _ O
used -X- _ O
in -X- _ O
conversational -X- _ O
systems -X- _ O
to -X- _ O
answer -X- _ O
contextual -X- _ O
questions -X- _ O
in -X- _ O
multi -X- _ O
- -X- _ O
turn -X- _ O
dialogues -X- _ O
( -X- _ O
Ye -X- _ O
et -X- _ O
al -X- _ O
. -X- _ O
, -X- _ O
2022 -X- _ O
) -X- _ O
. -X- _ O
While -X- _ O
QA -X- _ B-TaskName
models -X- _ O
can -X- _ O
be -X- _ O
improved -X- _ O
with -X- _ O
fine -X- _ O
- -X- _ O
tuning -X- _ O
, -X- _ O
real -X- _ O
- -X- _ O
world -X- _ O
systems -X- _ O
have -X- _ O
multiple -X- _ O
QA -X- _ B-TaskName
backends -X- _ O
and -X- _ O
retraining -X- _ O
is -X- _ O
expensive -X- _ O
, -X- _ O
making -X- _ O
input -X- _ O
rewriting -X- _ O
a -X- _ O
practical -X- _ O
solution -X- _ O
( -X- _ O
Chen -X- _ O
et -X- _ O
al -X- _ O
. -X- _ O
, -X- _ O
2022 -X- _ O
) -X- _ O
. -X- _ O
This -X- _ O
has -X- _ O
the -X- _ O
added -X- _ O
benefit -X- _ O
that -X- _ O
a -X- _ O
single -X- _ O
QR -X- _ B-MethodName
model -X- _ O
may -X- _ O
improve -X- _ O
multiple -X- _ O
QA -X- _ B-TaskName
systems -X- _ O
. -X- _ O

We -X- _ O
propose -X- _ O
applying -X- _ O
QR -X- _ B-MethodName
to -X- _ O
reformulate -X- _ O
difficult -X- _ O
or -X- _ O
unanswered -X- _ O
questions -X- _ O
. -X- _ O
We -X- _ O
analyzed -X- _ O
millions -X- _ O
of -X- _ O
answered -X- _ O
and -X- _ O
unanswered -X- _ O
real -X- _ O
- -X- _ O
world -X- _ O
questions -X- _ O
from -X- _ O
a -X- _ O
leading -X- _ O
voice -X- _ O
assistant -X- _ O
to -X- _ O
understand -X- _ O
the -X- _ O
factors -X- _ O
impacting -X- _ O
QA -X- _ B-TaskName
failure -X- _ O
( -X- _ O
§ -X- _ O
3 -X- _ O
) -X- _ O
. -X- _ O
In -X- _ O
addition -X- _ O
to -X- _ O
the -X- _ O
well -X- _ O
- -X- _ O
known -X- _ O
issue -X- _ O
of -X- _ O
disfluencies -X- _ O
, -X- _ O
we -X- _ O
identify -X- _ O
novel -X- _ O
challenges -X- _ O
from -X- _ O
question -X- _ O
structure -X- _ O
and -X- _ O
specificity -X- _ O
. -X- _ O
To -X- _ O
address -X- _ O
them -X- _ O
, -X- _ O
we -X- _ O
propose -X- _ O
three -X- _ O
linguisticallyinformed -X- _ O
reformulation -X- _ O
operations -X- _ O
that -X- _ O
only -X- _ O
require -X- _ O
the -X- _ O
question -X- _ O
( -X- _ O
§ -X- _ O
4 -X- _ O
) -X- _ O
. -X- _ O
The -X- _ O
operations -X- _ O
, -X- _ O
shown -X- _ O
in -X- _ O
Figure -X- _ O
1 -X- _ O
, -X- _ O
are -X- _ O
designed -X- _ O
to -X- _ O
improve -X- _ O
answerability -X- _ O
1 -X- _ O
based -X- _ O
on -X- _ O
common -X- _ O
speech -X- _ O
patterns -X- _ O
, -X- _ O
so -X- _ O
that -X- _ O
for -X- _ O
a -X- _ O
previously -X- _ O
unanswered -X- _ O
question -X- _ O
, -X- _ O
the -X- _ O
same -X- _ O
QA -X- _ B-TaskName
system -X- _ O
is -X- _ O
able -X- _ O
to -X- _ O
provide -X- _ O
an -X- _ O
answer -X- _ O
for -X- _ O
its -X- _ O
reformulation -X- _ O
. -X- _ O

Live -X- _ O
deployment -X- _ O
of -X- _ O
our -X- _ O
model -X- _ O
( -X- _ O
§ -X- _ O
6.4 -X- _ O
) -X- _ O
achieves -X- _ O
positive -X- _ O
impact -X- _ O
for -X- _ O
millions -X- _ O
of -X- _ O
users -X- _ O
with -X- _ O
unanswered -X- _ O
questions -X- _ O
, -X- _ O
and -X- _ O
explicit -X- _ O
relevance -X- _ O
feedback -X- _ O
from -X- _ O
customers -X- _ O
shows -X- _ O
high -X- _ O
satisfaction -X- _ O
. -X- _ O

Related -X- _ O
Work -X- _ O

Question -X- _ O
Complexity -X- _ O
: -X- _ O
Depending -X- _ O
on -X- _ O
the -X- _ O
QA -X- _ B-TaskName
system -X- _ O
, -X- _ O
some -X- _ O
questions -X- _ O
may -X- _ O
be -X- _ O
more -X- _ O
difficult -X- _ O
to -X- _ O
answer -X- _ O
. -X- _ O
It -X- _ O
has -X- _ O
been -X- _ O
shown -X- _ O
that -X- _ O
questions -X- _ O
requiring -X- _ O
multi -X- _ O
- -X- _ O
hop -X- _ O
reasoning -X- _ O
are -X- _ O
more -X- _ O
challenging -X- _ O
( -X- _ O
Yang -X- _ O
et -X- _ O
al -X- _ O
. -X- _ O
, -X- _ O
2018 -X- _ O
) -X- _ O
, -X- _ O
often -X- _ O
leading -X- _ O
to -X- _ O
no -X- _ O
answers -X- _ O
or -X- _ O
wrong -X- _ O
answers -X- _ O
. -X- _ O
Questions -X- _ O
are -X- _ O
affected -X- _ O
by -X- _ O
the -X- _ O
broader -X- _ O
types -X- _ O
of -X- _ O
syntactic -X- _ O
complexity -X- _ O
explored -X- _ O
in -X- _ O
the -X- _ O
field -X- _ O
( -X- _ O
Nassar -X- _ O
et -X- _ O
al -X- _ O
. -X- _ O
, -X- _ O
2019 -X- _ O
; -X- _ O
Martin -X- _ O
et -X- _ O
al -X- _ O
. -X- _ O
, -X- _ O
2020 -X- _ O
; -X- _ O
Sheang -X- _ O
and -X- _ O
Saggion -X- _ O
, -X- _ O
2021 -X- _ O
) -X- _ O
. -X- _ O
Regardless -X- _ O
of -X- _ O
complexity -X- _ O
, -X- _ O
questions -X- _ O
may -X- _ O
also -X- _ O
be -X- _ O
unanswerable -X- _ O
due -X- _ O
to -X- _ O
incorrect -X- _ O
framing -X- _ O
or -X- _ O
false -X- _ O
suppositions -X- _ O
( -X- _ O
Kim -X- _ O
et -X- _ O
al -X- _ O
. -X- _ O
, -X- _ O
2021 -X- _ O
) -X- _ O
. -X- _ O
Other -X- _ O
work -X- _ O
has -X- _ O
analyzed -X- _ O
questions -X- _ O
in -X- _ O
different -X- _ O
datasets -X- _ O
, -X- _ O
showing -X- _ O
that -X- _ O
wh- -X- _ O
* -X- _ O
words -X- _ O
( -X- _ O
e.g. -X- _ O
who -X- _ O
, -X- _ O
what -X- _ O
, -X- _ O
when -X- _ O
) -X- _ O
are -X- _ O
the -X- _ O
dominant -X- _ O
way -X- _ O
to -X- _ O
start -X- _ O
a -X- _ O
question -X- _ O
( -X- _ O
Ko -X- _ O
et -X- _ O
al -X- _ O
. -X- _ O
, -X- _ O
2020 -X- _ O
) -X- _ O
, -X- _ O
and -X- _ O
that -X- _ O
these -X- _ O
words -X- _ O
and -X- _ O
related -X- _ O
phrases -X- _ O
( -X- _ O
e.g. -X- _ O
, -X- _ O
" -X- _ O
how -X- _ O
much -X- _ O
" -X- _ O
, -X- _ O
" -X- _ O
how -X- _ O
large -X- _ O
" -X- _ O
) -X- _ O
are -X- _ O
associated -X- _ O
with -X- _ O
reduced -X- _ O
answering -X- _ O
complexity -X- _ O
( -X- _ O
Chali -X- _ O
and -X- _ O
Hasan -X- _ O
, -X- _ O
2012 -X- _ O
) -X- _ O
. -X- _ O
In -X- _ O
our -X- _ O
work -X- _ O
we -X- _ O
consider -X- _ O
how -X- _ O
controlled -X- _ O
syntactic -X- _ O
restructuring -X- _ O
can -X- _ O
address -X- _ O
the -X- _ O
above -X- _ O
challenges -X- _ O
to -X- _ O
reduce -X- _ O
answering -X- _ O
complexity -X- _ O
. -X- _ O

Question -X- _ O
Rewriting -X- _ O
: -X- _ O
Rewriting -X- _ O
questions -X- _ O
is -X- _ O
a -X- _ O
natural -X- _ O
extension -X- _ O
of -X- _ O
query -X- _ O
reformulation -X- _ O
approaches -X- _ O
used -X- _ O
to -X- _ O
improve -X- _ O
Information -X- _ O
Retrieval -X- _ O
( -X- _ O
He -X- _ O
et -X- _ O
al -X- _ O
. -X- _ O
, -X- _ O
2016 -X- _ O
) -X- _ O
. -X- _ O
Question -X- _ O
rewriting -X- _ O
has -X- _ O
been -X- _ O
applied -X- _ O
to -X- _ O
improve -X- _ O
QA -X- _ B-TaskName
in -X- _ O
different -X- _ O
ways -X- _ O
. -X- _ O
Question -X- _ O
paraphrasing -X- _ O
has -X- _ O
been -X- _ O
used -X- _ O
as -X- _ O
a -X- _ O
data -X- _ O
augmentation -X- _ O
approach -X- _ O
to -X- _ O
retrain -X- _ O
QA -X- _ B-TaskName
systems -X- _ O
to -X- _ O
improve -X- _ O
robustness -X- _ O
( -X- _ O
Gan -X- _ O
and -X- _ O
Ng -X- _ O
, -X- _ O
2019 -X- _ O
) -X- _ O
. -X- _ O
Buck -X- _ O
et -X- _ O
al -X- _ O
. -X- _ O
( -X- _ O
2018 -X- _ O
) -X- _ O
propose -X- _ O
using -X- _ O
a -X- _ O
reinforcement -X- _ O
learning -X- _ O
agent -X- _ O
between -X- _ O
the -X- _ O
original -X- _ O
question -X- _ O
and -X- _ O
a -X- _ O
black -X- _ O
box -X- _ O
QA -X- _ B-TaskName
system -X- _ O
. -X- _ O
The -X- _ O
agent -X- _ O
probes -X- _ O
the -X- _ O
QA -X- _ B-TaskName
system -X- _ O
with -X- _ O
several -X- _ O
reformulations -X- _ O
to -X- _ O
learn -X- _ O
how -X- _ O
to -X- _ O
elicit -X- _ O
the -X- _ O
best -X- _ O
answer -X- _ O
. -X- _ O
Liu -X- _ O
et -X- _ O
al -X- _ O
. -X- _ O
( -X- _ O
2019 -X- _ O
) -X- _ O
propose -X- _ O
a -X- _ O
question -X- _ O
refinement -X- _ O
system -X- _ O
to -X- _ O
rewrite -X- _ O
malformed -X- _ O
questions -X- _ O
. -X- _ O

Our -X- _ O
work -X- _ O
is -X- _ O
inspired -X- _ O
by -X- _ O
all -X- _ O
of -X- _ O
the -X- _ O
above -X- _ O
, -X- _ O
but -X- _ O
differs -X- _ O
in -X- _ O
several -X- _ O
ways -X- _ O
. -X- _ O
We -X- _ O
expand -X- _ O
on -X- _ O
the -X- _ O
known -X- _ O
issues -X- _ O
in -X- _ O
QA -X- _ B-TaskName
by -X- _ O
analyzing -X- _ O
real -X- _ O
voice -X- _ O
assistant -X- _ O
data -X- _ O
to -X- _ O
identify -X- _ O
prevalent -X- _ O
challenges -X- _ O
to -X- _ O
tackle -X- _ O
; -X- _ O
we -X- _ O
consider -X- _ O
malformed -X- _ O
question -X- _ O
correction -X- _ O
as -X- _ O
a -X- _ O
prerequisite -X- _ O
for -X- _ O
dealing -X- _ O
with -X- _ O
challenges -X- _ O
of -X- _ O
complex -X- _ O
questions -X- _ O
. -X- _ O
Additionally -X- _ O
, -X- _ O
prior -X- _ O
rewriting -X- _ O
approaches -X- _ O
aim -X- _ O
to -X- _ O
improve -X- _ O
QA -X- _ B-TaskName
via -X- _ O
retraining -X- _ O
, -X- _ O
or -X- _ O
by -X- _ O
building -X- _ O
a -X- _ O
rewriter -X- _ O
tailored -X- _ O
to -X- _ O
a -X- _ O
single -X- _ O
QA -X- _ B-TaskName
system -X- _ O
. -X- _ O
We -X- _ O
take -X- _ O
a -X- _ O
different -X- _ O
approach -X- _ O
that -X- _ O
does -X- _ O
not -X- _ O
rely -X- _ O
on -X- _ O
answer -X- _ O
data -X- _ O
or -X- _ O
QA -X- _ B-TaskName
system -X- _ O
feedback -X- _ O
, -X- _ O
and -X- _ O
build -X- _ O
a -X- _ O
general -X- _ O
model -X- _ O
that -X- _ O
can -X- _ O
benefit -X- _ O
multiple -X- _ O
QA -X- _ B-TaskName
systems -X- _ O
in -X- _ O
a -X- _ O
federated -X- _ O
architecture -X- _ O
. -X- _ O
Instead -X- _ O
of -X- _ O
uncontrolled -X- _ O
paraphrasing -X- _ O
, -X- _ O
we -X- _ O
deal -X- _ O
with -X- _ O
question -X- _ O
complexity -X- _ O
via -X- _ O
controllable -X- _ O
reformulations -X- _ O
that -X- _ O
distinguish -X- _ O
between -X- _ O
lexical -X- _ O
modification -X- _ O
, -X- _ O
interrogative -X- _ O
clause -X- _ O
restructuring -X- _ O
, -X- _ O
and -X- _ O
semantic -X- _ O
changes -X- _ O
. -X- _ O
We -X- _ O
propose -X- _ O
novel -X- _ O
linguistic -X- _ O
restructuring -X- _ O
operations -X- _ O
to -X- _ O
deal -X- _ O
with -X- _ O
complex -X- _ O
syntax -X- _ O
, -X- _ O
and -X- _ O
generalize -X- _ O
high -X- _ O
- -X- _ O
specificity -X- _ O
elements -X- _ O
. -X- _ O

3 -X- _ O
Challenges -X- _ O
in -X- _ O
Real -X- _ O
- -X- _ O
world -X- _ O
Spoken -X- _ B-TaskName
QA -X- _ I-TaskName
First -X- _ O
, -X- _ O
to -X- _ O
quantify -X- _ O
and -X- _ O
understand -X- _ O
why -X- _ O
spoken -X- _ B-TaskName
QA -X- _ I-TaskName
fails -X- _ O
, -X- _ O
we -X- _ O
perform -X- _ O
a -X- _ O
failure -X- _ O
analysis -X- _ O
on -X- _ O
10 -X- _ O
million -X- _ O
real -X- _ O
questions -X- _ O
, -X- _ O
by -X- _ O
further -X- _ O
distinguishing -X- _ O
questions -X- _ O
according -X- _ O
to -X- _ O
their -X- _ O
question -X- _ O
type -X- _ O
( -X- _ O
we -X- _ O
define -X- _ O
5 -X- _ O
types -X- _ O
based -X- _ O
on -X- _ O
linguistic -X- _ O
properties -X- _ O
, -X- _ O
see -X- _ O
Appendix -X- _ O
B -X- _ O
for -X- _ O
details -X- _ O
) -X- _ O
from -X- _ O
a -X- _ O
leading -X- _ O
voice -X- _ O
assistant -X- _ O
. -X- _ O

Scope -X- _ O
: -X- _ O
we -X- _ O
limit -X- _ O
our -X- _ O
work -X- _ O
to -X- _ O
questions -X- _ O
that -X- _ O
were -X- _ O
not -X- _ O
answered -X- _ O
due -X- _ O
to -X- _ O
retrieval -X- _ O
failure -X- _ O
, -X- _ O
but -X- _ O
may -X- _ O
potentially -X- _ O
have -X- _ O
relevant -X- _ O
answers -X- _ O
if -X- _ O
reformulated -X- _ O
. -X- _ O
They -X- _ O
must -X- _ O
be -X- _ O
valid -X- _ O
questions -X- _ O
( -X- _ O
seek -X- _ O
knowable -X- _ O
knowledge -X- _ O
) -X- _ O
whose -X- _ O
information -X- _ O
need -X- _ O
can -X- _ O
be -X- _ O
understood -X- _ O
( -X- _ O
by -X- _ O
humans -X- _ O
) -X- _ O
and -X- _ O
re -X- _ O
- -X- _ O
stated -X- _ O
. -X- _ O
QA -X- _ B-TaskName
may -X- _ O
fail -X- _ O
for -X- _ O
other -X- _ O
reasons -X- _ O
; -X- _ O
we -X- _ O
do -X- _ O
not -X- _ O
consider -X- _ O
such -X- _ O
issues -X- _ O
e.g. -X- _ O
, -X- _ O
inter -X- _ O
alia -X- _ O
, -X- _ O
ASR -X- _ O
errors -X- _ O
, -X- _ O
invalid -X- _ O
or -X- _ O
difficult -X- _ O
to -X- _ O
understand -X- _ O
questions -X- _ O
, -X- _ O
subjectivity -X- _ O
, -X- _ O
and -X- _ O
other -X- _ O
reasons -X- _ O
for -X- _ O
retrieval -X- _ O
failure -X- _ O
. -X- _ O

C1 -X- _ O
. -X- _ O
Malformed -X- _ O
Utterances -X- _ O
: -X- _ O
Questions -X- _ O
with -X- _ O
disfluencies -X- _ O
and -X- _ O
syntactic -X- _ O
errors -X- _ O
were -X- _ O
more -X- _ O
likely -X- _ O
to -X- _ O
fail -X- _ O
e.g. -X- _ O
, -X- _ O
Fig -X- _ O
. -X- _ O
1 -X- _ O
( -X- _ O
Q1 -X- _ O
) -X- _ O
. -X- _ O
Correction -X- _ O
methods -X- _ O
have -X- _ O
previously -X- _ O
been -X- _ O
used -X- _ O
to -X- _ O
fix -X- _ O
these -X- _ O
( -X- _ O
Gupta -X- _ O
et -X- _ O
al -X- _ O
. -X- _ O
, -X- _ O
2021 -X- _ O
) -X- _ O
. -X- _ O

C2 -X- _ O
. -X- _ O
Lexical -X- _ O
Gaps -X- _ O
Questions -X- _ O
framed -X- _ O
colloquially -X- _ O
or -X- _ O
lacking -X- _ O
appropriate -X- _ O
parlance -X- _ O
for -X- _ O
a -X- _ O
topic -X- _ O
e.g. -X- _ O
, -X- _ O
Fig -X- _ O
. -X- _ O
1 -X- _ O
( -X- _ O
Q2 -X- _ O
) -X- _ O
, -X- _ O
were -X- _ O
associated -X- _ O
with -X- _ O
failure -X- _ O
. -X- _ O
This -X- _ O
is -X- _ O
caused -X- _ O
by -X- _ O
lexical -X- _ O
gaps -X- _ O
( -X- _ O
Riezler -X- _ O
and -X- _ O
Liu -X- _ O
, -X- _ O
2010 -X- _ O
) -X- _ O
arising -X- _ O
from -X- _ O
language -X- _ O
mismatch -X- _ O
between -X- _ O
the -X- _ O
user -X- _ O
input -X- _ O
and -X- _ O
answer -X- _ O
sources -X- _ O
, -X- _ O
as -X- _ O
QA -X- _ B-TaskName
systems -X- _ O
use -X- _ O
formal -X- _ O
knowledge -X- _ O
sources -X- _ O
for -X- _ O
retrieval -X- _ O
. -X- _ O
Lexical -X- _ O
substitution -X- _ O
and -X- _ O
rephrasing -X- _ O
may -X- _ O
address -X- _ O
this -X- _ O
challenge -X- _ O
. -X- _ O

C3 -X- _ O
. -X- _ O
Complex -X- _ O
Syntactic -X- _ O
Structure -X- _ O
: -X- _ O
Utterances -X- _ O
with -X- _ O
complex -X- _ O
structure -X- _ O
, -X- _ O
such -X- _ O
as -X- _ O
multi -X- _ O
- -X- _ O
clause -X- _ O
questions -X- _ O
, -X- _ O
can -X- _ O
lead -X- _ O
to -X- _ O
QA -X- _ B-TaskName
failure -X- _ O
. -X- _ O
Such -X- _ O
phrasing -X- _ O
is -X- _ O
more -X- _ O
common -X- _ O
in -X- _ O
spoken -X- _ O
language -X- _ O
, -X- _ O
and -X- _ O
can -X- _ O
be -X- _ O
simplified -X- _ O
via -X- _ O
syntactic -X- _ O
restructuring -X- _ O
, -X- _ O
e.g. -X- _ O
, -X- _ O
Fig -X- _ O
. -X- _ O
1 -X- _ O
( -X- _ O
Q3 -X- _ O
- -X- _ O
5 -X- _ O
) -X- _ O
. -X- _ O

C4 -X- _ O
. -X- _ O
Polar -X- _ O
Propositions -X- _ O
: -X- _ O
Yes -X- _ O
- -X- _ O
No -X- _ O
questions -X- _ O
are -X- _ O
asked -X- _ O
to -X- _ O
confirm -X- _ O
a -X- _ O
specific -X- _ O
proposition -X- _ O
, -X- _ O
e.g. -X- _ O
, -X- _ O
" -X- _ O
Do -X- _ O
box -X- _ O
turtles -X- _ O
live -X- _ O
in -X- _ O
Japan -X- _ O
? -X- _ O
" -X- _ O
. -X- _ O
Answering -X- _ O
polar -X- _ O
questions -X- _ O
is -X- _ O
more -X- _ O
difficult -X- _ O
than -X- _ O
wh -X- _ O
- -X- _ O
questions -X- _ O
for -X- _ O
both -X- _ O
humans -X- _ O
( -X- _ O
Moradlou -X- _ O
et -X- _ O
al -X- _ O
. -X- _ O
, -X- _ O
2021 -X- _ O
) -X- _ O
and -X- _ O
QA -X- _ B-TaskName
systems -X- _ O
( -X- _ O
Clark -X- _ O
et -X- _ O
al -X- _ O
. -X- _ O
, -X- _ O
2019 -X- _ O
) -X- _ O
, -X- _ O
due -X- _ O
to -X- _ O
the -X- _ O
entailment -X- _ O
and -X- _ O
inferences -X- _ O
required -X- _ O
to -X- _ O
arrive -X- _ O
at -X- _ O
an -X- _ O
answer -X- _ O
. -X- _ O
This -X- _ O
can -X- _ O
be -X- _ O
simplified -X- _ O
by -X- _ O
reformulating -X- _ O
to -X- _ O
a -X- _ O
factoid -X- _ O
whquestion -X- _ O
, -X- _ O
e.g. -X- _ O
, -X- _ O
" -X- _ O
Where -X- _ O
do -X- _ O
box -X- _ O
turtles -X- _ O
live -X- _ O
? -X- _ O
" -X- _ O
. -X- _ O
2 -X- _ O
The -X- _ O
exact -X- _ O
numbers -X- _ O
can -X- _ O
not -X- _ O
be -X- _ O
divulged -X- _ O
for -X- _ O
confidentiality -X- _ O
. -X- _ O

We -X- _ O
now -X- _ O
describe -X- _ O
our -X- _ O
proposed -X- _ O
Semantic -X- _ B-TaskName
Question -X- _ I-TaskName
Reformulation -X- _ I-TaskName
model -X- _ O
( -X- _ O
SURF -X- _ B-TaskName
) -X- _ O
and -X- _ O
the -X- _ O
reformulation -X- _ O
operators -X- _ O
that -X- _ O
it -X- _ O
supports -X- _ O
. -X- _ O

Each -X- _ O
prefix -X- _ O
p -X- _ O
instructs -X- _ O
F -X- _ O
to -X- _ O
perform -X- _ O
a -X- _ O
specific -X- _ O
type -X- _ O
of -X- _ O
reformulation -X- _ O
. -X- _ O
We -X- _ O
define -X- _ O
the -X- _ O
following -X- _ O
prefix -X- _ O
operators -X- _ O
based -X- _ O
on -X- _ O
the -X- _ O
challenges -X- _ O
presented -X- _ O
in -X- _ O
§ -X- _ O
3 -X- _ O
. -X- _ O

Using -X- _ O
a -X- _ O
human -X- _ B-MethodName
study -X- _ I-MethodName
, -X- _ O
we -X- _ O
intrinsically -X- _ O
evaluate -X- _ O
the -X- _ O
reformulation -X- _ O
accuracy -X- _ O
3 -X- _ O
to -X- _ O
assess -X- _ O
if -X- _ O
: -X- _ O
( -X- _ O
1 -X- _ O
) -X- _ O
the -X- _ O
reformulation -X- _ O
retains -X- _ O
the -X- _ O
intent -X- _ O
of -X- _ O
the -X- _ O
input -X- _ O
question -X- _ O
; -X- _ O
and -X- _ O
( -X- _ O
2 -X- _ O
) -X- _ O
the -X- _ O
reformulation -X- _ O
satisfies -X- _ O
the -X- _ O
properties -X- _ O
of -X- _ O
the -X- _ O
reformulation -X- _ O
operator -X- _ O
p -X- _ O
. -X- _ O

For -X- _ O
the -X- _ O
extrinsic -X- _ O
evaluation -X- _ O
, -X- _ O
we -X- _ O
assess -X- _ O
the -X- _ O
impact -X- _ O
of -X- _ O
the -X- _ O
reformulated -X- _ O
questions -X- _ O
on -X- _ O
two -X- _ O
aspects -X- _ O
: -X- _ O
Answer -X- _ B-MetricName
Rate -X- _ I-MetricName
: -X- _ O
measured -X- _ O
as -X- _ O
the -X- _ O
percentage -X- _ O
of -X- _ O
reformulations -X- _ O
that -X- _ O
obtain -X- _ O
an -X- _ O
answer -X- _ O
. -X- _ O
Answer -X- _ B-MetricName
Relevance -X- _ I-MetricName
: -X- _ O
a -X- _ O
three -X- _ O
- -X- _ O
point -X- _ O
scale -X- _ O
measuring -X- _ O
the -X- _ O
answer -X- _ O
relevance -X- _ O
to -X- _ O
the -X- _ O
original -X- _ O
question -X- _ O
( -X- _ O
obtained -X- _ O
from -X- _ O
the -X- _ O
reformulated -X- _ O
questions -X- _ O
) -X- _ O
: -X- _ O
Irrelevant -X- _ O
( -X- _ O
0 -X- _ O
) -X- _ O
: -X- _ O
answer -X- _ O
is -X- _ O
not -X- _ O
related -X- _ O
to -X- _ O
q -X- _ O
; -X- _ O
Related -X- _ O
( -X- _ O
1 -X- _ O
) -X- _ O
: -X- _ O
answer -X- _ O
is -X- _ O
partially -X- _ O
relevant -X- _ O
; -X- _ O
4 -X- _ O
and -X- _ O
Exact -X- _ O
( -X- _ O
2 -X- _ O
) -X- _ O
: -X- _ O
answer -X- _ O
exactly -X- _ O
satisfies -X- _ O
question -X- _ O
's -X- _ O
information -X- _ O
need -X- _ O
. -X- _ O
Evaluation -X- _ O
Data -X- _ O
: -X- _ O
For -X- _ O
the -X- _ O
two -X- _ O
aspects -X- _ O
we -X- _ O
measure -X- _ O
, -X- _ O
we -X- _ O
consider -X- _ O
the -X- _ O
following -X- _ O
evaluation -X- _ O
datasets -X- _ O
: -X- _ O

• -X- _ O
Answer -X- _ B-MetricName
Rate -X- _ I-MetricName
: -X- _ O
We -X- _ O
randomly -X- _ O
sampled -X- _ O
1 -X- _ O
M -X- _ O
unanswered -X- _ O
questions -X- _ O
by -X- _ O
our -X- _ O
QA -X- _ B-TaskName
system -X- _ O
( -X- _ O
see -X- _ O
Appendix -X- _ O
F -X- _ O
for -X- _ O
additional -X- _ O
details -X- _ O
) -X- _ O
. -X- _ O

• -X- _ O
Answer -X- _ B-MetricName
Relevance -X- _ I-MetricName
: -X- _ O
on -X- _ O
the -X- _ O
same -X- _ O
questions -X- _ O
used -X- _ O
for -X- _ O
intrinsic -X- _ O
evaluation -X- _ O
, -X- _ O
the -X- _ O
annotators -X- _ O
also -X- _ O
check -X- _ O
the -X- _ O
answer -X- _ O
relevance -X- _ O
w.r.t -X- _ O
the -X- _ O
original -X- _ O
question -X- _ O
. -X- _ O

Pre -X- _ O
- -X- _ O
training -X- _ O
Data -X- _ O
. -X- _ O
We -X- _ O
create -X- _ O
a -X- _ O
weakly -X- _ O
- -X- _ O
supervised -X- _ O
dataset -X- _ O
of -X- _ O
1.2 -X- _ O
M -X- _ O
samples -X- _ O
, -X- _ O
derived -X- _ O
from -X- _ O
the -X- _ O
MQR -X- _ B-DatasetName
corpus -X- _ O
( -X- _ O
Chu -X- _ O
et -X- _ O
al -X- _ O
. -X- _ O
, -X- _ O
2020 -X- _ O
) -X- _ O
, -X- _ O
which -X- _ O
provides -X- _ O
tuples -X- _ O
of -X- _ O
ill -X- _ O
- -X- _ O
formed -X- _ O
and -X- _ O
well -X- _ O
- -X- _ O
formed -X- _ O
questions -X- _ O
( -X- _ O
c.f -X- _ O
. -X- _ O
§ -X- _ O
D -X- _ O
) -X- _ O
. -X- _ O

To -X- _ O
construct -X- _ O
input -X- _ O
tuples -X- _ O
⟨p -X- _ O
, -X- _ O
q⟩ -X- _ O
for -X- _ O
pre -X- _ O
- -X- _ O
training -X- _ O
F -X- _ O
, -X- _ O
from -X- _ O
a -X- _ O
target -X- _ O
question -X- _ O
q -X- _ O
′ -X- _ O
we -X- _ O
derive -X- _ O
p -X- _ O
as -X- _ O
follows -X- _ O
. -X- _ O

Fine -X- _ O
- -X- _ O
Tuning -X- _ O
Data -X- _ O
. -X- _ O
We -X- _ O
sampled -X- _ O
3 -X- _ O
, -X- _ O
851 -X- _ O
questions -X- _ O
and -X- _ O
annotated -X- _ O
reformulations -X- _ O
, -X- _ O
based -X- _ O
on -X- _ O
guidelines -X- _ O
listed -X- _ O
in -X- _ O
§ -X- _ O
E -X- _ O
, -X- _ O
for -X- _ O
all -X- _ O
operators -X- _ O
in -X- _ O
§ -X- _ O
4.2 -X- _ O
. -X- _ O
We -X- _ O
use -X- _ O
10 -X- _ B-HyperparameterValue
% -X- _ I-HyperparameterValue
of -X- _ O
annotated -X- _ O
data -X- _ O
for -X- _ O
validation -X- _ B-HyperparameterName
; -X- _ O
the -X- _ O
rest -X- _ O
is -X- _ O
used -X- _ O
during -X- _ O
the -X- _ O
second -X- _ O
stage -X- _ O
of -X- _ O
training -X- _ O
to -X- _ O
fine -X- _ O
- -X- _ O
tune -X- _ O
F -X- _ O
. -X- _ O

We -X- _ O
now -X- _ O
turn -X- _ O
to -X- _ O
a -X- _ O
discussion -X- _ O
of -X- _ O
the -X- _ O
results -X- _ O
for -X- _ O
the -X- _ O
intrinsic -X- _ O
( -X- _ O
accuracy -X- _ B-MetricName
) -X- _ O
and -X- _ O
extrinsic -X- _ O
( -X- _ O
answer -X- _ B-MetricName
rate -X- _ I-MetricName
and -X- _ O
relevance -X- _ B-MetricName
) -X- _ O
evaluation -X- _ O
strategies -X- _ O
. -X- _ O
Table -X- _ O
1 -X- _ O
shows -X- _ O
the -X- _ O
human -X- _ O
evaluation -X- _ O
results -X- _ O
for -X- _ O
reformulation -X- _ B-MetricName
accuracy -X- _ I-MetricName
. -X- _ O
The -X- _ O
best -X- _ O
accuracy -X- _ O
is -X- _ O
achieved -X- _ O
for -X- _ O
GEN -X- _ B-MethodName
, -X- _ O
with -X- _ O
83 -X- _ B-MetricValue
% -X- _ I-MetricValue
of -X- _ O
the -X- _ O
reformulations -X- _ O
being -X- _ O
accurate -X- _ O
. -X- _ O
This -X- _ O
is -X- _ O
because -X- _ O
GEN -X- _ B-MethodName
does -X- _ O
not -X- _ O
require -X- _ O
changing -X- _ O
the -X- _ O
question -X- _ O
type -X- _ O
like -X- _ O
ROO -X- _ B-MethodName
. -X- _ O

REP -X- _ B-MethodName
achieves -X- _ O
second -X- _ O
best -X- _ O
accuracy -X- _ B-MetricName
. -X- _ O
One -X- _ O
reason -X- _ O
for -X- _ O
the -X- _ O
slightly -X- _ O
lower -X- _ O
accuracy -X- _ B-MetricName
than -X- _ O
GEN -X- _ B-MethodName
, -X- _ O
is -X- _ O
that -X- _ O
it -X- _ O
sometimes -X- _ O
changes -X- _ O
the -X- _ O
question -X- _ O
type -X- _ O
( -X- _ O
e.g. -X- _ O
request -X- _ O
to -X- _ O
root -X- _ O
) -X- _ O
, -X- _ O
which -X- _ O
goes -X- _ O
beyond -X- _ O
the -X- _ O
REP -X- _ B-MethodName
's -X- _ O
reformulation -X- _ O
scope -X- _ O
. -X- _ O
Although -X- _ O
according -X- _ O
to -X- _ O
our -X- _ O
intrinsic -X- _ O
evaluation -X- _ O
strategy -X- _ O
such -X- _ O
cases -X- _ O
represent -X- _ O
inaccurate -X- _ O
reformulation -X- _ O
, -X- _ O
in -X- _ O
practice -X- _ O
this -X- _ O
is -X- _ O
benign -X- _ O
as -X- _ O
QA -X- _ B-TaskName
systems -X- _ O
perform -X- _ O
very -X- _ O
well -X- _ O
on -X- _ O
root -X- _ O
factoid -X- _ O
questions -X- _ O
. -X- _ O

Finally -X- _ O
, -X- _ O
we -X- _ O
note -X- _ O
that -X- _ O
reformulations -X- _ O
significantly -X- _ O
shorten -X- _ O
the -X- _ O
input -X- _ O
questions -X- _ O
and -X- _ O
result -X- _ O
in -X- _ O
higher -X- _ O
type -X- _ B-MetricName
- -X- _ I-MetricName
token -X- _ I-MetricName
ratio -X- _ I-MetricName
( -X- _ O
Appendix -X- _ O
H -X- _ O
) -X- _ O
. -X- _ O
We -X- _ O
list -X- _ O
many -X- _ O
examples -X- _ O
of -X- _ O
model -X- _ O
input -X- _ O
/ -X- _ O
output -X- _ O
pairs -X- _ O
in -X- _ O
Appendix -X- _ O
I. -X- _ O
6 -X- _ O
Live -X- _ O
deployment -X- _ O
latency -X- _ O
requirements -X- _ O
prohibit -X- _ O
producing -X- _ O
all -X- _ O
possible -X- _ O
reformulations -X- _ O
and -X- _ O
running -X- _ O
through -X- _ O
a -X- _ O
QA -X- _ B-TaskName
system -X- _ O
; -X- _ O
therefore -X- _ O
we -X- _ O
try -X- _ O
to -X- _ O
determine -X- _ O
the -X- _ O
best -X- _ O
single -X- _ O
operator -X- _ O
p -X- _ O
offline -X- _ O
. -X- _ O

Our -X- _ O
large -X- _ O
weakly -X- _ O
supervised -X- _ O
⟨q -X- _ O
, -X- _ O
q -X- _ O
′ -X- _ O
⟩ -X- _ O
data -X- _ O
enables -X- _ O
learning -X- _ O
the -X- _ O
REP -X- _ B-MethodName
and -X- _ O
ROO -X- _ B-MethodName
operations -X- _ O
, -X- _ O
leading -X- _ O
to -X- _ O
an -X- _ O
answer -X- _ B-MetricName
rate -X- _ I-MetricName
improvement -X- _ O
for -X- _ O
SURF -X- _ B-MethodName
- -X- _ I-MethodName
ROO -X- _ I-MethodName
with -X- _ O
13.18 -X- _ B-MetricValue
% -X- _ I-MetricValue
over -X- _ O
the -X- _ O
Baseline -X- _ O
of -X- _ O
9.26 -X- _ B-MetricValue
% -X- _ I-MetricValue
( -X- _ O
a -X- _ O
3.92 -X- _ B-MetricValue
% -X- _ I-MetricValue
absolute -X- _ O
improvement -X- _ O
) -X- _ O
. -X- _ O
Figure -X- _ O
2 -X- _ O
shows -X- _ O
a -X- _ O
breakdown -X- _ O
of -X- _ O
the -X- _ O
impact -X- _ O
of -X- _ O
the -X- _ O
operators -X- _ O
by -X- _ O
question -X- _ O
type -X- _ O
. -X- _ O

Impact -X- _ O
of -X- _ O
Speech -X- _ O
Errors -X- _ O
: -X- _ O
the -X- _ O
REP -X- _ B-MethodName
operation -X- _ O
, -X- _ O
which -X- _ O
performs -X- _ O
correction -X- _ O
and -X- _ O
makes -X- _ O
question -X- _ O
more -X- _ O
formal -X- _ O
, -X- _ O
shows -X- _ O
a -X- _ O
consistent -X- _ O
answer -X- _ B-MetricName
rate -X- _ I-MetricName
improvement -X- _ O
across -X- _ O
all -X- _ O
tasks -X- _ O
and -X- _ O
models -X- _ O
, -X- _ O
improving -X- _ O
it -X- _ O
by -X- _ O
9.4 -X- _ B-MetricValue
% -X- _ I-MetricValue
. -X- _ O
This -X- _ O
demonstrated -X- _ O
that -X- _ O
for -X- _ O
many -X- _ O
questions -X- _ O
speech -X- _ O
errors -X- _ O
and -X- _ O
framing -X- _ O
cause -X- _ O
retrieval -X- _ O
failure -X- _ O
. -X- _ O
In -X- _ O
Figure -X- _ O
2 -X- _ O
we -X- _ O
note -X- _ O
that -X- _ O
REP -X- _ B-MethodName
provides -X- _ O
a -X- _ O
consistent -X- _ O
improvement -X- _ O
across -X- _ O
all -X- _ O
question -X- _ O
types -X- _ O
. -X- _ O
This -X- _ O
improvement -X- _ O
is -X- _ O
intuitive -X- _ O
given -X- _ O
that -X- _ O
a -X- _ O
core -X- _ O
component -X- _ O
of -X- _ O
QA -X- _ B-TaskName
systems -X- _ O
is -X- _ O
their -X- _ O
ability -X- _ O
to -X- _ O
understand -X- _ O
questions -X- _ O
before -X- _ O
answering -X- _ O
, -X- _ O
hence -X- _ O
any -X- _ O
speech -X- _ O
or -X- _ O
syntactic -X- _ O
errors -X- _ O
negatively -X- _ O
impact -X- _ O
answering -X- _ O
. -X- _ O

Impact -X- _ O
of -X- _ O
Root -X- _ O
Transformation -X- _ O
: -X- _ O
the -X- _ O
ROO -X- _ B-MethodName
operation -X- _ O
repairs -X- _ O
and -X- _ O
reformulates -X- _ O
the -X- _ O
question -X- _ O
to -X- _ O
its -X- _ O
root -X- _ O
form -X- _ O
. -X- _ O
It -X- _ O
shows -X- _ O
better -X- _ O
performance -X- _ O
than -X- _ O
REP -X- _ B-MethodName
, -X- _ O
although -X- _ O
it -X- _ O
may -X- _ O
change -X- _ O
the -X- _ O
original -X- _ O
question -X- _ O
type -X- _ O
. -X- _ O
For -X- _ O
SURF -X- _ B-MethodName
, -X- _ O
the -X- _ O
improvement -X- _ O
of -X- _ O
ROO -X- _ B-MethodName
over -X- _ O
REP -X- _ B-MethodName
are -X- _ O
with -X- _ O
3.77 -X- _ B-MetricValue
% -X- _ I-MetricValue
, -X- _ O
contrary -X- _ O
for -X- _ O
baseline -X- _ O
where -X- _ O
the -X- _ O
improvement -X- _ O
is -X- _ O
only -X- _ O
1.16 -X- _ B-MetricValue
% -X- _ I-MetricValue
. -X- _ O
This -X- _ O
further -X- _ O
highlights -X- _ O
the -X- _ O
importance -X- _ O
of -X- _ O
the -X- _ O
pre -X- _ O
- -X- _ O
training -X- _ O
stage -X- _ O
for -X- _ O
SURF -X- _ B-MethodName
. -X- _ O

Impact -X- _ O
of -X- _ O
Generalization -X- _ O
: -X- _ O
the -X- _ O
GEN -X- _ B-MethodName
operation -X- _ O
repairs -X- _ O
and -X- _ O
generalizes -X- _ O
the -X- _ O
original -X- _ O
question -X- _ O
to -X- _ O
be -X- _ O
less -X- _ O
specific -X- _ O
. -X- _ O
For -X- _ O
SURF -X- _ B-MethodName
, -X- _ O
GEN -X- _ B-MethodName
obtains -X- _ O
4.93 -X- _ B-MetricValue
% -X- _ I-MetricValue
absolute -X- _ O
improvement -X- _ O
over -X- _ O
REP -X- _ B-MethodName
in -X- _ O
terms -X- _ O
of -X- _ O
answer -X- _ B-MetricName
rate -X- _ I-MetricName
, -X- _ O
similar -X- _ O
is -X- _ O
improvement -X- _ O
for -X- _ O
the -X- _ O
baseline -X- _ O
with -X- _ O
5.19 -X- _ B-MetricValue
% -X- _ I-MetricValue
( -X- _ O
cf -X- _ O
. -X- _ O
Table -X- _ O
2 -X- _ O
) -X- _ O
. -X- _ O
As -X- _ O
we -X- _ O
show -X- _ O
in -X- _ O
§ -X- _ O
6.3 -X- _ O
, -X- _ O
most -X- _ O
of -X- _ O
the -X- _ O
provided -X- _ O
answers -X- _ O
to -X- _ O
the -X- _ O
generalized -X- _ O
questions -X- _ O
are -X- _ O
in -X- _ O
fact -X- _ O
relevant -X- _ O
to -X- _ O
the -X- _ O
original -X- _ O
question -X- _ O
's -X- _ O
intent -X- _ O
. -X- _ O

ROO+GEN -X- _ B-MethodName
achieves -X- _ O
the -X- _ O
best -X- _ O
performance -X- _ O
across -X- _ O
all -X- _ O
tasks -X- _ O
. -X- _ O
This -X- _ O
is -X- _ O
intuitive -X- _ O
as -X- _ O
questions -X- _ O
are -X- _ O
first -X- _ O
corrected -X- _ O
for -X- _ O
possible -X- _ O
errors -X- _ O
, -X- _ O
then -X- _ O
converted -X- _ O
into -X- _ O
a -X- _ O
root -X- _ O
wh -X- _ O
- -X- _ O
structure -X- _ O
, -X- _ O
after -X- _ O
which -X- _ O
high -X- _ O
specificity -X- _ O
elements -X- _ O
are -X- _ O
dropped -X- _ O
to -X- _ O
construct -X- _ O
a -X- _ O
more -X- _ O
generic -X- _ O
question -X- _ O
( -X- _ O
cf -X- _ O
. -X- _ O
Figure -X- _ O
1 -X- _ O
, -X- _ O
Q7 -X- _ O
, -X- _ O
Q8 -X- _ O
, -X- _ O
Q9 -X- _ O
) -X- _ O
. -X- _ O
SURF -X- _ B-MethodName
- -X- _ I-MethodName
ROO+GEN -X- _ I-MethodName
only -X- _ O
has -X- _ O
an -X- _ O
8 -X- _ B-MetricValue
% -X- _ I-MetricValue
gap -X- _ O
to -X- _ O
the -X- _ O
OPTIMAL -X- _ B-MethodName
performance -X- _ O
. -X- _ O
Figure -X- _ O
2 -X- _ O
shows -X- _ O
that -X- _ O
for -X- _ O
all -X- _ O
question -X- _ O
types -X- _ O
, -X- _ O
ROO+GEN -X- _ B-MethodName
obtains -X- _ O
the -X- _ O
highest -X- _ O
improvement -X- _ O
in -X- _ O
answer -X- _ B-MetricName
rate -X- _ I-MetricName
. -X- _ O
Comparing -X- _ O
the -X- _ O
answer -X- _ B-MetricName
rates -X- _ I-MetricName
of -X- _ O
ROO+GEN -X- _ B-MethodName
and -X- _ O
OPTIMAL -X- _ B-MethodName
we -X- _ O
make -X- _ O
an -X- _ O
interesting -X- _ O
observation -X- _ O
: -X- _ O
although -X- _ O
ROO+GEN -X- _ B-MethodName
combines -X- _ O
all -X- _ O
operators -X- _ O
in -X- _ O
p -X- _ O
, -X- _ O
its -X- _ O
answer -X- _ B-MetricName
rate -X- _ I-MetricName
is -X- _ O
still -X- _ O
lower -X- _ O
than -X- _ O
OPTIMAL -X- _ B-MethodName
. -X- _ O
This -X- _ O
shows -X- _ O
that -X- _ O
applying -X- _ O
all -X- _ O
operators -X- _ O
is -X- _ O
not -X- _ O
desirable -X- _ O
for -X- _ O
all -X- _ O
questions -X- _ O
. -X- _ O
However -X- _ O
, -X- _ O
in -X- _ O
practical -X- _ O
settings -X- _ O
, -X- _ O
processing -X- _ O
questions -X- _ O
separately -X- _ O
with -X- _ O
all -X- _ O
operators -X- _ O
is -X- _ O
not -X- _ O
feasible -X- _ O
due -X- _ O
to -X- _ O
the -X- _ O
induced -X- _ O
generation -X- _ O
and -X- _ O
QA -X- _ B-TaskName
latency -X- _ O
. -X- _ O
Hence -X- _ O
, -X- _ O
our -X- _ O
proposed -X- _ O
solution -X- _ O
represents -X- _ O
a -X- _ O
trade -X- _ O
- -X- _ O
off -X- _ O
between -X- _ O
deployment -X- _ O
feasibility -X- _ O
and -X- _ O
improvement -X- _ O
in -X- _ O
answer -X- _ B-MetricName
rate -X- _ I-MetricName
. -X- _ O

It -X- _ O
is -X- _ O
important -X- _ O
to -X- _ O
consider -X- _ O
if -X- _ O
the -X- _ O
provided -X- _ O
answers -X- _ O
to -X- _ O
previously -X- _ O
unanswered -X- _ O
questions -X- _ O
are -X- _ O
relevant -X- _ O
to -X- _ O
the -X- _ O
user -X- _ O
's -X- _ O
information -X- _ O
need -X- _ O
. -X- _ O
Since -X- _ O
SURF -X- _ B-MethodName
performs -X- _ O
numerous -X- _ O
syntactic -X- _ O
and -X- _ O
semantic -X- _ O
changes -X- _ O
, -X- _ O
there -X- _ O
is -X- _ O
a -X- _ O
risk -X- _ O
that -X- _ O
the -X- _ O
reformulated -X- _ O
questions -X- _ O
will -X- _ O
result -X- _ O
in -X- _ O
answers -X- _ O
that -X- _ O
are -X- _ O
not -X- _ O
related -X- _ O
to -X- _ O
the -X- _ O
user -X- _ O
's -X- _ O
intent -X- _ O
. -X- _ O

The -X- _ O
SURF -X- _ B-MethodName
- -X- _ I-MethodName
ROO -X- _ I-MethodName
model -X- _ O
7 -X- _ O
was -X- _ O
deployed -X- _ O
for -X- _ O
real -X- _ O
- -X- _ O
time -X- _ O
reformulation -X- _ O
of -X- _ O
unanswered -X- _ O
questions -X- _ O
in -X- _ O
a -X- _ O
leading -X- _ O
voice -X- _ O
assistant -X- _ O
. -X- _ O
This -X- _ O
live -X- _ O
deployment -X- _ O
enables -X- _ O
answering -X- _ O
for -X- _ O
millions -X- _ O
of -X- _ O
previously -X- _ O
unanswered -X- _ O
requests -X- _ O
. -X- _ O
Each -X- _ O
day -X- _ O
we -X- _ O
solicit -X- _ O
explicit -X- _ O
binary -X- _ O
relevance -X- _ O
feedback -X- _ O
from -X- _ O
a -X- _ O
portion -X- _ O
of -X- _ O
customers -X- _ O
receiving -X- _ O
answers -X- _ O
of -X- _ O
SURF -X- _ B-MethodName
reformulations -X- _ O
, -X- _ O
with -X- _ O
metrics -X- _ O
exceeding -X- _ O
or -X- _ O
matching -X- _ O
those -X- _ O
reported -X- _ O
in -X- _ O
Table -X- _ O
1 -X- _ O
. -X- _ O

We -X- _ O
tackled -X- _ O
the -X- _ O
problem -X- _ O
of -X- _ O
improving -X- _ O
spoken -X- _ B-TaskName
QA -X- _ I-TaskName
, -X- _ O
and -X- _ O
analyzed -X- _ O
questions -X- _ O
from -X- _ O
live -X- _ O
data -X- _ O
to -X- _ O
identify -X- _ O
key -X- _ O
challenges -X- _ O
that -X- _ O
could -X- _ O
be -X- _ O
addressed -X- _ O
with -X- _ O
reformulation -X- _ O
. -X- _ O
Based -X- _ O
on -X- _ O
this -X- _ O
we -X- _ O
proposed -X- _ O
SURF -X- _ B-MethodName
with -X- _ O
novel -X- _ O
linguistically -X- _ O
- -X- _ O
motivated -X- _ O
reformulation -X- _ O
operators -X- _ O
to -X- _ O
solve -X- _ O
the -X- _ O
identified -X- _ O
challenges -X- _ O
. -X- _ O
Offline -X- _ O
experiments -X- _ O
show -X- _ O
the -X- _ O
effectiveness -X- _ O
of -X- _ O
our -X- _ O
novel -X- _ O
root -X- _ O
transformation -X- _ O
and -X- _ O
generalization -X- _ O
operations -X- _ O
, -X- _ O
with -X- _ O
up -X- _ O
to -X- _ O
24 -X- _ B-MetricValue
% -X- _ I-MetricValue
of -X- _ O
unanswered -X- _ O
questions -X- _ O
being -X- _ O
answered -X- _ O
via -X- _ O
reformulations -X- _ O
with -X- _ O
high -X- _ O
answer -X- _ B-MetricName
relevance -X- _ I-MetricName
. -X- _ O
Live -X- _ O
deployment -X- _ O
in -X- _ O
a -X- _ O
leading -X- _ O
voice -X- _ O
assistant -X- _ O
has -X- _ O
positively -X- _ O
impacted -X- _ O
millions -X- _ O
of -X- _ O
requests -X- _ O
. -X- _ O

We -X- _ O
showed -X- _ O
reformulation -X- _ O
helps -X- _ O
QA -X- _ B-TaskName
systems -X- _ O
adapt -X- _ O
to -X- _ O
spoken -X- _ O
user -X- _ O
questions -X- _ O
. -X- _ O
We -X- _ O
presented -X- _ O
key -X- _ O
insights -X- _ O
from -X- _ O
a -X- _ O
deployed -X- _ O
solution -X- _ O
showing -X- _ O
that -X- _ O
performance -X- _ O
can -X- _ O
be -X- _ O
significantly -X- _ O
increased -X- _ O
, -X- _ O
without -X- _ O
changing -X- _ O
the -X- _ O
underlying -X- _ O
QA -X- _ B-TaskName
backends -X- _ O
, -X- _ O
by -X- _ O
simply -X- _ O
improving -X- _ O
questions -X- _ O
in -X- _ O
their -X- _ O
syntax -X- _ O
and -X- _ O
semantics -X- _ O
. -X- _ O

In -X- _ O
this -X- _ O
work -X- _ O
we -X- _ O
did -X- _ O
not -X- _ O
consider -X- _ O
the -X- _ O
following -X- _ O
aspects -X- _ O
, -X- _ O
which -X- _ O
we -X- _ O
discuss -X- _ O
below -X- _ O
and -X- _ O
lay -X- _ O
out -X- _ O
directions -X- _ O
for -X- _ O
how -X- _ O
to -X- _ O
address -X- _ O
them -X- _ O
in -X- _ O
future -X- _ O
work -X- _ O
. -X- _ O

• -X- _ O
Root -X- _ O
: -X- _ O
a -X- _ O
question -X- _ O
which -X- _ O
starts -X- _ O
with -X- _ O
a -X- _ O
wh- -X- _ O
* -X- _ O
or -X- _ O
some -X- _ O
specific -X- _ O
how -X- _ O
- -X- _ O
bigrams -X- _ O
. -X- _ O

• -X- _ O
Polar -X- _ O
: -X- _ O
A -X- _ O
yes -X- _ O
or -X- _ O
no -X- _ O
question -X- _ O
starting -X- _ O
with -X- _ O
predefined -X- _ O
keywords -X- _ O
. -X- _ O

• -X- _ O
Open -X- _ O
: -X- _ O
Start -X- _ O
with -X- _ O
how -X- _ O
, -X- _ O
but -X- _ O
not -X- _ O
a -X- _ O
root -X- _ O
question -X- _ O
. -X- _ O

One -X- _ O
limitation -X- _ O
of -X- _ O
the -X- _ O
current -X- _ O
representation -X- _ O
is -X- _ O
the -X- _ O
absence -X- _ O
of -X- _ O
temporal -X- _ O
placement -X- _ O
of -X- _ O
objects -X- _ O
in -X- _ O
time -X- _ O
. -X- _ O

Crises -X- _ O
such -X- _ O
as -X- _ O
the -X- _ O
COVID-19 -X- _ O
pandemic -X- _ O
continuously -X- _ O
threaten -X- _ O
our -X- _ O
world -X- _ O
and -X- _ O
emotionally -X- _ O
affect -X- _ O
billions -X- _ O
of -X- _ O
people -X- _ O
worldwide -X- _ O
in -X- _ O
distinct -X- _ O
ways -X- _ O
. -X- _ O
Understanding -X- _ O
the -X- _ O
triggers -X- _ O
leading -X- _ O
to -X- _ O
people -X- _ O
's -X- _ O
emotions -X- _ O
is -X- _ O
of -X- _ O
crucial -X- _ O
importance -X- _ O
. -X- _ O
Social -X- _ O
media -X- _ O
posts -X- _ O
can -X- _ O
be -X- _ O
a -X- _ O
good -X- _ O
source -X- _ O
of -X- _ O
such -X- _ O
analysis -X- _ O
, -X- _ O
yet -X- _ O
these -X- _ O
texts -X- _ O
tend -X- _ O
to -X- _ O
be -X- _ O
charged -X- _ O
with -X- _ O
multiple -X- _ O
emotions -X- _ O
, -X- _ O
with -X- _ O
triggers -X- _ O
scattering -X- _ O
across -X- _ O
multiple -X- _ O
sentences -X- _ O
. -X- _ O
This -X- _ O
paper -X- _ O
takes -X- _ O
a -X- _ O
novel -X- _ O
angle -X- _ O
, -X- _ O
namely -X- _ O
, -X- _ O
emotion -X- _ B-TaskName
detection -X- _ I-TaskName
and -X- _ I-TaskName
trigger -X- _ I-TaskName
summarization -X- _ I-TaskName
, -X- _ O
aiming -X- _ O
to -X- _ O
both -X- _ O
detect -X- _ O
perceived -X- _ O
emotions -X- _ O
in -X- _ O
text -X- _ O
, -X- _ O
and -X- _ O
summarize -X- _ O
events -X- _ O
and -X- _ O
their -X- _ O
appraisals -X- _ O
that -X- _ O
trigger -X- _ O
each -X- _ O
emotion -X- _ O
. -X- _ O
To -X- _ O
support -X- _ O
this -X- _ O
goal -X- _ O
, -X- _ O
we -X- _ O
introduce -X- _ O
COVIDET -X- _ B-DatasetName
( -X- _ O
Emotions -X- _ B-DatasetName
and -X- _ I-DatasetName
their -X- _ I-DatasetName
Triggers -X- _ I-DatasetName
during -X- _ I-DatasetName
Covid-19 -X- _ I-DatasetName
) -X- _ O
, -X- _ O
a -X- _ O
dataset -X- _ O
of~1 -X- _ O
, -X- _ O
900 -X- _ O
English -X- _ O
Reddit -X- _ O
posts -X- _ O
related -X- _ O
to -X- _ O
COVID-19 -X- _ O
, -X- _ O
which -X- _ O
contains -X- _ O
manual -X- _ O
annotations -X- _ O
of -X- _ O
perceived -X- _ O
emotions -X- _ O
and -X- _ O
abstractive -X- _ O
summaries -X- _ O
of -X- _ O
their -X- _ O
triggers -X- _ O
described -X- _ O
in -X- _ O
the -X- _ O
post -X- _ O
. -X- _ O
We -X- _ O
develop -X- _ O
strong -X- _ O
baselines -X- _ O
to -X- _ O
jointly -X- _ O
detect -X- _ B-TaskName
emotions -X- _ I-TaskName
and -X- _ I-TaskName
summarize -X- _ I-TaskName
emotion -X- _ I-TaskName
triggers -X- _ I-TaskName
. -X- _ O
Our -X- _ O
analyses -X- _ O
show -X- _ O
that -X- _ O
COVIDET -X- _ B-DatasetName
presents -X- _ O
new -X- _ O
challenges -X- _ O
in -X- _ O
emotion -X- _ B-TaskName
- -X- _ I-TaskName
specific -X- _ I-TaskName
summarization -X- _ I-TaskName
, -X- _ O
as -X- _ O
well -X- _ O
as -X- _ O
multi -X- _ B-DatasetName
- -X- _ I-DatasetName
emotion -X- _ I-DatasetName
detection -X- _ I-DatasetName
in -X- _ O
long -X- _ O
social -X- _ O
media -X- _ O
posts -X- _ O
. -X- _ O
* -X- _ O
Hongli -X- _ O
Zhan -X- _ O
and -X- _ O
Tiberiu -X- _ O
Sosea -X- _ O
contributed -X- _ O
equally -X- _ O
. -X- _ O
Reddit -X- _ O
Post -X- _ O
1 -X- _ O
: -X- _ O
My -X- _ O
sibling -X- _ O
is -X- _ O
19 -X- _ O
and -X- _ O
she -X- _ O
constantly -X- _ O
goes -X- _ O
places -X- _ O
with -X- _ O
her -X- _ O
friends -X- _ O
and -X- _ O
to -X- _ O
there -X- _ O
houses -X- _ O
and -X- _ O
its -X- _ O
honestly -X- _ O
stressing -X- _ O
me -X- _ O
out -X- _ O
. -X- _ O
2 -X- _ O
: -X- _ O
Our -X- _ O
grandfather -X- _ O
lives -X- _ O
with -X- _ O
us -X- _ O
and -X- _ O
he -X- _ O
has -X- _ O
dementia -X- _ O
along -X- _ O
with -X- _ O
other -X- _ O
health -X- _ O
issues -X- _ O
and -X- _ O
my -X- _ O
mom -X- _ O
has -X- _ O
diabetes -X- _ O
and -X- _ O
heart -X- _ O
problems -X- _ O
and -X- _ O
I -X- _ O
have -X- _ O
autoimmune -X- _ O
diseases -X- _ O
& -X- _ O
chronic -X- _ O
health -X- _ O
issues -X- _ O
. -X- _ O
3 -X- _ O
: -X- _ O
She -X- _ O
also -X- _ O
has -X- _ O
asthma -X- _ O
. -X- _ O
4 -X- _ O
: -X- _ O
Its -X- _ O
stressing -X- _ O
me -X- _ O
out -X- _ O
because -X- _ O
despite -X- _ O
this -X- _ O
she -X- _ O
seems -X- _ O
to -X- _ O
not -X- _ O
care -X- _ O
about -X- _ O
how -X- _ O
badly -X- _ O
it -X- _ O
would -X- _ O
affect -X- _ O
all -X- _ O
of -X- _ O
us -X- _ O
if -X- _ O
we -X- _ O
were -X- _ O
to -X- _ O
get -X- _ O
the -X- _ O
virus -X- _ O
. -X- _ O
5 -X- _ O
: -X- _ O
And -X- _ O
sadly -X- _ O
I -X- _ O
feel -X- _ O
like -X- _ O
its -X- _ O
not -X- _ O
much -X- _ O
I -X- _ O
can -X- _ O
do -X- _ O
she -X- _ O
literally -X- _ O
does -X- _ O
n't -X- _ O
respect -X- _ O
my -X- _ O
mom -X- _ O
and -X- _ O
though -X- _ O
I -X- _ O
'm -X- _ O
older -X- _ O
she -X- _ O
does -X- _ O
n't -X- _ O
respect -X- _ O
me -X- _ O
either -X- _ O
. -X- _ O
6 -X- _ O
: -X- _ O
Its -X- _ O
so -X- _ O
frustrating -X- _ O
. -X- _ O

We -X- _ O
further -X- _ O
examine -X- _ O
the -X- _ O
similarity -X- _ O
in -X- _ O
the -X- _ O
annotated -X- _ O
summaries -X- _ O
of -X- _ O
triggers -X- _ O
when -X- _ O
two -X- _ O
annotators -X- _ O
both -X- _ O
select -X- _ O
the -X- _ O
same -X- _ O
emotion -X- _ O
for -X- _ O
one -X- _ O
example -X- _ O
, -X- _ O
using -X- _ O
ROUGE -X- _ B-MetricName
( -X- _ O
Lin -X- _ O
, -X- _ O
2004 -X- _ O
) -X- _ O
for -X- _ O
lexical -X- _ O
overlap -X- _ O
and -X- _ O
BERTScore -X- _ B-MetricName
( -X- _ O
Zhang -X- _ O
et -X- _ O
al -X- _ O
. -X- _ O
, -X- _ O
2019 -X- _ O
) -X- _ O
for -X- _ O
semantic -X- _ O
similarity -X- _ O
. -X- _ O
The -X- _ O
average -X- _ O
BERTScore -X- _ B-MetricName
( -X- _ I-MetricName
F1 -X- _ I-MetricName
) -X- _ I-MetricName
between -X- _ O
the -X- _ O
two -X- _ O
annotators -X- _ O
is -X- _ O
0.883 -X- _ B-MetricValue
, -X- _ O
indicating -X- _ O
highly -X- _ O
similar -X- _ O
summaries -X- _ O
. -X- _ O
Yet -X- _ O
the -X- _ O
lexical -X- _ O
overlap -X- _ O
is -X- _ O
low -X- _ O
: -X- _ O
the -X- _ O
average -X- _ B-MetricName
ROUGE -X- _ I-MetricName
F -X- _ I-MetricName
scores -X- _ O
between -X- _ O
two -X- _ O
annotators -X- _ O
are -X- _ O
: -X- _ O
ROUGE-1 -X- _ B-MetricName
: -X- _ O
0.255 -X- _ B-MetricValue
, -X- _ O
ROUGE-2 -X- _ B-MetricName
: -X- _ O
0.055 -X- _ B-MetricValue
, -X- _ O
ROUGE -X- _ B-MetricName
- -X- _ I-MetricName
L -X- _ I-MetricName
: -X- _ O
0.190 -X- _ B-MetricValue
. -X- _ O

For -X- _ O
those -X- _ O
posts -X- _ O
doubly -X- _ O
annotated -X- _ O
by -X- _ O
linguistics -X- _ O
students -X- _ O
and -X- _ O
crowd -X- _ O
workers -X- _ O
, -X- _ O
the -X- _ O
ROUGE -X- _ B-MetricName
values -X- _ O
are -X- _ O
similar -X- _ O
for -X- _ O
students -X- _ O
vs. -X- _ O
workers -X- _ O
: -X- _ O
BERTScore -X- _ B-MetricName
: -X- _ O
0.876 -X- _ B-MetricValue
; -X- _ O
ROUGE-1 -X- _ B-MetricName
: -X- _ O
0.246 -X- _ B-MetricValue
, -X- _ O
ROUGE-2 -X- _ B-MetricName
: -X- _ O
0.063 -X- _ B-MetricValue
, -X- _ O
ROUGE -X- _ B-MetricName
- -X- _ I-MetricName
L -X- _ I-MetricName
: -X- _ O
0.188 -X- _ B-MetricValue
. -X- _ O
3 -X- _ O

We -X- _ O
describe -X- _ O
the -X- _ O
validation -X- _ O
framework -X- _ O
as -X- _ O
follows -X- _ O
. -X- _ O
The -X- _ O
validators -X- _ O
are -X- _ O
given -X- _ O
an -X- _ O
annotated -X- _ O
trigger -X- _ O
summary -X- _ O
. -X- _ O
We -X- _ O
first -X- _ O
validate -X- _ O
whether -X- _ O
the -X- _ O
summary -X- _ O
actually -X- _ O
indicates -X- _ O
the -X- _ O
annotated -X- _ O
emotion -X- _ O
by -X- _ O
asking -X- _ O
a -X- _ O
yes -X- _ O
/ -X- _ O
no -X- _ O
question -X- _ O
. -X- _ O
Next -X- _ O
, -X- _ O
if -X- _ O
the -X- _ O
validator -X- _ O
confirms -X- _ O
the -X- _ O
presence -X- _ O
of -X- _ O
emotion -X- _ O
in -X- _ O
the -X- _ O
summary -X- _ O
, -X- _ O
we -X- _ O
then -X- _ O
ask -X- _ O
whether -X- _ O
the -X- _ O
summary -X- _ O
indeed -X- _ O
expresses -X- _ O
the -X- _ O
trigger -X- _ O
and -X- _ O
not -X- _ O
the -X- _ O
emotion -X- _ O
by -X- _ O
raising -X- _ O
another -X- _ O
yes -X- _ O
/ -X- _ O
no -X- _ O
question -X- _ O
. -X- _ O
We -X- _ O
present -X- _ O
the -X- _ O
validation -X- _ O
results -X- _ O
based -X- _ O
on -X- _ O
the -X- _ O
abstractive -X- _ O
summaries -X- _ O
in -X- _ O
Table -X- _ O
1 -X- _ O
et -X- _ O
al -X- _ O
. -X- _ O
, -X- _ O
2003 -X- _ O
) -X- _ O
. -X- _ O
The -X- _ O
words -X- _ O
are -X- _ O
associated -X- _ O
with -X- _ O
the -X- _ O
most -X- _ O
prominent -X- _ O
topic -X- _ O
among -X- _ O
the -X- _ O
abstractive -X- _ O
summaries -X- _ O
of -X- _ O
triggers -X- _ O
of -X- _ O
each -X- _ O
emotion -X- _ O
category -X- _ O
in -X- _ O
COVIDET -X- _ B-DatasetName
. -X- _ O
be -X- _ O
noted -X- _ O
that -X- _ O
annotators -X- _ O
commonly -X- _ O
adopt -X- _ O
some -X- _ O
sentence -X- _ O
patterns -X- _ O
that -X- _ O
can -X- _ O
be -X- _ O
easily -X- _ O
identified -X- _ O
as -X- _ O
emotion -X- _ O
triggers -X- _ O
. -X- _ O
For -X- _ O
example -X- _ O
, -X- _ O
in -X- _ O
expressing -X- _ O
the -X- _ O
abstractive -X- _ O
trigger -X- _ O
for -X- _ O
anger -X- _ O
, -X- _ O
an -X- _ O
annotation -X- _ O
in -X- _ O
COVIDET -X- _ B-DatasetName
is -X- _ O
I -X- _ O
am -X- _ O
angry -X- _ O
that -X- _ O
they -X- _ O
would -X- _ O
put -X- _ O
me -X- _ O
at -X- _ O
risk -X- _ O
of -X- _ O
catching -X- _ O
COVID -X- _ O
and -X- _ O
not -X- _ O
tell -X- _ O
me -X- _ O
, -X- _ O
a -X- _ O
sentence -X- _ O
which -X- _ O
is -X- _ O
highly -X- _ O
linguistically -X- _ O
explicit -X- _ O
of -X- _ O
the -X- _ O
emotion -X- _ O
. -X- _ O

We -X- _ O
present -X- _ O
the -X- _ O
emotion -X- _ O
co -X- _ O
- -X- _ O
occurrence -X- _ O
heatmap -X- _ O
in -X- _ O
Figure -X- _ O
5 -X- _ O
. -X- _ O
Anticipation -X- _ O
co -X- _ O
- -X- _ O
occurs -X- _ O
with -X- _ O
fear -X- _ O
and -X- _ O
anger -X- _ O
most -X- _ O
frequently -X- _ O
in -X- _ O
COVIDET -X- _ B-DatasetName
. -X- _ O
Close -X- _ O
scrutiny -X- _ O
of -X- _ O
the -X- _ O
data -X- _ O
reveals -X- _ O
that -X- _ O
the -X- _ O
poster -X- _ O
is -X- _ O
either -X- _ O
predicting -X- _ O
negative -X- _ O
events -X- _ O
during -X- _ O
COVID-19 -X- _ O
, -X- _ O
or -X- _ O
expecting -X- _ O
advice -X- _ O
on -X- _ O
what -X- _ O
do -X- _ O
do -X- _ O
under -X- _ O
austere -X- _ O
situations -X- _ O
. -X- _ O

We -X- _ O
discuss -X- _ O
our -X- _ O
methods -X- _ O
across -X- _ O
three -X- _ O
main -X- _ O
dimensions -X- _ O
: -X- _ O
emotion -X- _ B-TaskName
detection -X- _ I-TaskName
, -X- _ O
summarization -X- _ B-TaskName
, -X- _ O
and -X- _ O
joint -X- _ B-TaskName
emotion -X- _ I-TaskName
detection -X- _ I-TaskName
and -X- _ I-TaskName
trigger -X- _ I-TaskName
summarization -X- _ I-TaskName
. -X- _ O
( -X- _ O
Desai -X- _ O
et -X- _ O
al -X- _ O
. -X- _ O
, -X- _ O
2020 -X- _ O
) -X- _ O
, -X- _ O
the -X- _ O
same -X- _ O
approach -X- _ O
with -X- _ O
the -X- _ O
model -X- _ O
trained -X- _ O
on -X- _ O
a -X- _ O
Twitter -X- _ O
disaster -X- _ O
dataset -X- _ O
. -X- _ O
Finally -X- _ O
, -X- _ O
we -X- _ O
use -X- _ O
a -X- _ O
4 -X- _ O
) -X- _ O
BERT -X- _ B-MethodName
- -X- _ I-MethodName
large -X- _ I-MethodName
model -X- _ O
fine -X- _ O
- -X- _ O
tuned -X- _ O
on -X- _ O
COVIDET -X- _ B-DatasetName
using -X- _ O
the -X- _ O
[ -X- _ O
CLS -X- _ O
] -X- _ O
token -X- _ O
and -X- _ O
an -X- _ O
additional -X- _ O
linear -X- _ O
layer -X- _ O
to -X- _ O
classify -X- _ O
the -X- _ O
entire -X- _ O
post -X- _ O
. -X- _ O

We -X- _ O
propose -X- _ O
a -X- _ O
joint -X- _ O
model -X- _ O
based -X- _ O
on -X- _ O
BART -X- _ B-MethodName
that -X- _ O
can -X- _ O
be -X- _ O
trained -X- _ O
to -X- _ O
simultaneously -X- _ O
perform -X- _ O
emotion -X- _ B-TaskName
detection -X- _ I-TaskName
and -X- _ I-TaskName
abstractive -X- _ I-TaskName
trigger -X- _ I-TaskName
summarization -X- _ I-TaskName
for -X- _ O
a -X- _ O
particular -X- _ O
emotion -X- _ O
e -X- _ O
using -X- _ O
a -X- _ O
multitasking -X- _ O
framework -X- _ O
. -X- _ O
The -X- _ O
model -X- _ O
follows -X- _ O
the -X- _ O
architecture -X- _ O
of -X- _ O
BART -X- _ B-MethodName
( -X- _ O
Lewis -X- _ O
et -X- _ O
al -X- _ O
. -X- _ O
, -X- _ O
2020 -X- _ O
) -X- _ O
, -X- _ O
where -X- _ O
we -X- _ O
add -X- _ O
a -X- _ O
single -X- _ O
linear -X- _ O
layer -X- _ O
for -X- _ O
emotion -X- _ O
classification -X- _ O
. -X- _ O
We -X- _ O
show -X- _ O
the -X- _ O
architecture -X- _ O
of -X- _ O
our -X- _ O
model -X- _ O
in -X- _ O
Figure -X- _ O
6 -X- _ O
and -X- _ O
detail -X- _ O
our -X- _ O
training -X- _ O
procedure -X- _ O
as -X- _ O
follows -X- _ O
: -X- _ O

and -X- _ O
s -X- _ O
i -X- _ O
is -X- _ O
an -X- _ O
abstractive -X- _ O
summary -X- _ O
of -X- _ O
the -X- _ O
trigger -X- _ O
for -X- _ O
emotion -X- _ O
y -X- _ O
i -X- _ O
and -X- _ O
post -X- _ O
x -X- _ O
i -X- _ O
. -X- _ O
Next -X- _ O
, -X- _ O
we -X- _ O
sample -X- _ O
a -X- _ O
set -X- _ O
of -X- _ O
negative -X- _ O
examples -X- _ O
for -X- _ O
classification -X- _ O
of -X- _ O
the -X- _ O
same -X- _ O
size -X- _ O
as -X- _ O
follows -X- _ O
: -X- _ O

We -X- _ O
carry -X- _ O
out -X- _ O
all -X- _ O
our -X- _ O
experiments -X- _ O
on -X- _ O
an -X- _ O
Nvidia -X- _ O
A5000 -X- _ O
GPU -X- _ O
. -X- _ O
We -X- _ O
use -X- _ O
the -X- _ O
HuggingFace -X- _ O
Transformers -X- _ O
( -X- _ O
Wolf -X- _ O
et -X- _ O
al -X- _ O
. -X- _ O
, -X- _ O
2020 -X- _ O
) -X- _ O
library -X- _ O
for -X- _ O
our -X- _ O
model -X- _ O
implementations -X- _ O
and -X- _ O
we -X- _ O
will -X- _ O
make -X- _ O
the -X- _ O
code -X- _ O
for -X- _ O
our -X- _ O
methods -X- _ O
and -X- _ O
data -X- _ O
available -X- _ O
. -X- _ O
We -X- _ O
report -X- _ O
the -X- _ O
performance -X- _ O
for -X- _ O
emotion -X- _ B-TaskName
detection -X- _ I-TaskName
in -X- _ O
terms -X- _ O
of -X- _ O
F1 -X- _ B-MetricName
and -X- _ O
use -X- _ O
automatic -X- _ O
approaches -X- _ O
such -X- _ O
as -X- _ O
ROUGE -X- _ B-MetricName
( -X- _ O
Lin -X- _ O
, -X- _ O
2004 -X- _ O
) -X- _ O
and -X- _ O
BERTScore -X- _ B-MetricName
( -X- _ O
Zhang -X- _ O
et -X- _ O
al -X- _ O
. -X- _ O
, -X- _ O
2019 -X- _ O
) -X- _ O
to -X- _ O
evaluate -X- _ O
the -X- _ O
summarization -X- _ B-TaskName
performance -X- _ O
. -X- _ O
To -X- _ O
enable -X- _ O
a -X- _ O
fair -X- _ O
comparison -X- _ O
with -X- _ O
the -X- _ O
joint -X- _ O
model -X- _ O
, -X- _ O
for -X- _ O
summarization -X- _ B-TaskName
, -X- _ O
we -X- _ O
only -X- _ O
consider -X- _ O
test -X- _ O
examples -X- _ O
where -X- _ O
the -X- _ O
joint -X- _ O
model -X- _ O
emotion -X- _ O
predictions -X- _ O
are -X- _ O
correct -X- _ O
to -X- _ O
compute -X- _ O
summarization -X- _ B-TaskName
metrics -X- _ O
. -X- _ O
We -X- _ O
run -X- _ O
our -X- _ O
approaches -X- _ O
five -X- _ O
times -X- _ O
with -X- _ O
different -X- _ O
model -X- _ O
initializations -X- _ O
and -X- _ O
report -X- _ O
average -X- _ O
values -X- _ O
. -X- _ O
We -X- _ O
provide -X- _ O
extensive -X- _ O
details -X- _ O
about -X- _ O
our -X- _ O
hyperparameters -X- _ O
, -X- _ O
such -X- _ O
as -X- _ O
batch -X- _ B-HyperparameterName
size -X- _ I-HyperparameterName
or -X- _ O
loss -X- _ B-HyperparameterName
weighting -X- _ I-HyperparameterName
λ -X- _ B-HyperparameterName
in -X- _ O
Appendix -X- _ O
§ -X- _ O
D. -X- _ O
Additionally -X- _ O
, -X- _ O
we -X- _ O
carry -X- _ O
out -X- _ O
an -X- _ O
extensive -X- _ O
human -X- _ B-MethodName
evaluation -X- _ I-MethodName
of -X- _ O
trigger -X- _ O
summaries -X- _ O
generated -X- _ O
by -X- _ O
our -X- _ O
BART -X- _ B-MethodName
- -X- _ I-MethodName
FT -X- _ I-MethodName
- -X- _ I-MethodName
JOINT -X- _ I-MethodName
model -X- _ O
and -X- _ O
a -X- _ O
general -X- _ O
BART -X- _ B-MethodName
( -X- _ O
Lewis -X- _ O
et -X- _ O
al -X- _ O
. -X- _ O
, -X- _ O
2020 -X- _ O
) -X- _ O
model -X- _ O
trained -X- _ O
on -X- _ O
CNN -X- _ B-DatasetName
/ -X- _ I-DatasetName
DailyMail -X- _ I-DatasetName
. -X- _ O

Emotion -X- _ B-TaskName
Detection -X- _ I-TaskName
. -X- _ O
We -X- _ O
show -X- _ O
the -X- _ O
F1s -X- _ B-MetricName
obtained -X- _ O
using -X- _ O
our -X- _ O
models -X- _ O
on -X- _ O
emotion -X- _ B-TaskName
detection -X- _ I-TaskName
in -X- _ O
Table -X- _ O
3 -X- _ O
. -X- _ O
First -X- _ O
, -X- _ O
we -X- _ O
observe -X- _ O
that -X- _ O
our -X- _ O
lexicon -X- _ O
- -X- _ O
based -X- _ O
EmoLex -X- _ B-MethodName
approach -X- _ O
performs -X- _ O
poorly -X- _ O
compared -X- _ O
to -X- _ O
other -X- _ O
methods -X- _ O
. -X- _ O
We -X- _ O
also -X- _ O
note -X- _ O
that -X- _ O
approaches -X- _ O
trained -X- _ O
outside -X- _ O
our -X- _ O
domain -X- _ O
lag -X- _ O
behind -X- _ O
considerably -X- _ O
compared -X- _ O
to -X- _ O
approaches -X- _ O
trained -X- _ O
on -X- _ O
our -X- _ O
data -X- _ O
. -X- _ O
Specifically -X- _ O
, -X- _ O
a -X- _ O
BERT -X- _ B-MethodName
large -X- _ I-MethodName
model -X- _ O
trained -X- _ O
on -X- _ O
our -X- _ O
data -X- _ O
outperforms -X- _ O
the -X- _ O
GoEmotions -X- _ B-MethodName
model -X- _ O
by -X- _ O
as -X- _ O
much -X- _ O
as -X- _ O
23 -X- _ B-MetricValue
% -X- _ I-MetricValue
in -X- _ O
F1 -X- _ B-MetricName
on -X- _ O
anger -X- _ O
and -X- _ O
28 -X- _ B-MetricValue
% -X- _ I-MetricValue
in -X- _ O
fear -X- _ O
. -X- _ O
We -X- _ O
observe -X- _ O
the -X- _ O
same -X- _ O
trend -X- _ O
for -X- _ O
models -X- _ O
trained -X- _ O
on -X- _ O
hurricane -X- _ O
disasters -X- _ O
, -X- _ O
which -X- _ O
decrease -X- _ O
the -X- _ O
performance -X- _ O
by -X- _ O
38 -X- _ B-MetricValue
% -X- _ I-MetricValue
on -X- _ O
fear -X- _ O
and -X- _ O
9 -X- _ B-MetricValue
% -X- _ I-MetricValue
on -X- _ O
joy -X- _ O
. -X- _ O
This -X- _ O
result -X- _ O
indicates -X- _ O
that -X- _ O
models -X- _ O
trained -X- _ O
on -X- _ O
natural -X- _ O
disasters -X- _ O
generalize -X- _ O
poorly -X- _ O
to -X- _ O
Covid-19 -X- _ O
, -X- _ O
further -X- _ O
emphasizing -X- _ O
the -X- _ O
uniqueness -X- _ O
of -X- _ O
our -X- _ O
dataset -X- _ O
. -X- _ O
We -X- _ O
also -X- _ O
note -X- _ O
that -X- _ O
our -X- _ O
BART -X- _ B-MethodName
- -X- _ I-MethodName
FT -X- _ I-MethodName
- -X- _ I-MethodName
JOINT -X- _ I-MethodName
model -X- _ O
, -X- _ O
which -X- _ O
is -X- _ O
trained -X- _ O
on -X- _ O
our -X- _ O
data -X- _ O
to -X- _ O
perform -X- _ O
both -X- _ O
detection -X- _ B-TaskName
and -X- _ I-TaskName
summarization -X- _ I-TaskName
obtains -X- _ O
an -X- _ O
average -X- _ O
improvement -X- _ O
of -X- _ O
1 -X- _ B-MetricValue
% -X- _ I-MetricValue
over -X- _ O
the -X- _ O
BERT -X- _ B-MethodName
- -X- _ I-MethodName
large -X- _ I-MethodName
model -X- _ O
. -X- _ O

Trigger -X- _ B-TaskName
Summarization -X- _ I-TaskName
. -X- _ O
We -X- _ O
show -X- _ O
in -X- _ O
BERTScore -X- _ B-MetricName
on -X- _ O
the -X- _ O
summarization -X- _ B-TaskName
task -X- _ O
. -X- _ O
First -X- _ O
, -X- _ O
we -X- _ O
note -X- _ O
that -X- _ O
basic -X- _ O
approaches -X- _ O
such -X- _ O
as -X- _ O
1 -X- _ B-MethodName
- -X- _ I-MethodName
SENT -X- _ I-MethodName
or -X- _ O
3 -X- _ B-MethodName
- -X- _ I-MethodName
SENT -X- _ I-MethodName
, -X- _ O
which -X- _ O
select -X- _ O
the -X- _ O
first -X- _ O
sentences -X- _ O
in -X- _ O
a -X- _ O
post -X- _ O
as -X- _ O
the -X- _ O
trigger -X- _ O
summaries -X- _ O
, -X- _ O
perform -X- _ O
similarly -X- _ O
to -X- _ O
general -X- _ O
summarization -X- _ B-TaskName
models -X- _ O
like -X- _ O
the -X- _ O
Pegasus -X- _ B-MethodName
model -X- _ O
trained -X- _ O
on -X- _ O
Reddit -X- _ B-DatasetName
TIFU -X- _ I-DatasetName
or -X- _ O
the -X- _ O
BART -X- _ B-MethodName
trained -X- _ O
on -X- _ O
CNN -X- _ B-DatasetName
/ -X- _ I-DatasetName
DailyMail -X- _ I-DatasetName
. -X- _ O
This -X- _ O
result -X- _ O
highlights -X- _ O
the -X- _ O
distinct -X- _ O
nature -X- _ O
of -X- _ O
our -X- _ O
trigger -X- _ B-TaskName
summarization -X- _ I-TaskName
task -X- _ O
, -X- _ O
which -X- _ O
bears -X- _ O
very -X- _ O
few -X- _ O
similarities -X- _ O
with -X- _ O
a -X- _ O
general -X- _ O
summarization -X- _ B-TaskName
task -X- _ O
. -X- _ O
Fine -X- _ O
- -X- _ O
tuning -X- _ O
these -X- _ O
models -X- _ O
on -X- _ O
our -X- _ O
data -X- _ O
, -X- _ O
however -X- _ O
, -X- _ O
brings -X- _ O
substantial -X- _ O
improvements -X- _ O
. -X- _ O
We -X- _ O
see -X- _ O
improvements -X- _ O
as -X- _ O
large -X- _ O
as -X- _ O
18 -X- _ B-MetricValue
% -X- _ I-MetricValue
in -X- _ O
terms -X- _ O
of -X- _ O
BERTScore -X- _ B-MetricName
by -X- _ O
fine -X- _ O
- -X- _ O
tuning -X- _ O
a -X- _ O
BART -X- _ B-MethodName
model -X- _ O
on -X- _ O
anger -X- _ O
and -X- _ O
19 -X- _ B-MetricValue
% -X- _ I-MetricValue
on -X- _ O
anticipation -X- _ O
. -X- _ O
Our -X- _ O
fine -X- _ O
- -X- _ O
tuned -X- _ O
models -X- _ O
also -X- _ O
consistently -X- _ O
outperform -X- _ O
the -X- _ O
baselines -X- _ O
in -X- _ O
ROUGE -X- _ B-MetricName
- -X- _ I-MetricName
L. -X- _ I-MetricName
For -X- _ O
instance -X- _ O
, -X- _ O
our -X- _ O
fine -X- _ O
- -X- _ O
tuned -X- _ O
Pegasus -X- _ B-MethodName
obtains -X- _ O
an -X- _ O
improvement -X- _ O
of -X- _ O
4.2 -X- _ B-MetricValue
% -X- _ I-MetricValue
ROUGE -X- _ B-MetricName
- -X- _ I-MetricName
L -X- _ I-MetricName
on -X- _ O
fear -X- _ O
and -X- _ O
2 -X- _ B-MetricValue
% -X- _ I-MetricValue
on -X- _ O
sadness -X- _ O
. -X- _ O
We -X- _ O
note -X- _ O
that -X- _ O
applying -X- _ O
our -X- _ O
joint -X- _ O
model -X- _ O
results -X- _ O
in -X- _ O
no -X- _ O
loss -X- _ O
of -X- _ O
performance -X- _ O
across -X- _ O
all -X- _ O
emotions -X- _ O
. -X- _ O
We -X- _ O
emphasize -X- _ O
that -X- _ O
in -X- _ O
practice -X- _ O
, -X- _ O
generating -X- _ B-TaskName
trigger -X- _ I-TaskName
summaries -X- _ I-TaskName
and -X- _ I-TaskName
detecting -X- _ I-TaskName
emotions -X- _ I-TaskName
using -X- _ O
a -X- _ O
joint -X- _ O
model -X- _ O
has -X- _ O
various -X- _ O
advantages -X- _ O
over -X- _ O
single -X- _ O
- -X- _ O
task -X- _ O
approaches -X- _ O
, -X- _ O
such -X- _ O
as -X- _ O
reduced -X- _ O
memory -X- _ O
footprint -X- _ O
( -X- _ O
i.e. -X- _ O
, -X- _ O
by -X- _ O
using -X- _ O
a -X- _ O
single -X- _ O
model -X- _ O
) -X- _ O
and -X- _ O
reduced -X- _ O
inference -X- _ O
time -X- _ O
. -X- _ O
Moreover -X- _ O
, -X- _ O
our -X- _ O
approach -X- _ O
improves -X- _ O
the -X- _ O
performance -X- _ O
in -X- _ O
emotion -X- _ B-TaskName
detection -X- _ I-TaskName
. -X- _ O

Human -X- _ B-MethodName
Evaluation -X- _ I-MethodName
of -X- _ O
Model -X- _ O
Summaries -X- _ O

We -X- _ O
perform -X- _ O
human -X- _ B-MethodName
evaluation -X- _ I-MethodName
and -X- _ O
qualitative -X- _ O
analysis -X- _ O
of -X- _ O
our -X- _ O
model -X- _ O
- -X- _ O
generated -X- _ O
trigger -X- _ O
summaries -X- _ O
to -X- _ O
measure -X- _ O
the -X- _ O
overall -X- _ O
quality -X- _ O
and -X- _ O
compare -X- _ O
our -X- _ O
BART -X- _ B-MethodName
- -X- _ I-MethodName
FT -X- _ I-MethodName
- -X- _ I-MethodName
JOINT -X- _ I-MethodName
model -X- _ O
against -X- _ O
a -X- _ O
general -X- _ O
BART -X- _ B-MethodName
summarization -X- _ B-TaskName
model -X- _ O
. -X- _ O

Conclusion -X- _ O

Aaron -X- _ O
Astor -X- _ O
has -X- _ O
made -X- _ O
an -X- _ O
interesting -X- _ O
discovery -X- _ O
on -X- _ O
the -X- _ O
Delta -X- _ O
Variant -X- _ O
, -X- _ O
according -X- _ O
to -X- _ O
his -X- _ O
Twitter -X- _ O
. -X- _ O
According -X- _ O
to -X- _ O
graphs -X- _ O
in -X- _ O
Scotland -X- _ O
, -X- _ O
the -X- _ O
variant -X- _ O
may -X- _ O
hit -X- _ O
hard -X- _ O
and -X- _ O
fast -X- _ O
, -X- _ O
but -X- _ O
it -X- _ O
ultimately -X- _ O
does -X- _ O
n't -X- _ O
do -X- _ O
as -X- _ O
bad -X- _ O
a -X- _ O
damage -X- _ O
as -X- _ O
other -X- _ O
variants -X- _ O
. -X- _ O
In -X- _ O
fact -X- _ O
, -X- _ O
Scotland -X- _ O
's -X- _ O
cases -X- _ O
peaked -X- _ O
at -X- _ O
June -X- _ O
30 -X- _ O
after -X- _ O
having -X- _ O
a -X- _ O
big -X- _ O
spike -X- _ O
. -X- _ O
But -X- _ O
now -X- _ O
the -X- _ O
cases -X- _ O
have -X- _ O
since -X- _ O
crashed -X- _ O
. -X- _ O
Big -X- _ O
time -X- _ O
. -X- _ O
More -X- _ O
importantly -X- _ O
, -X- _ O
the -X- _ O
hospitalization -X- _ O
's -X- _ O
peak -X- _ O
, -X- _ O
two -X- _ O
weeks -X- _ O
after -X- _ O
, -X- _ O
topped -X- _ O
out -X- _ O
at -X- _ O
1 -X- _ O
/ -X- _ O
4 -X- _ O
that -X- _ O
of -X- _ O
Alpha -X- _ O
. -X- _ O
Again -X- _ O
, -X- _ O
most -X- _ O
of -X- _ O
that -X- _ O
has -X- _ O
to -X- _ O
do -X- _ O
with -X- _ O
how -X- _ O
vaccinated -X- _ O
Scotland -X- _ O
was -X- _ O
. -X- _ O
More -X- _ O
interestingly -X- _ O
, -X- _ O
the -X- _ O
most -X- _ O
vaccinated -X- _ O
regions -X- _ O
did -X- _ O
n't -X- _ O
have -X- _ O
such -X- _ O
a -X- _ O
major -X- _ O
impact -X- _ O
with -X- _ O
it -X- _ O
and -X- _ O
barely -X- _ O
had -X- _ O
any -X- _ O
huge -X- _ O
numbers -X- _ O
. -X- _ O
The -X- _ O
unvaccinated -X- _ O
ones -X- _ O
, -X- _ O
on -X- _ O
the -X- _ O
other -X- _ O
hand -X- _ O
, -X- _ O
did -X- _ O
. -X- _ O
What -X- _ O
does -X- _ O
all -X- _ O
this -X- _ O
mean -X- _ O
? -X- _ O
One -X- _ O
, -X- _ O
it -X- _ O
means -X- _ O
that -X- _ O
perhaps -X- _ O
the -X- _ O
Delta -X- _ O
Variant -X- _ O
wave -X- _ O
wo -X- _ O
n't -X- _ O
be -X- _ O
as -X- _ O
long -X- _ O
or -X- _ O
as -X- _ O
massively -X- _ O
damaging -X- _ O
as -X- _ O
some -X- _ O
people -X- _ O
are -X- _ O
fearing -X- _ O
, -X- _ O
and -X- _ O
two -X- _ O
, -X- _ O
the -X- _ O
vaccine -X- _ O
helps -X- _ O
. -X- _ O
Again -X- _ O
, -X- _ O
the -X- _ O
more -X- _ O
we -X- _ O
vaccinate -X- _ O
, -X- _ O
the -X- _ O
faster -X- _ O
we -X- _ O
'll -X- _ O
be -X- _ O
out -X- _ O
of -X- _ O
this -X- _ O
. -X- _ O
But -X- _ O
having -X- _ O
said -X- _ O
that -X- _ O
, -X- _ O
the -X- _ O
Delta -X- _ O
Variant -X- _ O
's -X- _ O
wave -X- _ O
thankfully -X- _ O
may -X- _ O
not -X- _ O
be -X- _ O
as -X- _ O
lengthy -X- _ O
. -X- _ O
That -X- _ O
's -X- _ O
attributed -X- _ O
to -X- _ O
how -X- _ O
much -X- _ O
vaccinations -X- _ O
we -X- _ O
have -X- _ O
made -X- _ O
. -X- _ O
The -X- _ O
more -X- _ O
people -X- _ O
we -X- _ O
do -X- _ O
this -X- _ O
to -X- _ O
, -X- _ O
the -X- _ O
better -X- _ O
. -X- _ O
I -X- _ O
hope -X- _ O
I -X- _ O
am -X- _ O
not -X- _ O
giving -X- _ O
any -X- _ O
false -X- _ O
hopes -X- _ O
, -X- _ O
but -X- _ O
this -X- _ O
post -X- _ O
DID -X- _ O
have -X- _ O
me -X- _ O
intrigued -X- _ O
. -X- _ O

Annotator -X- _ O
2 -X- _ O

• -X- _ O
Joy -X- _ O
→ -X- _ O
Abstractive -X- _ O
Summary -X- _ O
of -X- _ O
Trigger -X- _ O
: -X- _ O
I -X- _ O
'm -X- _ O
happy -X- _ O
that -X- _ O
Delta -X- _ O
does -X- _ O
n't -X- _ O
seem -X- _ O
to -X- _ O
be -X- _ O
as -X- _ O
bad -X- _ O
as -X- _ O
other -X- _ O
variants -X- _ O
, -X- _ O
that -X- _ O
Delta -X- _ O
cases -X- _ O
are -X- _ O
falling -X- _ O
, -X- _ O
and -X- _ O
that -X- _ O
the -X- _ O
peak -X- _ O
is -X- _ O
n't -X- _ O
as -X- _ O
bad -X- _ O
as -X- _ O
the -X- _ O
first -X- _ O
variants -X- _ O
. -X- _ O
I -X- _ O
'm -X- _ O
also -X- _ O
happy -X- _ O
to -X- _ O
see -X- _ O
that -X- _ O
vaccination -X- _ O
is -X- _ O
working -X- _ O
. -X- _ O
I -X- _ O
expect -X- _ O
that -X- _ O
this -X- _ O
post -X- _ O
will -X- _ O
be -X- _ O
removed -X- _ O
from -X- _ O
Reddit -X- _ O
because -X- _ O
I -X- _ O
'm -X- _ O
too -X- _ O
depressed -X- _ O
to -X- _ O
post -X- _ O
it -X- _ O
because -X- _ O
I -X- _ O
expect -X- _ O
that -X- _ O
no -X- _ O
one -X- _ O
will -X- _ O
want -X- _ O
to -X- _ O
read -X- _ O
it -X- _ O
and -X- _ O
everyone -X- _ O
will -X- _ O
think -X- _ O
that -X- _ O
I -X- _ O
'm -X- _ O
crazy -X- _ O
for -X- _ O
thinking -X- _ O
that -X- _ O
I -X- _ O
should -X- _ O
stop -X- _ O
eating -X- _ O
so -X- _ O
that -X- _ O
I -X- _ O
can -X- _ O
afford -X- _ O
to -X- _ O
see -X- _ O
a -X- _ O
therapist -X- _ O
. -X- _ O
. -X- _ O
Model -X- _ O
Summary -X- _ O
includes -X- _ O
information -X- _ O
in -X- _ O
the -X- _ O
summary -X- _ O
not -X- _ O
discussed -X- _ O
in -X- _ O
the -X- _ O
post -X- _ O
israel -X- _ O
imposed -X- _ O
their -X- _ O
mask -X- _ O
mandate -X- _ O
, -X- _ O
despite -X- _ O
being -X- _ O
one -X- _ O
of -X- _ O
the -X- _ O
most -X- _ O
vaccinated -X- _ O
countries -X- _ O
. -X- _ O
i -X- _ O
feel -X- _ O
like -X- _ O
this -X- _ O
will -X- _ O
never -X- _ O
end -X- _ O
and -X- _ O
I -X- _ O
do -X- _ O
n't -X- _ O
need -X- _ O
stupid -X- _ O
replies -X- _ O
like -X- _ O
" -X- _ O
hang -X- _ O
in -X- _ O
there -X- _ O
" -X- _ O
or -X- _ O
" -X- _ O
it -X- _ O
will -X- _ O
be -X- _ O
okay -X- _ O
. -X- _ O
" -X- _ O
and -X- _ O
do -X- _ O
n't -X- _ O
remove -X- _ O
this -X- _ O
post -X- _ O
because -X- _ O
it -X- _ O
" -X- _ O
causes -X- _ O
anxiety -X- _ O
. -X- _ O
" -X- _ O
I -X- _ O
'm -X- _ O
not -X- _ O
. -X- _ O
I -X- _ O
'm -X- _ O
simply -X- _ O
worried -X- _ O
that -X- _ O
we -X- _ O
'll -X- _ O
never -X- _ O
get -X- _ O
back -X- _ O
to -X- _ O
normal -X- _ O
. -X- _ O

I -X- _ O
am -X- _ O
disgusted -X- _ O
to -X- _ O
see -X- _ O
myself -X- _ O
being -X- _ O
selfish -X- _ O
because -X- _ O
I -X- _ O
have -X- _ O
done -X- _ O
all -X- _ O
I -X- _ O
can -X- _ O
to -X- _ O
prevent -X- _ O
COVID -X- _ O
and -X- _ O
I -X- _ O
want -X- _ O
to -X- _ O
live -X- _ O
my -X- _ O
life -X- _ O
as -X- _ O
if -X- _ O
I -X- _ O
had -X- _ O
not -X- _ O
had -X- _ O
any -X- _ O
COVID -X- _ O
side -X- _ O
effects -X- _ O
at -X- _ O
all -X- _ O
since -X- _ O
I -X- _ O
have -X- _ O
taken -X- _ O
every -X- _ O
precaution -X- _ O
possible -X- _ O
to -X- _ O
prevent -X- _ O
the -X- _ O
COVID -X- _ O
variant -X- _ O
. -X- _ O

Is -X- _ O
anyone -X- _ O
else -X- _ O
experiencing -X- _ O
bad -X- _ O
post -X- _ O
- -X- _ O
outing -X- _ O
anxiety -X- _ O
? -X- _ O
I -X- _ O
ve -X- _ O
been -X- _ O
trying -X- _ O
to -X- _ O
push -X- _ O
myself -X- _ O
out -X- _ O
of -X- _ O
my -X- _ O
comfort -X- _ O
zone -X- _ O
( -X- _ O
and -X- _ O
sometimes -X- _ O
I -X- _ O
even -X- _ O
get -X- _ O
excited -X- _ O
to -X- _ O
) -X- _ O
and -X- _ O
so -X- _ O
I -X- _ O
get -X- _ O
ahead -X- _ O
of -X- _ O
myself -X- _ O
and -X- _ O
leave -X- _ O
my -X- _ O
house -X- _ O
. -X- _ O
No -X- _ O
bars -X- _ O
or -X- _ O
clubs -X- _ O
, -X- _ O
but -X- _ O
I -X- _ O
did -X- _ O
attend -X- _ O
an -X- _ O
outdoor -X- _ O
gathering -X- _ O
that -X- _ O
s -X- _ O
weighing -X- _ O
heavy -X- _ O
on -X- _ O
my -X- _ O
mind -X- _ O
. -X- _ O
While -X- _ O
I -X- _ O
m -X- _ O
out -X- _ O
, -X- _ O
I -X- _ O
ve -X- _ O
surprisingly -X- _ O
found -X- _ O
I -X- _ O
m -X- _ O
quite -X- _ O
bored -X- _ O
when -X- _ O
I -X- _ O
leave -X- _ O
my -X- _ O
house -X- _ O
, -X- _ O
but -X- _ O
the -X- _ O
real -X- _ O
problem -X- _ O
comes -X- _ O
the -X- _ O
day -X- _ O
afterwards -X- _ O
. -X- _ O
I -X- _ O
sit -X- _ O
and -X- _ O
think -X- _ O
was -X- _ O
that -X- _ O
too -X- _ O
soon -X- _ O
? -X- _ O
Can -X- _ O
I -X- _ O
re -X- _ O
- -X- _ O
enter -X- _ O
my -X- _ O
bubble -X- _ O
now -X- _ O
that -X- _ O
people -X- _ O
have -X- _ O
seen -X- _ O
me -X- _ O
? -X- _ O
Am -X- _ O
I -X- _ O
a -X- _ O
hypocrite -X- _ O
? -X- _ O
And -X- _ O
these -X- _ O
questions -X- _ O
flow -X- _ O
through -X- _ O
my -X- _ O
brain -X- _ O
in -X- _ O
a -X- _ O
never -X- _ O
ending -X- _ O
sequence -X- _ O
. -X- _ O
Feeling -X- _ O
that -X- _ O
I -X- _ O
ve -X- _ O
been -X- _ O
perceived -X- _ O
by -X- _ O
others -X- _ O
and -X- _ O
I -X- _ O
ca -X- _ O
nt -X- _ O
take -X- _ O
it -X- _ O
back -X- _ O
feels -X- _ O
unbearable -X- _ O
, -X- _ O
yet -X- _ O
I -X- _ O
took -X- _ O
the -X- _ O
decision -X- _ O
to -X- _ O
leave -X- _ O
my -X- _ O
house -X- _ O
so -X- _ O
I -X- _ O
then -X- _ O
encounter -X- _ O
feelings -X- _ O
of -X- _ O
embarrassment -X- _ O
, -X- _ O
guilt -X- _ O
and -X- _ O
shame -X- _ O
. -X- _ O
Not -X- _ O
to -X- _ O
mention -X- _ O
the -X- _ O
obvious -X- _ O
fear -X- _ O
of -X- _ O
the -X- _ O
delta -X- _ O
variant -X- _ O
, -X- _ O
and -X- _ O
overall -X- _ O
uncertainty -X- _ O
over -X- _ O
cdc -X- _ O
recommendations -X- _ O
. -X- _ O
( -X- _ O
I -X- _ O
wish -X- _ O
someone -X- _ O
could -X- _ O
spell -X- _ O
out -X- _ O
a -X- _ O
good -X- _ O
plan -X- _ O
for -X- _ O
reintegration -X- _ O
besides -X- _ O
-rip -X- _ O
off -X- _ O
the -X- _ O
mask -X- _ O
and -X- _ O
live -X- _ O
! -X- _ O
) -X- _ O
Everyone -X- _ O
I -X- _ O
know -X- _ O
has -X- _ O
returned -X- _ O
to -X- _ O
life -X- _ O
normally -X- _ O
and -X- _ O
I -X- _ O
m -X- _ O
here -X- _ O
in -X- _ O
a -X- _ O
weird -X- _ O
limbo -X- _ O
. -X- _ O
I -X- _ O
know -X- _ O
a -X- _ O
lot -X- _ O
of -X- _ O
people -X- _ O
in -X- _ O
this -X- _ O
struggle -X- _ O
with -X- _ O
just -X- _ O
leaving -X- _ O
the -X- _ O
house -X- _ O
, -X- _ O
but -X- _ O
is -X- _ O
anyone -X- _ O
else -X- _ O
out -X- _ O
there -X- _ O
struggling -X- _ O
with -X- _ O
how -X- _ O
they -X- _ O
feel -X- _ O
once -X- _ O
they -X- _ O
do -X- _ O
? -X- _ O
I -X- _ O
find -X- _ O
it -X- _ O
hard -X- _ O
to -X- _ O
leave -X- _ O
the -X- _ O
house -X- _ O
and -X- _ O
it -X- _ O
surprises -X- _ O
me -X- _ O
when -X- _ O
I -X- _ O
find -X- _ O
out -X- _ O
that -X- _ O
I -X- _ O
'm -X- _ O
not -X- _ O
feeling -X- _ O
the -X- _ O
same -X- _ O
way -X- _ O
when -X- _ O
I -X- _ O
do -X- _ O
. -X- _ O
I -X- _ O
feel -X- _ O
embarrassed -X- _ O
and -X- _ O
ashamed -X- _ O
that -X- _ O
I -X- _ O
've -X- _ O
been -X- _ O
seen -X- _ O
out -X- _ O
in -X- _ O
public -X- _ O
and -X- _ O
that -X- _ O
I -X- _ O
ca -X- _ O
n't -X- _ O
go -X- _ O
back -X- _ O
and -X- _ O
change -X- _ O
what -X- _ O
I -X- _ O
've -X- _ O
done -X- _ O
. -X- _ O

We -X- _ O
thank -X- _ O
Desmond -X- _ O
Ong -X- _ O
and -X- _ O
the -X- _ O
anonymous -X- _ O
reviewers -X- _ O
for -X- _ O
their -X- _ O
valuable -X- _ O
comments -X- _ O
and -X- _ O
feedback -X- _ O
, -X- _ O
which -X- _ O
helped -X- _ O
improve -X- _ O
our -X- _ O
paper -X- _ O
. -X- _ O
We -X- _ O
also -X- _ O
thank -X- _ O
our -X- _ O
annotators -X- _ O
for -X- _ O
their -X- _ O
dedication -X- _ O
and -X- _ O
hard -X- _ O
work -X- _ O
. -X- _ O
We -X- _ O
thank -X- _ O
John -X- _ O
Henry -X- _ O
Cruz -X- _ O
for -X- _ O
his -X- _ O
help -X- _ O
with -X- _ O
Reddit -X- _ O
data -X- _ O
. -X- _ O
This -X- _ O
research -X- _ O
is -X- _ O
partially -X- _ O
supported -X- _ O
by -X- _ O
Good -X- _ O
Systems -X- _ O
, -X- _ O
4 -X- _ O
a -X- _ O
UT -X- _ O
Austin -X- _ O
Grand -X- _ O
Challenge -X- _ O
to -X- _ O
develop -X- _ O
responsible -X- _ O
AI -X- _ O
technologies -X- _ O
, -X- _ O
and -X- _ O
NSF -X- _ O
grants -X- _ O
IIS-2145479 -X- _ O
, -X- _ O
IIS-2107524 -X- _ O
, -X- _ O
IIS-2107487 -X- _ O
, -X- _ O
and -X- _ O
BigData-1912887 -X- _ O
. -X- _ O
We -X- _ O
acknowledge -X- _ O
the -X- _ O
Texas -X- _ O
Advanced -X- _ O
Computing -X- _ O
Center -X- _ O
( -X- _ O
TACC -X- _ O
) -X- _ O
5 -X- _ O
at -X- _ O
UT -X- _ O
Austin -X- _ O
and -X- _ O
AWS -X- _ O
for -X- _ O
many -X- _ O
of -X- _ O
the -X- _ O
results -X- _ O
within -X- _ O
this -X- _ O
paper -X- _ O

Currently -X- _ O
, -X- _ O
the -X- _ O
reduction -X- _ O
in -X- _ O
the -X- _ O
parameter -X- _ O
scale -X- _ O
of -X- _ O
large -X- _ O
- -X- _ O
scale -X- _ O
pre -X- _ O
- -X- _ O
trained -X- _ O
language -X- _ O
models -X- _ O
( -X- _ O
PLMs -X- _ O
) -X- _ O
through -X- _ O
knowledge -X- _ B-TaskName
distillation -X- _ I-TaskName
has -X- _ O
greatly -X- _ O
facilitated -X- _ O
their -X- _ O
widespread -X- _ O
deployment -X- _ O
on -X- _ O
various -X- _ O
devices -X- _ O
. -X- _ O
However -X- _ O
, -X- _ O
the -X- _ O
deployment -X- _ O
of -X- _ O
knowledge -X- _ B-TaskName
distillation -X- _ I-TaskName
systems -X- _ O
faces -X- _ O
great -X- _ O
challenges -X- _ O
in -X- _ O
real -X- _ O
- -X- _ O
world -X- _ O
industrial -X- _ O
- -X- _ O
strength -X- _ O
applications -X- _ O
, -X- _ O
which -X- _ O
require -X- _ O
the -X- _ O
use -X- _ O
of -X- _ O
complex -X- _ O
distillation -X- _ B-TaskName
methods -X- _ O
on -X- _ O
even -X- _ O
larger -X- _ O
- -X- _ O
scale -X- _ O
PLMs -X- _ O
( -X- _ O
over -X- _ O
10B -X- _ O
) -X- _ O
, -X- _ O
limited -X- _ O
by -X- _ O
memory -X- _ O
on -X- _ O
GPUs -X- _ O
and -X- _ O
the -X- _ O
switching -X- _ O
of -X- _ O
methods -X- _ O
. -X- _ O
To -X- _ O
overcome -X- _ O
these -X- _ O
challenges -X- _ O
, -X- _ O
we -X- _ O
propose -X- _ O
GKD -X- _ B-MethodName
, -X- _ O
a -X- _ O
general -X- _ B-MethodName
knowledge -X- _ I-MethodName
distillation -X- _ I-MethodName
framework -X- _ O
that -X- _ O
supports -X- _ O
distillation -X- _ O
on -X- _ O
larger -X- _ O
- -X- _ O
scale -X- _ O
PLMs -X- _ O
using -X- _ O
various -X- _ O
distillation -X- _ B-TaskName
methods -X- _ O
. -X- _ O
With -X- _ O
GKD -X- _ B-MethodName
, -X- _ O
developers -X- _ O
can -X- _ O
build -X- _ O
larger -X- _ O
distillation -X- _ B-TaskName
models -X- _ O
on -X- _ O
memorylimited -X- _ O
GPUs -X- _ O
and -X- _ O
easily -X- _ O
switch -X- _ O
and -X- _ O
combine -X- _ O
different -X- _ O
distillation -X- _ B-TaskName
methods -X- _ O
within -X- _ O
a -X- _ O
single -X- _ O
framework -X- _ O
. -X- _ O
Experimental -X- _ O
results -X- _ O
show -X- _ O
that -X- _ O
GKD -X- _ B-MethodName
can -X- _ O
support -X- _ O
the -X- _ O
distillation -X- _ O
of -X- _ O
at -X- _ O
least -X- _ O
100B -X- _ O
- -X- _ O
scale -X- _ O
PLMs -X- _ O
and -X- _ O
25 -X- _ O
mainstream -X- _ O
methods -X- _ O
on -X- _ O
8 -X- _ O
NVIDIA -X- _ O
A100 -X- _ O
( -X- _ O
40 -X- _ O
GB -X- _ O
) -X- _ O
GPUs -X- _ O
. -X- _ O
1 -X- _ O
* -X- _ O
This -X- _ O
work -X- _ O
was -X- _ O
done -X- _ O
when -X- _ O
the -X- _ O
author -X- _ O
visited -X- _ O
Zhipu -X- _ O
. -X- _ O
AI -X- _ O
. -X- _ O

In -X- _ O
this -X- _ O
paper -X- _ O
, -X- _ O
we -X- _ O
propose -X- _ O
a -X- _ O
general -X- _ B-MethodName
knowledge -X- _ I-MethodName
distillation -X- _ I-MethodName
framework -X- _ O
, -X- _ O
GKD -X- _ B-MethodName
, -X- _ O
for -X- _ O
deploying -X- _ O
knowledge -X- _ B-TaskName
distillation -X- _ I-TaskName
systems -X- _ O
targeting -X- _ O
large -X- _ O
- -X- _ O
scale -X- _ O
PLMs -X- _ O
. -X- _ O
GKD -X- _ B-MethodName
satisfies -X- _ O
the -X- _ O
demands -X- _ O
of -X- _ O
real -X- _ O
- -X- _ O
world -X- _ O
applications -X- _ O
by -X- _ O
employing -X- _ O
a -X- _ O
parallel -X- _ O
strategy -X- _ O
and -X- _ O
adaptive -X- _ O
architecture -X- _ O
, -X- _ O
allowing -X- _ O
for -X- _ O
the -X- _ O
distillation -X- _ B-TaskName
of -X- _ O
ultra -X- _ O
- -X- _ O
large -X- _ O
scale -X- _ O
PLMs -X- _ O
( -X- _ O
over -X- _ O
10B -X- _ O
) -X- _ O
and -X- _ O
the -X- _ O
switch -X- _ O
of -X- _ O
various -X- _ O
advanced -X- _ O
distillation -X- _ B-TaskName
methods -X- _ O
. -X- _ O
In -X- _ O
the -X- _ O
future -X- _ O
, -X- _ O
we -X- _ O
plan -X- _ O
to -X- _ O
launch -X- _ O
our -X- _ O
knowledge -X- _ B-TaskName
distillation -X- _ I-TaskName
system -X- _ O
for -X- _ O
facilitating -X- _ O
the -X- _ O
mass -X- _ O
production -X- _ O
and -X- _ O
deployment -X- _ O
of -X- _ O
student -X- _ O
models -X- _ O
. -X- _ O

The -X- _ O
batch -X- _ B-HyperparameterName
size -X- _ I-HyperparameterName
, -X- _ O
number -X- _ B-HyperparameterName
of -X- _ I-HyperparameterName
iterations -X- _ I-HyperparameterName
, -X- _ O
and -X- _ O
peak -X- _ B-HyperparameterName
learning -X- _ I-HyperparameterName
rate -X- _ I-HyperparameterName
for -X- _ O
the -X- _ O
pre -X- _ O
- -X- _ O
training -X- _ O
stage -X- _ O
were -X- _ O
set -X- _ O
to -X- _ O
64 -X- _ B-HyperparameterValue
, -X- _ O
150000 -X- _ B-HyperparameterValue
, -X- _ O
and -X- _ O
4e-4 -X- _ B-HyperparameterValue
, -X- _ O
respectively -X- _ O
. -X- _ O
The -X- _ O
taskspecific -X- _ O
hyperparameters -X- _ O
for -X- _ O
specific -X- _ O
methods -X- _ O
were -X- _ O
set -X- _ O
to -X- _ O
the -X- _ O
optimal -X- _ O
values -X- _ O
from -X- _ O
their -X- _ O
corresponding -X- _ O
papers -X- _ O
, -X- _ O
while -X- _ O
other -X- _ O
hyperparameters -X- _ O
( -X- _ O
see -X- _ O
Table -X- _ O
6 -X- _ O
) -X- _ O
were -X- _ O
kept -X- _ O
consistent -X- _ O
with -X- _ O
the -X- _ O
fine -X- _ O
- -X- _ O
tuning -X- _ O
teacher -X- _ O
. -X- _ O
For -X- _ O
single -X- _ O
- -X- _ O
teacher -X- _ O
methods -X- _ O
in -X- _ O
the -X- _ O
taskspecific -X- _ O
stage -X- _ O
, -X- _ O
grid -X- _ O
search -X- _ O
was -X- _ O
used -X- _ O
to -X- _ O
optimize -X- _ O
hyperparameters -X- _ O
, -X- _ O
including -X- _ O
learning -X- _ B-HyperparameterName
rate -X- _ I-HyperparameterName
{ -X- _ O
5e-6,1e-5,2e-5 -X- _ B-HyperparameterValue
} -X- _ O
and -X- _ O
batch -X- _ B-HyperparameterName
size -X- _ I-HyperparameterName
{ -X- _ O
16,32 -X- _ B-HyperparameterValue
} -X- _ O
. -X- _ O
Table -X- _ O
7 -X- _ O
presents -X- _ O
the -X- _ O
learning -X- _ B-HyperparameterName
rate -X- _ I-HyperparameterName
and -X- _ O
batch -X- _ B-HyperparameterName
size -X- _ I-HyperparameterName
for -X- _ O
each -X- _ O
method -X- _ O
on -X- _ O
each -X- _ O
dataset -X- _ O
in -X- _ O
the -X- _ O
SuperGLUE -X- _ B-DatasetName
benchmark -X- _ O
. -X- _ O
The -X- _ O
results -X- _ O
for -X- _ O
all -X- _ O
methods -X- _ O
were -X- _ O
averaged -X- _ O
over -X- _ O
three -X- _ O
random -X- _ O
seeds -X- _ O
. -X- _ O

This -X- _ O
work -X- _ O
is -X- _ O
supported -X- _ O
by -X- _ O
Technology -X- _ O
and -X- _ O
Innovation -X- _ O
Major -X- _ O
Project -X- _ O
of -X- _ O
the -X- _ O
Ministry -X- _ O
of -X- _ O
Science -X- _ O
and -X- _ O
Technology -X- _ O
of -X- _ O
China -X- _ O
under -X- _ O
Grant -X- _ O
2020AAA0108400 -X- _ O
and -X- _ O
2020AAA0108402 -X- _ O
, -X- _ O
the -X- _ O
Natural -X- _ O
Science -X- _ O
Foundation -X- _ O
of -X- _ O
China -X- _ O
under -X- _ O
Grant -X- _ O
No -X- _ O
. -X- _ O
61836013 -X- _ O
, -X- _ O
the -X- _ O
Major -X- _ O
Program -X- _ O
of -X- _ O
the -X- _ O
National -X- _ O
Social -X- _ O
Science -X- _ O
Foundation -X- _ O
of -X- _ O
China -X- _ O
under -X- _ O
Grant -X- _ O
No -X- _ O
. -X- _ O
18ZDA032 -X- _ O
, -X- _ O
and -X- _ O
funds -X- _ O
from -X- _ O
CCF -X- _ O
- -X- _ O
Zhipu -X- _ O
. -X- _ O
AI -X- _ O
and -X- _ O
Beijing -X- _ O
Academy -X- _ O
of -X- _ O
Artificial -X- _ O
Intelligence -X- _ O
( -X- _ O
BAAI -X- _ O
) -X- _ O
. -X- _ O
The -X- _ O
GPUs -X- _ O
used -X- _ O
are -X- _ O
sponsored -X- _ O
by -X- _ O
Zhipu -X- _ O
. -X- _ O
AI -X- _ O

Towards -X- _ O
Comprehensive -X- _ O
Patent -X- _ B-TaskName
Approval -X- _ I-TaskName
Predictions -X- _ I-TaskName
: -X- _ O
Beyond -X- _ O
Traditional -X- _ O
Document -X- _ O
Classification -X- _ O

Predicting -X- _ B-TaskName
the -X- _ I-TaskName
approval -X- _ I-TaskName
odds -X- _ I-TaskName
of -X- _ I-TaskName
a -X- _ I-TaskName
patent -X- _ I-TaskName
application -X- _ I-TaskName
is -X- _ O
a -X- _ O
challenging -X- _ O
problem -X- _ O
involving -X- _ O
multiple -X- _ O
factors -X- _ O
. -X- _ O
The -X- _ O
most -X- _ O
important -X- _ O
factor -X- _ O
is -X- _ O
arguably -X- _ O
the -X- _ O
novelty -X- _ O
-35 -X- _ O
U.S. -X- _ O
Code -X- _ O
§ -X- _ O
102 -X- _ O
rejects -X- _ O
applications -X- _ O
that -X- _ O
are -X- _ O
not -X- _ O
sufficiently -X- _ O
differentiated -X- _ O
from -X- _ O
prior -X- _ O
art -X- _ O
. -X- _ O
Novelty -X- _ O
evaluation -X- _ O
distinguishes -X- _ O
the -X- _ O
patent -X- _ O
approval -X- _ O
prediction -X- _ O
from -X- _ O
conventional -X- _ O
document -X- _ O
classification -X- _ O
-toosimilar -X- _ O
newer -X- _ O
submissions -X- _ O
are -X- _ O
considered -X- _ O
as -X- _ O
not -X- _ O
novel -X- _ O
and -X- _ O
would -X- _ O
receive -X- _ O
the -X- _ O
opposite -X- _ O
label -X- _ O
, -X- _ O
thus -X- _ O
confusing -X- _ O
standard -X- _ O
document -X- _ O
classifiers -X- _ O
( -X- _ O
e.g. -X- _ O
, -X- _ O
BERT -X- _ B-MethodName
) -X- _ O
. -X- _ O
To -X- _ O
address -X- _ O
this -X- _ O
issue -X- _ O
, -X- _ O
we -X- _ O
propose -X- _ O
a -X- _ O
novel -X- _ O
framework -X- _ O
AISeer -X- _ B-MethodName
that -X- _ O
unifies -X- _ O
the -X- _ O
document -X- _ O
classifier -X- _ O
with -X- _ O
handcrafted -X- _ O
features -X- _ O
, -X- _ O
particularly -X- _ O
time -X- _ O
- -X- _ O
dependent -X- _ O
novelty -X- _ O
scores -X- _ O
. -X- _ O
Specifically -X- _ O
, -X- _ O
we -X- _ O
formulate -X- _ O
the -X- _ O
novelty -X- _ O
scores -X- _ O
by -X- _ O
comparing -X- _ O
each -X- _ O
application -X- _ O
with -X- _ O
millions -X- _ O
of -X- _ O
prior -X- _ O
art -X- _ O
using -X- _ O
a -X- _ O
hybrid -X- _ O
of -X- _ O
efficient -X- _ O
filters -X- _ O
and -X- _ O
a -X- _ O
neural -X- _ O
bi -X- _ O
- -X- _ O
encoder -X- _ O
. -X- _ O
Moreover -X- _ O
, -X- _ O
we -X- _ O
impose -X- _ O
a -X- _ O
new -X- _ O
regularization -X- _ O
term -X- _ O
into -X- _ O
the -X- _ O
classification -X- _ O
objective -X- _ O
to -X- _ O
enforce -X- _ O
the -X- _ O
monotonic -X- _ O
change -X- _ O
of -X- _ O
approval -X- _ O
prediction -X- _ O
w.r.t -X- _ O
. -X- _ O
novelty -X- _ O
scores -X- _ O
, -X- _ O
From -X- _ O
extensive -X- _ O
experiments -X- _ O
on -X- _ O
a -X- _ O
large -X- _ O
- -X- _ O
scale -X- _ O
USPTO -X- _ B-DatasetName
dataset -X- _ O
, -X- _ O
we -X- _ O
find -X- _ O
that -X- _ O
standard -X- _ O
BERT -X- _ B-MethodName
fine -X- _ O
- -X- _ O
tuning -X- _ O
can -X- _ O
partially -X- _ O
learn -X- _ O
the -X- _ O
correct -X- _ O
relationship -X- _ O
between -X- _ O
novelty -X- _ O
and -X- _ O
approvals -X- _ O
from -X- _ O
inconsistent -X- _ O
data -X- _ O
. -X- _ O
However -X- _ O
, -X- _ O
our -X- _ O
time -X- _ O
- -X- _ O
dependent -X- _ O
novelty -X- _ O
feature -X- _ O
and -X- _ O
other -X- _ O
handcrafted -X- _ O
features -X- _ O
offer -X- _ O
a -X- _ O
significant -X- _ O
boost -X- _ O
on -X- _ O
top -X- _ O
of -X- _ O
it -X- _ O
. -X- _ O
Also -X- _ O
, -X- _ O
our -X- _ O
monotonic -X- _ O
regularization -X- _ O
, -X- _ O
while -X- _ O
shrinking -X- _ O
the -X- _ O
search -X- _ O
space -X- _ O
, -X- _ O
can -X- _ O
drive -X- _ O
the -X- _ O
optimizer -X- _ O
to -X- _ O
better -X- _ O
local -X- _ O
optima -X- _ O
, -X- _ O
yielding -X- _ O
a -X- _ O
further -X- _ O
small -X- _ O
performance -X- _ O
gain -X- _ O
. -X- _ O

Introduction -X- _ O

Intellectual -X- _ O
property -X- _ O
( -X- _ O
IP -X- _ O
) -X- _ O
is -X- _ O
an -X- _ O
important -X- _ O
and -X- _ O
integral -X- _ O
to -X- _ O
the -X- _ O
economy -X- _ O
. -X- _ O
IP -X- _ O
- -X- _ O
intensive -X- _ O
industries -X- _ O
directly -X- _ O
accounted -X- _ O
for -X- _ O
27.9 -X- _ O
million -X- _ O
jobs -X- _ O
in -X- _ O
the -X- _ O
U.S. -X- _ O
( -X- _ O
USPTO -X- _ O
, -X- _ O
2016 -X- _ O
) -X- _ O
Theoretical -X- _ O
and -X- _ O
empirical -X- _ O
evidence -X- _ O
shows -X- _ O
that -X- _ O
patents -X- _ O
are -X- _ O
effective -X- _ O
in -X- _ O
fostering -X- _ O
technological -X- _ O
progress -X- _ O
. -X- _ O
( -X- _ O
Gallini -X- _ O
, -X- _ O
2002 -X- _ O
; -X- _ O
Hu -X- _ O
and -X- _ O
Png -X- _ O
, -X- _ O
2013 -X- _ O
; -X- _ O
Hall -X- _ O
and -X- _ O
Harhoff -X- _ O
, -X- _ O
2012 -X- _ O
) -X- _ O
Securing -X- _ O
patent -X- _ O
approvals -X- _ O
offers -X- _ O
a -X- _ O
major -X- _ O
shot -X- _ O
in -X- _ O
the -X- _ O
arm -X- _ O
to -X- _ O
inventors -X- _ O
* -X- _ O
Jingbo -X- _ O
Shang -X- _ O
is -X- _ O
the -X- _ O
corresponding -X- _ O
author -X- _ O
. -X- _ O
and -X- _ O
innovators -X- _ O
, -X- _ O
increasing -X- _ O
the -X- _ O
chances -X- _ O
of -X- _ O
obtaining -X- _ O
angel -X- _ O
and -X- _ O
venture -X- _ O
capital -X- _ O
investments -X- _ O
. -X- _ O
However -X- _ O
, -X- _ O
the -X- _ O
process -X- _ O
of -X- _ O
getting -X- _ O
a -X- _ O
patent -X- _ O
approved -X- _ O
can -X- _ O
cost -X- _ O
applicants -X- _ O
tens -X- _ O
of -X- _ O
thousands -X- _ O
of -X- _ O
dollars -X- _ O
in -X- _ O
payments -X- _ O
to -X- _ O
law -X- _ O
firms -X- _ O
who -X- _ O
claim -X- _ O
to -X- _ O
be -X- _ O
helpful -X- _ O
in -X- _ O
understanding -X- _ O
what -X- _ O
gets -X- _ O
approved -X- _ O
and -X- _ O
improving -X- _ O
the -X- _ O
odds -X- _ O
of -X- _ O
success -X- _ O
of -X- _ O
a -X- _ O
patent -X- _ O
application -X- _ O
. -X- _ O
Thus -X- _ O
, -X- _ O
algorithmic -X- _ O
approaches -X- _ O
to -X- _ O
aid -X- _ O
in -X- _ O
the -X- _ O
patent -X- _ B-TaskName
evaluation -X- _ I-TaskName
process -X- _ O
can -X- _ O
potentially -X- _ O
save -X- _ O
precious -X- _ O
time -X- _ O
and -X- _ O
resources -X- _ O
for -X- _ O
applicants -X- _ O
during -X- _ O
the -X- _ O
patent -X- _ O
application -X- _ O
phase -X- _ O
, -X- _ O
as -X- _ O
well -X- _ O
as -X- _ O
benefit -X- _ O
patent -X- _ O
examiners -X- _ O
in -X- _ O
government -X- _ O
patent -X- _ O
offices -X- _ O
around -X- _ O
the -X- _ O
world -X- _ O
, -X- _ O
accelerating -X- _ O
and -X- _ O
improving -X- _ O
the -X- _ O
review -X- _ O
process -X- _ O
( -X- _ O
Ebrahim -X- _ O
, -X- _ O
2018 -X- _ O
) -X- _ O
. -X- _ O

The -X- _ O
approval -X- _ O
of -X- _ O
a -X- _ O
patent -X- _ O
application -X- _ O
, -X- _ O
according -X- _ O
to -X- _ O
U.S. -X- _ O
patent -X- _ O
laws -X- _ O
, -X- _ O
is -X- _ O
determined -X- _ O
necessarily -X- _ O
and -X- _ O
sufficiently -X- _ O
by -X- _ O
the -X- _ O
approval -X- _ O
of -X- _ O
application -X- _ O
claims -X- _ O
. -X- _ O
Patent -X- _ O
laws -X- _ O
define -X- _ O
individual -X- _ O
claims -X- _ O
as -X- _ O
the -X- _ O
subject -X- _ O
matter -X- _ O
of -X- _ O
inventions -X- _ O
( -X- _ O
35 -X- _ O
U.S. -X- _ O
Code -X- _ O
§ -X- _ O
112 -X- _ O
) -X- _ O
, -X- _ O
on -X- _ O
which -X- _ O
" -X- _ O
patentability -X- _ O
" -X- _ O
is -X- _ O
defined -X- _ O
( -X- _ O
35 -X- _ O
U.S. -X- _ O
Code -X- _ O
§ -X- _ O
101 -X- _ O
, -X- _ O
102 -X- _ O
, -X- _ O
and -X- _ O
103 -X- _ O
) -X- _ O
( -X- _ O
refer -X- _ O
to -X- _ O
Appendix -X- _ O
B -X- _ O
) -X- _ O
. -X- _ O
No -X- _ O
overall -X- _ O
assessment -X- _ O
of -X- _ O
a -X- _ O
patent -X- _ O
application -X- _ O
is -X- _ O
provisioned -X- _ O
. -X- _ O

To -X- _ O
the -X- _ O
best -X- _ O
of -X- _ O
our -X- _ O
knowledge -X- _ O
, -X- _ O
we -X- _ O
are -X- _ O
the -X- _ O
first -X- _ O
to -X- _ O
try -X- _ O
to -X- _ O
predict -X- _ B-TaskName
patent -X- _ I-TaskName
( -X- _ I-TaskName
claim -X- _ I-TaskName
) -X- _ I-TaskName
approval -X- _ I-TaskName
, -X- _ O
which -X- _ O
is -X- _ O
as -X- _ O
an -X- _ O
extremely -X- _ O
challenging -X- _ O
problem -X- _ O
for -X- _ O
multiple -X- _ O
reasons -X- _ O
. -X- _ O
First -X- _ O
, -X- _ O
patent -X- _ O
documents -X- _ O
comprise -X- _ O
of -X- _ O
technically -X- _ O
nuanced -X- _ O
and -X- _ O
challenging -X- _ O
to -X- _ O
parse -X- _ O
language -X- _ O
( -X- _ O
intricate -X- _ O
legalese -X- _ O
) -X- _ O
. -X- _ O
Patent -X- _ O
texts -X- _ O
are -X- _ O
usually -X- _ O
legal -X- _ O
and -X- _ O
technical -X- _ O
descriptions -X- _ O
of -X- _ O
objects -X- _ O
or -X- _ O
pro -X- _ O
- -X- _ O
cesses -X- _ O
, -X- _ O
which -X- _ O
tend -X- _ O
to -X- _ O
be -X- _ O
complex -X- _ O
in -X- _ O
vocabulary -X- _ O
and -X- _ O
grammatical -X- _ O
structures -X- _ O
( -X- _ O
Singer -X- _ O
and -X- _ O
Smith -X- _ O
, -X- _ O
1967 -X- _ O
) -X- _ O
. -X- _ O
Claims -X- _ O
are -X- _ O
examined -X- _ O
not -X- _ O
only -X- _ O
literally -X- _ O
, -X- _ O
but -X- _ O
also -X- _ O
for -X- _ O
their -X- _ O
legal -X- _ O
implications -X- _ O
. -X- _ O
Appendix -X- _ O
A -X- _ O
provides -X- _ O
a -X- _ O
few -X- _ O
example -X- _ O
application -X- _ O
claims -X- _ O
. -X- _ O

To -X- _ O
mitigate -X- _ O
the -X- _ O
issues -X- _ O
, -X- _ O
we -X- _ O
first -X- _ O
develop -X- _ O
several -X- _ O
handcrafted -X- _ O
features -X- _ O
based -X- _ O
on -X- _ O
domain -X- _ O
knowledge -X- _ O
for -X- _ O
use -X- _ O
alongside -X- _ O
the -X- _ O
language -X- _ O
model -X- _ O
for -X- _ O
context -X- _ O
and -X- _ O
control -X- _ O
. -X- _ O
The -X- _ O
time -X- _ O
- -X- _ O
dependent -X- _ O
nature -X- _ O
of -X- _ O
the -X- _ O
novelty -X- _ O
also -X- _ O
makes -X- _ O
traditional -X- _ O
document -X- _ O
classifiers -X- _ O
not -X- _ O
suitable -X- _ O
here -X- _ O
, -X- _ O
because -X- _ O
they -X- _ O
typically -X- _ O
assume -X- _ O
that -X- _ O
similar -X- _ O
instances -X- _ O
belong -X- _ O
to -X- _ O
the -X- _ O
same -X- _ O
label -X- _ O
. -X- _ O
To -X- _ O
address -X- _ O
this -X- _ O
challenge -X- _ O
, -X- _ O
we -X- _ O
propose -X- _ O
a -X- _ O
novel -X- _ O
framework -X- _ O
AISeer -X- _ B-MethodName
as -X- _ O
shown -X- _ O
in -X- _ O
Figure -X- _ O
1 -X- _ O
. -X- _ O
We -X- _ O
formulate -X- _ O
a -X- _ O
time -X- _ O
- -X- _ O
dependent -X- _ O
novelty -X- _ O
score -X- _ O
for -X- _ O
each -X- _ O
patent -X- _ O
claim -X- _ O
with -X- _ O
its -X- _ O
semantic -X- _ O
similarity -X- _ O
against -X- _ O
prior -X- _ O
approved -X- _ O
claims -X- _ O
from -X- _ O
patent -X- _ O
grants -X- _ O
, -X- _ O
which -X- _ O
are -X- _ O
final -X- _ O
versions -X- _ O
of -X- _ O
approved -X- _ O
patents -X- _ O
. -X- _ O
Specifically -X- _ O
, -X- _ O
inside -X- _ O
a -X- _ O
comprehensive -X- _ O
pool -X- _ O
comprising -X- _ O
millions -X- _ O
of -X- _ O
grants -X- _ O
, -X- _ O
we -X- _ O
consider -X- _ O
those -X- _ O
approved -X- _ O
before -X- _ O
the -X- _ O
filing -X- _ O
date -X- _ O
of -X- _ O
the -X- _ O
focal -X- _ O
application -X- _ O
and -X- _ O
then -X- _ O
measure -X- _ O
the -X- _ O
maximum -X- _ O
semantic -X- _ O
similarity -X- _ O
score -X- _ O
of -X- _ O
the -X- _ O
focal -X- _ O
patent -X- _ O
claim -X- _ O
matched -X- _ O
with -X- _ O
all -X- _ O
approved -X- _ O
claims -X- _ O
in -X- _ O
the -X- _ O
timedependent -X- _ O
sub -X- _ O
- -X- _ O
pool -X- _ O
. -X- _ O
To -X- _ O
improve -X- _ O
computing -X- _ O
efficiency -X- _ O
, -X- _ O
we -X- _ O
apply -X- _ O
document -X- _ O
- -X- _ O
level -X- _ O
filters -X- _ O
to -X- _ O
narrow -X- _ O
the -X- _ O
sub -X- _ O
- -X- _ O
pool -X- _ O
for -X- _ O
each -X- _ O
claim -X- _ O
. -X- _ O
Integrating -X- _ O
such -X- _ O
similarity -X- _ O
scores -X- _ O
with -X- _ O
handcrafted -X- _ O
features -X- _ O
and -X- _ O
BERT -X- _ B-MethodName
, -X- _ O
we -X- _ O
conduct -X- _ O
experiments -X- _ O
on -X- _ O
the -X- _ O
large -X- _ O
- -X- _ O
scale -X- _ O
USPTO -X- _ B-DatasetName
dataset -X- _ O
and -X- _ O
find -X- _ O
significant -X- _ O
performance -X- _ O
gains -X- _ O
over -X- _ O
fine -X- _ O
- -X- _ O
tuning -X- _ O
a -X- _ O
standard -X- _ O
BERT -X- _ B-MethodName
alone -X- _ O
. -X- _ O

All -X- _ O
else -X- _ O
equal -X- _ O
, -X- _ O
a -X- _ O
patent -X- _ O
claim -X- _ O
with -X- _ O
a -X- _ O
higher -X- _ O
similarity -X- _ O
score -X- _ O
, -X- _ O
i.e. -X- _ O
, -X- _ O
semantically -X- _ O
more -X- _ O
similar -X- _ O
to -X- _ O
prior -X- _ O
approved -X- _ O
claims -X- _ O
, -X- _ O
should -X- _ O
be -X- _ O
less -X- _ O
likely -X- _ O
to -X- _ O
be -X- _ O
approved -X- _ O
. -X- _ O
Hence -X- _ O
we -X- _ O
propose -X- _ O
to -X- _ O
impose -X- _ O
monotonic -X- _ O
regularization -X- _ O
on -X- _ O
the -X- _ O
novelty -X- _ O
score -X- _ O
so -X- _ O
that -X- _ O
the -X- _ O
loss -X- _ O
function -X- _ O
has -X- _ O
an -X- _ O
additional -X- _ O
term -X- _ O
of -X- _ O
the -X- _ O
hinge -X- _ O
loss -X- _ O
to -X- _ O
further -X- _ O
penalize -X- _ O
non -X- _ O
- -X- _ O
decreasing -X- _ O
predictions -X- _ O
in -X- _ O
the -X- _ O
similarity -X- _ O
. -X- _ O
This -X- _ O
effectively -X- _ O
restricts -X- _ O
the -X- _ O
search -X- _ O
space -X- _ O
for -X- _ O
the -X- _ O
optimizer -X- _ O
to -X- _ O
prediction -X- _ O
mechanisms -X- _ O
that -X- _ O
are -X- _ O
reasonably -X- _ O
consistent -X- _ O
with -X- _ O
the -X- _ O
novelty -X- _ O
measure -X- _ O
. -X- _ O
From -X- _ O
our -X- _ O
experiments -X- _ O
, -X- _ O
this -X- _ O
regularization -X- _ O
significantly -X- _ O
impacts -X- _ O
the -X- _ O
model -X- _ O
outputs -X- _ O
. -X- _ O
Although -X- _ O
performance -X- _ O
improvements -X- _ O
are -X- _ O
limited -X- _ O
, -X- _ O
it -X- _ O
can -X- _ O
help -X- _ O
the -X- _ O
optimizer -X- _ O
steer -X- _ O
away -X- _ O
from -X- _ O
unfavorable -X- _ O
local -X- _ O
optima -X- _ O
and -X- _ O
further -X- _ O
improve -X- _ O
AUROC -X- _ B-MetricName
. -X- _ O
We -X- _ O
further -X- _ O
discuss -X- _ O
the -X- _ O
experimental -X- _ O
findings -X- _ O
in -X- _ O
depth -X- _ O
to -X- _ O
illustrate -X- _ O
how -X- _ O
BERT -X- _ B-MethodName
and -X- _ O
handcrafted -X- _ O
features -X- _ O
contribute -X- _ O
in -X- _ O
overcoming -X- _ O
the -X- _ O
unconventional -X- _ O
data -X- _ O
issues -X- _ O
. -X- _ O

https -X- _ O
: -X- _ O
/ -X- _ O
/ -X- _ O
github.com -X- _ O
/ -X- _ O
acl-2022 -X- _ O
- -X- _ O
towards -X- _ O
- -X- _ O
comprehensive -X- _ O
/ -X- _ O
acl-2022 -X- _ O
- -X- _ O
camera -X- _ O
- -X- _ O
ready -X- _ O
. -X- _ O

Problem -X- _ O
Formulation -X- _ O
and -X- _ O
Benchmark -X- _ O

A -X- _ O
k -X- _ O
, -X- _ O
k -X- _ O
∈ -X- _ O
{ -X- _ O
1 -X- _ O
• -X- _ O
• -X- _ O
• -X- _ O
M -X- _ O
} -X- _ O
, -X- _ O
sorted -X- _ O
by -X- _ O
filing -X- _ O
dates -X- _ O
, -X- _ O
comprises -X- _ O
of -X- _ O
a -X- _ O
number -X- _ O
of -X- _ O
application -X- _ O
claims -X- _ O
. -X- _ O
Given -X- _ O
text -X- _ O
representation -X- _ O
X -X- _ O
i -X- _ O
, -X- _ O
i -X- _ O
∈ -X- _ O
{ -X- _ O
1 -X- _ O
• -X- _ O
• -X- _ O
• -X- _ O
N -X- _ O
} -X- _ O
, -X- _ O
of -X- _ O
each -X- _ O
application -X- _ O
claim -X- _ O
, -X- _ O
there -X- _ O
ex- -X- _ O
ist -X- _ O
{ -X- _ O
i -X- _ O
k -X- _ O
} -X- _ O
, -X- _ O
k -X- _ O
∈ -X- _ O
{ -X- _ O
0 -X- _ O
• -X- _ O
• -X- _ O
• -X- _ O
M -X- _ O
} -X- _ O
such -X- _ O
that -X- _ O
claim -X- _ O
representa- -X- _ O
tions -X- _ O
{ -X- _ O
X -X- _ O
i -X- _ O
k−1 -X- _ O
• -X- _ O
• -X- _ O
• -X- _ O
X -X- _ O
i -X- _ O
k -X- _ O
} -X- _ O
belong -X- _ O
to -X- _ O
patent -X- _ O
application -X- _ O
A -X- _ O
k -X- _ O
. -X- _ O

Common -X- _ O
Document -X- _ O
Classifiers -X- _ O
. -X- _ O
We -X- _ O
mainly -X- _ O
evaluate -X- _ O
the -X- _ O
following -X- _ O
common -X- _ O
document -X- _ O
classifiers -X- _ O
. -X- _ O
• -X- _ O
Log -X- _ B-MethodName
. -X- _ I-MethodName
Reg -X- _ I-MethodName
. -X- _ I-MethodName
refers -X- _ O
to -X- _ O
logistics -X- _ B-MethodName
regression -X- _ I-MethodName
using -X- _ O
TF -X- _ O
- -X- _ O
TDF -X- _ O
features -X- _ O
. -X- _ O
• -X- _ O
Text -X- _ B-MethodName
- -X- _ I-MethodName
CNN -X- _ I-MethodName
( -X- _ O
Kim -X- _ O
, -X- _ O
2014 -X- _ O
) -X- _ O
with -X- _ O
GloVe -X- _ B-MethodName
( -X- _ O
Pennington -X- _ O
et -X- _ O
al -X- _ O
. -X- _ O
, -X- _ O
2014 -X- _ O
) -X- _ O
( -X- _ O
Lee -X- _ O
and -X- _ O
Hsiang -X- _ O
, -X- _ O
2019 -X- _ O
) -X- _ O
with -X- _ O
a -X- _ O
different -X- _ O
set -X- _ O
of -X- _ O
hyper -X- _ O
- -X- _ O
parameters -X- _ O
and -X- _ O
balanced -X- _ O
class -X- _ O
weights -X- _ O
. -X- _ O
The -X- _ O
original -X- _ O
PatentBERT -X- _ B-MethodName
model -X- _ O
is -X- _ O
designed -X- _ O
for -X- _ O
a -X- _ O
different -X- _ O
task -X- _ O
, -X- _ O
and -X- _ O
the -X- _ O
experimental -X- _ O
setting -X- _ O
is -X- _ O
not -X- _ O
suitable -X- _ O
for -X- _ O
predicting -X- _ O
patent -X- _ O
approvals -X- _ O
, -X- _ O
hence -X- _ O
we -X- _ O
make -X- _ O
the -X- _ O
tweaks -X- _ O
. -X- _ O
In -X- _ O
all -X- _ O
of -X- _ O
the -X- _ O
models -X- _ O
, -X- _ O
we -X- _ O
impose -X- _ O
class -X- _ O
weights -X- _ O
in -X- _ O
the -X- _ O
loss -X- _ O
functions -X- _ O
inversely -X- _ O
proportional -X- _ O
to -X- _ O
the -X- _ O
number -X- _ O
of -X- _ O
class -X- _ O
instances -X- _ O
, -X- _ O
such -X- _ O
that -X- _ O
two -X- _ O
classes -X- _ O
are -X- _ O
treated -X- _ O
equally -X- _ O
by -X- _ O
the -X- _ O
optimizer -X- _ O
. -X- _ O
For -X- _ O
the -X- _ O
details -X- _ O
, -X- _ O
please -X- _ O
refer -X- _ O
to -X- _ O
Section -X- _ O
3.1 -X- _ O
. -X- _ O
The -X- _ O
neural -X- _ O
models -X- _ O
are -X- _ O
trained -X- _ O
with -X- _ O
text -X- _ O
inputs -X- _ O
processed -X- _ O
at -X- _ O
a -X- _ O
maximum -X- _ B-HyperparameterValue
length -X- _ I-HyperparameterValue
of -X- _ O
128 -X- _ B-HyperparameterValue
tokens -X- _ O
per -X- _ O
claim -X- _ O
and -X- _ O
on -X- _ O
a -X- _ O
single -X- _ O
GPU -X- _ O
. -X- _ O
Evaluation -X- _ O
Metrics -X- _ O
. -X- _ O
Given -X- _ O
the -X- _ O
imbalanced -X- _ O
nature -X- _ O
of -X- _ O
our -X- _ O
dataset -X- _ O
, -X- _ O
we -X- _ O
adopt -X- _ O
both -X- _ O
the -X- _ O
Area -X- _ B-MetricName
Under -X- _ I-MetricName
the -X- _ I-MetricName
Curve -X- _ I-MetricName
for -X- _ I-MetricName
the -X- _ I-MetricName
ROC -X- _ I-MetricName
plot -X- _ I-MetricName
( -X- _ O
Fawcett -X- _ O
, -X- _ O
2004 -X- _ O
) -X- _ O
( -X- _ O
AUROC -X- _ B-MetricName
) -X- _ O
and -X- _ O
macro -X- _ B-MetricName
F1 -X- _ I-MetricName
score -X- _ O
as -X- _ O
our -X- _ O
evaluation -X- _ O
metrics -X- _ O
. -X- _ O
With -X- _ O
AUROC -X- _ B-MetricName
, -X- _ O
the -X- _ O
predicting -X- _ O
performance -X- _ O
of -X- _ O
the -X- _ O
minority -X- _ O
class -X- _ O
could -X- _ O
be -X- _ O
taken -X- _ O
into -X- _ O
consideration -X- _ O
with -X- _ O
a -X- _ O
similar -X- _ O
weight -X- _ O
as -X- _ O
for -X- _ O
the -X- _ O
majority -X- _ O
class -X- _ O
( -X- _ O
in -X- _ O
our -X- _ O
case -X- _ O
, -X- _ O
positive -X- _ O
class -X- _ O
) -X- _ O
. -X- _ O
Moreover -X- _ O
, -X- _ O
the -X- _ O
probabilitybased -X- _ O
metric -X- _ O
can -X- _ O
provide -X- _ O
more -X- _ O
detailed -X- _ O
insights -X- _ O
into -X- _ O
model -X- _ O
performances -X- _ O
. -X- _ O
Therefore -X- _ O
, -X- _ O
we -X- _ O
choose -X- _ O
AUROC -X- _ B-MetricName
as -X- _ O
our -X- _ O
main -X- _ O
metric -X- _ O
. -X- _ O
The -X- _ O
macro -X- _ B-MetricName
F1 -X- _ I-MetricName
score -X- _ O
is -X- _ O
a -X- _ O
direct -X- _ O
average -X- _ O
of -X- _ O
F1 -X- _ B-MetricName
scores -X- _ O
of -X- _ O
both -X- _ O
the -X- _ O
positive -X- _ O
class -X- _ O
and -X- _ O
the -X- _ O
negative -X- _ O
class -X- _ O
and -X- _ O
provides -X- _ O
an -X- _ O
alternative -X- _ O
balanced -X- _ O
view -X- _ O
of -X- _ O
both -X- _ O
classes -X- _ O
' -X- _ O
performances -X- _ O
. -X- _ O

Our -X- _ O
AISeer -X- _ B-MethodName
framework -X- _ O
unifies -X- _ O
the -X- _ O
document -X- _ O
classifier -X- _ O
, -X- _ O
handcrafted -X- _ O
features -X- _ O
and -X- _ O
monotonic -X- _ O
regularization -X- _ O
, -X- _ O
as -X- _ O
shown -X- _ O
in -X- _ O
Figure -X- _ O
1 -X- _ O
. -X- _ O
It -X- _ O
is -X- _ O
compatible -X- _ O
with -X- _ O
almost -X- _ O
all -X- _ O
document -X- _ O
classifiers -X- _ O
. -X- _ O
In -X- _ O
this -X- _ O
paper -X- _ O
, -X- _ O
we -X- _ O
choose -X- _ O
BERT -X- _ B-MethodName
as -X- _ O
the -X- _ O
base -X- _ O
document -X- _ O
classifier -X- _ O
to -X- _ O
demonstrate -X- _ O
the -X- _ O
effects -X- _ O
as -X- _ O
it -X- _ O
is -X- _ O
widely -X- _ O
adopted -X- _ O
and -X- _ O
also -X- _ O
performs -X- _ O
well -X- _ O
in -X- _ O
our -X- _ O
benchmark -X- _ O
evaluations -X- _ O
. -X- _ O
After -X- _ O
each -X- _ O
application -X- _ O
claim -X- _ O
text -X- _ O
is -X- _ O
run -X- _ O
through -X- _ O
the -X- _ O
BERT -X- _ B-MethodName
model -X- _ O
, -X- _ O
the -X- _ O
output -X- _ O
representation -X- _ O
is -X- _ O
concatenated -X- _ O
with -X- _ O
the -X- _ O
corresponding -X- _ O
handcrafted -X- _ O
features -X- _ O
. -X- _ O
Our -X- _ O
handcrafted -X- _ O
features -X- _ O
include -X- _ O
a -X- _ O
time -X- _ O
- -X- _ O
dependent -X- _ O
claim -X- _ O
- -X- _ O
level -X- _ O
novelty -X- _ O
score -X- _ O
, -X- _ O
claim -X- _ O
- -X- _ O
level -X- _ O
structural -X- _ O
features -X- _ O
, -X- _ O
document -X- _ O
- -X- _ O
level -X- _ O
similarity -X- _ O
scores -X- _ O
, -X- _ O
and -X- _ O
other -X- _ O
application -X- _ O
metadata -X- _ O
features -X- _ O
. -X- _ O
We -X- _ O
further -X- _ O
impose -X- _ O
a -X- _ O
monotonic -X- _ O
regularization -X- _ O
on -X- _ O
the -X- _ O
impact -X- _ O
of -X- _ O
the -X- _ O
claim -X- _ O
- -X- _ O
level -X- _ O
novelty -X- _ O
score -X- _ O
so -X- _ O
that -X- _ O
the -X- _ O
loss -X- _ O
function -X- _ O
has -X- _ O
an -X- _ O
additional -X- _ O
term -X- _ O
of -X- _ O
the -X- _ O
hinge -X- _ O
loss -X- _ O
. -X- _ O

where -X- _ O
w -X- _ O
y -X- _ O
i -X- _ O
denotes -X- _ O
the -X- _ O
fixed -X- _ O
weights -X- _ O
of -X- _ O
the -X- _ O
two -X- _ O
classes -X- _ O
, -X- _ O
which -X- _ O
is -X- _ O
inversely -X- _ O
proportional -X- _ O
to -X- _ O
the -X- _ O
number -X- _ O
of -X- _ O
instances -X- _ O
from -X- _ O
the -X- _ O
corresponding -X- _ O
class -X- _ O
, -X- _ O
balancing -X- _ O
the -X- _ O
training -X- _ O
weights -X- _ O
of -X- _ O
the -X- _ O
two -X- _ O
classes -X- _ O
. -X- _ O

The -X- _ O
baseline -X- _ O
BERT -X- _ B-MethodName
model -X- _ O
gives -X- _ O
decent -X- _ O
AUC -X- _ B-MetricName
( -X- _ I-MetricName
ROC -X- _ I-MetricName
) -X- _ I-MetricName
and -X- _ O
macro -X- _ B-MetricName
F1 -X- _ I-MetricName
. -X- _ O
The -X- _ O
full -X- _ O
- -X- _ O
fledged -X- _ O
AISeer -X- _ B-MethodName
, -X- _ O
combining -X- _ O
handcrafted -X- _ O
novelty -X- _ O
feature -X- _ O
along -X- _ O
with -X- _ O
other -X- _ O
computed -X- _ O
ones -X- _ O
and -X- _ O
motonic -X- _ O
regularization -X- _ O
, -X- _ O
helps -X- _ O
with -X- _ O
both -X- _ O
the -X- _ O
metric -X- _ O
dimensions -X- _ O
: -X- _ O
AISeer -X- _ B-MethodName
boosts -X- _ O
AUROC -X- _ B-MetricName
by -X- _ O
around -X- _ O
2.5 -X- _ B-MetricValue
% -X- _ I-MetricValue
percent -X- _ O
and -X- _ O
macro -X- _ B-MetricName
F1 -X- _ I-MetricName
by -X- _ O
around -X- _ O
1 -X- _ B-MetricValue
% -X- _ I-MetricValue
compared -X- _ O
to -X- _ O
the -X- _ O
best -X- _ O
common -X- _ O
document -X- _ O
classifiers -X- _ O
. -X- _ O
Figure -X- _ O
5 -X- _ O
in -X- _ O
Appendix -X- _ O
F -X- _ O
shows -X- _ O
the -X- _ O
AUROC -X- _ B-MetricName
improvement -X- _ O
originates -X- _ O
con -X- _ O
- -X- _ O
sistently -X- _ O
from -X- _ O
the -X- _ O
entire -X- _ O
spectrum -X- _ O
of -X- _ O
prediction -X- _ O
scores -X- _ O
. -X- _ O

Comparing -X- _ O
AISeer -X- _ B-MethodName
w -X- _ O
/ -X- _ O
o -X- _ O
Regu -X- _ O
. -X- _ O
result -X- _ O
, -X- _ O
also -X- _ O
in -X- _ O
the -X- _ O
lower -X- _ O
half -X- _ O
of -X- _ O
Table -X- _ O
3 -X- _ O
, -X- _ O
and -X- _ O
the -X- _ O
standard -X- _ O
BERT -X- _ B-MethodName
and -X- _ O
LSTM -X- _ B-MethodName
results -X- _ O
, -X- _ O
it -X- _ O
is -X- _ O
shown -X- _ O
that -X- _ O
handcrafted -X- _ O
features -X- _ O
improve -X- _ O
on -X- _ O
best -X- _ O
common -X- _ O
document -X- _ O
classifiers -X- _ O
by -X- _ O
about -X- _ O
2 -X- _ B-MetricValue
% -X- _ I-MetricValue
. -X- _ O
We -X- _ O
believe -X- _ O
that -X- _ O
the -X- _ O
handcrafted -X- _ O
features -X- _ O
combined -X- _ O
, -X- _ O
in -X- _ O
particular -X- _ O
, -X- _ O
the -X- _ O
novelty -X- _ O
feature -X- _ O
, -X- _ O
helps -X- _ O
in -X- _ O
resolving -X- _ O
label -X- _ O
contradictions -X- _ O
and -X- _ O
data -X- _ O
inconsistency -X- _ O
. -X- _ O

We -X- _ O
also -X- _ O
evaluate -X- _ O
the -X- _ O
Spearman -X- _ B-MetricName
correlation -X- _ I-MetricName
coefficients -X- _ I-MetricName
of -X- _ O
the -X- _ O
probability -X- _ O
prediction -X- _ O
scores -X- _ O
produced -X- _ O
by -X- _ O
the -X- _ O
models -X- _ O
with -X- _ O
the -X- _ O
claim -X- _ O
- -X- _ O
level -X- _ O
novelty -X- _ O
feature -X- _ O
Pearson -X- _ B-MetricName
correlations -X- _ I-MetricName
with -X- _ O
the -X- _ O
document -X- _ O
- -X- _ O
level -X- _ O
similarity -X- _ O
score -X- _ O
. -X- _ O
Spearman -X- _ B-MetricName
correlations -X- _ I-MetricName
measure -X- _ O
the -X- _ O
strength -X- _ O
and -X- _ O
direction -X- _ O
of -X- _ O
monotonic -X- _ O
association -X- _ O
between -X- _ O
two -X- _ O
variables -X- _ O
. -X- _ O
According -X- _ O
to -X- _ O
Table -X- _ O
5 -X- _ O
, -X- _ O
first -X- _ O
we -X- _ O
can -X- _ O
confirm -X- _ O
that -X- _ O
applying -X- _ O
monotonic -X- _ O
regularization -X- _ O
significantly -X- _ O
pushes -X- _ O
the -X- _ O
prediction -X- _ B-MetricName
scores -X- _ I-MetricName
to -X- _ O
be -X- _ O
more -X- _ O
monotonically -X- _ O
decreasing -X- _ O
in -X- _ O
the -X- _ O
core -X- _ O
novelty -X- _ O
feature -X- _ O
-the -X- _ O
Spearman -X- _ B-MetricName
correlation -X- _ I-MetricName
shifts -X- _ O
from -X- _ O
-0.0230 -X- _ B-MetricValue
to -X- _ O
-0.103 -X- _ B-MetricValue
. -X- _ O
However -X- _ O
, -X- _ O
compared -X- _ O
to -X- _ O
the -X- _ O
BERT -X- _ B-MethodName
, -X- _ O
the -X- _ O
regularization -X- _ O
effect -X- _ O
is -X- _ O
less -X- _ O
prominent -X- _ O
. -X- _ O
Observe -X- _ O
that -X- _ O
adding -X- _ O
handcrafted -X- _ O
features -X- _ O
will -X- _ O
actually -X- _ O
steer -X- _ O
the -X- _ O
monotonicity -X- _ O
into -X- _ O
the -X- _ O
opposite -X- _ O
direction -X- _ O
. -X- _ O
Our -X- _ O
regularized -X- _ O
AISeer -X- _ B-MethodName
model -X- _ O
manages -X- _ O
to -X- _ O
both -X- _ O
benefit -X- _ O
from -X- _ O
the -X- _ O
novelty -X- _ O
feature -X- _ O
and -X- _ O
incorporate -X- _ O
knowledge -X- _ O
from -X- _ O
other -X- _ O
handcrafted -X- _ O
features -X- _ O
. -X- _ O

In -X- _ O
this -X- _ O
paper -X- _ O
, -X- _ O
we -X- _ O
tackle -X- _ O
the -X- _ O
challenging -X- _ O
problem -X- _ O
of -X- _ O
predicting -X- _ B-TaskName
patent -X- _ I-TaskName
approval -X- _ I-TaskName
decisions -X- _ I-TaskName
as -X- _ O
per -X- _ O
35 -X- _ O
U.S. -X- _ O
Code -X- _ O
§ -X- _ O
102 -X- _ O
, -X- _ O
namely -X- _ O
the -X- _ O
novelty -X- _ O
- -X- _ O
based -X- _ O
decisions -X- _ O
. -X- _ O
We -X- _ O
have -X- _ O
prepared -X- _ O
a -X- _ O
large -X- _ O
- -X- _ O
scale -X- _ O
benchmark -X- _ O
dataset -X- _ O
by -X- _ O
consolidating -X- _ O
different -X- _ O
data -X- _ O
sources -X- _ O
from -X- _ O
USPTO -X- _ B-DatasetName
. -X- _ O
From -X- _ O
the -X- _ O
evaluations -X- _ O
of -X- _ O
the -X- _ O
popular -X- _ O
document -X- _ O
classifiers -X- _ O
, -X- _ O
BERT -X- _ B-MethodName
and -X- _ O
LSTM -X- _ B-MethodName
are -X- _ O
arguably -X- _ O
the -X- _ O
most -X- _ O
effective -X- _ O
ones -X- _ O
. -X- _ O
We -X- _ O
identify -X- _ O
the -X- _ O
timedependent -X- _ O
challenge -X- _ O
of -X- _ O
the -X- _ O
novelty -X- _ O
judgement -X- _ O
, -X- _ O
and -X- _ O
therefore -X- _ O
propose -X- _ O
AISeer -X- _ B-MethodName
, -X- _ O
a -X- _ O
novel -X- _ O
framework -X- _ O
going -X- _ O
beyond -X- _ O
the -X- _ O
traditional -X- _ O
document -X- _ O
classifiers -X- _ O
. -X- _ O
Specifically -X- _ O
, -X- _ O
we -X- _ O
construct -X- _ O
a -X- _ O
claim -X- _ O
- -X- _ O
level -X- _ O
core -X- _ O
novelty -X- _ O
feature -X- _ O
along -X- _ O
with -X- _ O
several -X- _ O
other -X- _ O
handcrafted -X- _ O
features -X- _ O
and -X- _ O
apply -X- _ O
them -X- _ O
on -X- _ O
top -X- _ O
of -X- _ O
the -X- _ O
pre -X- _ O
- -X- _ O
trained -X- _ O
BERT -X- _ B-MethodName
model -X- _ O
. -X- _ O
We -X- _ O
further -X- _ O
propose -X- _ O
to -X- _ O
add -X- _ O
the -X- _ O
monotonic -X- _ O
regularization -X- _ O
on -X- _ O
the -X- _ O
core -X- _ O
novelty -X- _ O
feature -X- _ O
to -X- _ O
resolve -X- _ O
the -X- _ O
potential -X- _ O
label -X- _ O
conflicts -X- _ O
caused -X- _ O
by -X- _ O
the -X- _ O
mechanism -X- _ O
of -X- _ O
the -X- _ O
patent -X- _ O
examination -X- _ O
process -X- _ O
. -X- _ O
Experimental -X- _ O
results -X- _ O
have -X- _ O
verified -X- _ O
the -X- _ O
superiority -X- _ O
of -X- _ O
AISeer -X- _ B-MethodName
and -X- _ O
also -X- _ O
the -X- _ O
effectiveness -X- _ O
of -X- _ O
introducing -X- _ O
novelty -X- _ O
features -X- _ O
and -X- _ O
monotonic -X- _ O
regularization -X- _ O
. -X- _ O

We -X- _ O
believe -X- _ O
that -X- _ O
our -X- _ O
work -X- _ O
is -X- _ O
beneficial -X- _ O
to -X- _ O
various -X- _ O
parties -X- _ O
, -X- _ O
including -X- _ O
patent -X- _ O
applicants -X- _ O
, -X- _ O
attorneys -X- _ O
, -X- _ O
examiners -X- _ O
and -X- _ O
regulators -X- _ O
. -X- _ O
While -X- _ O
the -X- _ O
advantages -X- _ O
of -X- _ O
our -X- _ O
regularization -X- _ O
methodology -X- _ O
are -X- _ O
significant -X- _ O
, -X- _ O
there -X- _ O
is -X- _ O
still -X- _ O
room -X- _ O
for -X- _ O
potential -X- _ O
metric -X- _ O
improvements -X- _ O
, -X- _ O
thus -X- _ O
further -X- _ O
developing -X- _ O
the -X- _ O
work -X- _ O
will -X- _ O
yield -X- _ O
opportunities -X- _ O
for -X- _ O
promising -X- _ O
future -X- _ O
research -X- _ O
and -X- _ O
greater -X- _ O
contributions -X- _ O
to -X- _ O
the -X- _ O
communities -X- _ O
. -X- _ O
In -X- _ O
future -X- _ O
, -X- _ O
it -X- _ O
is -X- _ O
important -X- _ O
to -X- _ O
extend -X- _ O
the -X- _ O
scope -X- _ O
from -X- _ O
claims -X- _ O
to -X- _ O
the -X- _ O
other -X- _ O
sections -X- _ O
in -X- _ O
the -X- _ O
patent -X- _ O
applications -X- _ O
. -X- _ O
Relationships -X- _ O
among -X- _ O
components -X- _ O
and -X- _ O
entities -X- _ O
described -X- _ O
in -X- _ O
claims -X- _ O
and -X- _ O
relations -X- _ O
among -X- _ O
claims -X- _ O
are -X- _ O
also -X- _ O
critical -X- _ O
to -X- _ O
investigate -X- _ O
. -X- _ O

We -X- _ O
want -X- _ O
to -X- _ O
thank -X- _ O
the -X- _ O
anonymous -X- _ O
reviewers -X- _ O
for -X- _ O
their -X- _ O
insightful -X- _ O
comments -X- _ O
. -X- _ O
The -X- _ O
research -X- _ O
was -X- _ O
sponsored -X- _ O
in -X- _ O
part -X- _ O
by -X- _ O
National -X- _ O
Science -X- _ O
Foundation -X- _ O
Convergence -X- _ O
Accelerator -X- _ O
under -X- _ O
award -X- _ O
OIA-2040727 -X- _ O
as -X- _ O
well -X- _ O
as -X- _ O
generous -X- _ O
gifts -X- _ O
from -X- _ O
Google -X- _ O
, -X- _ O
Adobe -X- _ O
, -X- _ O
and -X- _ O
Teradata -X- _ O
. -X- _ O
Any -X- _ O
opinions -X- _ O
, -X- _ O
findings -X- _ O
, -X- _ O
conclusions -X- _ O
, -X- _ O
or -X- _ O
recommendations -X- _ O
expressed -X- _ O
herein -X- _ O
are -X- _ O
those -X- _ O
of -X- _ O
the -X- _ O
authors -X- _ O
and -X- _ O
should -X- _ O
not -X- _ O
be -X- _ O
interpreted -X- _ O
as -X- _ O
necessarily -X- _ O
representing -X- _ O
the -X- _ O
views -X- _ O
, -X- _ O
either -X- _ O
expressed -X- _ O
or -X- _ O
implied -X- _ O
, -X- _ O
of -X- _ O
the -X- _ O
U.S. -X- _ O
Government -X- _ O
. -X- _ O
The -X- _ O
U.S. -X- _ O
Government -X- _ O
is -X- _ O
authorized -X- _ O
to -X- _ O
reproduce -X- _ O
and -X- _ O
distribute -X- _ O
reprints -X- _ O
for -X- _ O
government -X- _ O
purposes -X- _ O
notwithstanding -X- _ O
any -X- _ O
copyright -X- _ O
annotation -X- _ O
hereon -X- _ O
. -X- _ O

Information -X- _ O
- -X- _ O
Theoretic -X- _ O
Text -X- _ O
Hallucination -X- _ O
Reduction -X- _ O
for -X- _ O
Video -X- _ B-TaskName
- -X- _ I-TaskName
grounded -X- _ I-TaskName
Dialogue -X- _ I-TaskName

Video -X- _ B-TaskName
- -X- _ I-TaskName
grounded -X- _ I-TaskName
Dialogue -X- _ I-TaskName
( -X- _ O
VGD -X- _ B-TaskName
) -X- _ O
aims -X- _ O
to -X- _ O
decode -X- _ O
an -X- _ O
answer -X- _ O
sentence -X- _ O
to -X- _ O
a -X- _ O
question -X- _ O
regarding -X- _ O
a -X- _ O
given -X- _ O
video -X- _ O
and -X- _ O
dialogue -X- _ O
context -X- _ O
. -X- _ O
Despite -X- _ O
the -X- _ O
recent -X- _ O
success -X- _ O
of -X- _ O
multi -X- _ O
- -X- _ O
modal -X- _ O
reasoning -X- _ O
to -X- _ O
generate -X- _ O
answer -X- _ O
sentences -X- _ O
, -X- _ O
existing -X- _ O
dialogue -X- _ O
systems -X- _ O
still -X- _ O
suffer -X- _ O
from -X- _ O
a -X- _ O
text -X- _ O
hallucination -X- _ O
problem -X- _ O
, -X- _ O
which -X- _ O
denotes -X- _ O
indiscriminate -X- _ O
text -X- _ O
- -X- _ O
copying -X- _ O
from -X- _ O
input -X- _ O
texts -X- _ O
without -X- _ O
an -X- _ O
understanding -X- _ O
of -X- _ O
the -X- _ O
question -X- _ O
. -X- _ O
This -X- _ O
is -X- _ O
due -X- _ O
to -X- _ O
learning -X- _ O
spurious -X- _ O
correlations -X- _ O
from -X- _ O
the -X- _ O
fact -X- _ O
that -X- _ O
answer -X- _ O
sentences -X- _ O
in -X- _ O
the -X- _ O
dataset -X- _ O
usually -X- _ O
include -X- _ O
the -X- _ O
words -X- _ O
of -X- _ O
input -X- _ O
texts -X- _ O
, -X- _ O
thus -X- _ O
the -X- _ O
VGD -X- _ B-TaskName
system -X- _ O
excessively -X- _ O
relies -X- _ O
on -X- _ O
copying -X- _ O
words -X- _ O
from -X- _ O
input -X- _ O
texts -X- _ O
by -X- _ O
hoping -X- _ O
those -X- _ O
words -X- _ O
to -X- _ O
overlap -X- _ O
with -X- _ O
ground -X- _ O
- -X- _ O
truth -X- _ O
texts -X- _ O
. -X- _ O
Hence -X- _ O
, -X- _ O
we -X- _ O
design -X- _ O
Text -X- _ B-MethodName
Hallucination -X- _ I-MethodName
Mitigating -X- _ I-MethodName
( -X- _ O
THAM -X- _ B-MethodName
) -X- _ O
framework -X- _ O
, -X- _ O
which -X- _ O
incorporates -X- _ O
Text -X- _ O
Hallucination -X- _ O
Regularization -X- _ O
( -X- _ O
THR -X- _ O
) -X- _ O
loss -X- _ O
derived -X- _ O
from -X- _ O
the -X- _ O
proposed -X- _ O
information -X- _ O
- -X- _ O
theoretic -X- _ O
text -X- _ O
hallucination -X- _ O
measurement -X- _ O
approach -X- _ O
. -X- _ O
Applying -X- _ O
THAM -X- _ B-MethodName
with -X- _ O
current -X- _ O
dialogue -X- _ O
systems -X- _ O
validates -X- _ O
the -X- _ O
effectiveness -X- _ O
on -X- _ O
VGD -X- _ B-TaskName
benchmarks -X- _ O
( -X- _ O
i.e. -X- _ O
, -X- _ O
AVSD -X- _ B-DatasetName
@ -X- _ I-DatasetName
DSTC7 -X- _ I-DatasetName
and -X- _ O
AVSD -X- _ B-DatasetName
@ -X- _ I-DatasetName
DSTC8 -X- _ I-DatasetName
) -X- _ O
and -X- _ O
shows -X- _ O
enhanced -X- _ O
interpretability -X- _ O
. -X- _ O

Introduction -X- _ O

Achieving -X- _ O
a -X- _ O
natural -X- _ O
conversational -X- _ O
agent -X- _ O
that -X- _ O
can -X- _ O
do -X- _ O
' -X- _ O
look -X- _ O
' -X- _ O
( -X- _ O
i.e. -X- _ O
, -X- _ O
understand -X- _ O
what -X- _ O
they -X- _ O
are -X- _ O
seeing -X- _ O
) -X- _ O
and -X- _ O
' -X- _ O
tell -X- _ O
' -X- _ O
( -X- _ O
i.e. -X- _ O
, -X- _ O
converse -X- _ O
what -X- _ O
they -X- _ O
are -X- _ O
thinking -X- _ O
) -X- _ O
is -X- _ O
desiderata -X- _ O
in -X- _ O
our -X- _ O
vision -X- _ O
- -X- _ O
language -X- _ O
community -X- _ O
. -X- _ O
By -X- _ O
the -X- _ O
broad -X- _ O
application -X- _ O
of -X- _ O
conversational -X- _ O
agent -X- _ O
, -X- _ O
it -X- _ O
can -X- _ O
potentially -X- _ O
assist -X- _ O
various -X- _ O
subsections -X- _ O
of -X- _ O
our -X- _ O
environment -X- _ O
including -X- _ O
education -X- _ O
, -X- _ O
entertainment -X- _ O
, -X- _ O
security -X- _ O
, -X- _ O
and -X- _ O
visual -X- _ O
or -X- _ O
other -X- _ O
impairments -X- _ O
. -X- _ O
For -X- _ O
the -X- _ O
natural -X- _ O
conversation -X- _ O
between -X- _ O
humans -X- _ O
and -X- _ O
computers -X- _ O
, -X- _ O
a -X- _ O
video -X- _ B-TaskName
- -X- _ I-TaskName
grounded -X- _ I-TaskName
dialogue -X- _ I-TaskName
( -X- _ O
VGD -X- _ B-TaskName
) -X- _ O
task -X- _ O
( -X- _ O
Alamri -X- _ O
et -X- _ O
al -X- _ O
. -X- _ O
, -X- _ O
2019 -X- _ O
; -X- _ O
has -X- _ O
been -X- _ O
introduced -X- _ O
to -X- _ O
generate -X- _ O
adequate -X- _ O
conversational -X- _ O
responses -X- _ O
to -X- _ O
the -X- _ O
queries -X- _ O
of -X- _ O
humans -X- _ O
, -X- _ O
while -X- _ O
following -X- _ O
up -X- _ O
on -X- _ O
video -X- _ O
and -X- _ O
dialogue -X- _ O
context -X- _ O
, -X- _ O
which -X- _ O
gives -X- _ O
more -X- _ O
challenging -X- _ O
than -X- _ O
traditional -X- _ O
image -X- _ O
- -X- _ O
grounded -X- _ O
or -X- _ O
text -X- _ O
- -X- _ O
grounded -X- _ O
dialogue -X- _ O
tasks -X- _ O
. -X- _ O
To -X- _ O
be -X- _ O
specific -X- _ O
, -X- _ O
given -X- _ O
video -X- _ O
V -X- _ O
, -X- _ O
video -X- _ O
caption -X- _ O
C -X- _ O
, -X- _ O
dialogue -X- _ O
history -X- _ O
of -X- _ O
past -X- _ O
Q -X- _ O
& -X- _ O
A -X- _ O
pairs -X- _ O
: -X- _ O
H -X- _ O
= -X- _ O
{ -X- _ O
( -X- _ O
Q -X- _ O
1 -X- _ O
, -X- _ O
A -X- _ O
1 -X- _ O
) -X- _ O
, -X- _ O
... -X- _ O
, -X- _ O
( -X- _ O
Q -X- _ O
r−1 -X- _ O
, -X- _ O
A -X- _ O
r−1 -X- _ O
) -X- _ O
} -X- _ O
, -X- _ O
and -X- _ O
current -X- _ O
r -X- _ O
- -X- _ O
th -X- _ O
round -X- _ O
question -X- _ O
Q -X- _ O
r -X- _ O
, -X- _ O
VGD -X- _ B-TaskName
system -X- _ O
is -X- _ O
expected -X- _ O
to -X- _ O
make -X- _ O
free -X- _ O
- -X- _ O
form -X- _ O
answer -X- _ O
sentence -X- _ O
A -X- _ O
r -X- _ O
to -X- _ O
given -X- _ O
question -X- _ O
. -X- _ O
Despite -X- _ O
recent -X- _ O
advancements -X- _ O
in -X- _ O
multimodal -X- _ O
interactions -X- _ O
including -X- _ O
transformer -X- _ O
( -X- _ O
Vaswani -X- _ O
et -X- _ O
al -X- _ O
. -X- _ O
, -X- _ O
2017 -X- _ O
) -X- _ O
, -X- _ O
current -X- _ O
VGD -X- _ B-TaskName
systems -X- _ O
still -X- _ O
suffer -X- _ O
text -X- _ O
hallucination -X- _ O
problem -X- _ O
, -X- _ O
which -X- _ O
denotes -X- _ O
indiscriminate -X- _ O
text -X- _ O
- -X- _ O
copying -X- _ O
from -X- _ O
input -X- _ O
texts -X- _ O
( -X- _ O
i.e. -X- _ O
, -X- _ O
question -X- _ O
, -X- _ O
caption -X- _ O
, -X- _ O
and -X- _ O
dialogue -X- _ O
history -X- _ O
) -X- _ O
to -X- _ O
decode -X- _ O
answer -X- _ O
tokens -X- _ O
, -X- _ O
but -X- _ O
the -X- _ O
generated -X- _ O
answer -X- _ O
sentences -X- _ O
are -X- _ O
rather -X- _ O
inadequate -X- _ O
and -X- _ O
not -X- _ O
related -X- _ O
to -X- _ O
the -X- _ O
question -X- _ O
. -X- _ O
This -X- _ O
is -X- _ O
because -X- _ O
current -X- _ O
VGD -X- _ B-TaskName
systems -X- _ O
learn -X- _ O
spurious -X- _ O
correlations -X- _ O
from -X- _ O
the -X- _ O
fact -X- _ O
that -X- _ O
many -X- _ O
ground -X- _ O
- -X- _ O
truth -X- _ O
answers -X- _ O
in -X- _ O
the -X- _ O
dataset -X- _ O
include -X- _ O
partial -X- _ O
input -X- _ O
texts -X- _ O
, -X- _ O
thus -X- _ O
they -X- _ O
perform -X- _ O
incorrect -X- _ O
text -X- _ O
- -X- _ O
copy -X- _ O
from -X- _ O
input -X- _ O
texts -X- _ O
, -X- _ O
namely -X- _ O
text -X- _ O
hallucination -X- _ O
, -X- _ O
even -X- _ O
in -X- _ O
answers -X- _ O
where -X- _ O
input -X- _ O
texts -X- _ O
are -X- _ O
unnecessary -X- _ O
. -X- _ O

Figure -X- _ O
1 -X- _ O
gives -X- _ O
two -X- _ O
indiscriminate -X- _ O
text -X- _ O
hallucinating -X- _ O
cases -X- _ O
confounded -X- _ O
by -X- _ O
spurious -X- _ O
correlations -X- _ O
in -X- _ O
VGD -X- _ B-TaskName
. -X- _ O
As -X- _ O
shown -X- _ O
in -X- _ O
Figure -X- _ O
1 -X- _ O
( -X- _ O
a -X- _ O
) -X- _ O
, -X- _ O
for -X- _ O
the -X- _ O
given -X- _ O
question -X- _ O
' -X- _ O
does -X- _ O
he -X- _ O
place -X- _ O
the -X- _ O
towel -X- _ O
and -X- _ O
clothes -X- _ O
anywhere -X- _ O
? -X- _ O
' -X- _ O
, -X- _ O
we -X- _ O
human -X- _ O
identify -X- _ O
where -X- _ O
the -X- _ O
man -X- _ O
placed -X- _ O
the -X- _ O
towel -X- _ O
and -X- _ O
clothes -X- _ O
, -X- _ O
and -X- _ O
if -X- _ O
it -X- _ O
can -X- _ O
not -X- _ O
be -X- _ O
confirmed -X- _ O
, -X- _ O
we -X- _ O
give -X- _ O
a -X- _ O
sentence -X- _ O
meaning -X- _ O
' -X- _ O
unknown -X- _ O
' -X- _ O
. -X- _ O
However -X- _ O
, -X- _ O
in -X- _ O
many -X- _ O
cases -X- _ O
, -X- _ O
VGD -X- _ B-TaskName
systems -X- _ O
are -X- _ O
optimized -X- _ O
in -X- _ O
situations -X- _ O
where -X- _ O
they -X- _ O
could -X- _ O
find -X- _ O
clues -X- _ O
in -X- _ O
video -X- _ O
and -X- _ O
dialogue -X- _ O
, -X- _ O
so -X- _ O
for -X- _ O
a -X- _ O
case -X- _ O
that -X- _ O
they -X- _ O
can -X- _ O
not -X- _ O
find -X- _ O
clues -X- _ O
, -X- _ O
they -X- _ O
simply -X- _ O
pretend -X- _ O
to -X- _ O
know -X- _ O
the -X- _ O
answer -X- _ O
by -X- _ O
copying -X- _ O
texts -X- _ O
from -X- _ O
input -X- _ O
sentences -X- _ O
without -X- _ O
reasoning -X- _ O
why -X- _ O
the -X- _ O
question -X- _ O
is -X- _ O
not -X- _ O
answerable -X- _ O
. -X- _ O
Thus -X- _ O
, -X- _ O
the -X- _ O
VGD -X- _ B-TaskName
systems -X- _ O
depend -X- _ O
on -X- _ O
indiscriminate -X- _ O
text -X- _ O
hallucination -X- _ O
, -X- _ O
copying -X- _ O
input -X- _ O
sentences -X- _ O
( -X- _ O
i.e. -X- _ O
, -X- _ O
questions -X- _ O
, -X- _ O
caption -X- _ O
, -X- _ O
dialogue -X- _ O
) -X- _ O
, -X- _ O
hoping -X- _ O
the -X- _ O
copied -X- _ O
answer -X- _ O
words -X- _ O
to -X- _ O
overlap -X- _ O
the -X- _ O
ground -X- _ O
- -X- _ O
truth -X- _ O
words -X- _ O
. -X- _ O
Figure -X- _ O
1 -X- _ O
( -X- _ O
b -X- _ O
) -X- _ O
presents -X- _ O
another -X- _ O
dependence -X- _ O
on -X- _ O
this -X- _ O
text -X- _ O
hallucination -X- _ O
even -X- _ O
in -X- _ O
the -X- _ O
answerable -X- _ O
question -X- _ O
. -X- _ O
Given -X- _ O
the -X- _ O
question -X- _ O
of -X- _ O
' -X- _ O
does -X- _ O
the -X- _ O
man -X- _ O
wear -X- _ O
glasses -X- _ O
? -X- _ O
' -X- _ O
, -X- _ O
the -X- _ O
current -X- _ O
VGD -X- _ B-TaskName
system -X- _ O
provides -X- _ O
incorrect -X- _ O
answer -X- _ O
without -X- _ O
referring -X- _ O
to -X- _ O
the -X- _ O
video -X- _ O
and -X- _ O
focuses -X- _ O
on -X- _ O
pretending -X- _ O
to -X- _ O
know -X- _ O
the -X- _ O
C -X- _ O
: -X- _ O
a -X- _ O
smiling -X- _ O
person -X- _ O
grabs -X- _ O
a -X- _ O
towel -X- _ O
, -X- _ O
and -X- _ O
fresh -X- _ O
clothes -X- _ O
. -X- _ O
then -X- _ O
the -X- _ O
person -X- _ O
begins -X- _ O
undressing -X- _ O
. -X- _ O

: -X- _ O
where -X- _ O
does -X- _ O
the -X- _ O
video -X- _ O
take -X- _ O
place -X- _ O
? -X- _ O
: -X- _ O
looks -X- _ O
like -X- _ O
a -X- _ O
bedroom -X- _ O
maybe -X- _ O
. -X- _ O

: -X- _ O
what -X- _ O
happens -X- _ O
after -X- _ O
he -X- _ O
enters -X- _ O
the -X- _ O
room -X- _ O
? -X- _ O
: -X- _ O
he -X- _ O
grabs -X- _ O
a -X- _ O
towel -X- _ O
and -X- _ O
some -X- _ O
clothes -X- _ O
and -X- _ O
then -X- _ O
goes -X- _ O
off -X- _ O
screen -X- _ O
. -X- _ O

: -X- _ O
does -X- _ O
he -X- _ O
place -X- _ O
the -X- _ O
towel -X- _ O
and -X- _ O
clothes -X- _ O
anywhere -X- _ O
? -X- _ O

: -X- _ O
yes -X- _ O
, -X- _ O
he -X- _ O
grabs -X- _ O
a -X- _ O
towel -X- _ O
and -X- _ O
clothes -X- _ O
. -X- _ O
: -X- _ O
not -X- _ O
that -X- _ O
i -X- _ O
can -X- _ O
see -X- _ O
because -X- _ O
he -X- _ O
goes -X- _ O
off -X- _ O
screen -X- _ O
with -X- _ O
them -X- _ O
. -X- _ O

Dialogue -X- _ O
History -X- _ O
( -X- _ O
H -X- _ O
) -X- _ O
, -X- _ O
Caption -X- _ O
( -X- _ O
C -X- _ O
) -X- _ O
Answer -X- _ O
( -X- _ O
) -X- _ O
Question -X- _ O
( -X- _ O
) -X- _ O
( -X- _ O
a -X- _ O
) -X- _ O
Text -X- _ O
hallucination -X- _ O
by -X- _ O
non -X- _ O
- -X- _ O
answerable -X- _ O
question -X- _ O
C -X- _ O
: -X- _ O
a -X- _ O
man -X- _ O
is -X- _ O
using -X- _ O
a -X- _ O
sink -X- _ O
and -X- _ O
is -X- _ O
opening -X- _ O
a -X- _ O
bottom -X- _ O
drawer -X- _ O
to -X- _ O
take -X- _ O
out -X- _ O
a -X- _ O
red -X- _ O
bag -X- _ O
. -X- _ O

: -X- _ O
does -X- _ O
the -X- _ O
man -X- _ O
wear -X- _ O
glasses -X- _ O
? -X- _ O
: -X- _ O
he -X- _ O
does -X- _ O
not -X- _ O
wear -X- _ O
glasses -X- _ O
. -X- _ O
: -X- _ O
he -X- _ O
has -X- _ O
a -X- _ O
pair -X- _ O
of -X- _ O
glasses -X- _ O
on -X- _ O
during -X- _ O
the -X- _ O
video -X- _ O
. -X- _ O
and -X- _ O
answer -X- _ O
sentence -X- _ O
( -X- _ O
prediction -X- _ O
, -X- _ O
ground -X- _ O
- -X- _ O
truth -X- _ O
) -X- _ O
. -X- _ O
( -X- _ O
b -X- _ O
) -X- _ O
sentence -X- _ O
similarity -X- _ O
between -X- _ O
input -X- _ O
sentences -X- _ O
and -X- _ O
answer -X- _ O
sentences -X- _ O
( -X- _ O
incorrect -X- _ O
predictions -X- _ O
, -X- _ O
ground -X- _ O
- -X- _ O
truth -X- _ O
) -X- _ O
, -X- _ O
which -X- _ O
tells -X- _ O
that -X- _ O
incorrect -X- _ O
answers -X- _ O
have -X- _ O
made -X- _ O
mistakes -X- _ O
by -X- _ O
hallucinating -X- _ O
input -X- _ O
sentences -X- _ O
. -X- _ O

Our -X- _ O
manual -X- _ O
studies -X- _ O
in -X- _ O
Figure -X- _ O
2 -X- _ O
give -X- _ O
experimental -X- _ O
evidence -X- _ O
that -X- _ O
the -X- _ O
answer -X- _ O
sentences -X- _ O
predicted -X- _ O
by -X- _ O
current -X- _ O
VGD -X- _ B-TaskName
systems -X- _ O
( -X- _ O
Le -X- _ O
et -X- _ O
al -X- _ O
. -X- _ O
, -X- _ O
2019b -X- _ O
; -X- _ O
are -X- _ O
dependent -X- _ O
on -X- _ O
indiscriminate -X- _ O
text -X- _ O
hallucination -X- _ O
. -X- _ O
Figure -X- _ O
2 -X- _ O
( -X- _ O
a -X- _ O
) -X- _ O
presents -X- _ O
sentence -X- _ O
similarity -X- _ O
score -X- _ O
, -X- _ O
BLEU -X- _ B-MetricName
( -X- _ O
Papineni -X- _ O
et -X- _ O
al -X- _ O
. -X- _ O
, -X- _ O
2002 -X- _ O
) -X- _ O
, -X- _ O
which -X- _ O
computes -X- _ O
word -X- _ O
overlapping -X- _ O
between -X- _ O
( -X- _ O
1 -X- _ O
) -X- _ O
predicted -X- _ O
answers -X- _ O
and -X- _ O
input -X- _ O
texts -X- _ O
( -X- _ O
i.e. -X- _ O
, -X- _ O
caption -X- _ O
, -X- _ O
dialogue -X- _ O
and -X- _ O
question -X- _ O
) -X- _ O
, -X- _ O
and -X- _ O
( -X- _ O
2 -X- _ O
) -X- _ O
ground -X- _ O
- -X- _ O
truth -X- _ O
answers -X- _ O
and -X- _ O
input -X- _ O
texts -X- _ O
from -X- _ O
AVSD -X- _ B-DatasetName
1 -X- _ I-DatasetName
validation -X- _ O
dataset -X- _ O
. -X- _ O
The -X- _ O
higher -X- _ O
scores -X- _ O
between -X- _ O
predicted -X- _ O
answers -X- _ O
and -X- _ O
input -X- _ O
texts -X- _ O
explain -X- _ O
the -X- _ O
reliance -X- _ O
on -X- _ O
input -X- _ O
texts -X- _ O
for -X- _ O
decoding -X- _ O
answer -X- _ O
tokens -X- _ O
. -X- _ O
We -X- _ O
may -X- _ O
take -X- _ O
this -X- _ O
for -X- _ O
granted -X- _ O
, -X- _ O
but -X- _ O
as -X- _ O
shown -X- _ O
in -X- _ O
Figure -X- _ O
2 -X- _ O
( -X- _ O
b -X- _ O
) -X- _ O
, -X- _ O
the -X- _ O
problem -X- _ O
gets -X- _ O
distinguishable -X- _ O
when -X- _ O
collecting -X- _ O
all -X- _ O
the -X- _ O
' -X- _ O
incorrect -X- _ O
' -X- _ O
2 -X- _ O
predictions -X- _ O
. -X- _ O
Many -X- _ O
failure -X- _ O
cases -X- _ O
( -X- _ O
i.e. -X- _ O
, -X- _ O
incorrect -X- _ O
predictions -X- _ O
) -X- _ O
include -X- _ O
that -X- _ O
the -X- _ O
predicted -X- _ O
answers -X- _ O
are -X- _ O
more -X- _ O
similar -X- _ O
to -X- _ O
input -X- _ O
texts -X- _ O
, -X- _ O
which -X- _ O
proves -X- _ O
indiscriminate -X- _ O
text -X- _ O
hallucination -X- _ O
without -X- _ O
the -X- _ O
understanding -X- _ O
of -X- _ O
given -X- _ O
questions -X- _ O
and -X- _ O
videos -X- _ O
. -X- _ O

One -X- _ O
straightforward -X- _ O
solution -X- _ O
to -X- _ O
mitigate -X- _ O
this -X- _ O
indiscriminate -X- _ O
text -X- _ O
hallucination -X- _ O
is -X- _ O
to -X- _ O
extend -X- _ O
the -X- _ O
dataset -X- _ O
using -X- _ O
augmentations -X- _ O
or -X- _ O
modulating -X- _ O
answer -X- _ O
descriptions -X- _ O
to -X- _ O
be -X- _ O
more -X- _ O
stereoscopic -X- _ O
. -X- _ O
However -X- _ O
, -X- _ O
the -X- _ O
augmentation -X- _ O
has -X- _ O
limitations -X- _ O
in -X- _ O
terms -X- _ O
of -X- _ O
diversity -X- _ O
and -X- _ O
the -X- _ O
modulated -X- _ O
descriptions -X- _ O
can -X- _ O
be -X- _ O
sometimes -X- _ O
ad -X- _ O
- -X- _ O
hoc -X- _ O
and -X- _ O
unnecessarily -X- _ O
extravagant -X- _ O
. -X- _ O
Intrigued -X- _ O
by -X- _ O
the -X- _ O
current -X- _ O
overconfidence -X- _ O
in -X- _ O
text -X- _ O
hallucination -X- _ O
of -X- _ O
VGD -X- _ B-TaskName
systems -X- _ O
, -X- _ O
we -X- _ O
contrive -X- _ O
to -X- _ O
build -X- _ O
Text -X- _ B-MethodName
Hallucination -X- _ I-MethodName
Mitigating -X- _ I-MethodName
( -X- _ O
THAM -X- _ B-MethodName
) -X- _ O
framework -X- _ O
that -X- _ O
mitigates -X- _ O
feature -X- _ O
- -X- _ O
level -X- _ O
hallucination -X- _ O
effects -X- _ O
via -X- _ O
introducing -X- _ O
information -X- _ O
- -X- _ O
theoretic -X- _ O
regularization -X- _ O
. -X- _ O
THAM -X- _ B-MethodName
framework -X- _ O
incorporates -X- _ O
Text -X- _ O
Hallucination -X- _ O
Regularization -X- _ O
( -X- _ O
THR -X- _ O
) -X- _ O
loss -X- _ O
derived -X- _ O
from -X- _ O
the -X- _ O
mutual -X- _ O
information -X- _ O
between -X- _ O
the -X- _ O
response -X- _ O
language -X- _ O
model -X- _ O
and -X- _ O
the -X- _ O
proposed -X- _ O
hallucination -X- _ O
lan -X- _ O
- -X- _ O
guage -X- _ O
model -X- _ O
. -X- _ O
Minimizing -X- _ O
THR -X- _ O
loss -X- _ O
contributes -X- _ O
to -X- _ O
reducing -X- _ O
indiscriminate -X- _ O
text -X- _ O
copying -X- _ O
and -X- _ O
boosting -X- _ O
dialogue -X- _ O
performances -X- _ O
. -X- _ O
THAM -X- _ B-MethodName
validates -X- _ O
effectiveness -X- _ O
with -X- _ O
steady -X- _ O
performance -X- _ O
gain -X- _ O
on -X- _ O
top -X- _ O
of -X- _ O
the -X- _ O
current -X- _ O
several -X- _ O
runner -X- _ O
models -X- _ O
( -X- _ O
Hori -X- _ O
et -X- _ O
al -X- _ O
. -X- _ O
, -X- _ O
2019a -X- _ O
; -X- _ O
Le -X- _ O
et -X- _ O
al -X- _ O
. -X- _ O
, -X- _ O
2019b -X- _ O
; -X- _ O
Kim -X- _ O
et -X- _ O
al -X- _ O
. -X- _ O
, -X- _ O
2021 -X- _ O
; -X- _ O
via -X- _ O
a -X- _ O
model -X- _ O
- -X- _ O
agnostic -X- _ O
approach -X- _ O
. -X- _ O
experimental -X- _ O
results -X- _ O
show -X- _ O
state -X- _ O
- -X- _ O
of -X- _ O
- -X- _ O
the -X- _ O
- -X- _ O
art -X- _ O
performances -X- _ O
on -X- _ O
two -X- _ O
VGD -X- _ B-TaskName
benchmarks -X- _ O
( -X- _ O
i.e. -X- _ O
, -X- _ O
AVSD -X- _ B-DatasetName
@ -X- _ I-DatasetName
DSTC7 -X- _ I-DatasetName
and -X- _ O
AVSD -X- _ B-DatasetName
@ -X- _ I-DatasetName
DSTC8 -X- _ I-DatasetName
) -X- _ O
and -X- _ O
enhanced -X- _ O
interpretability -X- _ O
. -X- _ O

Related -X- _ O
Work -X- _ O

To -X- _ O
identify -X- _ O
the -X- _ O
feature -X- _ O
- -X- _ O
level -X- _ O
text -X- _ O
hallucination -X- _ O
, -X- _ O
we -X- _ O
first -X- _ O
introduce -X- _ O
the -X- _ O
mutual -X- _ O
information -X- _ O
I -X- _ O
( -X- _ O
• -X- _ O
; -X- _ O
• -X- _ O
) -X- _ O
, -X- _ O
which -X- _ O
measures -X- _ O
co -X- _ O
- -X- _ O
dependence -X- _ O
between -X- _ O
two -X- _ O
random -X- _ O
variables -X- _ O
X -X- _ O
and -X- _ O
Y -X- _ O
over -X- _ O
the -X- _ O
space -X- _ O
X -X- _ O
× -X- _ O
Y -X- _ O
like -X- _ O
below -X- _ O
: -X- _ O

where -X- _ O
H -X- _ O
( -X- _ O
• -X- _ O
) -X- _ O
is -X- _ O
the -X- _ O
Shannon -X- _ O
entropy -X- _ O
and -X- _ O
H -X- _ O
( -X- _ O
X|Y -X- _ O
) -X- _ O
is -X- _ O
the -X- _ O
conditional -X- _ O
entropy -X- _ O
of -X- _ O
X -X- _ O
given -X- _ O
Y -X- _ O
. -X- _ O
This -X- _ O
mutual -X- _ O
information -X- _ O
is -X- _ O
also -X- _ O
equal -X- _ O
to -X- _ O
the -X- _ O
Kullback -X- _ O
- -X- _ O
Leibler -X- _ O
( -X- _ O
KL- -X- _ O
) -X- _ O
divergence -X- _ O
D -X- _ O
KL -X- _ O
( -X- _ O
•||• -X- _ O
) -X- _ O
between -X- _ O
joint -X- _ O
probability -X- _ O
distribution -X- _ O
P -X- _ O
XY -X- _ O
and -X- _ O
the -X- _ O
product -X- _ O
of -X- _ O
marginals -X- _ O
P -X- _ O
X -X- _ O
⊗ -X- _ O
P -X- _ O
Y -X- _ O
like -X- _ O
below -X- _ O
: -X- _ O

where -X- _ O
T -X- _ O
φ -X- _ O
: -X- _ O
R -X- _ O
D -X- _ O
→ -X- _ O
R -X- _ O
is -X- _ O
a -X- _ O
neural -X- _ O
network -X- _ O
parameterized -X- _ O
by -X- _ O
φ -X- _ O
∈ -X- _ O
Φ -X- _ O
, -X- _ O
and -X- _ O
the -X- _ O
expectations -X- _ O
of -X- _ O
E -X- _ O
P -X- _ O
XY -X- _ O
and -X- _ O
E -X- _ O
P -X- _ O
X -X- _ O
⊗P -X- _ O
Y -X- _ O
are -X- _ O
approximated -X- _ O
by -X- _ O
empirical -X- _ O
sampling -X- _ O
. -X- _ O
Thus -X- _ O
, -X- _ O
maximizing -X- _ O
I -X- _ O
φ -X- _ O
( -X- _ O
X -X- _ O
; -X- _ O
Y -X- _ O
) -X- _ O
provides -X- _ O
a -X- _ O
tight -X- _ O
lower -X- _ O
bound -X- _ O
of -X- _ O
original -X- _ O
mutual -X- _ O
information -X- _ O
4 -X- _ O
I -X- _ O
( -X- _ O
X -X- _ O
; -X- _ O
Y -X- _ O
) -X- _ O
. -X- _ O

Video -X- _ B-TaskName
- -X- _ I-TaskName
grounded -X- _ I-TaskName
Dialogue -X- _ I-TaskName
Task -X- _ O

Video -X- _ B-TaskName
- -X- _ I-TaskName
grounded -X- _ I-TaskName
Dialogue -X- _ I-TaskName
( -X- _ O
VGD -X- _ B-TaskName
) -X- _ O
aims -X- _ O
to -X- _ O
produce -X- _ O
free -X- _ O
- -X- _ O
form -X- _ O
natural -X- _ O
language -X- _ O
answer -X- _ O
for -X- _ O
a -X- _ O
given -X- _ O
question -X- _ O
. -X- _ O
In -X- _ O
the -X- _ O
formal -X- _ O
definition -X- _ O
of -X- _ O
the -X- _ O
VGD -X- _ B-TaskName
task -X- _ O
( -X- _ O
Alamri -X- _ O
et -X- _ O
al -X- _ O
. -X- _ O
, -X- _ O
2019 -X- _ O
) -X- _ O
, -X- _ O
VGD -X- _ B-TaskName
system -X- _ O
takes -X- _ O
tuples -X- _ O
( -X- _ O
v -X- _ O
, -X- _ O
h -X- _ O
, -X- _ O
q -X- _ O
r -X- _ O
) -X- _ O
as -X- _ O
inputs -X- _ O
and -X- _ O
produces -X- _ O
answer -X- _ O
sentence -X- _ O
a -X- _ O
r -X- _ O
, -X- _ O
where -X- _ O
v -X- _ O
is -X- _ O
video -X- _ O
, -X- _ O
h -X- _ O
is -X- _ O
dialogue -X- _ O
history -X- _ O
and -X- _ O
q -X- _ O
r -X- _ O
question -X- _ O
asked -X- _ O
at -X- _ O
current -X- _ O
round -X- _ O
r -X- _ O
∈ -X- _ O
{ -X- _ O
1 -X- _ O
, -X- _ O
• -X- _ O
• -X- _ O
• -X- _ O
, -X- _ O
R -X- _ O
} -X- _ O
. -X- _ O
Here -X- _ O
, -X- _ O
the -X- _ O
dialogue -X- _ O
history -X- _ O
h -X- _ O
= -X- _ O
{ -X- _ O
c -X- _ O
, -X- _ O
( -X- _ O
q -X- _ O
1 -X- _ O
, -X- _ O
a -X- _ O
1 -X- _ O
) -X- _ O
, -X- _ O
• -X- _ O
• -X- _ O
• -X- _ O
, -X- _ O
( -X- _ O
q -X- _ O
r−1 -X- _ O
, -X- _ O
a -X- _ O
r−1 -X- _ O
) -X- _ O
} -X- _ O
is -X- _ O
a -X- _ O
set -X- _ O
of -X- _ O
questionanswer -X- _ O
pairs -X- _ O
of -X- _ O
previous -X- _ O
rounds -X- _ O
and -X- _ O
caption -X- _ O
c -X- _ O
describing -X- _ O
the -X- _ O
summary -X- _ O
of -X- _ O
the -X- _ O
video -X- _ O
. -X- _ O
For -X- _ O
training -X- _ O
of -X- _ O
the -X- _ O
VGD -X- _ B-TaskName
system -X- _ O
, -X- _ O
we -X- _ O
perform -X- _ O
next -X- _ O
- -X- _ O
word -X- _ O
prediction -X- _ O
, -X- _ O
where -X- _ O
it -X- _ O
is -X- _ O
trained -X- _ O
to -X- _ O
predict -X- _ O
t -X- _ O
- -X- _ O
th -X- _ O
answer -X- _ O
word -X- _ O
token -X- _ O
a -X- _ O
r -X- _ O
t -X- _ O
for -X- _ O
given -X- _ O
inputs -X- _ O
of -X- _ O
tuples -X- _ O
( -X- _ O
v -X- _ O
, -X- _ O
h -X- _ O
, -X- _ O
q -X- _ O
r -X- _ O
) -X- _ O
and -X- _ O
partial -X- _ O
answer -X- _ O
word -X- _ O
tokens -X- _ O
a -X- _ O
r -X- _ O
< -X- _ O
t -X- _ O
before -X- _ O
t -X- _ O
- -X- _ O
th -X- _ O
. -X- _ O
: -X- _ O
what -X- _ O
is -X- _ O
happening -X- _ O
in -X- _ O
the -X- _ O
video -X- _ O
? -X- _ O
: -X- _ O
there -X- _ O
's -X- _ O
a -X- _ O
person -X- _ O
sitting -X- _ O
on -X- _ O
the -X- _ O
sofa -X- _ O
. -X- _ O

where -X- _ O
f -X- _ O
denotes -X- _ O
the -X- _ O
transformer -X- _ O
encoders -X- _ O
of -X- _ O
each -X- _ O
model -X- _ O
. -X- _ O
These -X- _ O
two -X- _ O
features -X- _ O
( -X- _ O
i.e. -X- _ O
, -X- _ O
F -X- _ O
< -X- _ O
t -X- _ O
, -X- _ O
F -X- _ O
< -X- _ O
t -X- _ O
) -X- _ O
are -X- _ O
outputs -X- _ O
from -X- _ O
the -X- _ O
position -X- _ O
of -X- _ O
a -X- _ O
t−1 -X- _ O
in -X- _ O
the -X- _ O
transformer -X- _ O
. -X- _ O

We -X- _ O
follow -X- _ O
official -X- _ O
natural -X- _ O
language -X- _ O
generation -X- _ O
metrics -X- _ O
for -X- _ O
AVSD -X- _ B-DatasetName
benchmark -X- _ O
( -X- _ O
i.e. -X- _ O
, -X- _ O
BLEU -X- _ B-MetricName
, -X- _ O
METEOR -X- _ B-MetricName
( -X- _ O
Banerjee -X- _ O
and -X- _ O
Lavie -X- _ O
, -X- _ O
2005 -X- _ O
) -X- _ O
, -X- _ O
ROUGE -X- _ B-MetricName
- -X- _ I-MetricName
L -X- _ I-MetricName
( -X- _ O
Lin -X- _ O
, -X- _ O
2004 -X- _ O
) -X- _ O
, -X- _ O
and -X- _ O
CIDEr -X- _ B-MetricName
( -X- _ O
Vedantam -X- _ O
et -X- _ O
al -X- _ O
. -X- _ O
, -X- _ O
2015 -X- _ O
) -X- _ O
) -X- _ O
. -X- _ O
The -X- _ O
metrics -X- _ O
are -X- _ O
provided -X- _ O
by -X- _ O
challenge -X- _ O
organizers -X- _ O
8 -X- _ O
and -X- _ O
formulated -X- _ O
to -X- _ O
compute -X- _ O
the -X- _ O
word -X- _ O
overlapping -X- _ O
between -X- _ O
each -X- _ O
generated -X- _ O
answer -X- _ O
and -X- _ O
reference -X- _ O
answer -X- _ O
. -X- _ O

Table -X- _ O
1 -X- _ O
summarizes -X- _ O
the -X- _ O
experimental -X- _ O
results -X- _ O
on -X- _ O
the -X- _ O
AVSD -X- _ B-DatasetName
dataset -X- _ O
. -X- _ O
THAM -X- _ B-MethodName
is -X- _ O
compared -X- _ O
to -X- _ O
several -X- _ O
previous -X- _ O
results -X- _ O
of -X- _ O
VGD -X- _ B-TaskName
systems -X- _ O
( -X- _ O
Please -X- _ O
refer -X- _ O
the -X- _ O
descriptions -X- _ O
about -X- _ O
these -X- _ O
VGD -X- _ B-TaskName
systems -X- _ O
in -X- _ O
the -X- _ O
) -X- _ O
, -X- _ O
where -X- _ O
the -X- _ O
performances -X- _ O
of -X- _ O
the -X- _ O
official -X- _ O
six -X- _ O
references -X- _ O
are -X- _ O
evaluated -X- _ O
on -X- _ O
AVSD -X- _ B-DatasetName
@ -X- _ I-DatasetName
DSTC7 -X- _ I-DatasetName
and -X- _ O
AVSD -X- _ B-DatasetName
@ -X- _ I-DatasetName
DSTC8 -X- _ I-DatasetName
. -X- _ O
To -X- _ O
validate -X- _ O
the -X- _ O
effectiveness -X- _ O
of -X- _ O
proposed -X- _ O
our -X- _ O
THR -X- _ O
loss -X- _ O
, -X- _ O
we -X- _ O
report -X- _ O
performances -X- _ O
of -X- _ O
our -X- _ O
naive -X- _ O
VGD -X- _ B-TaskName
model -X- _ O
( -X- _ O
i.e. -X- _ O
, -X- _ O
RLM -X- _ B-MethodName
) -X- _ O
based -X- _ O
on -X- _ O
the -X- _ O
T5 -X- _ O
Transformer -X- _ O
( -X- _ O
Raffel -X- _ O
et -X- _ O
al -X- _ O
. -X- _ O
, -X- _ O
2020 -X- _ O
) -X- _ O
. -X- _ O
Here -X- _ O
, -X- _ O
we -X- _ O
use -X- _ O
' -X- _ O
T5RLM -X- _ B-MethodName
' -X- _ O
for -X- _ O
the -X- _ O
terminology -X- _ O
of -X- _ O
our -X- _ O
RLM -X- _ B-MethodName
to -X- _ O
avoid -X- _ O
confusion -X- _ O
with -X- _ O
RLM -X- _ B-MethodName
in -X- _ O
based -X- _ O
on -X- _ O
GPT2 -X- _ O
Transformer -X- _ O
( -X- _ O
Radford -X- _ O
et -X- _ O
al -X- _ O
. -X- _ O
, -X- _ O
2019 -X- _ O
) -X- _ O
. -X- _ O
In -X- _ O
the -X- _ O
method -X- _ O
, -X- _ O
we -X- _ O
select -X- _ O
a -X- _ O
Transformer -X- _ O
- -X- _ O
base -X- _ O
encoder -X- _ O
for -X- _ O
THAM -X- _ B-MethodName
for -X- _ O
its -X- _ O
simplicity -X- _ O
. -X- _ O
However -X- _ O
, -X- _ O
as -X- _ O
our -X- _ O
framework -X- _ O
can -X- _ O
be -X- _ O
applied -X- _ O
to -X- _ O
any -X- _ O
other -X- _ O
VGD -X- _ B-TaskName
systems -X- _ O
in -X- _ O
a -X- _ O
model -X- _ O
- -X- _ O
agnostic -X- _ O
manner -X- _ O
, -X- _ O
we -X- _ O
also -X- _ O
validate -X- _ O
its -X- _ O
effectiveness -X- _ O
on -X- _ O
recent -X- _ O
runner -X- _ O
VGD -X- _ B-TaskName
models -X- _ O
in -X- _ O
Table -X- _ O
2 -X- _ O
. -X- _ O
In -X- _ O
detail -X- _ O
, -X- _ O
we -X- _ O
repro- -X- _ O
duce -X- _ O
the -X- _ O
MTN -X- _ B-MethodName
, -X- _ O
SCGA -X- _ B-MethodName
and -X- _ O
RLM -X- _ B-MethodName
from -X- _ O
their -X- _ O
public -X- _ O
papers -X- _ O
and -X- _ O
codes -X- _ O
. -X- _ O
For -X- _ O
the -X- _ O
MTN -X- _ B-MethodName
, -X- _ O
we -X- _ O
measure -X- _ O
predicted -X- _ O
answers -X- _ O
with -X- _ O
a -X- _ O
single -X- _ O
reference -X- _ O
following -X- _ O
the -X- _ O
original -X- _ O
work -X- _ O
of -X- _ O
it -X- _ O
. -X- _ O
On -X- _ O
top -X- _ O
of -X- _ O
VGD -X- _ B-TaskName
models -X- _ O
, -X- _ O
THR -X- _ O
loss -X- _ O
show -X- _ O
steady -X- _ O
performance -X- _ O
gain -X- _ O
on -X- _ O
both -X- _ O
AVSD -X- _ B-DatasetName
datasets -X- _ O
. -X- _ O

Figure -X- _ O
5 -X- _ O
gives -X- _ O
joint -X- _ O
distributions -X- _ O
among -X- _ O
the -X- _ O
language -X- _ O
models -X- _ O
' -X- _ O
encoder -X- _ O
features -X- _ O
. -X- _ O
Here -X- _ O
, -X- _ O
the -X- _ O
RLM -X- _ O
is -X- _ O
fully -X- _ O
trained -X- _ O
from -X- _ O
THAM -X- _ B-MethodName
framework -X- _ O
. -X- _ O
From -X- _ O
512 -X- _ O
samples -X- _ O
of -X- _ O
AVSD -X- _ B-DatasetName
validation -X- _ O
set -X- _ O
, -X- _ O
we -X- _ O
select -X- _ O
a -X- _ O
single -X- _ O
value -X- _ O
among -X- _ O
the -X- _ O
d -X- _ O
- -X- _ O
dimensional -X- _ O
space -X- _ O
at -X- _ O
the -X- _ O
same -X- _ O
position -X- _ O
of -X- _ O
each -X- _ O
encoder -X- _ O
feature -X- _ O
( -X- _ O
i.e. -X- _ O
, -X- _ O
F -X- _ O
< -X- _ O
t -X- _ O
, -X- _ O
F -X- _ O
< -X- _ O
t -X- _ O
, -X- _ O
G -X- _ O
< -X- _ O
t -X- _ O
) -X- _ O
. -X- _ O
Figure -X- _ O
5 -X- _ O
( -X- _ O
a -X- _ O
) -X- _ O
summarizes -X- _ O
joint -X- _ O
plots -X- _ O
between -X- _ O
F -X- _ O
< -X- _ O
t -X- _ O
and -X- _ O
F -X- _ O
< -X- _ O
t -X- _ O
, -X- _ O
where -X- _ O
the -X- _ O
correlations -X- _ O
are -X- _ O
confirmed -X- _ O
due -X- _ O
to -X- _ O
the -X- _ O
common -X- _ O
grammatical -X- _ O
knowledge -X- _ O
from -X- _ O
language -X- _ O
models -X- _ O
. -X- _ O
However -X- _ O
Figure -X- _ O
5 -X- _ O
( -X- _ O
b -X- _ O
) -X- _ O
shows -X- _ O
uncorrelated -X- _ O
distributions -X- _ O
between -X- _ O
F -X- _ O
< -X- _ O
t -X- _ O
and -X- _ O
G -X- _ O
< -X- _ O
t -X- _ O
, -X- _ O
which -X- _ O
means -X- _ O
the -X- _ O
grammatical -X- _ O
knowledge -X- _ O
is -X- _ O
properly -X- _ O
removed -X- _ O
from -X- _ O
G -X- _ O
< -X- _ O
t -X- _ O
. -X- _ O
Figure -X- _ O
6 -X- _ O
gives -X- _ O
responses -X- _ O
of -X- _ O
naive -X- _ O
RLM -X- _ B-MethodName
and -X- _ O
THAM -X- _ B-MethodName
( -X- _ O
naive -X- _ O
RLM -X- _ O
+ -X- _ O
THR -X- _ O
loss -X- _ O
) -X- _ O
. -X- _ O
For -X- _ O
the -X- _ O
question -X- _ O
of -X- _ O
" -X- _ O
what -X- _ O
are -X- _ O
they -X- _ O
both -X- _ O
wearing -X- _ O
" -X- _ O
, -X- _ O
naive -X- _ O
RLM -X- _ B-MethodName
shows -X- _ O
the -X- _ O
reliance -X- _ O
on -X- _ O
texts -X- _ O
from -X- _ O
history -X- _ O
without -X- _ O
understanding -X- _ O
of -X- _ O
the -X- _ O
question -X- _ O
. -X- _ O
However -X- _ O
, -X- _ O
the -X- _ O
THAM -X- _ B-MethodName
is -X- _ O
generating -X- _ O
correct -X- _ O
answer -X- _ O
sentence -X- _ O
pertinent -X- _ O
to -X- _ O
the -X- _ O
given -X- _ O
question -X- _ O
. -X- _ O

Text -X- _ B-MethodName
Hallucination -X- _ I-MethodName
Mitigating -X- _ I-MethodName
framework -X- _ O
is -X- _ O
proposed -X- _ O
for -X- _ O
Video -X- _ B-TaskName
- -X- _ I-TaskName
grounded -X- _ I-TaskName
Dialogue -X- _ I-TaskName
. -X- _ O
THAM -X- _ B-MethodName
considers -X- _ O
the -X- _ O
text -X- _ O
hallucination -X- _ O
problem -X- _ O
, -X- _ O
which -X- _ O
copies -X- _ O
input -X- _ O
texts -X- _ O
for -X- _ O
answer -X- _ O
generation -X- _ O
without -X- _ O
understanding -X- _ O
of -X- _ O
the -X- _ O
question -X- _ O
. -X- _ O
THAM -X- _ B-MethodName
framework -X- _ O
incorporates -X- _ O
Text -X- _ O
Hallucination -X- _ O
Regularization -X- _ O
loss -X- _ O
derived -X- _ O
from -X- _ O
proposed -X- _ O
information -X- _ O
- -X- _ O
theoretic -X- _ O
text -X- _ O
hallucination -X- _ O
measurement -X- _ O
approach -X- _ O
. -X- _ O
Empirical -X- _ O
results -X- _ O
on -X- _ O
VGD -X- _ B-TaskName
benchmarks -X- _ O
show -X- _ O
that -X- _ O
THAM -X- _ B-MethodName
achieves -X- _ O
state -X- _ O
- -X- _ O
of -X- _ O
- -X- _ O
the -X- _ O
- -X- _ O
art -X- _ O
performances -X- _ O
and -X- _ O
effectiveness -X- _ O
. -X- _ O
We -X- _ O
would -X- _ O
also -X- _ O
like -X- _ O
to -X- _ O
thank -X- _ O
the -X- _ O
anonymous -X- _ O
reviewers -X- _ O
for -X- _ O
their -X- _ O
feedback -X- _ O
. -X- _ O

Limitations -X- _ O

The -X- _ O
limitations -X- _ O
of -X- _ O
the -X- _ O
Text -X- _ B-MethodName
Hallucination -X- _ I-MethodName
Mitigating -X- _ I-MethodName
Framework -X- _ O
are -X- _ O
as -X- _ O
follows -X- _ O
. -X- _ O
First -X- _ O
, -X- _ O
our -X- _ O
empirical -X- _ O
analysis -X- _ O
provides -X- _ O
that -X- _ O
THAM -X- _ B-MethodName
is -X- _ O
facing -X- _ O
a -X- _ O
failure -X- _ O
case -X- _ O
about -X- _ O
the -X- _ O
question -X- _ O
of -X- _ O
sounds -X- _ O
. -X- _ O
In -X- _ O
Figure -X- _ O
7 -X- _ O
in -X- _ O
supplemental -X- _ O
materials -X- _ O
, -X- _ O
for -X- _ O
the -X- _ O
question -X- _ O
of -X- _ O
" -X- _ O
what -X- _ O
kind -X- _ O
of -X- _ O
noise -X- _ O
" -X- _ O
, -X- _ O
THAM -X- _ O
is -X- _ O
hallucinating -X- _ O
response -X- _ O
without -X- _ O
understanding -X- _ O
the -X- _ O
question -X- _ O
. -X- _ O
Although -X- _ O
the -X- _ O
answer -X- _ O
" -X- _ O
i -X- _ O
can -X- _ O
hear -X- _ O
some -X- _ O
noise -X- _ O
" -X- _ O
can -X- _ O
be -X- _ O
plausible -X- _ O
, -X- _ O
but -X- _ O
it -X- _ O
also -X- _ O
seems -X- _ O
just -X- _ O
hallucinating -X- _ O
by -X- _ O
copying -X- _ O
from -X- _ O
history -X- _ O
texts -X- _ O
. -X- _ O
We -X- _ O
speculate -X- _ O
this -X- _ O
is -X- _ O
because -X- _ O
the -X- _ O
sound -X- _ O
features -X- _ O
contain -X- _ O
less -X- _ O
information -X- _ O
( -X- _ O
128 -X- _ O
dimensions -X- _ O
) -X- _ O
comparing -X- _ O
to -X- _ O
video -X- _ O
( -X- _ O
2048 -X- _ O
dimensions -X- _ O
) -X- _ O
, -X- _ O
which -X- _ O
requires -X- _ O
more -X- _ O
specialized -X- _ O
attention -X- _ O
( -X- _ O
e.g. -X- _ O
, -X- _ O
fine -X- _ O
- -X- _ O
grained -X- _ O
audio -X- _ O
processing -X- _ O
) -X- _ O
. -X- _ O
For -X- _ O
the -X- _ O
second -X- _ O
limitation -X- _ O
, -X- _ O
THAM -X- _ B-MethodName
is -X- _ O
based -X- _ O
on -X- _ O
two -X- _ O
- -X- _ O
stage -X- _ O
training -X- _ O
mechanism -X- _ O
. -X- _ O
To -X- _ O
perform -X- _ O
mitigation -X- _ O
of -X- _ O
text -X- _ O
hallucination -X- _ O
, -X- _ O
pre -X- _ O
- -X- _ O
training -X- _ O
of -X- _ O
each -X- _ O
language -X- _ O
model -X- _ O
is -X- _ O
required -X- _ O
as -X- _ O
a -X- _ O
first -X- _ O
- -X- _ O
stage -X- _ O
training -X- _ O
. -X- _ O
To -X- _ O
overcome -X- _ O
the -X- _ O
aforementioned -X- _ O
limitations -X- _ O
, -X- _ O
we -X- _ O
will -X- _ O
perform -X- _ O
further -X- _ O
studies -X- _ O
and -X- _ O
make -X- _ O
an -X- _ O
effort -X- _ O
on -X- _ O
video -X- _ O
interpretability -X- _ O
improvements -X- _ O
. -X- _ O

As -X- _ O
one -X- _ O
of -X- _ O
the -X- _ O
interactive -X- _ O
AI -X- _ O
, -X- _ O
the -X- _ O
Video -X- _ B-TaskName
- -X- _ I-TaskName
grounded -X- _ I-TaskName
Dialogue -X- _ I-TaskName
system -X- _ O
is -X- _ O
designed -X- _ O
for -X- _ O
providing -X- _ O
assistance -X- _ O
to -X- _ O
various -X- _ O
subsections -X- _ O
of -X- _ O
our -X- _ O
environments -X- _ O
including -X- _ O
education -X- _ O
, -X- _ O
entertainment -X- _ O
, -X- _ O
and -X- _ O
visual -X- _ O
impairments -X- _ O
. -X- _ O
Our -X- _ O
proposed -X- _ O
Text -X- _ B-MethodName
Hallucination -X- _ I-MethodName
Mitigation -X- _ I-MethodName
Framework -X- _ I-MethodName
have -X- _ O
contributed -X- _ O
to -X- _ O
improving -X- _ O
response -X- _ O
qualities -X- _ O
and -X- _ O
alleviating -X- _ O
abnormalities -X- _ O
in -X- _ O
the -X- _ O
system -X- _ O
. -X- _ O
We -X- _ O
also -X- _ O
consider -X- _ O
the -X- _ O
potential -X- _ O
negative -X- _ O
societal -X- _ O
impact -X- _ O
that -X- _ O
those -X- _ O
who -X- _ O
are -X- _ O
aware -X- _ O
of -X- _ O
the -X- _ O
VGD -X- _ B-TaskName
system -X- _ O
can -X- _ O
deliberately -X- _ O
manipulate -X- _ O
it -X- _ O
to -X- _ O
get -X- _ O
prohibited -X- _ O
information -X- _ O
. -X- _ O
Furthermore -X- _ O
, -X- _ O
to -X- _ O
apply -X- _ O
the -X- _ O
VGD -X- _ B-TaskName
system -X- _ O
in -X- _ O
the -X- _ O
real -X- _ O
environment -X- _ O
, -X- _ O
fairness -X- _ O
and -X- _ O
bias -X- _ O
issues -X- _ O
of -X- _ O
dialogue -X- _ O
systems -X- _ O
should -X- _ O
also -X- _ O
be -X- _ O
addressed -X- _ O
. -X- _ O

Training -X- _ O
. -X- _ O
THAM -X- _ B-MethodName
is -X- _ O
trained -X- _ O
on -X- _ O
NVIDIA -X- _ O
TITAN -X- _ O
V -X- _ O
( -X- _ O
12 -X- _ O
GB -X- _ O
of -X- _ O
memory -X- _ O
) -X- _ O
GPU -X- _ O
with -X- _ O
Adam -X- _ O
optimizer -X- _ O
( -X- _ O
Kingma -X- _ O
and -X- _ O
Ba -X- _ O
, -X- _ O
2014 -X- _ O
) -X- _ O
with -X- _ O
β -X- _ B-HyperparameterName
1 -X- _ I-HyperparameterName
= -X- _ O
0.9 -X- _ B-HyperparameterValue
, -X- _ O
β -X- _ B-HyperparameterName
2 -X- _ I-HyperparameterName
= -X- _ O
0.99 -X- _ B-HyperparameterValue
, -X- _ O
and -X- _ O
= -X- _ O
10e-8 -X- _ B-HyperparameterValue
. -X- _ O
We -X- _ O
utilized -X- _ O
the -X- _ O
piece -X- _ O
- -X- _ O
wise -X- _ O
linearly -X- _ O
decreased -X- _ O
learning -X- _ B-HyperparameterName
rate -X- _ I-HyperparameterName
from -X- _ O
6.25e-4 -X- _ B-HyperparameterValue
to -X- _ O
0 -X- _ B-HyperparameterValue
and -X- _ O
set -X- _ O
the -X- _ O
learning -X- _ B-HyperparameterName
rate -X- _ I-HyperparameterName
warm -X- _ I-HyperparameterName
- -X- _ I-HyperparameterName
up -X- _ I-HyperparameterName
strategy -X- _ O
to -X- _ O
10,000 -X- _ B-HyperparameterValue
training -X- _ I-HyperparameterValue
steps -X- _ I-HyperparameterValue
and -X- _ O
trained -X- _ O
the -X- _ O
model -X- _ O
up -X- _ O
to -X- _ O
20 -X- _ B-HyperparameterValue
epochs -X- _ B-HyperparameterName
. -X- _ O
In -X- _ O
Section -X- _ O
4.1 -X- _ O
, -X- _ O
the -X- _ O
interpolation -X- _ O
is -X- _ O
conducted -X- _ O
via -X- _ O
the -X- _ O
window -X- _ O
overlapping -X- _ O
method -X- _ O
. -X- _ O
The -X- _ O
first -X- _ O
- -X- _ O
stage -X- _ O
training -X- _ O
is -X- _ O
performed -X- _ O
on -X- _ O
three -X- _ O
language -X- _ O
models -X- _ O
( -X- _ O
i.e. -X- _ O
, -X- _ O
RLM -X- _ B-MethodName
, -X- _ O
HLM -X- _ B-MethodName
, -X- _ O
LM -X- _ B-MethodName
) -X- _ O
respectively -X- _ O
with -X- _ O
a -X- _ O
batch -X- _ B-HyperparameterName
size -X- _ I-HyperparameterName
of -X- _ O
8 -X- _ B-HyperparameterValue
and -X- _ O
a -X- _ O
dropout -X- _ B-HyperparameterName
rate -X- _ I-HyperparameterName
of -X- _ O
0.3 -X- _ B-HyperparameterValue
. -X- _ O
For -X- _ O
the -X- _ O
d -X- _ B-HyperparameterName
- -X- _ O
dimensional -X- _ O
space -X- _ O
, -X- _ O
all -X- _ O
language -X- _ O
models -X- _ O
use -X- _ O
d=768 -X- _ B-HyperparameterName
. -X- _ O
The -X- _ O
secondstage -X- _ O
training -X- _ O
is -X- _ O
performed -X- _ O
on -X- _ O
RLM -X- _ B-MethodName
with -X- _ O
THR -X- _ O
loss -X- _ O
with -X- _ O
the -X- _ O
same -X- _ O
batch -X- _ B-HyperparameterName
size -X- _ I-HyperparameterName
and -X- _ O
dropout -X- _ B-HyperparameterName
rate -X- _ I-HyperparameterName
with -X- _ O
the -X- _ O
first -X- _ O
training -X- _ O
. -X- _ O
The -X- _ O
best -X- _ O
model -X- _ O
is -X- _ O
decided -X- _ O
by -X- _ O
the -X- _ O
lowest -X- _ O
validation -X- _ O
loss -X- _ O
on -X- _ O
the -X- _ O
validation -X- _ O
- -X- _ O
set -X- _ O
with -X- _ O
α -X- _ B-HyperparameterName
= -X- _ O
0.01 -X- _ B-HyperparameterValue
in -X- _ O
equation -X- _ O
( -X- _ O
11 -X- _ O
) -X- _ O
of -X- _ O
the -X- _ O
main -X- _ O
paper -X- _ O
on -X- _ O
the -X- _ O
setting -X- _ O
X -X- _ O
< -X- _ O
t -X- _ O
= -X- _ O
[ -X- _ O
h||a -X- _ O
< -X- _ O
t -X- _ O
] -X- _ O
. -X- _ O
The -X- _ O
training -X- _ O
takes -X- _ O
about -X- _ O
5 -X- _ O
hours -X- _ O
to -X- _ O
be -X- _ O
fully -X- _ O
optimized -X- _ O
at -X- _ O
the -X- _ O
losses -X- _ O
of -X- _ O
about -X- _ O
0.184 -X- _ O
on -X- _ O
training -X- _ O
and -X- _ O
0.284 -X- _ O
on -X- _ O
validation -X- _ O
. -X- _ O
Inference -X- _ B-MetricName
time -X- _ I-MetricName
for -X- _ O
generating -X- _ O
the -X- _ O
answer -X- _ O
for -X- _ O
a -X- _ O
single -X- _ O
question -X- _ O
takes -X- _ O
about -X- _ O
2 -X- _ B-MetricValue
seconds -X- _ I-MetricValue
. -X- _ O
Our -X- _ O
model -X- _ O
is -X- _ O
not -X- _ O
performed -X- _ O
on -X- _ O
hyperparameter -X- _ O
searching -X- _ O
for -X- _ O
model -X- _ O
fine -X- _ O
- -X- _ O
tuning -X- _ O
. -X- _ O

For -X- _ O
the -X- _ O
probability -X- _ O
distribution -X- _ O
of -X- _ O
P -X- _ O
and -X- _ O
Q -X- _ O
, -X- _ O
the -X- _ O
KL -X- _ O
divergence -X- _ O
admits -X- _ O
the -X- _ O
following -X- _ O
dual -X- _ O
representation -X- _ O
as -X- _ O
: -X- _ O

We -X- _ O
also -X- _ O
confirmed -X- _ O
that -X- _ O
the -X- _ O
proposed -X- _ O
THAM -X- _ B-MethodName
is -X- _ O
fragile -X- _ O
to -X- _ O
the -X- _ O
questions -X- _ O
of -X- _ O
asking -X- _ O
sounds -X- _ O
in -X- _ O
the -X- _ O
video -X- _ O
, -X- _ O
where -X- _ O
it -X- _ O
copies -X- _ O
the -X- _ O
input -X- _ O
texts -X- _ O
of -X- _ O
" -X- _ O
i -X- _ O
can -X- _ O
hear -X- _ O
some -X- _ O
noise -X- _ O
" -X- _ O
from -X- _ O
history -X- _ O
texts -X- _ O
in -X- _ O
Figure -X- _ O
7 -X- _ O
. -X- _ O
While -X- _ O
we -X- _ O
admit -X- _ O
that -X- _ O
the -X- _ O
above -X- _ O
case -X- _ O
can -X- _ O
produce -X- _ O
semantically -X- _ O
correct -X- _ O
answers -X- _ O
, -X- _ O
we -X- _ O
feel -X- _ O
that -X- _ O
the -X- _ O
VGD -X- _ B-TaskName
systems -X- _ O
should -X- _ O
be -X- _ O
able -X- _ O
to -X- _ O
generate -X- _ O
more -X- _ O
rich -X- _ O
answers -X- _ O
using -X- _ O
their -X- _ O
own -X- _ O
languages -X- _ O
. -X- _ O
Furthermore -X- _ O
, -X- _ O
the -X- _ O
sound -X- _ O
features -X- _ O
contain -X- _ O
less -X- _ O
information -X- _ O
( -X- _ O
128 -X- _ O
dimensions -X- _ O
) -X- _ O
compared -X- _ O
to -X- _ O
video -X- _ O
( -X- _ O
2048 -X- _ O
dimensions -X- _ O
) -X- _ O
, -X- _ O
which -X- _ O
requires -X- _ O
more -X- _ O
specialized -X- _ O
attention -X- _ O
. -X- _ O

Acknowledgements -X- _ O

RAPO -X- _ B-MethodName
: -X- _ O
An -X- _ O
Adaptive -X- _ O
Ranking -X- _ O
Paradigm -X- _ O
for -X- _ O
Bilingual -X- _ B-TaskName
Lexicon -X- _ I-TaskName
Induction -X- _ I-TaskName

Bilingual -X- _ B-TaskName
lexicon -X- _ I-TaskName
induction -X- _ I-TaskName
induces -X- _ O
the -X- _ O
word -X- _ O
translations -X- _ O
by -X- _ O
aligning -X- _ O
independently -X- _ O
trained -X- _ O
word -X- _ O
embeddings -X- _ O
in -X- _ O
two -X- _ O
languages -X- _ O
. -X- _ O
Existing -X- _ O
approaches -X- _ O
generally -X- _ O
focus -X- _ O
on -X- _ O
minimizing -X- _ O
the -X- _ O
distances -X- _ O
between -X- _ O
words -X- _ O
in -X- _ O
the -X- _ O
aligned -X- _ O
pairs -X- _ O
, -X- _ O
while -X- _ O
suffering -X- _ O
from -X- _ O
low -X- _ O
discriminative -X- _ O
capability -X- _ O
to -X- _ O
distinguish -X- _ O
the -X- _ O
relative -X- _ O
orders -X- _ O
between -X- _ O
positive -X- _ O
and -X- _ O
negative -X- _ O
candidates -X- _ O
. -X- _ O
In -X- _ O
addition -X- _ O
, -X- _ O
the -X- _ O
mapping -X- _ O
function -X- _ O
is -X- _ O
globally -X- _ O
shared -X- _ O
by -X- _ O
all -X- _ O
words -X- _ O
, -X- _ O
whose -X- _ O
performance -X- _ O
might -X- _ O
be -X- _ O
hindered -X- _ O
by -X- _ O
the -X- _ O
deviations -X- _ O
in -X- _ O
the -X- _ O
distributions -X- _ O
of -X- _ O
different -X- _ O
languages -X- _ O
. -X- _ O
In -X- _ O
this -X- _ O
work -X- _ O
, -X- _ O
we -X- _ O
propose -X- _ O
a -X- _ O
novel -X- _ O
ranking -X- _ O
- -X- _ O
oriented -X- _ O
induction -X- _ O
model -X- _ O
RAPO -X- _ B-MethodName
to -X- _ O
learn -X- _ O
personalized -X- _ O
mapping -X- _ O
function -X- _ O
for -X- _ O
each -X- _ O
word -X- _ O
. -X- _ O
RAPO -X- _ B-MethodName
is -X- _ O
capable -X- _ O
of -X- _ O
enjoying -X- _ O
the -X- _ O
merits -X- _ O
from -X- _ O
the -X- _ O
unique -X- _ O
characteristics -X- _ O
of -X- _ O
a -X- _ O
single -X- _ O
word -X- _ O
and -X- _ O
the -X- _ O
cross -X- _ O
- -X- _ O
language -X- _ O
isomorphism -X- _ O
simultaneously -X- _ O
. -X- _ O
Extensive -X- _ O
experimental -X- _ O
results -X- _ O
on -X- _ O
public -X- _ O
datasets -X- _ O
including -X- _ O
both -X- _ O
rich -X- _ O
- -X- _ O
resource -X- _ O
and -X- _ O
lowresource -X- _ O
languages -X- _ O
demonstrate -X- _ O
the -X- _ O
superiority -X- _ O
of -X- _ O
our -X- _ O
proposal -X- _ O
. -X- _ O
Our -X- _ O
code -X- _ O
is -X- _ O
publicly -X- _ O
available -X- _ O
in -X- _ O
https -X- _ O
: -X- _ O
/ -X- _ O
/ -X- _ O
github.com -X- _ O
/ -X- _ O
Jlfj345wf -X- _ O
/ -X- _ O
RAPO -X- _ O
. -X- _ O

Bilingual -X- _ B-TaskName
lexicon -X- _ I-TaskName
induction -X- _ I-TaskName
( -X- _ O
BLI -X- _ B-TaskName
) -X- _ O
aims -X- _ O
at -X- _ O
inducing -X- _ O
the -X- _ O
word -X- _ O
translations -X- _ O
across -X- _ O
two -X- _ O
languages -X- _ O
based -X- _ O
on -X- _ O
the -X- _ O
monolingual -X- _ O
corpora -X- _ O
, -X- _ O
which -X- _ O
is -X- _ O
capable -X- _ O
of -X- _ O
transferring -X- _ O
valuable -X- _ O
semantic -X- _ O
knowledge -X- _ O
between -X- _ O
different -X- _ O
languages -X- _ O
, -X- _ O
spawning -X- _ O
a -X- _ O
myriad -X- _ O
of -X- _ O
NLP -X- _ O
tasks -X- _ O
such -X- _ O
as -X- _ O
machine -X- _ O
translation -X- _ O
Artetxe -X- _ O
et -X- _ O
al -X- _ O
. -X- _ O
, -X- _ O
2018c -X- _ O
) -X- _ O
, -X- _ O
semantic -X- _ O
parsing -X- _ O
( -X- _ O
Xiao -X- _ O
and -X- _ O
Guo -X- _ O
, -X- _ O
2014 -X- _ O
) -X- _ O
, -X- _ O
and -X- _ O
document -X- _ O
classification -X- _ O
( -X- _ O
Klementiev -X- _ O
et -X- _ O
al -X- _ O
. -X- _ O
, -X- _ O
2012 -X- _ O
) -X- _ O
. -X- _ O
The -X- _ O
nucleus -X- _ O
of -X- _ O
BLI -X- _ B-TaskName
is -X- _ O
learning -X- _ O
a -X- _ O
desirable -X- _ O
mapping -X- _ O
function -X- _ O
to -X- _ O
align -X- _ O
two -X- _ O
sets -X- _ O
of -X- _ O
independently -X- _ O
trained -X- _ O
monolingual -X- _ O
word -X- _ O
embeddings -X- _ O
( -X- _ O
Mikolov -X- _ O
et -X- _ O
al -X- _ O
. -X- _ O
, -X- _ O
2013 -X- _ O
; -X- _ O
Glavaš -X- _ O
et -X- _ O
al -X- _ O
. -X- _ O
, -X- _ O
2019 -X- _ O
) -X- _ O
. -X- _ O
Mikolov -X- _ O
et -X- _ O
al -X- _ O
. -X- _ O
( -X- _ O
2013 -X- _ O
) -X- _ O
empirically -X- _ O
observe -X- _ O
that -X- _ O
the -X- _ O
linear -X- _ O
projections -X- _ O
are -X- _ O
superior -X- _ O
to -X- _ O
their -X- _ O
non -X- _ O
- -X- _ O
linear -X- _ O
counterparts -X- _ O
due -X- _ O
to -X- _ O
the -X- _ O
isomorphism -X- _ O
across -X- _ O
different -X- _ O
embedding -X- _ O
spaces -X- _ O
. -X- _ O
Sub -X- _ O
- -X- _ O
sequent -X- _ O
improvements -X- _ O
are -X- _ O
successively -X- _ O
proposed -X- _ O
to -X- _ O
advance -X- _ O
BLI -X- _ B-TaskName
task -X- _ O
by -X- _ O
imposing -X- _ O
orthogonal -X- _ O
constraints -X- _ O
( -X- _ O
Xing -X- _ O
et -X- _ O
al -X- _ O
. -X- _ O
, -X- _ O
2015 -X- _ O
; -X- _ O
, -X- _ O
normalizing -X- _ O
the -X- _ O
embeddings -X- _ O
( -X- _ O
Artetxe -X- _ O
et -X- _ O
al -X- _ O
. -X- _ O
, -X- _ O
2016 -X- _ O
( -X- _ O
Artetxe -X- _ O
et -X- _ O
al -X- _ O
. -X- _ O
, -X- _ O
, -X- _ O
2018aZhang -X- _ O
et -X- _ O
al -X- _ O
. -X- _ O
, -X- _ O
2019 -X- _ O
) -X- _ O
, -X- _ O
reducing -X- _ O
the -X- _ O
noises -X- _ O
( -X- _ O
Artetxe -X- _ O
et -X- _ O
al -X- _ O
. -X- _ O
, -X- _ O
2018b -X- _ O
; -X- _ O
Yehezkel -X- _ O
Lubin -X- _ O
et -X- _ O
al -X- _ O
. -X- _ O
, -X- _ O
2019 -X- _ O
) -X- _ O
, -X- _ O
relaxing -X- _ O
the -X- _ O
hypothesis -X- _ O
of -X- _ O
isomorphism -X- _ O
( -X- _ O
Søgaard -X- _ O
et -X- _ O
al -X- _ O
. -X- _ O
, -X- _ O
2018 -X- _ O
; -X- _ O
Patra -X- _ O
et -X- _ O
al -X- _ O
. -X- _ O
, -X- _ O
2019 -X- _ O
) -X- _ O
, -X- _ O
and -X- _ O
iteratively -X- _ O
refining -X- _ O
the -X- _ O
seed -X- _ O
dictionary -X- _ O
( -X- _ O
Zhao -X- _ O
et -X- _ O
al -X- _ O
. -X- _ O
, -X- _ O
2020 -X- _ O
) -X- _ O
. -X- _ O

Existing -X- _ O
methods -X- _ O
( -X- _ O
Artetxe -X- _ O
et -X- _ O
al -X- _ O
. -X- _ O
, -X- _ O
2016 -X- _ O
( -X- _ O
Artetxe -X- _ O
et -X- _ O
al -X- _ O
. -X- _ O
, -X- _ O
, -X- _ O
2018aJawanpuria -X- _ O
et -X- _ O
al -X- _ O
. -X- _ O
, -X- _ O
2020 -X- _ O
) -X- _ O
usually -X- _ O
aim -X- _ O
at -X- _ O
minimizing -X- _ O
the -X- _ O
distance -X- _ O
between -X- _ O
the -X- _ O
word -X- _ O
from -X- _ O
the -X- _ O
source -X- _ O
language -X- _ O
and -X- _ O
its -X- _ O
aligned -X- _ O
word -X- _ O
in -X- _ O
the -X- _ O
target -X- _ O
language -X- _ O
( -X- _ O
e.g. -X- _ O
, -X- _ O
crow -X- _ O
and -X- _ O
cuervo -X- _ O
in -X- _ O
Figure -X- _ O
1 -X- _ O
) -X- _ O
. -X- _ O
However -X- _ O
, -X- _ O
BLI -X- _ B-TaskName
is -X- _ O
essentially -X- _ O
a -X- _ O
ranking -X- _ O
- -X- _ O
oriented -X- _ O
task -X- _ O
because -X- _ O
for -X- _ O
each -X- _ O
source -X- _ O
word -X- _ O
, -X- _ O
we -X- _ O
expect -X- _ O
to -X- _ O
select -X- _ O
its -X- _ O
top -X- _ O
k -X- _ O
highconfidence -X- _ O
target -X- _ O
candidates -X- _ O
. -X- _ O
Namely -X- _ O
, -X- _ O
a -X- _ O
desirable -X- _ O
BLI -X- _ B-TaskName
model -X- _ O
should -X- _ O
also -X- _ O
be -X- _ O
capable -X- _ O
of -X- _ O
distinguishing -X- _ O
the -X- _ O
relative -X- _ O
orders -X- _ O
between -X- _ O
the -X- _ O
positive -X- _ O
and -X- _ O
negative -X- _ O
candidates -X- _ O
( -X- _ O
e.g. -X- _ O
, -X- _ O
crow -X- _ O
and -X- _ O
curevo -X- _ O
should -X- _ O
be -X- _ O
distributed -X- _ O
closer -X- _ O
than -X- _ O
crow -X- _ O
and -X- _ O
pájaro -X- _ O
) -X- _ O
. -X- _ O
The -X- _ O
objective -X- _ O
functions -X- _ O
used -X- _ O
by -X- _ O
previous -X- _ O
works -X- _ O
solely -X- _ O
focus -X- _ O
on -X- _ O
the -X- _ O
distances -X- _ O
between -X- _ O
positive -X- _ O
pairs -X- _ O
and -X- _ O
can -X- _ O
not -X- _ O
explicitly -X- _ O
provide -X- _ O
such -X- _ O
important -X- _ O
ranking -X- _ O
signals -X- _ O
, -X- _ O
leading -X- _ O
to -X- _ O
the -X- _ O
low -X- _ O
discriminative -X- _ O
capability -X- _ O
. -X- _ O

In -X- _ O
addition -X- _ O
, -X- _ O
conventional -X- _ O
BLI -X- _ B-TaskName
models -X- _ O
( -X- _ O
Mikolov -X- _ O
et -X- _ O
al -X- _ O
. -X- _ O
, -X- _ O
2013 -X- _ O
; -X- _ O
Xing -X- _ O
et -X- _ O
al -X- _ O
. -X- _ O
, -X- _ O
2015 -X- _ O
; -X- _ O
Zhao -X- _ O
et -X- _ O
al -X- _ O
. -X- _ O
, -X- _ O
2020 -X- _ O
) -X- _ O
induce -X- _ O
the -X- _ O
bilingual -X- _ O
space -X- _ O
via -X- _ O
a -X- _ O
shared -X- _ O
mapping -X- _ O
function -X- _ O
, -X- _ O
in -X- _ O
which -X- _ O
different -X- _ O
words -X- _ O
in -X- _ O
the -X- _ O
same -X- _ O
language -X- _ O
tend -X- _ O
to -X- _ O
be -X- _ O
rotated -X- _ O
in -X- _ O
the -X- _ O
same -X- _ O
directions -X- _ O
. -X- _ O
However -X- _ O
, -X- _ O
several -X- _ O
studies -X- _ O
( -X- _ O
Søgaard -X- _ O
et -X- _ O
al -X- _ O
. -X- _ O
, -X- _ O
2018 -X- _ O
; -X- _ O
Patra -X- _ O
et -X- _ O
al -X- _ O
. -X- _ O
, -X- _ O
2019 -X- _ O
) -X- _ O
have -X- _ O
demonstrated -X- _ O
that -X- _ O
the -X- _ O
isomorphic -X- _ O
assumption -X- _ O
may -X- _ O
not -X- _ O
strictly -X- _ O
hold -X- _ O
true -X- _ O
in -X- _ O
general -X- _ O
, -X- _ O
and -X- _ O
thus -X- _ O
a -X- _ O
global -X- _ O
- -X- _ O
shared -X- _ O
mapping -X- _ O
is -X- _ O
not -X- _ O
the -X- _ O
optimal -X- _ O
solution -X- _ O
. -X- _ O
As -X- _ O
shown -X- _ O
in -X- _ O
Figure -X- _ O
1 -X- _ O
, -X- _ O
even -X- _ O
for -X- _ O
two -X- _ O
close -X- _ O
languages -X- _ O
like -X- _ O
English -X- _ O
and -X- _ O
Spanish -X- _ O
, -X- _ O
due -X- _ O
to -X- _ O
deviations -X- _ O
in -X- _ O
the -X- _ O
distributions -X- _ O
of -X- _ O
different -X- _ O
training -X- _ O
corpora -X- _ O
and -X- _ O
insufficient -X- _ O
training -X- _ O
of -X- _ O
lowfrequency -X- _ O
word -X- _ O
embeddings -X- _ O
, -X- _ O
the -X- _ O
optimal -X- _ O
mapping -X- _ O
directions -X- _ O
are -X- _ O
slightly -X- _ O
shifted -X- _ O
for -X- _ O
different -X- _ O
words -X- _ O
. -X- _ O
Therefore -X- _ O
, -X- _ O
the -X- _ O
BLI -X- _ B-TaskName
performance -X- _ O
could -X- _ O
be -X- _ O
further -X- _ O
improved -X- _ O
if -X- _ O
we -X- _ O
could -X- _ O
learn -X- _ O
unique -X- _ O
or -X- _ O
personalized -X- _ O
mapping -X- _ O
functions -X- _ O
for -X- _ O
different -X- _ O
words -X- _ O
. -X- _ O
Glavaš -X- _ O
and -X- _ O
Vulić -X- _ O
( -X- _ O
2020 -X- _ O
) -X- _ O
first -X- _ O
propose -X- _ O
to -X- _ O
achieve -X- _ O
the -X- _ O
personalized -X- _ O
mappings -X- _ O
. -X- _ O
However -X- _ O
, -X- _ O
Glavaš -X- _ O
and -X- _ O
Vulić -X- _ O
( -X- _ O
2020 -X- _ O
) -X- _ O
is -X- _ O
a -X- _ O
non -X- _ O
- -X- _ O
parametric -X- _ O
model -X- _ O
, -X- _ O
in -X- _ O
which -X- _ O
the -X- _ O
personalized -X- _ O
mappings -X- _ O
are -X- _ O
unlearnable -X- _ O
and -X- _ O
built -X- _ O
upon -X- _ O
the -X- _ O
heuristic -X- _ O
assumptions -X- _ O
, -X- _ O
which -X- _ O
might -X- _ O
be -X- _ O
unreliable -X- _ O
and -X- _ O
suffer -X- _ O
from -X- _ O
low -X- _ O
generality -X- _ O
. -X- _ O

To -X- _ O
address -X- _ O
the -X- _ O
mentioned -X- _ O
limitations -X- _ O
under -X- _ O
a -X- _ O
unified -X- _ O
framework -X- _ O
, -X- _ O
we -X- _ O
propose -X- _ O
a -X- _ O
novel -X- _ O
Ranking -X- _ B-MethodName
- -X- _ I-MethodName
based -X- _ I-MethodName
model -X- _ I-MethodName
with -X- _ I-MethodName
Adaptive -X- _ I-MethodName
Personalized -X- _ I-MethodName
Offsets -X- _ I-MethodName
, -X- _ O
dubbed -X- _ O
RAPO -X- _ B-MethodName
. -X- _ O
Different -X- _ O
from -X- _ O
previous -X- _ O
works -X- _ O
solely -X- _ O
relying -X- _ O
on -X- _ O
the -X- _ O
aligned -X- _ O
pairs -X- _ O
, -X- _ O
RAPO -X- _ B-MethodName
is -X- _ O
formulated -X- _ O
as -X- _ O
a -X- _ O
ranking -X- _ O
paradigm -X- _ O
with -X- _ O
powerful -X- _ O
discriminative -X- _ O
capability -X- _ O
by -X- _ O
incorporating -X- _ O
abundant -X- _ O
unaligned -X- _ O
negative -X- _ O
samples -X- _ O
. -X- _ O
An -X- _ O
effective -X- _ O
dynamic -X- _ O
negative -X- _ O
sampling -X- _ O
strategy -X- _ O
is -X- _ O
further -X- _ O
proposed -X- _ O
to -X- _ O
optimize -X- _ O
the -X- _ O
ranking -X- _ O
objectives -X- _ O
. -X- _ O
Moreover -X- _ O
, -X- _ O
we -X- _ O
integrate -X- _ O
a -X- _ O
novel -X- _ O
personalized -X- _ O
adapter -X- _ O
into -X- _ O
RAPO -X- _ B-MethodName
to -X- _ O
learn -X- _ O
unique -X- _ O
mapping -X- _ O
directions -X- _ O
for -X- _ O
different -X- _ O
words -X- _ O
. -X- _ O
A -X- _ O
straightforward -X- _ O
strategy -X- _ O
is -X- _ O
to -X- _ O
directly -X- _ O
learn -X- _ O
an -X- _ O
independent -X- _ O
mapping -X- _ O
matrix -X- _ O
for -X- _ O
each -X- _ O
word -X- _ O
, -X- _ O
which -X- _ O
is -X- _ O
resourceconsuming -X- _ O
and -X- _ O
ignores -X- _ O
the -X- _ O
global -X- _ O
isomorphism -X- _ O
information -X- _ O
. -X- _ O
Differently -X- _ O
, -X- _ O
our -X- _ O
personalized -X- _ O
adapter -X- _ O
learns -X- _ O
the -X- _ O
unique -X- _ O
offset -X- _ O
for -X- _ O
each -X- _ O
word -X- _ O
to -X- _ O
calibrate -X- _ O
the -X- _ O
vanilla -X- _ O
embedding -X- _ O
, -X- _ O
and -X- _ O
then -X- _ O
a -X- _ O
shared -X- _ O
mapping -X- _ O
function -X- _ O
is -X- _ O
employed -X- _ O
to -X- _ O
induct -X- _ O
lexicons -X- _ O
. -X- _ O
By -X- _ O
organically -X- _ O
integrating -X- _ O
personalized -X- _ O
offsets -X- _ O
with -X- _ O
shared -X- _ O
mapping -X- _ O
functions -X- _ O
, -X- _ O
RAPO -X- _ B-MethodName
enjoys -X- _ O
the -X- _ O
merits -X- _ O
from -X- _ O
the -X- _ O
unique -X- _ O
traits -X- _ O
of -X- _ O
each -X- _ O
word -X- _ O
and -X- _ O
the -X- _ O
global -X- _ O
consistency -X- _ O
across -X- _ O
languages -X- _ O
. -X- _ O
We -X- _ O
further -X- _ O
propose -X- _ O
a -X- _ O
novel -X- _ O
Householder -X- _ O
projection -X- _ O
as -X- _ O
the -X- _ O
mapping -X- _ O
function -X- _ O
on -X- _ O
the -X- _ O
basis -X- _ O
of -X- _ O
Householder -X- _ O
matrices -X- _ O
( -X- _ O
Householder -X- _ O
, -X- _ O
1958 -X- _ O
) -X- _ O
, -X- _ O
which -X- _ O
strictly -X- _ O
ensures -X- _ O
the -X- _ O
orthogonality -X- _ O
during -X- _ O
the -X- _ O
model -X- _ O
optimization -X- _ O
. -X- _ O
We -X- _ O
conduct -X- _ O
extensive -X- _ O
experiments -X- _ O
over -X- _ O
multiple -X- _ O
language -X- _ O
pairs -X- _ O
in -X- _ O
the -X- _ O
public -X- _ O
MUSE -X- _ B-DatasetName
benchmarks -X- _ O
, -X- _ O
including -X- _ O
rich -X- _ O
- -X- _ O
and -X- _ O
low -X- _ O
- -X- _ O
resource -X- _ O
languages -X- _ O
. -X- _ O
Experimental -X- _ O
results -X- _ O
demonstrate -X- _ O
that -X- _ O
our -X- _ O
proposal -X- _ O
consistently -X- _ O
achieves -X- _ O
desirable -X- _ O
performance -X- _ O
in -X- _ O
both -X- _ O
supervised -X- _ O
and -X- _ O
semi -X- _ O
- -X- _ O
supervised -X- _ O
learning -X- _ O
settings -X- _ O
. -X- _ O

Our -X- _ O
contributions -X- _ O
are -X- _ O
summarized -X- _ O
as -X- _ O
follows -X- _ O
: -X- _ O

• -X- _ O
To -X- _ O
the -X- _ O
best -X- _ O
of -X- _ O
our -X- _ O
knowledge -X- _ O
, -X- _ O
we -X- _ O
are -X- _ O
the -X- _ O
first -X- _ O
to -X- _ O
propose -X- _ O
a -X- _ O
ranking -X- _ O
- -X- _ O
based -X- _ O
bilingual -X- _ B-TaskName
lexicon -X- _ I-TaskName
induction -X- _ I-TaskName
model -X- _ O
RAPO -X- _ B-MethodName
with -X- _ O
powerful -X- _ O
discriminative -X- _ O
capacity -X- _ O
. -X- _ O

• -X- _ O
We -X- _ O
propose -X- _ O
a -X- _ O
novel -X- _ O
personalized -X- _ O
adapter -X- _ O
to -X- _ O
achieve -X- _ O
unique -X- _ O
mapping -X- _ O
direction -X- _ O
for -X- _ O
each -X- _ O
word -X- _ O
by -X- _ O
adaptively -X- _ O
learning -X- _ O
the -X- _ O
personalized -X- _ O
embedding -X- _ O
offsets -X- _ O
. -X- _ O

• -X- _ O
We -X- _ O
conduct -X- _ O
extensive -X- _ O
experiments -X- _ O
over -X- _ O
popular -X- _ O
benchmarks -X- _ O
and -X- _ O
the -X- _ O
results -X- _ O
demonstrate -X- _ O
the -X- _ O
superiority -X- _ O
of -X- _ O
our -X- _ O
proposal -X- _ O
. -X- _ O

Preliminary -X- _ O

Let -X- _ O
X -X- _ O
∈ -X- _ O
R -X- _ O
d×nx -X- _ O
and -X- _ O
Y -X- _ O
∈ -X- _ O
R -X- _ O
d×ny -X- _ O
be -X- _ O
monolingual -X- _ O
embedding -X- _ O
matrices -X- _ O
consisting -X- _ O
of -X- _ O
n -X- _ O
x -X- _ O
and -X- _ O
n -X- _ O
y -X- _ O
words -X- _ O
for -X- _ O
the -X- _ O
source -X- _ O
and -X- _ O
target -X- _ O
languages -X- _ O
respectively -X- _ O
, -X- _ O
and -X- _ O
d -X- _ O
stands -X- _ O
for -X- _ O
the -X- _ O
embedding -X- _ O
size -X- _ O
. -X- _ O
D -X- _ O
= -X- _ O
{ -X- _ O
( -X- _ O
x -X- _ O
1 -X- _ O
, -X- _ O
y -X- _ O
1 -X- _ O
) -X- _ O
, -X- _ O
... -X- _ O
, -X- _ O
( -X- _ O
x -X- _ O
l -X- _ O
, -X- _ O
y -X- _ O
l -X- _ O
) -X- _ O
} -X- _ O
denotes -X- _ O
the -X- _ O
available -X- _ O
aligned -X- _ O
seeds -X- _ O
, -X- _ O
which -X- _ O
can -X- _ O
be -X- _ O
also -X- _ O
formulated -X- _ O
as -X- _ O
two -X- _ O
matrices -X- _ O
X -X- _ O
D -X- _ O
and -X- _ O
Y -X- _ O
D -X- _ O
∈ -X- _ O
R -X- _ O
d×l -X- _ O
. -X- _ O
BLI -X- _ B-TaskName
aims -X- _ O
to -X- _ O
map -X- _ O
the -X- _ O
source -X- _ O
and -X- _ O
target -X- _ O
words -X- _ O
from -X- _ O
their -X- _ O
original -X- _ O
embedding -X- _ O
spaces -X- _ O
into -X- _ O
a -X- _ O
shared -X- _ O
latent -X- _ O
space -X- _ O
, -X- _ O
in -X- _ O
which -X- _ O
the -X- _ O
mapped -X- _ O
source -X- _ O
word -X- _ O
ϕ -X- _ O
s -X- _ O
( -X- _ O
x -X- _ O
i -X- _ O
) -X- _ O
should -X- _ O
be -X- _ O
close -X- _ O
to -X- _ O
its -X- _ O
matched -X- _ O
target -X- _ O
word -X- _ O
ϕ -X- _ O
t -X- _ O
( -X- _ O
y -X- _ O
i -X- _ O
) -X- _ O
. -X- _ O
ϕ -X- _ O
s -X- _ O
and -X- _ O
ϕ -X- _ O
t -X- _ O
denote -X- _ O
the -X- _ O
mapping -X- _ O
functions -X- _ O
for -X- _ O
source -X- _ O
language -X- _ O
and -X- _ O
target -X- _ O
language -X- _ O
, -X- _ O
respectively -X- _ O
. -X- _ O
For -X- _ O
the -X- _ O
sake -X- _ O
of -X- _ O
clarification -X- _ O
, -X- _ O
notations -X- _ O
used -X- _ O
in -X- _ O
this -X- _ O
paper -X- _ O
are -X- _ O
listed -X- _ O
in -X- _ O
Appendix -X- _ O
A -X- _ O
. -X- _ O

A -X- _ O
widely -X- _ O
adopted -X- _ O
solution -X- _ O
is -X- _ O
to -X- _ O
set -X- _ O
the -X- _ O
source -X- _ O
mapping -X- _ O
function -X- _ O
ϕ -X- _ O
s -X- _ O
as -X- _ O
a -X- _ O
linear -X- _ O
transformation -X- _ O
matrix -X- _ O
W -X- _ O
∈ -X- _ O
R -X- _ O
d×d -X- _ O
and -X- _ O
the -X- _ O
target -X- _ O
mapping -X- _ O
function -X- _ O
ϕ -X- _ O
t -X- _ O
to -X- _ O
an -X- _ O
identity -X- _ O
matrix -X- _ O
I -X- _ O
∈ -X- _ O
R -X- _ O
d×d -X- _ O
. -X- _ O
The -X- _ O
objective -X- _ O
function -X- _ O
is -X- _ O
defined -X- _ O
as -X- _ O
follows -X- _ O
: -X- _ O

As -X- _ O
discussed -X- _ O
in -X- _ O
the -X- _ O
section -X- _ O
of -X- _ O
introduction -X- _ O
, -X- _ O
this -X- _ O
popular -X- _ O
induction -X- _ B-TaskName
paradigm -X- _ O
suffers -X- _ O
from -X- _ O
two -X- _ O
limitations -X- _ O
. -X- _ O
First -X- _ O
, -X- _ O
Formula -X- _ O
( -X- _ O
1 -X- _ O
) -X- _ O
only -X- _ O
focuses -X- _ O
on -X- _ O
minimizing -X- _ O
the -X- _ O
distance -X- _ O
between -X- _ O
the -X- _ O
aligned -X- _ O
words -X- _ O
( -X- _ O
e.g. -X- _ O
, -X- _ O
x -X- _ O
i -X- _ O
and -X- _ O
y -X- _ O
i -X- _ O
) -X- _ O
. -X- _ O
However -X- _ O
, -X- _ O
BLI -X- _ B-TaskName
task -X- _ O
is -X- _ O
essentially -X- _ O
a -X- _ O
ranking -X- _ O
problem -X- _ O
, -X- _ O
which -X- _ O
means -X- _ O
that -X- _ O
the -X- _ O
learned -X- _ O
mapping -X- _ O
function -X- _ O
should -X- _ O
also -X- _ O
be -X- _ O
able -X- _ O
to -X- _ O
distinguish -X- _ O
the -X- _ O
aligned -X- _ O
pair -X- _ O
{ -X- _ O
x -X- _ O
i -X- _ O
, -X- _ O
y -X- _ O
i -X- _ O
} -X- _ O
and -X- _ O
the -X- _ O
defective -X- _ O
one -X- _ O
{ -X- _ O
x -X- _ O
i -X- _ O
, -X- _ O
y -X- _ O
j -X- _ O
} -X- _ O
. -X- _ O
Second -X- _ O
, -X- _ O
the -X- _ O
globally -X- _ O
shared -X- _ O
mapping -X- _ O
matrix -X- _ O
W -X- _ O
might -X- _ O
be -X- _ O
inappropriate -X- _ O
since -X- _ O
the -X- _ O
optimal -X- _ O
mapping -X- _ O
directions -X- _ O
of -X- _ O
different -X- _ O
words -X- _ O
tend -X- _ O
to -X- _ O
be -X- _ O
various -X- _ O
. -X- _ O
Our -X- _ O
proposed -X- _ O
RAPO -X- _ B-MethodName
is -X- _ O
capable -X- _ O
of -X- _ O
addressing -X- _ O
the -X- _ O
mentioned -X- _ O
challenges -X- _ O
under -X- _ O
a -X- _ O
unified -X- _ O
learning -X- _ O
framework -X- _ O
. -X- _ O
We -X- _ O
will -X- _ O
introduce -X- _ O
the -X- _ O
details -X- _ O
of -X- _ O
RAPO -X- _ B-MethodName
in -X- _ O
the -X- _ O
next -X- _ O
section -X- _ O
. -X- _ O

As -X- _ O
shown -X- _ O
in -X- _ O
Figure -X- _ O
2 -X- _ O
, -X- _ O
RAPO -X- _ B-MethodName
consists -X- _ O
of -X- _ O
three -X- _ O
major -X- _ O
components -X- _ O
. -X- _ O
Given -X- _ O
the -X- _ O
monolingual -X- _ O
embeddings -X- _ O
and -X- _ O
training -X- _ O
seeds -X- _ O
, -X- _ O
the -X- _ O
personalized -X- _ O
adapter -X- _ O
first -X- _ O
generates -X- _ O
the -X- _ O
adaptive -X- _ O
offset -X- _ O
for -X- _ O
each -X- _ O
word -X- _ O
by -X- _ O
exploiting -X- _ O
the -X- _ O
contextual -X- _ O
semantic -X- _ O
information -X- _ O
. -X- _ O

The -X- _ O
vanilla -X- _ O
embedding -X- _ O
spaces -X- _ O
are -X- _ O
properly -X- _ O
calibrated -X- _ O
to -X- _ O
fit -X- _ O
the -X- _ O
induction -X- _ O
task -X- _ O
. -X- _ O
After -X- _ O
that -X- _ O
, -X- _ O
we -X- _ O
map -X- _ O
the -X- _ O
adapted -X- _ O
word -X- _ O
embeddings -X- _ O
to -X- _ O
a -X- _ O
shared -X- _ O
latent -X- _ O
space -X- _ O
via -X- _ O
the -X- _ O
novel -X- _ O
Householder -X- _ O
projections -X- _ O
, -X- _ O
which -X- _ O
is -X- _ O
capable -X- _ O
of -X- _ O
ensuring -X- _ O
the -X- _ O
strict -X- _ O
orthogonality -X- _ O
and -X- _ O
better -X- _ O
preserving -X- _ O
the -X- _ O
isomorphism -X- _ O
. -X- _ O
Finally -X- _ O
, -X- _ O
RAPO -X- _ B-MethodName
designs -X- _ O
the -X- _ O
ranking -X- _ O
objectives -X- _ O
to -X- _ O
distinguish -X- _ O
the -X- _ O
aligned -X- _ O
pairs -X- _ O
from -X- _ O
the -X- _ O
unmatched -X- _ O
ones -X- _ O
. -X- _ O
RAPO -X- _ B-MethodName
can -X- _ O
be -X- _ O
easily -X- _ O
adapted -X- _ O
to -X- _ O
the -X- _ O
supervised -X- _ O
and -X- _ O
semisupervised -X- _ O
settings -X- _ O
, -X- _ O
demonstrating -X- _ O
its -X- _ O
flexibility -X- _ O
. -X- _ O

Due -X- _ O
to -X- _ O
the -X- _ O
deviations -X- _ O
in -X- _ O
the -X- _ O
distribution -X- _ O
of -X- _ O
different -X- _ O
corpora -X- _ O
and -X- _ O
the -X- _ O
unbalanced -X- _ O
training -X- _ O
of -X- _ O
word -X- _ O
embeddings -X- _ O
, -X- _ O
recent -X- _ O
works -X- _ O
demonstrated -X- _ O
that -X- _ O
the -X- _ O
vanilla -X- _ O
word -X- _ O
embedding -X- _ O
space -X- _ O
may -X- _ O
not -X- _ O
be -X- _ O
fully -X- _ O
trustworthy -X- _ O
and -X- _ O
proper -X- _ O
adjustments -X- _ O
contribute -X- _ O
to -X- _ O
improving -X- _ O
induction -X- _ B-TaskName
performance -X- _ O
. -X- _ O
Previous -X- _ O
work -X- _ O
( -X- _ O
Glavaš -X- _ O
and -X- _ O
Vulić -X- _ O
, -X- _ O
2020 -X- _ O
) -X- _ O
proposes -X- _ O
to -X- _ O
modify -X- _ O
the -X- _ O
mapped -X- _ O
embedding -X- _ O
based -X- _ O
on -X- _ O
its -X- _ O
nearest -X- _ O
neighbors -X- _ O
in -X- _ O
the -X- _ O
training -X- _ O
dictionary -X- _ O
, -X- _ O
which -X- _ O
is -X- _ O
a -X- _ O
non -X- _ O
- -X- _ O
parametric -X- _ O
model -X- _ O
and -X- _ O
might -X- _ O
be -X- _ O
unreliable -X- _ O
. -X- _ O
Here -X- _ O
we -X- _ O
design -X- _ O
a -X- _ O
novel -X- _ O
learnable -X- _ O
personalized -X- _ O
adaptor -X- _ O
, -X- _ O
which -X- _ O
can -X- _ O
be -X- _ O
trained -X- _ O
through -X- _ O
the -X- _ O
gradient -X- _ O
descent -X- _ O
and -X- _ O
learn -X- _ O
task -X- _ O
- -X- _ O
relevant -X- _ O
personalized -X- _ O
offsets -X- _ O
. -X- _ O
Given -X- _ O
a -X- _ O
source -X- _ O
word -X- _ O
embedding -X- _ O
x -X- _ O
, -X- _ O
adapter -X- _ O
first -X- _ O
obtains -X- _ O
its -X- _ O
contextual -X- _ O
semantic -X- _ O
vectorx -X- _ O
by -X- _ O
averaging -X- _ O
the -X- _ O
embeddings -X- _ O
of -X- _ O
its -X- _ O
neighbor -X- _ O
words -X- _ O
M -X- _ O
s -X- _ O
( -X- _ O
x -X- _ O
) -X- _ O
in -X- _ O
the -X- _ O
source -X- _ O
space -X- _ O
. -X- _ O
Our -X- _ O
motivation -X- _ O
lies -X- _ O
in -X- _ O
that -X- _ O
a -X- _ O
single -X- _ O
word -X- _ O
can -X- _ O
only -X- _ O
provide -X- _ O
limited -X- _ O
information -X- _ O
, -X- _ O
while -X- _ O
a -X- _ O
set -X- _ O
clustering -X- _ O
similar -X- _ O
words -X- _ O
can -X- _ O
assemble -X- _ O
the -X- _ O
mutual -X- _ O
word -X- _ O
relationships -X- _ O
and -X- _ O
provide -X- _ O
richer -X- _ O
and -X- _ O
more -X- _ O
accurate -X- _ O
information -X- _ O
. -X- _ O
The -X- _ O
contextual -X- _ O
semantic -X- _ O
vectorx -X- _ O
is -X- _ O
formally -X- _ O
defined -X- _ O
as -X- _ O
: -X- _ O

where -X- _ O
m -X- _ O
s -X- _ O
is -X- _ O
the -X- _ O
size -X- _ O
of -X- _ O
M -X- _ O
s -X- _ O
( -X- _ O
x -X- _ O
) -X- _ O
and -X- _ O
⟨ -X- _ O
, -X- _ O
⟩ -X- _ O
denotes -X- _ O
the -X- _ O
dot -X- _ O
product -X- _ O
. -X- _ O
τ -X- _ B-HyperparameterName
s -X- _ O
is -X- _ O
a -X- _ O
hyper -X- _ O
- -X- _ O
parameter -X- _ O
denoting -X- _ O
the -X- _ O
similarity -X- _ B-HyperparameterName
threshold -X- _ I-HyperparameterName
. -X- _ O
Compared -X- _ O
to -X- _ O
the -X- _ O
original -X- _ O
word -X- _ O
embedding -X- _ O
x -X- _ O
, -X- _ O
the -X- _ O
contextual -X- _ O
vectorx -X- _ O
is -X- _ O
more -X- _ O
informative -X- _ O
by -X- _ O
incorporating -X- _ O
richer -X- _ O
semantics -X- _ O
. -X- _ O
After -X- _ O
that -X- _ O
, -X- _ O
personalized -X- _ O
adapter -X- _ O
learns -X- _ O
the -X- _ O
unique -X- _ O
offset -X- _ O
for -X- _ O
each -X- _ O
word -X- _ O
based -X- _ O
on -X- _ O
the -X- _ O
contextual -X- _ O
semantic -X- _ O
vector -X- _ O
, -X- _ O
which -X- _ O
can -X- _ O
be -X- _ O
effectively -X- _ O
optimized -X- _ O
by -X- _ O
the -X- _ O
training -X- _ O
objectives -X- _ O
. -X- _ O
Previous -X- _ O
work -X- _ O
( -X- _ O
Ren -X- _ O
et -X- _ O
al -X- _ O
. -X- _ O
, -X- _ O
2020 -X- _ O
) -X- _ O
has -X- _ O
observed -X- _ O
that -X- _ O
semantic -X- _ O
similar -X- _ O
words -X- _ O
enjoy -X- _ O
stronger -X- _ O
isomorphism -X- _ O
structures -X- _ O
across -X- _ O
different -X- _ O
embedding -X- _ O
spaces -X- _ O
. -X- _ O
Thus -X- _ O
, -X- _ O
our -X- _ O
motivation -X- _ O
lies -X- _ O
in -X- _ O
that -X- _ O
words -X- _ O
with -X- _ O
similar -X- _ O
contextual -X- _ O
semantics -X- _ O
also -X- _ O
tend -X- _ O
to -X- _ O
have -X- _ O
similar -X- _ O
personalized -X- _ O
offsets -X- _ O
. -X- _ O

Specifically -X- _ O
, -X- _ O
the -X- _ O
adapter -X- _ O
is -X- _ O
implemented -X- _ O
as -X- _ O
a -X- _ O
feed -X- _ O
- -X- _ O
forward -X- _ O
network -X- _ O
with -X- _ O
a -X- _ O
single -X- _ O
layer -X- _ O
: -X- _ O

where -X- _ O
σ -X- _ O
denotes -X- _ O
the -X- _ O
activation -X- _ O
function -X- _ O
and -X- _ O
it -X- _ O
could -X- _ O
be -X- _ O
linear -X- _ O
or -X- _ O
non -X- _ O
- -X- _ O
linear -X- _ O
. -X- _ O
W -X- _ O
s -X- _ O
∈ -X- _ O
R -X- _ O
d×d -X- _ O
stands -X- _ O
for -X- _ O
the -X- _ O
learnable -X- _ O
parameters -X- _ O
. -X- _ O
The -X- _ O
generated -X- _ O
offset -X- _ O
vector -X- _ O
indicates -X- _ O
the -X- _ O
personalized -X- _ O
offset -X- _ O
direction -X- _ O
, -X- _ O
and -X- _ O
is -X- _ O
further -X- _ O
combined -X- _ O
with -X- _ O
the -X- _ O
vanilla -X- _ O
embedding -X- _ O
x -X- _ O
: -X- _ O

Similarly -X- _ O
, -X- _ O
for -X- _ O
the -X- _ O
target -X- _ O
word -X- _ O
embedding -X- _ O
y -X- _ O
, -X- _ O
the -X- _ O
calibrated -X- _ O
embeddingỹ -X- _ O
can -X- _ O
be -X- _ O
calculated -X- _ O
as -X- _ O
: -X- _ O

3 -X- _ O
) -X- _ O
Task -X- _ O
- -X- _ O
relevant -X- _ O
: -X- _ O
vanilla -X- _ O
word -X- _ O
embeddings -X- _ O
are -X- _ O
unsupervised -X- _ O
learned -X- _ O
and -X- _ O
might -X- _ O
be -X- _ O
incompatible -X- _ O
with -X- _ O
the -X- _ O
BLI -X- _ B-TaskName
task -X- _ O
. -X- _ O
The -X- _ O
proposed -X- _ O
adapter -X- _ O
is -X- _ O
capable -X- _ O
of -X- _ O
properly -X- _ O
adjusting -X- _ O
the -X- _ O
original -X- _ O
embeddings -X- _ O
according -X- _ O
to -X- _ O
the -X- _ O
downstream -X- _ O
induction -X- _ B-TaskName
tasks -X- _ O
. -X- _ O

Based -X- _ O
on -X- _ O
the -X- _ O
calibrated -X- _ O
embeddings -X- _ O
, -X- _ O
we -X- _ O
further -X- _ O
need -X- _ O
to -X- _ O
design -X- _ O
desirable -X- _ O
mapping -X- _ O
functions -X- _ O
to -X- _ O
map -X- _ O
them -X- _ O
into -X- _ O
a -X- _ O
shared -X- _ O
latent -X- _ O
space -X- _ O
. -X- _ O
Previous -X- _ O
works -X- _ O
( -X- _ O
Xing -X- _ O
et -X- _ O
al -X- _ O
. -X- _ O
, -X- _ O
2015 -X- _ O
; -X- _ O
Patra -X- _ O
et -X- _ O
al -X- _ O
. -X- _ O
, -X- _ O
2019 -X- _ O
) -X- _ O
have -X- _ O
demonstrated -X- _ O
that -X- _ O
the -X- _ O
orthogonality -X- _ O
of -X- _ O
the -X- _ O
mapping -X- _ O
function -X- _ O
is -X- _ O
crucial -X- _ O
to -X- _ O
the -X- _ O
model -X- _ O
performance -X- _ O
. -X- _ O
A -X- _ O
general -X- _ O
approach -X- _ O
is -X- _ O
to -X- _ O
add -X- _ O
an -X- _ O
extra -X- _ O
constraint -X- _ O
in -X- _ O
the -X- _ O
objective -X- _ O
function -X- _ O
to -X- _ O
force -X- _ O
the -X- _ O
mapping -X- _ O
matrix -X- _ O
to -X- _ O
be -X- _ O
orthogonal -X- _ O
( -X- _ O
i.e. -X- _ O
, -X- _ O
min -X- _ O
W -X- _ O
||WW -X- _ O
⊤ -X- _ O
− -X- _ O
I|| -X- _ O
2 -X- _ O
) -X- _ O
. -X- _ O
Nevertheless -X- _ O
, -X- _ O
such -X- _ O
constraints -X- _ O
can -X- _ O
only -X- _ O
achieve -X- _ O
an -X- _ O
approximate -X- _ O
orthogonal -X- _ O
matrix -X- _ O
instead -X- _ O
of -X- _ O
the -X- _ O
strict -X- _ O
one -X- _ O
, -X- _ O
which -X- _ O
may -X- _ O
hinder -X- _ O
the -X- _ O
capability -X- _ O
of -X- _ O
BLI -X- _ B-TaskName
models -X- _ O
in -X- _ O
capturing -X- _ O
the -X- _ O
unsupervised -X- _ O
isomorphism -X- _ O
information -X- _ O
. -X- _ O
Here -X- _ O
we -X- _ O
propose -X- _ O
to -X- _ O
construct -X- _ O
a -X- _ O
strict -X- _ O
orthogonal -X- _ O
mapping -X- _ O
function -X- _ O
based -X- _ O
on -X- _ O
the -X- _ O
Householder -X- _ O
matrices -X- _ O
( -X- _ O
Householder -X- _ O
, -X- _ O
1958 -X- _ O
; -X- _ O
, -X- _ O
dubbed -X- _ O
Householder -X- _ O
projection -X- _ O
. -X- _ O

where -X- _ O
||v|| -X- _ O
2 -X- _ O
= -X- _ O
1 -X- _ O
and -X- _ O
I -X- _ O
is -X- _ O
the -X- _ O
d -X- _ O
× -X- _ O
d -X- _ O
identity -X- _ O
matrix -X- _ O
. -X- _ O

Next -X- _ O
we -X- _ O
will -X- _ O
introduce -X- _ O
how -X- _ O
to -X- _ O
employ -X- _ O
the -X- _ O
Householder -X- _ O
projections -X- _ O
in -X- _ O
the -X- _ O
RAPO -X- _ B-MethodName
model -X- _ O
. -X- _ O
Each -X- _ O
language -X- _ O
is -X- _ O
associated -X- _ O
with -X- _ O
its -X- _ O
unique -X- _ O
Householder -X- _ O
projection -X- _ O
to -X- _ O
map -X- _ O
words -X- _ O
into -X- _ O
the -X- _ O
shared -X- _ O
latent -X- _ O
space -X- _ O
. -X- _ O
Take -X- _ O
the -X- _ O
source -X- _ O
language -X- _ O
as -X- _ O
an -X- _ O
example -X- _ O
. -X- _ O
Given -X- _ O
the -X- _ O
calibrated -X- _ O
source -X- _ O
word -X- _ O
embeddingx -X- _ O
, -X- _ O
we -X- _ O
employ -X- _ O
the -X- _ O
source -X- _ O
Householder -X- _ O
projection -X- _ O
with -X- _ O
V -X- _ O
s -X- _ O
= -X- _ O
{ -X- _ O
v -X- _ O
1 -X- _ O
, -X- _ O
.. -X- _ O
, -X- _ O
v -X- _ O
n -X- _ O
} -X- _ O
as -X- _ O
the -X- _ O
mapping -X- _ O
function -X- _ O
: -X- _ O

BLI -X- _ B-TaskName
is -X- _ O
a -X- _ O
ranking -X- _ O
- -X- _ O
oriented -X- _ O
task -X- _ O
as -X- _ O
we -X- _ O
expect -X- _ O
to -X- _ O
select -X- _ O
the -X- _ O
top -X- _ O
k -X- _ O
target -X- _ O
words -X- _ O
with -X- _ O
high -X- _ O
confidence -X- _ O
for -X- _ O
each -X- _ O
source -X- _ O
word -X- _ O
. -X- _ O
However -X- _ O
, -X- _ O
the -X- _ O
training -X- _ O
objective -X- _ O
functions -X- _ O
( -X- _ O
e.g. -X- _ O
, -X- _ O
Formula -X- _ O
( -X- _ O
1 -X- _ O
) -X- _ O
) -X- _ O
of -X- _ O
previous -X- _ O
works -X- _ O
( -X- _ O
Artetxe -X- _ O
et -X- _ O
al -X- _ O
. -X- _ O
, -X- _ O
2016 -X- _ O
( -X- _ O
Artetxe -X- _ O
et -X- _ O
al -X- _ O
. -X- _ O
, -X- _ O
, -X- _ O
2018aJawanpuria -X- _ O
et -X- _ O
al -X- _ O
. -X- _ O
, -X- _ O
2020 -X- _ O
) -X- _ O
essentially -X- _ O
minimize -X- _ O
the -X- _ O
distances -X- _ O
between -X- _ O
the -X- _ O
aligned -X- _ O
words -X- _ O
, -X- _ O
which -X- _ O
can -X- _ O
not -X- _ O
provide -X- _ O
sufficient -X- _ O
discriminative -X- _ O
capacity -X- _ O
to -X- _ O
rank -X- _ O
the -X- _ O
candidates -X- _ O
. -X- _ O
Differently -X- _ O
, -X- _ O
we -X- _ O
propose -X- _ O
to -X- _ O
optimize -X- _ O
the -X- _ O
RAPO -X- _ B-MethodName
model -X- _ O
by -X- _ O
a -X- _ O
ranking -X- _ O
loss -X- _ O
, -X- _ O
which -X- _ O
empowers -X- _ O
our -X- _ O
proposal -X- _ O
the -X- _ O
ability -X- _ O
of -X- _ O
learning -X- _ O
the -X- _ O
relative -X- _ O
orders -X- _ O
between -X- _ O
the -X- _ O
aligned -X- _ O
words -X- _ O
and -X- _ O
unmatched -X- _ O
ones -X- _ O
. -X- _ O

Specifically -X- _ O
, -X- _ O
we -X- _ O
adopt -X- _ O
a -X- _ O
popular -X- _ O
pair -X- _ O
- -X- _ O
wise -X- _ O
ranking -X- _ O
loss -X- _ O
, -X- _ O
Bayesian -X- _ O
personalized -X- _ O
ranking -X- _ O
( -X- _ O
BPR -X- _ O
) -X- _ O
( -X- _ O
Rendle -X- _ O
et -X- _ O
al -X- _ O
. -X- _ O
, -X- _ O
2009 -X- _ O
; -X- _ O
Zhang -X- _ O
et -X- _ O
al -X- _ O
. -X- _ O
, -X- _ O
2022 -X- _ O
) -X- _ O
, -X- _ O
as -X- _ O
the -X- _ O
the -X- _ O
major -X- _ O
training -X- _ O
objective -X- _ O
function -X- _ O
. -X- _ O
Given -X- _ O
an -X- _ O
aligned -X- _ O
positive -X- _ O
pair -X- _ O
( -X- _ O
x -X- _ O
, -X- _ O
y -X- _ O
) -X- _ O
, -X- _ O
the -X- _ O
ranking -X- _ O
loss -X- _ O
is -X- _ O
defined -X- _ O
as -X- _ O
follows -X- _ O
: -X- _ O

In -X- _ O
order -X- _ O
to -X- _ O
counteract -X- _ O
the -X- _ O
challenge -X- _ O
of -X- _ O
hubness -X- _ O
problem -X- _ O
, -X- _ O
we -X- _ O
adopt -X- _ O
the -X- _ O
cross -X- _ O
- -X- _ O
domain -X- _ O
similarity -X- _ O
local -X- _ O
scaling -X- _ O
( -X- _ O
CSLS -X- _ O
) -X- _ O
( -X- _ O
Joulin -X- _ O
et -X- _ O
al -X- _ O
. -X- _ O
, -X- _ O
2018 -X- _ O
) -X- _ O
as -X- _ O
the -X- _ O
similarity -X- _ O
metric -X- _ O
, -X- _ O
which -X- _ O
penalizes -X- _ O
the -X- _ O
similarity -X- _ O
values -X- _ O
in -X- _ O
dense -X- _ O
areas -X- _ O
of -X- _ O
the -X- _ O
embedding -X- _ O
distribution -X- _ O
. -X- _ O
Set -X- _ O
N -X- _ O
− -X- _ O
contains -X- _ O
K -X- _ O
negative -X- _ O
samples -X- _ O
, -X- _ O
which -X- _ O
provides -X- _ O
crucial -X- _ O
ranking -X- _ O
signals -X- _ O
for -X- _ O
RAPO -X- _ B-MethodName
. -X- _ O
Most -X- _ O
of -X- _ O
the -X- _ O
negative -X- _ O
sampling -X- _ O
strategies -X- _ O
can -X- _ O
be -X- _ O
divided -X- _ O
into -X- _ O
hard -X- _ O
negative -X- _ O
sampling -X- _ O
and -X- _ O
random -X- _ O
negative -X- _ O
sampling -X- _ O
. -X- _ O
Following -X- _ O
the -X- _ O
theoretical -X- _ O
analysis -X- _ O
of -X- _ O
these -X- _ O
two -X- _ O
strategies -X- _ O
( -X- _ O
Zhan -X- _ O
et -X- _ O
al -X- _ O
. -X- _ O
, -X- _ O
2021 -X- _ O
) -X- _ O
, -X- _ O
we -X- _ O
propose -X- _ O
to -X- _ O
utilize -X- _ O
dynamic -X- _ O
hard -X- _ O
negatives -X- _ O
to -X- _ O
optimize -X- _ O
the -X- _ O
top -X- _ O
- -X- _ O
ranking -X- _ O
performance -X- _ O
and -X- _ O
random -X- _ O
negatives -X- _ O
to -X- _ O
stabilize -X- _ O
the -X- _ O
training -X- _ O
procedure -X- _ O
. -X- _ O

Additionally -X- _ O
, -X- _ O
another -X- _ O
loss -X- _ O
is -X- _ O
incorporated -X- _ O
to -X- _ O
emphasize -X- _ O
on -X- _ O
the -X- _ O
supervised -X- _ O
signals -X- _ O
by -X- _ O
minimizing -X- _ O
the -X- _ O
Euclidean -X- _ O
distance -X- _ O
between -X- _ O
the -X- _ O
aligned -X- _ O
words -X- _ O
: -X- _ O

where -X- _ O
θ -X- _ O
denotes -X- _ O
the -X- _ O
model -X- _ O
parameter -X- _ O
set -X- _ O
, -X- _ O
λ -X- _ B-HyperparameterName
1 -X- _ I-HyperparameterName
, -X- _ O
λ -X- _ B-HyperparameterName
2 -X- _ I-HyperparameterName
are -X- _ O
hyper -X- _ O
- -X- _ O
parameters -X- _ O
to -X- _ O
control -X- _ O
the -X- _ O
importance -X- _ B-HyperparameterName
of -X- _ I-HyperparameterName
losses -X- _ I-HyperparameterName
and -X- _ O
the -X- _ O
last -X- _ O
item -X- _ O
is -X- _ O
the -X- _ O
L2 -X- _ O
regularization -X- _ O
to -X- _ O
control -X- _ O
the -X- _ O
range -X- _ O
of -X- _ O
parameter -X- _ O
values -X- _ O
. -X- _ O

The -X- _ O
proposed -X- _ O
RAPO -X- _ B-MethodName
model -X- _ O
can -X- _ O
be -X- _ O
employed -X- _ O
in -X- _ O
both -X- _ O
supervised -X- _ O
and -X- _ O
semi -X- _ O
- -X- _ O
supervised -X- _ O
scenarios -X- _ O
. -X- _ O

Dataset -X- _ O
RAPO -X- _ B-MethodName
model -X- _ O
is -X- _ O
evaluated -X- _ O
on -X- _ O
the -X- _ O
the -X- _ O
widely -X- _ O
used -X- _ O
MUSE -X- _ B-DatasetName
dataset -X- _ O
. -X- _ O
Following -X- _ O
( -X- _ O
Mohiuddin -X- _ O
et -X- _ O
al -X- _ O
. -X- _ O
, -X- _ O
2020 -X- _ O
) -X- _ O
, -X- _ O
we -X- _ O
select -X- _ O
five -X- _ O
high -X- _ O
- -X- _ O
resource -X- _ O
language -X- _ O
pairs -X- _ O
and -X- _ O
five -X- _ O
low -X- _ O
- -X- _ O
resource -X- _ O
pairs -X- _ O
to -X- _ O
thoroughly -X- _ O
test -X- _ O
the -X- _ O
model -X- _ O
performance -X- _ O
. -X- _ O
Precision -X- _ B-MetricName
@ -X- _ I-MetricName
1 -X- _ I-MetricName
is -X- _ O
selected -X- _ O
as -X- _ O
the -X- _ O
measurement -X- _ O
. -X- _ O
We -X- _ O
use -X- _ O
the -X- _ O
data -X- _ O
splits -X- _ O
in -X- _ O
the -X- _ O
original -X- _ O
MUSE -X- _ B-DatasetName
dataset -X- _ O
. -X- _ O
Detailed -X- _ O
statistics -X- _ O
could -X- _ O
be -X- _ O
found -X- _ O
in -X- _ O
Appendix -X- _ O
D -X- _ O
. -X- _ O

Baselines -X- _ O
We -X- _ O
compare -X- _ O
RAPO -X- _ B-MethodName
with -X- _ O
popular -X- _ O
SOTA -X- _ O
BLI -X- _ B-TaskName
baselines -X- _ O
, -X- _ O
including -X- _ O
unsupervised -X- _ O
methods -X- _ O
Artetxe -X- _ O
et -X- _ O
al -X- _ O
. -X- _ O
, -X- _ O
2018b -X- _ O
; -X- _ O
Mohiuddin -X- _ O
and -X- _ O
Joty -X- _ O
, -X- _ O
2019 -X- _ O
; -X- _ O
Ren -X- _ O
et -X- _ O
al -X- _ O
. -X- _ O
, -X- _ O
2020 -X- _ O
) -X- _ O
and -X- _ O
semi -X- _ O
- -X- _ O
supervised -X- _ O
/ -X- _ O
supervised -X- _ O
methods -X- _ O
( -X- _ O
Artetxe -X- _ O
et -X- _ O
al -X- _ O
. -X- _ O
, -X- _ O
2018a -X- _ O
; -X- _ O
Joulin -X- _ O
et -X- _ O
al -X- _ O
. -X- _ O
, -X- _ O
2018 -X- _ O
; -X- _ O
Jawanpuria -X- _ O
et -X- _ O
al -X- _ O
. -X- _ O
, -X- _ O
2019 -X- _ O
; -X- _ O
Patra -X- _ O
et -X- _ O
al -X- _ O
. -X- _ O
, -X- _ O
2019 -X- _ O
; -X- _ O
Mohiuddin -X- _ O
et -X- _ O
al -X- _ O
. -X- _ O
, -X- _ O
2020 -X- _ O
; -X- _ O
Zhao -X- _ O
et -X- _ O
al -X- _ O
. -X- _ O
, -X- _ O
2020 -X- _ O
) -X- _ O
. -X- _ O
Please -X- _ O
refer -X- _ O
to -X- _ O
Appendix -X- _ O
E -X- _ O
for -X- _ O
the -X- _ O
details -X- _ O
. -X- _ O
For -X- _ O
each -X- _ O
baseline -X- _ O
, -X- _ O
we -X- _ O
directly -X- _ O
report -X- _ O
the -X- _ O
results -X- _ O
in -X- _ O
the -X- _ O
original -X- _ O
papers -X- _ O
and -X- _ O
conduct -X- _ O
experiments -X- _ O
with -X- _ O
the -X- _ O
publicly -X- _ O
available -X- _ O
code -X- _ O
if -X- _ O
necessary -X- _ O
. -X- _ O

Implementation -X- _ O
details -X- _ O
Following -X- _ O
previous -X- _ O
works -X- _ O
, -X- _ O
vocabularies -X- _ O
of -X- _ O
each -X- _ O
language -X- _ O
are -X- _ O
trimmed -X- _ O
to -X- _ O
the -X- _ O
200 -X- _ O
K -X- _ O
most -X- _ O
frequent -X- _ O
words -X- _ O
. -X- _ O
The -X- _ O
original -X- _ O
word -X- _ O
embeddings -X- _ O
are -X- _ O
normalized -X- _ O
to -X- _ O
enhance -X- _ O
performance -X- _ O
( -X- _ O
Artetxe -X- _ O
et -X- _ O
al -X- _ O
. -X- _ O
, -X- _ O
2018b -X- _ O
) -X- _ O
, -X- _ O
including -X- _ O
a -X- _ O
length -X- _ O
normalization -X- _ O
, -X- _ O
center -X- _ O
normalization -X- _ O
and -X- _ O
another -X- _ O
length -X- _ O
normalization -X- _ O
. -X- _ O
The -X- _ O
number -X- _ O
of -X- _ O
training -X- _ B-HyperparameterName
iterations -X- _ I-HyperparameterName
is -X- _ O
set -X- _ O
to -X- _ O
5 -X- _ B-HyperparameterValue
, -X- _ O
and -X- _ O
the -X- _ O
number -X- _ O
of -X- _ O
training -X- _ B-HyperparameterName
epochs -X- _ I-HyperparameterName
is -X- _ O
set -X- _ O
to -X- _ O
150 -X- _ B-HyperparameterValue
with -X- _ O
early -X- _ O
stopping -X- _ O
. -X- _ O
We -X- _ O
use -X- _ O
the -X- _ O
CSLS -X- _ O
as -X- _ O
the -X- _ O
induction -X- _ O
metric -X- _ O
, -X- _ O
and -X- _ O
the -X- _ O
number -X- _ B-HyperparameterName
of -X- _ I-HyperparameterName
nearest -X- _ I-HyperparameterName
neighbors -X- _ I-HyperparameterName
in -X- _ O
the -X- _ O
CSLS -X- _ O
is -X- _ O
set -X- _ O
to -X- _ O
10 -X- _ B-HyperparameterValue
. -X- _ O
Adam -X- _ O
optimizer -X- _ O
is -X- _ O
selected -X- _ O
to -X- _ O
minimize -X- _ O
training -X- _ O
loss -X- _ O
. -X- _ O
We -X- _ O
only -X- _ O
consider -X- _ O
15,000 -X- _ B-HyperparameterValue
most -X- _ B-HyperparameterName
frequent -X- _ I-HyperparameterName
words -X- _ I-HyperparameterName
in -X- _ O
the -X- _ O
seed -X- _ O
dictionary -X- _ O
augmentation -X- _ O
( -X- _ O
Zhao -X- _ O
et -X- _ O
al -X- _ O
. -X- _ O
, -X- _ O
2020 -X- _ O
) -X- _ O
. -X- _ O
The -X- _ O
search -X- _ O
spaces -X- _ O
of -X- _ O
hyper -X- _ O
- -X- _ O
parameters -X- _ O
are -X- _ O
presented -X- _ O
in -X- _ O
Appendix -X- _ O
F -X- _ O
. -X- _ O

The -X- _ O
proposed -X- _ O
RAPO -X- _ B-MethodName
model -X- _ O
is -X- _ O
extensively -X- _ O
evaluated -X- _ O
over -X- _ O
five -X- _ O
rich -X- _ O
- -X- _ O
resource -X- _ O
language -X- _ O
pairs -X- _ O
( -X- _ O
en -X- _ O
- -X- _ O
es -X- _ O
, -X- _ O
en -X- _ O
- -X- _ O
fr -X- _ O
, -X- _ O
en -X- _ O
- -X- _ O
it -X- _ O
, -X- _ O
en -X- _ O
- -X- _ O
ru -X- _ O
and -X- _ O
en -X- _ O
- -X- _ O
zh -X- _ O
) -X- _ O
and -X- _ O
five -X- _ O
low -X- _ O
- -X- _ O
resource -X- _ O
pairs -X- _ O
( -X- _ O
en -X- _ O
- -X- _ O
fa -X- _ O
, -X- _ O
en -X- _ O
- -X- _ O
tr -X- _ O
, -X- _ O
en -X- _ O
- -X- _ O
he -X- _ O
, -X- _ O
en -X- _ O
- -X- _ O
ar -X- _ O
and -X- _ O
en -X- _ O
- -X- _ O
et -X- _ O
) -X- _ O
in -X- _ O
both -X- _ O
directions -X- _ O
, -X- _ O
leading -X- _ O
to -X- _ O
20 -X- _ O
evaluation -X- _ O
sets -X- _ O
in -X- _ O
total -X- _ O
. -X- _ O
RAPO -X- _ B-MethodName
model -X- _ O
is -X- _ O
fully -X- _ O
trained -X- _ O
5 -X- _ O
times -X- _ O
over -X- _ O
each -X- _ O
dataset -X- _ O
and -X- _ O
we -X- _ O
report -X- _ O
the -X- _ O
average -X- _ O
performance -X- _ O
. -X- _ O
Table -X- _ O
1 -X- _ O
and -X- _ O
2 -X- _ O
present -X- _ O
the -X- _ O
Precision -X- _ B-MetricName
@ -X- _ I-MetricName
1 -X- _ I-MetricName
scores -X- _ O
of -X- _ O
different -X- _ O
models -X- _ O
. -X- _ O

From -X- _ O
the -X- _ O
results -X- _ O
, -X- _ O
one -X- _ O
can -X- _ O
clearly -X- _ O
see -X- _ O
that -X- _ O
the -X- _ O
proposed -X- _ O
RAPO -X- _ B-MethodName
model -X- _ O
achieves -X- _ O
best -X- _ O
performance -X- _ O
over -X- _ O
most -X- _ O
datasets -X- _ O
, -X- _ O
and -X- _ O
obtain -X- _ O
comparable -X- _ O
results -X- _ O
on -X- _ O
other -X- _ O
datasets -X- _ O
. -X- _ O
From -X- _ O
the -X- _ O
perspective -X- _ O
of -X- _ O
average -X- _ O
performance -X- _ O
, -X- _ O
RAPO -X- _ B-MethodName
- -X- _ I-MethodName
sup -X- _ I-MethodName
outperforms -X- _ O
the -X- _ O
best -X- _ O
baseline -X- _ O
by -X- _ O
0.7 -X- _ B-MetricValue
% -X- _ I-MetricValue
and -X- _ O
1.3 -X- _ B-MetricValue
% -X- _ I-MetricValue
over -X- _ O
the -X- _ O
rich -X- _ O
- -X- _ O
and -X- _ O
low -X- _ O
- -X- _ O
resource -X- _ O
datasets -X- _ O
, -X- _ O
and -X- _ O
RAPO -X- _ B-MethodName
- -X- _ I-MethodName
semi -X- _ I-MethodName
beats -X- _ O
the -X- _ O
best -X- _ O
baseline -X- _ O
by -X- _ O
0.7 -X- _ B-MetricValue
% -X- _ I-MetricValue
and -X- _ O
1.6 -X- _ B-MetricValue
% -X- _ I-MetricValue
under -X- _ O
the -X- _ O
semisupervised -X- _ O
setting -X- _ O
. -X- _ O
Such -X- _ O
consistent -X- _ O
performance -X- _ O
gains -X- _ O
demonstrate -X- _ O
the -X- _ O
superiority -X- _ O
and -X- _ O
generality -X- _ O
of -X- _ O
RAPO -X- _ B-MethodName
. -X- _ O
Besides -X- _ O
, -X- _ O
RAPO -X- _ B-MethodName
achieves -X- _ O
more -X- _ O
significant -X- _ O
improvements -X- _ O
over -X- _ O
the -X- _ O
distant -X- _ O
language -X- _ O
pairs -X- _ O
( -X- _ O
e.g. -X- _ O
, -X- _ O
en -X- _ O
- -X- _ O
ru -X- _ O
, -X- _ O
en -X- _ O
- -X- _ O
fa -X- _ O
and -X- _ O
en -X- _ O
- -X- _ O
tr -X- _ O
) -X- _ O
, -X- _ O
which -X- _ O
indicates -X- _ O
that -X- _ O
the -X- _ O
personalized -X- _ O
adapter -X- _ O
is -X- _ O
capable -X- _ O
of -X- _ O
bridging -X- _ O
the -X- _ O
gaps -X- _ O
between -X- _ O
language -X- _ O
pairs -X- _ O
by -X- _ O
calibrating -X- _ O
the -X- _ O
vanilla -X- _ O
embeddings -X- _ O
to -X- _ O
fit -X- _ O
the -X- _ O
BLI -X- _ B-TaskName
task -X- _ O
. -X- _ O
Overall -X- _ O
, -X- _ O
such -X- _ O
advanced -X- _ O
performance -X- _ O
of -X- _ O
RAPO -X- _ B-MethodName
owes -X- _ O
to -X- _ O
the -X- _ O
appropriate -X- _ O
ranking -X- _ O
objectives -X- _ O
, -X- _ O
personalized -X- _ O
adaptions -X- _ O
and -X- _ O
orthogonal -X- _ O
projections -X- _ O
. -X- _ O

To -X- _ O
investigate -X- _ O
the -X- _ O
effectiveness -X- _ O
of -X- _ O
various -X- _ O
components -X- _ O
in -X- _ O
RAPO -X- _ B-MethodName
, -X- _ O
we -X- _ O
conduct -X- _ O
extensive -X- _ O
ablation -X- _ O
studies -X- _ O
on -X- _ O
four -X- _ O
datasets -X- _ O
, -X- _ O
including -X- _ O
en -X- _ O
- -X- _ O
it -X- _ O
, -X- _ O
en -X- _ O
- -X- _ O
ru -X- _ O
, -X- _ O
en -X- _ O
- -X- _ O
tr -X- _ O
and -X- _ O
en -X- _ O
- -X- _ O
he -X- _ O
. -X- _ O
To -X- _ O
avoid -X- _ O
the -X- _ O
influence -X- _ O
of -X- _ O
the -X- _ O
potential -X- _ O
noises -X- _ O
introduced -X- _ O
by -X- _ O
the -X- _ O
self -X- _ O
- -X- _ O
learning -X- _ O
, -X- _ O
ablation -X- _ O
studies -X- _ O
are -X- _ O
investigated -X- _ O
under -X- _ O
the -X- _ O
supervised -X- _ O
setting -X- _ O
. -X- _ O

Training -X- _ O
objective -X- _ O
functions -X- _ O
As -X- _ O
shown -X- _ O
in -X- _ O
Formula -X- _ O
( -X- _ O
12 -X- _ O
) -X- _ O
, -X- _ O
the -X- _ O
loss -X- _ O
of -X- _ O
RAPO -X- _ B-MethodName
includes -X- _ O
two -X- _ O
parts -X- _ O
: -X- _ O
the -X- _ O
ranking -X- _ O
loss -X- _ O
L -X- _ O
r -X- _ O
and -X- _ O
the -X- _ O
MSE -X- _ O
loss -X- _ O
L -X- _ O
m -X- _ O
. -X- _ O
Table -X- _ O
5 -X- _ O
presents -X- _ O
the -X- _ O
model -X- _ O
performance -X- _ O
without -X- _ O
different -X- _ O
objectives -X- _ O
. -X- _ O
We -X- _ O
can -X- _ O
see -X- _ O
that -X- _ O
both -X- _ O
models -X- _ O
present -X- _ O
performance -X- _ O
decay -X- _ O
over -X- _ O
all -X- _ O
the -X- _ O
datasets -X- _ O
, -X- _ O
which -X- _ O
verifies -X- _ O
both -X- _ O
objective -X- _ O
functions -X- _ O
would -X- _ O
benefit -X- _ O
the -X- _ O
BLI -X- _ B-TaskName
task -X- _ O
. -X- _ O
Without -X- _ O
the -X- _ O
ranking -X- _ O
loss -X- _ O
, -X- _ O
RAPO -X- _ B-MethodName
presents -X- _ O
more -X- _ O
significant -X- _ O
performance -X- _ O
drop -X- _ O
compared -X- _ O
to -X- _ O
the -X- _ O
MSE -X- _ O
loss -X- _ O
. -X- _ O
It -X- _ O
reveals -X- _ O
that -X- _ O
the -X- _ O
BLI -X- _ B-TaskName
task -X- _ O
is -X- _ O
essentially -X- _ O
a -X- _ O
ranking -X- _ O
problem -X- _ O
and -X- _ O
thus -X- _ O
the -X- _ O
ranking -X- _ O
loss -X- _ O
L -X- _ O
r -X- _ O
would -X- _ O
be -X- _ O
more -X- _ O
important -X- _ O
. -X- _ O

In -X- _ O
this -X- _ O
paper -X- _ O
, -X- _ O
we -X- _ O
propose -X- _ O
a -X- _ O
novel -X- _ O
model -X- _ O
RAPO -X- _ B-MethodName
for -X- _ O
bilingual -X- _ B-TaskName
lexicon -X- _ I-TaskName
induction -X- _ I-TaskName
. -X- _ O
Different -X- _ O
from -X- _ O
previous -X- _ O
works -X- _ O
, -X- _ O
RAPO -X- _ B-MethodName
is -X- _ O
formulated -X- _ O
as -X- _ O
a -X- _ O
ranking -X- _ O
paradigm -X- _ O
, -X- _ O
which -X- _ O
is -X- _ O
more -X- _ O
suitable -X- _ O
to -X- _ O
the -X- _ O
nature -X- _ O
of -X- _ O
studied -X- _ O
tasks -X- _ O
. -X- _ O
Two -X- _ O
novel -X- _ O
modules -X- _ O
are -X- _ O
further -X- _ O
employed -X- _ O
by -X- _ O
deeply -X- _ O
mining -X- _ O
the -X- _ O
unique -X- _ O
characteristics -X- _ O
of -X- _ O
BLI -X- _ B-TaskName
task -X- _ O
: -X- _ O
the -X- _ O
Householder -X- _ O
projection -X- _ O
to -X- _ O
ensure -X- _ O
the -X- _ O
strict -X- _ O
orthogonal -X- _ O
mapping -X- _ O
function -X- _ O
, -X- _ O
and -X- _ O
the -X- _ O
personalized -X- _ O
adapter -X- _ O
to -X- _ O
learn -X- _ O
unique -X- _ O
embedding -X- _ O
offsets -X- _ O
for -X- _ O
different -X- _ O
words -X- _ O
. -X- _ O
Extensive -X- _ O
experimental -X- _ O
results -X- _ O
on -X- _ O
20 -X- _ O
datasets -X- _ O
demonstrate -X- _ O
the -X- _ O
superiority -X- _ O
of -X- _ O
our -X- _ O
proposal -X- _ O
. -X- _ O

Despite -X- _ O
the -X- _ O
promising -X- _ O
performance -X- _ O
of -X- _ O
the -X- _ O
proposed -X- _ O
RAPO -X- _ B-MethodName
model -X- _ O
, -X- _ O
it -X- _ O
may -X- _ O
suffer -X- _ O
from -X- _ O
the -X- _ O
following -X- _ O
limitations -X- _ O
: -X- _ O

• -X- _ O
RAPO -X- _ B-MethodName
has -X- _ O
more -X- _ O
hyper -X- _ O
- -X- _ O
parameters -X- _ O
than -X- _ O
the -X- _ O
previous -X- _ O
works -X- _ O
, -X- _ O
leading -X- _ O
to -X- _ O
the -X- _ O
exhausting -X- _ O
and -X- _ O
time -X- _ O
- -X- _ O
consuming -X- _ O
hyper -X- _ O
- -X- _ O
parameter -X- _ O
tuning -X- _ O
process -X- _ O
. -X- _ O

• -X- _ O
Though -X- _ O
RAPO -X- _ B-MethodName
has -X- _ O
achieved -X- _ O
the -X- _ O
best -X- _ O
performance -X- _ O
over -X- _ O
almost -X- _ O
all -X- _ O
the -X- _ O
datasets -X- _ O
, -X- _ O
it -X- _ O
fails -X- _ O
in -X- _ O
few -X- _ O
datasets -X- _ O
such -X- _ O
as -X- _ O
en→tr -X- _ O
, -X- _ O
which -X- _ O
might -X- _ O
be -X- _ O
caused -X- _ O
by -X- _ O
the -X- _ O
insufficient -X- _ O
hyper -X- _ O
- -X- _ O
parameter -X- _ O
tuning -X- _ O
. -X- _ O

• -X- _ O
The -X- _ O
supervised -X- _ O
signals -X- _ O
are -X- _ O
indispensable -X- _ O
to -X- _ O
our -X- _ O
proposal -X- _ O
, -X- _ O
and -X- _ O
thus -X- _ O
RAPO -X- _ B-MethodName
can -X- _ O
not -X- _ O
be -X- _ O
applied -X- _ O
to -X- _ O
the -X- _ O
unsupervised -X- _ O
learning -X- _ O
setting -X- _ O
without -X- _ O
any -X- _ O
labeled -X- _ O
data -X- _ O
. -X- _ O

From -X- _ O
the -X- _ O
above -X- _ O
we -X- _ O
can -X- _ O
see -X- _ O
that -X- _ O
any -X- _ O
n×n -X- _ O
orthogonal -X- _ O
matrix -X- _ O
can -X- _ O
be -X- _ O
decomposed -X- _ O
into -X- _ O
the -X- _ O
product -X- _ O
of -X- _ O
n -X- _ O
Householder -X- _ O
matrices -X- _ O
, -X- _ O
i.e. -X- _ O
, -X- _ O
O -X- _ O
( -X- _ O
n -X- _ O
) -X- _ O
⊂ -X- _ O
Image -X- _ O
( -X- _ O
HP -X- _ O
) -X- _ O
. -X- _ O
All -X- _ O
in -X- _ O
all -X- _ O
, -X- _ O
we -X- _ O
have -X- _ O
Image -X- _ O
( -X- _ O
HP -X- _ O
) -X- _ O
= -X- _ O
O -X- _ O
( -X- _ O
n -X- _ O
) -X- _ O
. -X- _ O

The -X- _ O
widely -X- _ O
used -X- _ O
MUSE -X- _ B-DatasetName
dataset -X- _ O

Recent -X- _ O
proposed -X- _ O
work -X- _ O
on -X- _ O
BLI -X- _ B-TaskName
can -X- _ O
be -X- _ O
mainly -X- _ O
divided -X- _ O
into -X- _ O
two -X- _ O
categories -X- _ O
. -X- _ O
The -X- _ O
first -X- _ O
is -X- _ O
unsupervised -X- _ O
learning -X- _ O
methods -X- _ O
, -X- _ O
which -X- _ O
induces -X- _ O
dictionaries -X- _ O
according -X- _ O
to -X- _ O
the -X- _ O
characteristics -X- _ O
of -X- _ O
the -X- _ O
embedding -X- _ O
space -X- _ O
. -X- _ O
The -X- _ O
second -X- _ O
is -X- _ O
the -X- _ O
supervised -X- _ O
and -X- _ O
semi -X- _ O
- -X- _ O
supervised -X- _ O
learning -X- _ O
methods -X- _ O
, -X- _ O
which -X- _ O
trains -X- _ O
the -X- _ O
model -X- _ O
based -X- _ O
on -X- _ O
a -X- _ O
small -X- _ O
seed -X- _ O
dictionary -X- _ O
. -X- _ O

The -X- _ O
hyper -X- _ O
- -X- _ O
parameters -X- _ O
are -X- _ O
tuned -X- _ O
by -X- _ O
the -X- _ O
random -X- _ O
search -X- _ O
( -X- _ O
Bergstra -X- _ O
and -X- _ O
Bengio -X- _ O
, -X- _ O
2012 -X- _ O
) -X- _ O
for -X- _ O
each -X- _ O
BLI -X- _ B-TaskName
dataset -X- _ O
, -X- _ O
including -X- _ O
number -X- _ B-HyperparameterName
of -X- _ I-HyperparameterName
dynamic -X- _ I-HyperparameterName
hard -X- _ I-HyperparameterName
negative -X- _ I-HyperparameterName
samples -X- _ I-HyperparameterName
K -X- _ B-HyperparameterName
h -X- _ I-HyperparameterName
, -X- _ O
number -X- _ B-HyperparameterName
of -X- _ I-HyperparameterName
negative -X- _ I-HyperparameterName
samples -X- _ I-HyperparameterName
K -X- _ B-HyperparameterName
r -X- _ I-HyperparameterName
, -X- _ O
activation -X- _ B-HyperparameterName
function -X- _ I-HyperparameterName
used -X- _ I-HyperparameterName
in -X- _ I-HyperparameterName
personalized -X- _ I-HyperparameterName
adapter -X- _ I-HyperparameterName
σ -X- _ B-HyperparameterName
, -X- _ O
learning -X- _ B-HyperparameterName
rate -X- _ I-HyperparameterName
lr -X- _ B-HyperparameterName
, -X- _ O
similarity -X- _ B-HyperparameterName
threshold -X- _ I-HyperparameterName
of -X- _ I-HyperparameterName
personal -X- _ I-HyperparameterName
- -X- _ I-HyperparameterName
ized -X- _ I-HyperparameterName
adapter -X- _ I-HyperparameterName
for -X- _ I-HyperparameterName
source -X- _ I-HyperparameterName
and -X- _ I-HyperparameterName
target -X- _ I-HyperparameterName
language -X- _ I-HyperparameterName
τ -X- _ B-HyperparameterName
s -X- _ I-HyperparameterName
, -X- _ O
τ -X- _ B-HyperparameterName
t -X- _ I-HyperparameterName
, -X- _ O
and -X- _ O
the -X- _ O
weights -X- _ B-HyperparameterName
in -X- _ I-HyperparameterName
loss -X- _ I-HyperparameterName
function -X- _ I-HyperparameterName
λ -X- _ B-HyperparameterName
1 -X- _ I-HyperparameterName
, -X- _ O
λ -X- _ B-HyperparameterName
2 -X- _ I-HyperparameterName
. -X- _ O
The -X- _ O
hyperparameter -X- _ O
search -X- _ O
space -X- _ O
is -X- _ O
shown -X- _ O
in -X- _ O
Table -X- _ O
9 -X- _ O

FiD -X- _ B-MethodName
- -X- _ I-MethodName
ICL -X- _ I-MethodName
: -X- _ O
A -X- _ O
Fusion -X- _ B-MethodName
- -X- _ I-MethodName
in -X- _ I-MethodName
- -X- _ I-MethodName
Decoder -X- _ I-MethodName
Approach -X- _ O
for -X- _ O
Efficient -X- _ O
In -X- _ B-TaskName
- -X- _ I-TaskName
Context -X- _ I-TaskName
Learning -X- _ I-TaskName

With -X- _ O
the -X- _ O
evergrowing -X- _ O
sizes -X- _ O
of -X- _ O
pre -X- _ O
- -X- _ O
trained -X- _ O
models -X- _ O
( -X- _ O
PTMs -X- _ O
) -X- _ O
, -X- _ O
it -X- _ O
has -X- _ O
been -X- _ O
an -X- _ O
emerging -X- _ O
practice -X- _ O
to -X- _ O
only -X- _ O
provide -X- _ O
the -X- _ O
inference -X- _ O
APIs -X- _ O
for -X- _ O
users -X- _ O
, -X- _ O
namely -X- _ O
model -X- _ O
- -X- _ O
as -X- _ O
- -X- _ O
a -X- _ O
- -X- _ O
service -X- _ O
( -X- _ O
MaaS -X- _ O
) -X- _ O
setting -X- _ O
. -X- _ O
To -X- _ O
adapt -X- _ O
PTMs -X- _ O
with -X- _ O
model -X- _ O
parameters -X- _ O
frozen -X- _ O
, -X- _ O
most -X- _ O
current -X- _ O
approaches -X- _ O
focus -X- _ O
on -X- _ O
the -X- _ O
input -X- _ O
side -X- _ O
, -X- _ O
seeking -X- _ O
for -X- _ O
powerful -X- _ O
prompts -X- _ O
to -X- _ O
stimulate -X- _ O
models -X- _ O
for -X- _ O
correct -X- _ O
answers -X- _ O
. -X- _ O
However -X- _ O
, -X- _ O
we -X- _ O
argue -X- _ O
that -X- _ O
input -X- _ O
- -X- _ O
side -X- _ O
adaptation -X- _ O
could -X- _ O
be -X- _ O
arduous -X- _ O
due -X- _ O
to -X- _ O
the -X- _ O
lack -X- _ O
of -X- _ O
gradient -X- _ O
signals -X- _ O
and -X- _ O
they -X- _ O
usually -X- _ O
require -X- _ O
thousands -X- _ O
of -X- _ O
API -X- _ O
queries -X- _ O
, -X- _ O
resulting -X- _ O
in -X- _ O
high -X- _ O
computation -X- _ O
and -X- _ O
time -X- _ O
costs -X- _ O
. -X- _ O
In -X- _ O
light -X- _ O
of -X- _ O
this -X- _ O
, -X- _ O
we -X- _ O
present -X- _ O
Decoder -X- _ B-MethodName
Tuning -X- _ I-MethodName
( -X- _ O
DecT -X- _ B-MethodName
) -X- _ O
, -X- _ O
which -X- _ O
in -X- _ O
contrast -X- _ O
optimizes -X- _ O
task -X- _ O
- -X- _ O
specific -X- _ O
decoder -X- _ O
networks -X- _ O
on -X- _ O
the -X- _ O
output -X- _ O
side -X- _ O
. -X- _ O
Specifically -X- _ O
, -X- _ O
DecT -X- _ B-MethodName
first -X- _ O
extracts -X- _ O
prompt -X- _ O
- -X- _ O
stimulated -X- _ O
output -X- _ O
scores -X- _ O
for -X- _ O
initial -X- _ O
predictions -X- _ O
. -X- _ O
On -X- _ O
top -X- _ O
of -X- _ O
that -X- _ O
, -X- _ O
we -X- _ O
train -X- _ O
an -X- _ O
additional -X- _ O
decoder -X- _ O
network -X- _ O
on -X- _ O
the -X- _ O
output -X- _ O
representations -X- _ O
to -X- _ O
incorporate -X- _ O
posterior -X- _ O
data -X- _ O
knowledge -X- _ O
. -X- _ O
By -X- _ O
gradientbased -X- _ O
optimization -X- _ O
, -X- _ O
DecT -X- _ B-MethodName
can -X- _ O
be -X- _ O
trained -X- _ O
within -X- _ O
several -X- _ O
seconds -X- _ O
and -X- _ O
requires -X- _ O
only -X- _ O
one -X- _ O
PTM -X- _ O
query -X- _ O
per -X- _ O
sample -X- _ O
. -X- _ O
Empirically -X- _ O
, -X- _ O
we -X- _ O
conduct -X- _ O
extensive -X- _ O
natural -X- _ B-TaskName
language -X- _ I-TaskName
understanding -X- _ I-TaskName
experiments -X- _ O
and -X- _ O
show -X- _ O
that -X- _ O
DecT -X- _ B-MethodName
significantly -X- _ O
outperforms -X- _ O
state -X- _ O
- -X- _ O
of -X- _ O
- -X- _ O
the -X- _ O
- -X- _ O
art -X- _ O
algorithms -X- _ O
with -X- _ O
a -X- _ O
200× -X- _ B-MetricValue
speed -X- _ B-MetricName
- -X- _ I-MetricName
up -X- _ I-MetricName
. -X- _ O
Our -X- _ O
codes -X- _ O
are -X- _ O
available -X- _ O
at -X- _ O
https -X- _ O
: -X- _ O
/ -X- _ O
/ -X- _ O
github.com -X- _ O
/ -X- _ O
thunlp -X- _ O
/ -X- _ O
DecT -X- _ O
. -X- _ O

Recent -X- _ O
advances -X- _ O
in -X- _ O
pre -X- _ O
- -X- _ O
trained -X- _ O
models -X- _ O
( -X- _ O
PTMs -X- _ O
) -X- _ O
demonstrate -X- _ O
the -X- _ O
power -X- _ O
of -X- _ O
the -X- _ O
" -X- _ O
pre -X- _ O
- -X- _ O
trainingfine -X- _ O
- -X- _ O
tuning -X- _ O
" -X- _ O
paradigm -X- _ O
, -X- _ O
which -X- _ O
empowers -X- _ O
broad -X- _ O
downstream -X- _ O
NLP -X- _ O
tasks -X- _ O
with -X- _ O
a -X- _ O
single -X- _ O
backbone -X- _ O
model -X- _ O
( -X- _ O
Devlin -X- _ O
et -X- _ O
al -X- _ O
. -X- _ O
, -X- _ O
2019 -X- _ O
; -X- _ O
Raffel -X- _ O
et -X- _ O
al -X- _ O
. -X- _ O
, -X- _ O
2020 -X- _ O
; -X- _ O
Radford -X- _ O
et -X- _ O
al -X- _ O
. -X- _ O
, -X- _ O
2019 -X- _ O
) -X- _ O
. -X- _ O
Given -X- _ O
the -X- _ O
million -X- _ O
even -X- _ O
billionscale -X- _ O
models -X- _ O
, -X- _ O
model -X- _ O
- -X- _ O
as -X- _ O
- -X- _ O
a -X- _ O
- -X- _ O
service -X- _ O
( -X- _ O
MaaS -X- _ O
) -X- _ O
has -X- _ O
become -X- _ O
an -X- _ O
emerging -X- _ O
practice -X- _ O
in -X- _ O
deploying -X- _ O
massive -X- _ O
PTMs -X- _ O
, -X- _ O
where -X- _ O
users -X- _ O
can -X- _ O
only -X- _ O
get -X- _ O
access -X- _ O
to -X- _ O
model -X- _ O
inference -X- _ O
APIs -X- _ O
( -X- _ O
Brown -X- _ O
et -X- _ O
al -X- _ O
. -X- _ O
, -X- _ O
2020 -X- _ O
; -X- _ O
. -X- _ O
Under -X- _ O
such -X- _ O
a -X- _ O
scenario -X- _ O
, -X- _ O
PTMs -X- _ O
' -X- _ O
parameters -X- _ O
are -X- _ O
frozen -X- _ O
, -X- _ O
and -X- _ O
users -X- _ O
can -X- _ O
not -X- _ O
fine -X- _ O
- -X- _ O
tune -X- _ O
the -X- _ O
model -X- _ O
on -X- _ O
downstream -X- _ O
tasks -X- _ O
for -X- _ O
adaptation -X- _ O
. -X- _ O
To -X- _ O
find -X- _ O
an -X- _ O
alternative -X- _ O
way -X- _ O
, -X- _ O
researchers -X- _ O
have -X- _ O
studied -X- _ O
MaaS -X- _ O
PTM -X- _ O
adaptation -X- _ O
methods -X- _ O
extensively -X- _ O
. -X- _ O

Most -X- _ O
existing -X- _ O
approaches -X- _ O
in -X- _ O
this -X- _ O
line -X- _ O
are -X- _ O
based -X- _ O
on -X- _ O
prompts -X- _ O
, -X- _ O
which -X- _ O
modify -X- _ O
inputs -X- _ O
with -X- _ O
specific -X- _ O
patterns -X- _ O
. -X- _ O
By -X- _ O
wrapping -X- _ O
inputs -X- _ O
into -X- _ O
cloze -X- _ O
- -X- _ O
style -X- _ O
questions -X- _ O
or -X- _ O
prepending -X- _ O
inputs -X- _ O
with -X- _ O
a -X- _ O
few -X- _ O
demonstrative -X- _ O
examples -X- _ O
, -X- _ O
PTMs -X- _ O
could -X- _ O
produce -X- _ O
the -X- _ O
right -X- _ O
outputs -X- _ O
directly -X- _ O
and -X- _ O
show -X- _ O
strong -X- _ O
" -X- _ O
in -X- _ O
- -X- _ O
context -X- _ O
" -X- _ O
learning -X- _ O
abilities -X- _ O
( -X- _ O
Petroni -X- _ O
et -X- _ O
al -X- _ O
. -X- _ O
, -X- _ O
2019 -X- _ O
; -X- _ O
Brown -X- _ O
et -X- _ O
al -X- _ O
. -X- _ O
, -X- _ O
2020 -X- _ O
) -X- _ O
without -X- _ O
any -X- _ O
parameter -X- _ O
update -X- _ O
. -X- _ O
Besides -X- _ O
heuristic -X- _ O
prompt -X- _ O
design -X- _ O
, -X- _ O
some -X- _ O
recent -X- _ O
works -X- _ O
try -X- _ O
to -X- _ O
optimize -X- _ O
the -X- _ O
input -X- _ O
prompts -X- _ O
without -X- _ O
gradients -X- _ O
. -X- _ O
Among -X- _ O
them -X- _ O
, -X- _ O
Black -X- _ B-MethodName
- -X- _ I-MethodName
box -X- _ I-MethodName
Tuning -X- _ I-MethodName
( -X- _ O
BBT -X- _ B-MethodName
) -X- _ O
and -X- _ O
BBTv2 -X- _ B-MethodName
( -X- _ O
Sun -X- _ O
et -X- _ O
al -X- _ O
. -X- _ O
, -X- _ O
2022a -X- _ O
) -X- _ O
apply -X- _ O
evolutionary -X- _ O
algorithm -X- _ O
( -X- _ O
Hansen -X- _ O
and -X- _ O
Ostermeier -X- _ O
, -X- _ O
2001 -X- _ O
) -X- _ O
on -X- _ O
continuous -X- _ O
prompt -X- _ O
tokens -X- _ O
, -X- _ O
while -X- _ O
RLPrompt -X- _ B-MethodName
( -X- _ O
Deng -X- _ O
et -X- _ O
al -X- _ O
. -X- _ O
, -X- _ O
2022 -X- _ O
) -X- _ O
adopts -X- _ O
reinforcement -X- _ O
learning -X- _ O
to -X- _ O
find -X- _ O
discrete -X- _ O
prompt -X- _ O
tokens -X- _ O
. -X- _ O
Nevertheless -X- _ O
, -X- _ O
gradientfree -X- _ O
optimization -X- _ O
is -X- _ O
rather -X- _ O
difficult -X- _ O
and -X- _ O
these -X- _ O
input -X- _ O
- -X- _ O
side -X- _ O
methods -X- _ O
need -X- _ O
to -X- _ O
query -X- _ O
the -X- _ O
PTMs -X- _ O
thousands -X- _ O
of -X- _ O
times -X- _ O
for -X- _ O
optimization -X- _ O
, -X- _ O
which -X- _ O
leads -X- _ O
to -X- _ O
huge -X- _ O
inference -X- _ O
costs -X- _ O
in -X- _ O
terms -X- _ O
of -X- _ O
time -X- _ O
and -X- _ O
computation -X- _ O
resources -X- _ O
. -X- _ O
Moreover -X- _ O
, -X- _ O
their -X- _ O
final -X- _ O
performance -X- _ O
is -X- _ O
not -X- _ O
satisfying -X- _ O
as -X- _ O
well -X- _ O
. -X- _ O

Based -X- _ O
on -X- _ O
these -X- _ O
findings -X- _ O
, -X- _ O
we -X- _ O
present -X- _ O
Decoder -X- _ B-MethodName
Tuning -X- _ I-MethodName
( -X- _ O
DecT -X- _ B-MethodName
) -X- _ O
, -X- _ O
an -X- _ O
enhanced -X- _ O
output -X- _ O
- -X- _ O
side -X- _ O
adaptation -X- _ O
method -X- _ O
. -X- _ O
Specifically -X- _ O
, -X- _ O
DecT -X- _ B-MethodName
has -X- _ O
two -X- _ O
crucial -X- _ O
design -X- _ O
choices -X- _ O
to -X- _ O
address -X- _ O
the -X- _ O
above -X- _ O
issues -X- _ O
. -X- _ O
First -X- _ O
, -X- _ O
DecT -X- _ B-MethodName
queries -X- _ O
the -X- _ O
PTM -X- _ O
with -X- _ O
prompts -X- _ O
and -X- _ O
adopts -X- _ O
model -X- _ O
output -X- _ O
scores -X- _ O
as -X- _ O
the -X- _ O
initial -X- _ O
predictions -X- _ O
, -X- _ O
which -X- _ O
takes -X- _ O
advantage -X- _ O
of -X- _ O
internal -X- _ O
model -X- _ O
knowledge -X- _ O
. -X- _ O
Second -X- _ O
, -X- _ O
on -X- _ O
top -X- _ O
of -X- _ O
the -X- _ O
output -X- _ O
representations -X- _ O
, -X- _ O
we -X- _ O
select -X- _ O
a -X- _ O
Prototypical -X- _ O
Network -X- _ O
( -X- _ O
ProtoNet -X- _ O
) -X- _ O
( -X- _ O
Snell -X- _ O
et -X- _ O
al -X- _ O
. -X- _ O
, -X- _ O
2017 -X- _ O
) -X- _ O
as -X- _ O
the -X- _ O
decoder -X- _ O
network -X- _ O
and -X- _ O
train -X- _ O
it -X- _ O
to -X- _ O
fit -X- _ O
the -X- _ O
training -X- _ O
data -X- _ O
, -X- _ O
which -X- _ O
is -X- _ O
more -X- _ O
suitable -X- _ O
for -X- _ O
few -X- _ O
- -X- _ O
shot -X- _ O
learning -X- _ O
. -X- _ O
In -X- _ O
this -X- _ O
way -X- _ O
, -X- _ O
DecT -X- _ B-MethodName
modifies -X- _ O
the -X- _ O
initial -X- _ O
model -X- _ O
scores -X- _ O
with -X- _ O
subsequent -X- _ O
training -X- _ O
data -X- _ O
, -X- _ O
thus -X- _ O
achieving -X- _ O
better -X- _ O
performance -X- _ O
. -X- _ O

Through -X- _ O
few -X- _ O
- -X- _ O
shot -X- _ O
learning -X- _ O
experiments -X- _ O
on -X- _ O
ten -X- _ O
language -X- _ O
understanding -X- _ O
datasets -X- _ O
, -X- _ O
we -X- _ O
highlight -X- _ O
three -X- _ O
advantages -X- _ O
of -X- _ O
DecT -X- _ B-MethodName
( -X- _ O
see -X- _ O
Figure -X- _ O
1 -X- _ O
) -X- _ O
. -X- _ O
( -X- _ O
1 -X- _ O
) -X- _ O
DecT -X- _ B-MethodName
achieves -X- _ O
over -X- _ O
3 -X- _ B-MetricValue
% -X- _ I-MetricValue
absolute -X- _ O
accuracy -X- _ B-MetricName
improvement -X- _ O
on -X- _ O
average -X- _ O
, -X- _ O
greatly -X- _ O
outperforming -X- _ O
previous -X- _ O
works -X- _ O
. -X- _ O

Given -X- _ O
a -X- _ O
set -X- _ O
of -X- _ O
training -X- _ O
data -X- _ O

as -X- _ O
the -X- _ O
template -X- _ O
with -X- _ O
V -X- _ O
= -X- _ O
{ -X- _ O
bad -X- _ O
, -X- _ O
great -X- _ O
} -X- _ O
as -X- _ O
label -X- _ O
words -X- _ O
for -X- _ O
negative -X- _ O
and -X- _ O
positive -X- _ O
sentiment -X- _ O
respectively -X- _ O
. -X- _ O
The -X- _ O
output -X- _ O
scores -X- _ O
on -X- _ O
these -X- _ O
label -X- _ O
words -X- _ O
further -X- _ O
correspond -X- _ O
to -X- _ O
the -X- _ O
classes -X- _ O
. -X- _ O

In -X- _ O
this -X- _ O
section -X- _ O
, -X- _ O
we -X- _ O
elaborate -X- _ O
on -X- _ O
our -X- _ O
proposed -X- _ O
Decoder -X- _ B-MethodName
Tuning -X- _ I-MethodName
( -X- _ O
DecT -X- _ B-MethodName
) -X- _ O
method -X- _ O
for -X- _ O
the -X- _ O
classification -X- _ O
task -X- _ O
. -X- _ O
We -X- _ O
start -X- _ O
with -X- _ O
reviewing -X- _ O
current -X- _ O
input -X- _ O
- -X- _ O
side -X- _ O
adaptation -X- _ O
methods -X- _ O
, -X- _ O
then -X- _ O
give -X- _ O
an -X- _ O
overview -X- _ O
of -X- _ O
DecT -X- _ B-MethodName
and -X- _ O
finally -X- _ O
detail -X- _ O
it -X- _ O
step -X- _ O
- -X- _ O
by -X- _ O
- -X- _ O
step -X- _ O
. -X- _ O

Previous -X- _ O
MaaS -X- _ O
adaptation -X- _ O
methods -X- _ O
seek -X- _ O
for -X- _ O
optimal -X- _ O
prompts -X- _ O
that -X- _ O
stimulate -X- _ O
PTMs -X- _ O
to -X- _ O
output -X- _ O
correct -X- _ O
answers -X- _ O
1 -X- _ O
. -X- _ O
Without -X- _ O
loss -X- _ O
of -X- _ O
generality -X- _ O
, -X- _ O
we -X- _ O
formulate -X- _ O
these -X- _ O
methods -X- _ O
with -X- _ O
a -X- _ O
transformation -X- _ O
function -X- _ O
f -X- _ O
( -X- _ O
• -X- _ O
) -X- _ O
which -X- _ O
pre -X- _ O
- -X- _ O
processes -X- _ O
the -X- _ O
input -X- _ O
x. -X- _ O
f -X- _ O
( -X- _ O
• -X- _ O
) -X- _ O
can -X- _ O
be -X- _ O
specialized -X- _ O
by -X- _ O
adding -X- _ O
demonstrations -X- _ O
( -X- _ O
Brown -X- _ O
et -X- _ O
al -X- _ O
. -X- _ O
, -X- _ O
2020 -X- _ O
) -X- _ O
, -X- _ O
discrete -X- _ O
prompt -X- _ O
tokens -X- _ O
( -X- _ O
Deng -X- _ O
et -X- _ O
al -X- _ O
. -X- _ O
, -X- _ O
2022 -X- _ O
) -X- _ O
or -X- _ O
soft -X- _ O
ones -X- _ O
( -X- _ O
Sun -X- _ O
et -X- _ O
al -X- _ O
. -X- _ O
, -X- _ O
2022a -X- _ O
, -X- _ O
b -X- _ O
) -X- _ O
. -X- _ O
Denote -X- _ O
the -X- _ O
final -X- _ O
score -X- _ O
as -X- _ O
q -X- _ O
( -X- _ O
x -X- _ O
) -X- _ O
and -X- _ O
probability -X- _ O
as -X- _ O
P -X- _ O
( -X- _ O
y|x -X- _ O
) -X- _ O
= -X- _ O
Softmax -X- _ O
( -X- _ O
q -X- _ O
( -X- _ O
x -X- _ O
) -X- _ O
) -X- _ O
, -X- _ O
these -X- _ O
methods -X- _ O
define -X- _ O
q -X- _ O
( -X- _ O
x -X- _ O
) -X- _ O
= -X- _ O
S -X- _ O
M -X- _ O
( -X- _ O
f -X- _ O
( -X- _ O
x -X- _ O
) -X- _ O
) -X- _ O
and -X- _ O
optimize -X- _ O
f -X- _ O
( -X- _ O
• -X- _ O
) -X- _ O
for -X- _ O
correct -X- _ O
predictions -X- _ O
. -X- _ O
Although -X- _ O
optimizing -X- _ O
f -X- _ O
( -X- _ O
• -X- _ O
) -X- _ O
without -X- _ O
model -X- _ O
gradients -X- _ O
is -X- _ O
possible -X- _ O
, -X- _ O
we -X- _ O
argue -X- _ O
that -X- _ O
it -X- _ O
is -X- _ O
highly -X- _ O
burdensome -X- _ O
. -X- _ O
Forwarding -X- _ O
through -X- _ O
a -X- _ O
large -X- _ O
" -X- _ O
black -X- _ O
box -X- _ O
" -X- _ O
model -X- _ O
M -X- _ O
, -X- _ O
it -X- _ O
is -X- _ O
rather -X- _ O
challenging -X- _ O
to -X- _ O
find -X- _ O
corresponding -X- _ O
inputs -X- _ O
for -X- _ O
specific -X- _ O
outputs -X- _ O
without -X- _ O
the -X- _ O
guidance -X- _ O
of -X- _ O
gradient -X- _ O
signals -X- _ O
. -X- _ O
As -X- _ O
a -X- _ O
result -X- _ O
, -X- _ O
users -X- _ O
may -X- _ O
get -X- _ O
suboptimal -X- _ O
performance -X- _ O
with -X- _ O
expensive -X- _ O
query -X- _ O
costs -X- _ O
. -X- _ O
We -X- _ O
empirically -X- _ O
validate -X- _ O
it -X- _ O
in -X- _ O
experiments -X- _ O
. -X- _ O

For -X- _ O
more -X- _ O
effective -X- _ O
and -X- _ O
efficient -X- _ O
PTM -X- _ O
adaptation -X- _ O
, -X- _ O
we -X- _ O
turn -X- _ O
to -X- _ O
output -X- _ O
- -X- _ O
side -X- _ O
adaptation -X- _ O
rather -X- _ O
than -X- _ O
inputside -X- _ O
. -X- _ O
Overall -X- _ O
, -X- _ O
output -X- _ O
- -X- _ O
side -X- _ O
adaptation -X- _ O
can -X- _ O
be -X- _ O
viewed -X- _ O
as -X- _ O
a -X- _ O
post -X- _ O
- -X- _ O
processing -X- _ O
of -X- _ O
model -X- _ O
outputs -X- _ O
which -X- _ O
uses -X- _ O
another -X- _ O
function -X- _ O
g -X- _ O
( -X- _ O
• -X- _ O
) -X- _ O
to -X- _ O
process -X- _ O
the -X- _ O
model -X- _ O
outputs -X- _ O
, -X- _ O
and -X- _ O
get -X- _ O
the -X- _ O
final -X- _ O
scores -X- _ O
q -X- _ O
( -X- _ O
x -X- _ O
) -X- _ O
= -X- _ O
g -X- _ O
( -X- _ O
S -X- _ O
M -X- _ O
( -X- _ O
T -X- _ O
( -X- _ O
x -X- _ O
) -X- _ O
) -X- _ O
) -X- _ O
. -X- _ O
Different -X- _ O
from -X- _ O
input -X- _ O
- -X- _ O
side -X- _ O
ones -X- _ O
, -X- _ O
output -X- _ O
- -X- _ O
side -X- _ O
adaptation -X- _ O
is -X- _ O
easy -X- _ O
- -X- _ O
to -X- _ O
- -X- _ O
optimize -X- _ O
with -X- _ O
gradient -X- _ O
descent -X- _ O
, -X- _ O
and -X- _ O
for -X- _ O
each -X- _ O
sample -X- _ O
, -X- _ O
we -X- _ O
only -X- _ O
need -X- _ O
to -X- _ O
query -X- _ O
the -X- _ O
PTM -X- _ O
once -X- _ O
. -X- _ O
For -X- _ O
DecT -X- _ B-MethodName
, -X- _ O
as -X- _ O
shown -X- _ O
in -X- _ O
Figure -X- _ O
2 -X- _ O
, -X- _ O
we -X- _ O
model -X- _ O
the -X- _ O
post -X- _ O
- -X- _ O
processing -X- _ O
as -X- _ O
decoding -X- _ O
, -X- _ O
which -X- _ O
refers -X- _ O
to -X- _ O
a -X- _ O
post -X- _ O
- -X- _ O
modification -X- _ O
to -X- _ O
the -X- _ O
initial -X- _ O
model -X- _ O
predictions -X- _ O
. -X- _ O
Specifically -X- _ O
, -X- _ O
we -X- _ O
first -X- _ O
query -X- _ O
the -X- _ O
PTM -X- _ O
with -X- _ O
promptenclosed -X- _ O
inputs -X- _ O
to -X- _ O
get -X- _ O
model -X- _ O
outputs -X- _ O
, -X- _ O
including -X- _ O
the -X- _ O
scores -X- _ O
for -X- _ O
each -X- _ O
class -X- _ O
and -X- _ O
hidden -X- _ O
states -X- _ O
. -X- _ O
Intuitively -X- _ O
, -X- _ O
output -X- _ O
scores -X- _ O
contain -X- _ O
prior -X- _ O
knowledge -X- _ O
inside -X- _ O
the -X- _ O
PTM -X- _ O
, -X- _ O
so -X- _ O
we -X- _ O
retain -X- _ O
them -X- _ O
as -X- _ O
part -X- _ O
of -X- _ O
the -X- _ O
final -X- _ O
scores -X- _ O
. -X- _ O
Then -X- _ O
, -X- _ O
we -X- _ O
tune -X- _ O
an -X- _ O
additional -X- _ O
decoder -X- _ O
function -X- _ O
on -X- _ O
the -X- _ O
hidden -X- _ O
states -X- _ O
to -X- _ O
fit -X- _ O
the -X- _ O
training -X- _ O
data -X- _ O
and -X- _ O
make -X- _ O
final -X- _ O
predictions -X- _ O
. -X- _ O
Next -X- _ O
, -X- _ O
we -X- _ O
describe -X- _ O
how -X- _ O
we -X- _ O
query -X- _ O
the -X- _ O
model -X- _ O
and -X- _ O
then -X- _ O
specify -X- _ O
the -X- _ O
implemen -X- _ O
- -X- _ O
tation -X- _ O
of -X- _ O
the -X- _ O
score -X- _ O
function -X- _ O
. -X- _ O

To -X- _ O
get -X- _ O
model -X- _ O
outputs -X- _ O
, -X- _ O
we -X- _ O
simply -X- _ O
follow -X- _ O
the -X- _ O
procedure -X- _ O
in -X- _ O
Section -X- _ O
2 -X- _ O
and -X- _ O
query -X- _ O
the -X- _ O
model -X- _ O
with -X- _ O
manual -X- _ O
template -X- _ O
- -X- _ O
wrapped -X- _ O
inputs -X- _ O
. -X- _ O
We -X- _ O
then -X- _ O
process -X- _ O
the -X- _ O
scores -X- _ O
by -X- _ O
calibration -X- _ O
. -X- _ O

After -X- _ O
getting -X- _ O
the -X- _ O
hidden -X- _ O
states -X- _ O
and -X- _ O
calibrated -X- _ O
scores -X- _ O
, -X- _ O
we -X- _ O
perform -X- _ O
DecT -X- _ B-MethodName
outside -X- _ O
the -X- _ O
PTM -X- _ O
to -X- _ O
modify -X- _ O
the -X- _ O
output -X- _ O
scores -X- _ O
fitting -X- _ O
the -X- _ O
training -X- _ O
data -X- _ O
. -X- _ O
Denote -X- _ O
the -X- _ O
final -X- _ O
score -X- _ O
on -X- _ O
class -X- _ O
k -X- _ O
as -X- _ O
q -X- _ O
( -X- _ O
x -X- _ O
, -X- _ O
k -X- _ O
) -X- _ O
, -X- _ O
we -X- _ O
calculate -X- _ O
it -X- _ O
by -X- _ O
the -X- _ O
following -X- _ O
function -X- _ O
: -X- _ O

On -X- _ O
prototypes -X- _ O
, -X- _ O
classical -X- _ O
approaches -X- _ O
model -X- _ O
them -X- _ O
as -X- _ O
points -X- _ O
in -X- _ O
the -X- _ O
embedding -X- _ O
space -X- _ O
, -X- _ O
which -X- _ O
overlook -X- _ O
the -X- _ O
different -X- _ O
class -X- _ O
characteristics -X- _ O
. -X- _ O
Inspired -X- _ O
by -X- _ O
Ding -X- _ O
et -X- _ O
al -X- _ O
. -X- _ O
( -X- _ O
2022a -X- _ O
) -X- _ O
, -X- _ O
we -X- _ O
model -X- _ O
prototypes -X- _ O
as -X- _ O
hyperspheres -X- _ O
with -X- _ O
an -X- _ O
additional -X- _ O
radius -X- _ O
parameter -X- _ O
. -X- _ O
Concretely -X- _ O
, -X- _ O
the -X- _ O
prototype -X- _ O
for -X- _ O
class -X- _ O
k -X- _ O
contains -X- _ O
two -X- _ O
parameters -X- _ O
, -X- _ O
center -X- _ O
position -X- _ O
vector -X- _ O
z -X- _ O
k -X- _ O
and -X- _ O
radius -X- _ O
scalar -X- _ O
r -X- _ O
k -X- _ O
. -X- _ O
We -X- _ O
randomly -X- _ O
initialize -X- _ O
z -X- _ O
k -X- _ O
and -X- _ O
initialize -X- _ O
r -X- _ O
k -X- _ O
as -X- _ O
the -X- _ O
average -X- _ O
distance -X- _ O
between -X- _ O
z -X- _ O
k -X- _ O
and -X- _ O
instances -X- _ O
in -X- _ O
class -X- _ O
k -X- _ O
: -X- _ O

Datasets -X- _ O
. -X- _ O
We -X- _ O
conduct -X- _ O
experiments -X- _ O
on -X- _ O
four -X- _ O
typical -X- _ O
natural -X- _ B-TaskName
language -X- _ I-TaskName
understanding -X- _ I-TaskName
tasks -X- _ O
. -X- _ O
For -X- _ O
sentiment -X- _ B-TaskName
analysis -X- _ I-TaskName
, -X- _ O
we -X- _ O
select -X- _ O
SST2 -X- _ B-DatasetName
( -X- _ O
Socher -X- _ O
et -X- _ O
al -X- _ O
. -X- _ O
, -X- _ O
2013 -X- _ O
) -X- _ O
, -X- _ O
Yelp -X- _ B-DatasetName
P. -X- _ I-DatasetName
( -X- _ O
Zhang -X- _ O
et -X- _ O
al -X- _ O
. -X- _ O
, -X- _ O
2015 -X- _ O
) -X- _ O
and -X- _ O
IMDB -X- _ B-DatasetName
( -X- _ O
Maas -X- _ O
et -X- _ O
al -X- _ O
. -X- _ O
, -X- _ O
2011 -X- _ O
) -X- _ O
. -X- _ O
For -X- _ O
text -X- _ B-TaskName
classification -X- _ I-TaskName
, -X- _ O
we -X- _ O
use -X- _ O
AG -X- _ B-DatasetName
's -X- _ I-DatasetName
News -X- _ I-DatasetName
, -X- _ O
Yahoo -X- _ B-DatasetName
( -X- _ O
Zhang -X- _ O
et -X- _ O
al -X- _ O
. -X- _ O
, -X- _ O
2015 -X- _ O
) -X- _ O
and -X- _ O
DBPedia -X- _ B-DatasetName
( -X- _ O
Lehmann -X- _ O
et -X- _ O
al -X- _ O
. -X- _ O
, -X- _ O
2015 -X- _ O
) -X- _ O
. -X- _ O
For -X- _ O
natural -X- _ B-TaskName
language -X- _ I-TaskName
inference -X- _ I-TaskName
( -X- _ O
NLI -X- _ B-TaskName
) -X- _ O
, -X- _ O
we -X- _ O
adopt -X- _ O
RTE -X- _ B-DatasetName
( -X- _ O
Dagan -X- _ O
et -X- _ O
al -X- _ O
. -X- _ O
, -X- _ O
2005 -X- _ O
; -X- _ O
Haim -X- _ O
et -X- _ O
al -X- _ O
. -X- _ O
, -X- _ O
2006 -X- _ O
; -X- _ O
Giampiccolo -X- _ O
et -X- _ O
al -X- _ O
. -X- _ O
, -X- _ O
2007 -X- _ O
; -X- _ O
Bentivogli -X- _ O
et -X- _ O
al -X- _ O
. -X- _ O
, -X- _ O
2009 -X- _ O
) -X- _ O
, -X- _ O
SNLI -X- _ B-DatasetName
( -X- _ O
Bowman -X- _ O
et -X- _ O
al -X- _ O
. -X- _ O
, -X- _ O
2015 -X- _ O
) -X- _ O
and -X- _ O
MNLI -X- _ B-DatasetName
( -X- _ O
Williams -X- _ O
et -X- _ O
al -X- _ O
. -X- _ O
, -X- _ O
2018 -X- _ O
) -X- _ O
. -X- _ O
For -X- _ O
entity -X- _ B-TaskName
typing -X- _ I-TaskName
, -X- _ O
we -X- _ O
experiment -X- _ O
on -X- _ O
FewNERD -X- _ B-DatasetName
( -X- _ O
Ding -X- _ O
et -X- _ O
al -X- _ O
. -X- _ O
, -X- _ O
2021b -X- _ O
) -X- _ O
. -X- _ O

From -X- _ O
the -X- _ O
results -X- _ O
, -X- _ O
we -X- _ O
have -X- _ O
these -X- _ O
observations -X- _ O
: -X- _ O
Overall -X- _ O
, -X- _ O
DecT -X- _ B-MethodName
outperforms -X- _ O
the -X- _ O
state -X- _ O
- -X- _ O
of -X- _ O
- -X- _ O
theart -X- _ O
baseline -X- _ O
methods -X- _ O
by -X- _ O
a -X- _ O
large -X- _ O
margin -X- _ O
( -X- _ O
more -X- _ O
than -X- _ O
3 -X- _ B-MetricValue
% -X- _ I-MetricValue
on -X- _ O
average -X- _ O
) -X- _ O
, -X- _ O
especially -X- _ O
under -X- _ O
extreme -X- _ O
data -X- _ O
scarcity -X- _ O
, -X- _ O
showing -X- _ O
its -X- _ O
superior -X- _ O
performance -X- _ O
. -X- _ O
Across -X- _ O
different -X- _ O
tasks -X- _ O
, -X- _ O
DecT -X- _ B-MethodName
and -X- _ O
baselines -X- _ O
obtain -X- _ O
similar -X- _ O
results -X- _ O
on -X- _ O
some -X- _ O
easy -X- _ O
sentiment -X- _ O
analysis -X- _ O
and -X- _ O
topic -X- _ O
classification -X- _ O
tasks -X- _ O
, -X- _ O
but -X- _ O
we -X- _ O
highlight -X- _ O
that -X- _ O
DecT -X- _ B-MethodName
is -X- _ O
much -X- _ O
more -X- _ O
favorable -X- _ O
on -X- _ O
difficult -X- _ O
datasets -X- _ O
, -X- _ O
such -X- _ O
as -X- _ O
Yahoo -X- _ B-DatasetName
and -X- _ O
FewNERD -X- _ B-DatasetName
. -X- _ O
While -X- _ O
other -X- _ O
baseline -X- _ O
methods -X- _ O
struggle -X- _ O
to -X- _ O
optimize -X- _ O
well -X- _ O
, -X- _ O
DecT -X- _ B-MethodName
surpasses -X- _ O
them -X- _ O
significantly -X- _ O
( -X- _ O
about -X- _ O
10 -X- _ B-MetricValue
% -X- _ I-MetricValue
on -X- _ O
Yahoo -X- _ B-DatasetName
and -X- _ O
20 -X- _ B-MetricValue
% -X- _ I-MetricValue
on -X- _ O
FewNERD -X- _ B-DatasetName
under -X- _ O
16 -X- _ O
- -X- _ O
shot -X- _ O
setting -X- _ O
compared -X- _ O
with -X- _ O
BBTv2 -X- _ B-MethodName
and -X- _ O
ICL -X- _ B-MethodName
) -X- _ O
. -X- _ O

On -X- _ O
stability -X- _ O
, -X- _ O
DecT -X- _ B-MethodName
also -X- _ O
has -X- _ O
consistently -X- _ O
low -X- _ O
variance -X- _ O
and -X- _ O
some -X- _ O
baselines -X- _ O
( -X- _ O
ICL -X- _ B-MethodName
, -X- _ O
RLPrompt -X- _ B-MethodName
and -X- _ O
PromptBoosting -X- _ B-MethodName
) -X- _ O
are -X- _ O
unstable -X- _ O
. -X- _ O
Given -X- _ O
the -X- _ O
difficulty -X- _ O
of -X- _ O
few -X- _ O
- -X- _ O
shot -X- _ O
PTM -X- _ O
adaptation -X- _ O
, -X- _ O
it -X- _ O
is -X- _ O
of -X- _ O
great -X- _ O
significance -X- _ O
that -X- _ O
the -X- _ O
adaptation -X- _ O
method -X- _ O
is -X- _ O
robust -X- _ O
to -X- _ O
random -X- _ O
seeds -X- _ O
. -X- _ O

Despite -X- _ O
the -X- _ O
superior -X- _ O
performance -X- _ O
, -X- _ O
another -X- _ O
major -X- _ O
advantage -X- _ O
of -X- _ O
DecT -X- _ B-MethodName
is -X- _ O
its -X- _ O
high -X- _ O
efficiency -X- _ O
. -X- _ O
In -X- _ O
Fig- -X- _ O
ure -X- _ O
1 -X- _ O
, -X- _ O
we -X- _ O
plot -X- _ O
average -X- _ B-MetricName
accuracy -X- _ I-MetricName
versus -X- _ O
training -X- _ B-MetricName
time -X- _ I-MetricName
for -X- _ O
each -X- _ O
method -X- _ O
under -X- _ O
different -X- _ O
shots -X- _ O
. -X- _ O
We -X- _ O
also -X- _ O
provide -X- _ O
detailed -X- _ O
statistics -X- _ O
of -X- _ O
training -X- _ B-MetricName
time -X- _ I-MetricName
, -X- _ O
query -X- _ B-MetricName
numbers -X- _ I-MetricName
, -X- _ O
and -X- _ O
parameter -X- _ B-MetricName
numbers -X- _ I-MetricName
for -X- _ O
16 -X- _ O
- -X- _ O
shot -X- _ O
experiments -X- _ O
in -X- _ O
Table -X- _ O
2 -X- _ O
. -X- _ O

From -X- _ O
Figure -X- _ O
1 -X- _ O
and -X- _ O
Table -X- _ O
2 -X- _ O
, -X- _ O
we -X- _ O
clearly -X- _ O
see -X- _ O
that -X- _ O
DecT -X- _ B-MethodName
can -X- _ O
be -X- _ O
optimized -X- _ O
quickly -X- _ O
and -X- _ O
only -X- _ O
requires -X- _ O
one -X- _ O
model -X- _ O
query -X- _ O
per -X- _ O
training -X- _ O
sample -X- _ O
, -X- _ O
which -X- _ O
is -X- _ O
about -X- _ O
200×faster -X- _ B-MetricValue
and -X- _ O
queries -X- _ O
10×fewer -X- _ B-MetricValue
than -X- _ O
all -X- _ O
prompt -X- _ O
optimization -X- _ O
methods -X- _ O
. -X- _ O
For -X- _ O
BBT -X- _ B-MethodName
, -X- _ O
BBTv2 -X- _ B-MethodName
, -X- _ O
and -X- _ O
RLPrompt -X- _ B-MethodName
, -X- _ O
users -X- _ O
have -X- _ O
to -X- _ O
query -X- _ O
the -X- _ O
model -X- _ O
near -X- _ O
10 -X- _ B-MetricValue
4 -X- _ I-MetricValue
times -X- _ O
and -X- _ O
spend -X- _ O
several -X- _ O
hours -X- _ O
for -X- _ O
sufficient -X- _ O
optimization -X- _ O
even -X- _ O
in -X- _ O
the -X- _ O
few -X- _ O
- -X- _ O
shot -X- _ O
scenario -X- _ O
. -X- _ O
When -X- _ O
the -X- _ O
inference -X- _ O
API -X- _ O
is -X- _ O
not -X- _ O
for -X- _ O
free -X- _ O
such -X- _ O
as -X- _ O
OpenAI -X- _ O
API -X- _ O
2 -X- _ O
, -X- _ O
using -X- _ O
these -X- _ O
methods -X- _ O
would -X- _ O
be -X- _ O
expensive -X- _ O
, -X- _ O
and -X- _ O
this -X- _ O
further -X- _ O
burdens -X- _ O
their -X- _ O
usage -X- _ O
in -X- _ O
the -X- _ O
scenarios -X- _ O
of -X- _ O
rich -X- _ O
data -X- _ O
and -X- _ O
large -X- _ O
models -X- _ O
. -X- _ O

( -X- _ O
1 -X- _ O
) -X- _ O
DecT -X- _ B-MethodName
continually -X- _ O
improves -X- _ O
its -X- _ O
performance -X- _ O
on -X- _ O
more -X- _ O
training -X- _ O
data -X- _ O
at -X- _ O
a -X- _ O
low -X- _ O
cost -X- _ O
. -X- _ O
The -X- _ O
average -X- _ O
accuracy -X- _ B-MetricName
gains -X- _ O
6 -X- _ B-MetricValue
% -X- _ I-MetricValue
from -X- _ O
16 -X- _ O
- -X- _ O
shot -X- _ O
to -X- _ O
256 -X- _ O
- -X- _ O
shot -X- _ O
while -X- _ O
the -X- _ O
average -X- _ O
training -X- _ B-MetricName
time -X- _ I-MetricName
is -X- _ O
less -X- _ O
than -X- _ O
100 -X- _ B-MetricValue
seconds -X- _ I-MetricValue
. -X- _ O
( -X- _ O
2 -X- _ O
) -X- _ O
Compared -X- _ O
with -X- _ O
fine -X- _ O
- -X- _ O
tuning -X- _ O
, -X- _ O
DecT -X- _ B-MethodName
is -X- _ O
even -X- _ O
on -X- _ O
par -X- _ O
with -X- _ O
it -X- _ O
in -X- _ O
the -X- _ O
64 -X- _ O
- -X- _ O
shot -X- _ O
scenario -X- _ O
and -X- _ O
gradually -X- _ O
falls -X- _ O
behind -X- _ O
in -X- _ O
the -X- _ O
256 -X- _ O
- -X- _ O
shot -X- _ O
setting -X- _ O
, -X- _ O
which -X- _ O
is -X- _ O
reasonable -X- _ O
as -X- _ O
we -X- _ O
only -X- _ O
tune -X- _ O
a -X- _ O
small -X- _ O
portion -X- _ O
of -X- _ O
parameters -X- _ O
outside -X- _ O
the -X- _ O
model -X- _ O
. -X- _ O
Through -X- _ O
further -X- _ O
task -X- _ O
- -X- _ O
level -X- _ O
observation -X- _ O
, -X- _ O
we -X- _ O
find -X- _ O
DecT -X- _ B-MethodName
still -X- _ O
performs -X- _ O
well -X- _ O
on -X- _ O
sentiment -X- _ O
analysis -X- _ O
and -X- _ O
topic -X- _ O
classification -X- _ O
, -X- _ O
but -X- _ O
can -X- _ O
not -X- _ O
catch -X- _ O
up -X- _ O
with -X- _ O
fine -X- _ O
- -X- _ O
tuning -X- _ O
on -X- _ O
NLI -X- _ B-TaskName
and -X- _ O
entity -X- _ B-TaskName
typing -X- _ I-TaskName
, -X- _ O
which -X- _ O
are -X- _ O
identified -X- _ O
as -X- _ O
harder -X- _ O
tasks -X- _ O
as -X- _ O
they -X- _ O
require -X- _ O
complex -X- _ O
reasoning -X- _ O
or -X- _ O
fine -X- _ O
- -X- _ O
grained -X- _ O
semantic -X- _ O
understanding -X- _ O
. -X- _ O
( -X- _ O
3 -X- _ O
) -X- _ O
In -X- _ O
experiments -X- _ O
, -X- _ O
we -X- _ O
find -X- _ O
fine -X- _ O
- -X- _ O
tuning -X- _ O
is -X- _ O
more -X- _ O
sensitive -X- _ O
to -X- _ O
random -X- _ O
seeds -X- _ O
in -X- _ O
the -X- _ O
few -X- _ O
- -X- _ O
shot -X- _ O
setting -X- _ O
due -X- _ O
to -X- _ O
the -X- _ O
huge -X- _ O
amount -X- _ O
of -X- _ O
trainable -X- _ O
parameters -X- _ O
and -X- _ O
relatively -X- _ O
few -X- _ O
loss -X- _ O
signals -X- _ O
, -X- _ O
which -X- _ O
is -X- _ O
evidenced -X- _ O
by -X- _ O
the -X- _ O
high -X- _ O
variance -X- _ O
in -X- _ O
the -X- _ O
64 -X- _ O
- -X- _ O
shot -X- _ O
setting -X- _ O
. -X- _ O
In -X- _ O
such -X- _ O
scenario -X- _ O
, -X- _ O
DecT -X- _ B-MethodName
has -X- _ O
lower -X- _ O
variances -X- _ O
due -X- _ O
to -X- _ O
most -X- _ O
parameters -X- _ O
are -X- _ O
frozen -X- _ O
. -X- _ O
Therefore -X- _ O
, -X- _ O
the -X- _ O
stability -X- _ O
advantage -X- _ O
of -X- _ O
DecT -X- _ B-MethodName
has -X- _ O
been -X- _ O
verified -X- _ O
again -X- _ O
. -X- _ O

To -X- _ O
conclude -X- _ O
, -X- _ O
we -X- _ O
take -X- _ O
the -X- _ O
first -X- _ O
step -X- _ O
to -X- _ O
applying -X- _ O
MaaS -X- _ O
methods -X- _ O
beyond -X- _ O
few -X- _ O
- -X- _ O
shot -X- _ O
learning -X- _ O
. -X- _ O
The -X- _ O
results -X- _ O
show -X- _ O
that -X- _ O
DecT -X- _ B-MethodName
is -X- _ O
competitive -X- _ O
against -X- _ O
fine -X- _ O
- -X- _ O
tuning -X- _ O
on -X- _ O
regular -X- _ O
classification -X- _ O
tasks -X- _ O
, -X- _ O
but -X- _ O
is -X- _ O
limited -X- _ O
on -X- _ O
difficult -X- _ O
tasks -X- _ O
. -X- _ O
How -X- _ O
to -X- _ O
adapt -X- _ O
PTMs -X- _ O
on -X- _ O
challenging -X- _ O
tasks -X- _ O
without -X- _ O
parameter -X- _ O
updates -X- _ O
still -X- _ O
needs -X- _ O
further -X- _ O
exploration -X- _ O
. -X- _ O

In -X- _ O
addition -X- _ O
to -X- _ O
main -X- _ O
experiments -X- _ O
, -X- _ O
we -X- _ O
further -X- _ O
provide -X- _ O
more -X- _ O
analytical -X- _ O
experiments -X- _ O
for -X- _ O
understanding -X- _ O
DecT. -X- _ B-MethodName
We -X- _ O
conduct -X- _ O
ablation -X- _ O
study -X- _ O
on -X- _ O
several -X- _ O
components -X- _ O
in -X- _ O
Section -X- _ O
5.1 -X- _ O
. -X- _ O
Then -X- _ O
we -X- _ O
evaluate -X- _ O
the -X- _ O
scaling -X- _ O
effect -X- _ O
( -X- _ O
Section -X- _ O
5.2 -X- _ O
) -X- _ O
, -X- _ O
the -X- _ O
impact -X- _ O
of -X- _ O
hyperparameter -X- _ O
λ -X- _ B-HyperparameterName
( -X- _ O
Section -X- _ O
5.3 -X- _ O
) -X- _ O
and -X- _ O
templates -X- _ O
( -X- _ O
Section -X- _ O
5.4 -X- _ O
) -X- _ O
respectively -X- _ O
. -X- _ O
We -X- _ O
further -X- _ O
conduct -X- _ O
transferability -X- _ O
experiments -X- _ O
in -X- _ O
Appendix -X- _ O
B -X- _ O
. -X- _ O

Although -X- _ O
DecT -X- _ B-MethodName
is -X- _ O
an -X- _ O
output -X- _ O
- -X- _ O
side -X- _ O
adaptation -X- _ O
method -X- _ O
, -X- _ O
the -X- _ O
choice -X- _ O
of -X- _ O
templates -X- _ O
also -X- _ O
affects -X- _ O
the -X- _ O
final -X- _ O
performance -X- _ O
. -X- _ O
To -X- _ O
assess -X- _ O
the -X- _ O
influence -X- _ O
of -X- _ O
templates -X- _ O
, -X- _ O
we -X- _ O
conduct -X- _ O
experiments -X- _ O
on -X- _ O
AG -X- _ B-DatasetName
's -X- _ I-DatasetName
News -X- _ I-DatasetName
and -X- _ O
SST2 -X- _ B-DatasetName
and -X- _ O
show -X- _ O
results -X- _ O
in -X- _ O
( -X- _ O
Raffel -X- _ O
et -X- _ O
al -X- _ O
. -X- _ O
, -X- _ O
2020 -X- _ O
) -X- _ O
. -X- _ O
We -X- _ O
run -X- _ O
each -X- _ O
experiment -X- _ O
over -X- _ O
5 -X- _ O
random -X- _ O
seeds -X- _ O
and -X- _ O
report -X- _ O
average -X- _ O
accuracy -X- _ B-MetricName
and -X- _ O
standard -X- _ B-MetricName
deviation -X- _ I-MetricName
( -X- _ O
% -X- _ O
) -X- _ O
. -X- _ O
mance -X- _ O
, -X- _ O
DecT -X- _ B-MethodName
largely -X- _ O
moderates -X- _ O
the -X- _ O
gaps -X- _ O
between -X- _ O
them -X- _ O
. -X- _ O
Additionally -X- _ O
, -X- _ O
we -X- _ O
try -X- _ O
two -X- _ O
templates -X- _ O
searched -X- _ O
from -X- _ O
RLPrompt -X- _ B-MethodName
( -X- _ O
Deng -X- _ O
et -X- _ O
al -X- _ O
. -X- _ O
, -X- _ O
2022 -X- _ O
) -X- _ O
and -X- _ O
they -X- _ O
both -X- _ O
achieve -X- _ O
satisfying -X- _ O
results -X- _ O
. -X- _ O
On -X- _ O
SST2 -X- _ B-DatasetName
, -X- _ O
the -X- _ O
template -X- _ O
from -X- _ O
RLPrompt -X- _ B-MethodName
is -X- _ O
even -X- _ O
better -X- _ O
than -X- _ O
manually -X- _ O
designed -X- _ O
ones -X- _ O
. -X- _ O
Therefore -X- _ O
, -X- _ O
we -X- _ O
highlight -X- _ O
that -X- _ O
DecT -X- _ B-MethodName
is -X- _ O
complementary -X- _ O
with -X- _ O
input -X- _ O
- -X- _ O
side -X- _ O
adaptation -X- _ O
algorithms -X- _ O
, -X- _ O
and -X- _ O
they -X- _ O
can -X- _ O
work -X- _ O
together -X- _ O
for -X- _ O
better -X- _ O
performance -X- _ O
. -X- _ O

Our -X- _ O
work -X- _ O
explores -X- _ O
how -X- _ O
to -X- _ O
efficiently -X- _ O
adapt -X- _ O
large -X- _ O
PTMs -X- _ O
. -X- _ O
In -X- _ O
this -X- _ O
section -X- _ O
, -X- _ O
we -X- _ O
review -X- _ O
three -X- _ O
lines -X- _ O
of -X- _ O
research -X- _ O
for -X- _ O
prompt -X- _ O
- -X- _ O
based -X- _ O
tuning -X- _ O
( -X- _ O
data -X- _ O
efficiency -X- _ O
) -X- _ O
, -X- _ O
parameter -X- _ O
- -X- _ O
efficient -X- _ O
tuning -X- _ O
( -X- _ O
parameter -X- _ O
efficiency -X- _ O
) -X- _ O
, -X- _ O
and -X- _ O
MaaS -X- _ O
adaptation -X- _ O
methods -X- _ O
respectively -X- _ O
. -X- _ O
Petroni -X- _ O
et -X- _ O
al -X- _ O
. -X- _ O
, -X- _ O
2019 -X- _ O
) -X- _ O
, -X- _ O
and -X- _ O
it -X- _ O
has -X- _ O
been -X- _ O
adopted -X- _ O
broadly -X- _ O
in -X- _ O
NLP -X- _ O
( -X- _ O
Schick -X- _ O
and -X- _ O
Schütze -X- _ O
, -X- _ O
2021 -X- _ O
; -X- _ O
Ding -X- _ O
et -X- _ O
al -X- _ O
. -X- _ O
, -X- _ O
2021a -X- _ O
; -X- _ O
Han -X- _ O
et -X- _ O
al -X- _ O
. -X- _ O
, -X- _ O
2021 -X- _ O
; -X- _ O
Cui -X- _ O
et -X- _ O
al -X- _ O
. -X- _ O
, -X- _ O
2022 -X- _ O
) -X- _ O
. -X- _ O
Despite -X- _ O
manually -X- _ O
designed -X- _ O
prompts -X- _ O
, -X- _ O
other -X- _ O
works -X- _ O
also -X- _ O
investigate -X- _ O
automatic -X- _ O
and -X- _ O
learnable -X- _ O
prompts -X- _ O
( -X- _ O
Shin -X- _ O
et -X- _ O
al -X- _ O
. -X- _ O
, -X- _ O
2020 -X- _ O
; -X- _ O
Gao -X- _ O
et -X- _ O
al -X- _ O
. -X- _ O
, -X- _ O
2021 -X- _ O
; -X- _ O
Hambardzumyan -X- _ O
et -X- _ O
al -X- _ O
. -X- _ O
, -X- _ O
2021 -X- _ O
; -X- _ O
Schick -X- _ O
et -X- _ O
al -X- _ O
. -X- _ O
, -X- _ O
2020 -X- _ O
; -X- _ O
Lester -X- _ O
et -X- _ O
al -X- _ O
. -X- _ O
, -X- _ O
2021 -X- _ O
) -X- _ O
to -X- _ O
alleviate -X- _ O
the -X- _ O
prompt -X- _ O
engineering -X- _ O
efforts -X- _ O
. -X- _ O
However -X- _ O
, -X- _ O
the -X- _ O
optimization -X- _ O
of -X- _ O
prompts -X- _ O
is -X- _ O
a -X- _ O
non -X- _ O
- -X- _ O
trivial -X- _ O
problem -X- _ O
( -X- _ O
Ding -X- _ O
et -X- _ O
al -X- _ O
. -X- _ O
, -X- _ O
2022c -X- _ O
; -X- _ O
Lester -X- _ O
et -X- _ O
al -X- _ O
. -X- _ O
, -X- _ O
2021 -X- _ O
) -X- _ O
which -X- _ O
sometimes -X- _ O
leads -X- _ O
to -X- _ O
more -X- _ O
computation -X- _ O
costs -X- _ O
and -X- _ O
suboptimal -X- _ O
performance -X- _ O
. -X- _ O
Thus -X- _ O
in -X- _ O
our -X- _ O
work -X- _ O
, -X- _ O
we -X- _ O
adopt -X- _ O
manual -X- _ O
prompts -X- _ O
to -X- _ O
stimulate -X- _ O
model -X- _ O
knowledge -X- _ O
and -X- _ O
help -X- _ O
data -X- _ O
- -X- _ O
efficient -X- _ O
model -X- _ O
adaptation -X- _ O
. -X- _ O

DecT -X- _ B-MethodName
explores -X- _ O
how -X- _ O
to -X- _ O
adapt -X- _ O
black -X- _ O
- -X- _ O
box -X- _ O
PTMs -X- _ O
on -X- _ O
downstream -X- _ O
tasks -X- _ O
. -X- _ O
As -X- _ O
we -X- _ O
show -X- _ O
in -X- _ O
Section -X- _ O
4.4 -X- _ O
, -X- _ O
our -X- _ O
method -X- _ O
is -X- _ O
not -X- _ O
comparable -X- _ O
to -X- _ O
fine -X- _ O
- -X- _ O
tuning -X- _ O
on -X- _ O
hard -X- _ O
tasks -X- _ O
with -X- _ O
increased -X- _ O
data -X- _ O
points -X- _ O
. -X- _ O
Moreover -X- _ O
, -X- _ O
we -X- _ O
only -X- _ O
focus -X- _ O
on -X- _ O
classification -X- _ B-TaskName
tasks -X- _ O
in -X- _ O
this -X- _ O
work -X- _ O
and -X- _ O
do -X- _ O
not -X- _ O
testify -X- _ O
DecT -X- _ B-MethodName
on -X- _ O
free -X- _ O
- -X- _ O
form -X- _ O
generation -X- _ B-TaskName
tasks -X- _ O
. -X- _ O

Capturing -X- _ B-TaskName
emotions -X- _ I-TaskName
within -X- _ I-TaskName
a -X- _ I-TaskName
conversation -X- _ I-TaskName
plays -X- _ O
an -X- _ O
essential -X- _ O
role -X- _ O
in -X- _ O
modern -X- _ O
dialogue -X- _ O
systems -X- _ O
. -X- _ O
However -X- _ O
, -X- _ O
the -X- _ O
weak -X- _ O
correlation -X- _ O
between -X- _ O
emotions -X- _ O
and -X- _ O
semantics -X- _ O
brings -X- _ O
many -X- _ O
challenges -X- _ O
to -X- _ O
emotion -X- _ B-TaskName
recognition -X- _ I-TaskName
in -X- _ I-TaskName
conversation -X- _ I-TaskName
( -X- _ O
ERC -X- _ B-TaskName
) -X- _ O
. -X- _ O
Even -X- _ O
semantically -X- _ O
similar -X- _ O
utterances -X- _ O
, -X- _ O
the -X- _ O
emotion -X- _ O
may -X- _ O
vary -X- _ O
drastically -X- _ O
depending -X- _ O
on -X- _ O
contexts -X- _ O
or -X- _ O
speakers -X- _ O
. -X- _ O
In -X- _ O
this -X- _ O
paper -X- _ O
, -X- _ O
we -X- _ O
propose -X- _ O
a -X- _ O
Supervised -X- _ B-MethodName
Prototypical -X- _ I-MethodName
Contrastive -X- _ I-MethodName
Learning -X- _ I-MethodName
( -X- _ O
SPCL -X- _ B-MethodName
) -X- _ O
loss -X- _ O
for -X- _ O
the -X- _ O
ERC -X- _ B-TaskName
task -X- _ O
. -X- _ O
Leveraging -X- _ O
the -X- _ O
Prototypical -X- _ O
Network -X- _ O
, -X- _ O
the -X- _ O
SPCL -X- _ B-MethodName
targets -X- _ O
at -X- _ O
solving -X- _ O
the -X- _ O
imbalanced -X- _ O
classification -X- _ O
problem -X- _ O
through -X- _ O
contrastive -X- _ O
learning -X- _ O
and -X- _ O
does -X- _ O
not -X- _ O
require -X- _ O
a -X- _ O
large -X- _ O
batch -X- _ O
size -X- _ O
. -X- _ O
Meanwhile -X- _ O
, -X- _ O
we -X- _ O
design -X- _ O
a -X- _ O
difficulty -X- _ O
measure -X- _ O
function -X- _ O
based -X- _ O
on -X- _ O
the -X- _ O
distance -X- _ O
between -X- _ O
classes -X- _ O
and -X- _ O
introduce -X- _ O
curriculum -X- _ O
learning -X- _ O
to -X- _ O
alleviate -X- _ O
the -X- _ O
impact -X- _ O
of -X- _ O
extreme -X- _ O
samples -X- _ O
. -X- _ O
We -X- _ O
achieve -X- _ O
state -X- _ O
- -X- _ O
of -X- _ O
- -X- _ O
the -X- _ O
- -X- _ O
art -X- _ O
results -X- _ O
on -X- _ O
three -X- _ O
widely -X- _ O
used -X- _ O
benchmarks -X- _ O
. -X- _ O
Further -X- _ O
, -X- _ O
we -X- _ O
conduct -X- _ O
analytical -X- _ O
experiments -X- _ O
to -X- _ O
demonstrate -X- _ O
the -X- _ O
effectiveness -X- _ O
of -X- _ O
our -X- _ O
proposed -X- _ O
SPCL -X- _ B-MethodName
and -X- _ O
curriculum -X- _ O
learning -X- _ O
strategy -X- _ O
. -X- _ O
We -X- _ O
release -X- _ O
the -X- _ O
code -X- _ O
at -X- _ O
https -X- _ O
: -X- _ O
/ -X- _ O
/ -X- _ O
github.com -X- _ O
/ -X- _ O
caskcsg -X- _ O
/ -X- _ O
SPCL -X- _ O
. -X- _ O

With -X- _ O
the -X- _ O
development -X- _ O
of -X- _ O
online -X- _ O
social -X- _ O
networks -X- _ O
, -X- _ O
capturing -X- _ B-TaskName
emotions -X- _ I-TaskName
during -X- _ I-TaskName
conversations -X- _ I-TaskName
has -X- _ O
gained -X- _ O
increasing -X- _ O
attention -X- _ O
in -X- _ O
both -X- _ O
academia -X- _ O
and -X- _ O
industry -X- _ O
( -X- _ O
Li -X- _ O
et -X- _ O
al -X- _ O
. -X- _ O
, -X- _ O
2020 -X- _ O
; -X- _ O
Ghosal -X- _ O
et -X- _ O
al -X- _ O
. -X- _ O
, -X- _ O
2020 -X- _ O
; -X- _ O
Song -X- _ O
et -X- _ O
al -X- _ O
. -X- _ O
, -X- _ O
2022 -X- _ O
; -X- _ O
Zhu -X- _ O
et -X- _ O
al -X- _ O
. -X- _ O
, -X- _ O
2021 -X- _ O
) -X- _ O
. -X- _ O
Emotion -X- _ B-TaskName
recognition -X- _ I-TaskName
in -X- _ I-TaskName
conversation -X- _ I-TaskName
( -X- _ O
ERC -X- _ B-TaskName
) -X- _ O
is -X- _ O
critical -X- _ O
in -X- _ O
many -X- _ O
scenarios -X- _ O
, -X- _ O
such -X- _ O
as -X- _ O
chatbots -X- _ O
, -X- _ O
healthcare -X- _ O
applications -X- _ O
, -X- _ O
mining -X- _ O
opinions -X- _ O
on -X- _ O
social -X- _ O
media -X- _ O
, -X- _ O
and -X- _ O
so -X- _ O
on -X- _ O
( -X- _ O
Poria -X- _ O
et -X- _ O
al -X- _ O
. -X- _ O
, -X- _ O
2019b -X- _ O
) -X- _ O
. -X- _ O
The -X- _ O
ERC -X- _ B-TaskName
task -X- _ O
aims -X- _ O
to -X- _ O
identify -X- _ O
different -X- _ O
emotions -X- _ O
at -X- _ O
each -X- _ O
turn -X- _ O
within -X- _ O
a -X- _ O
conversation -X- _ O
based -X- _ O
on -X- _ O
the -X- _ O
transcript -X- _ O
. -X- _ O
A -X- _ O
conversation -X- _ O
often -X- _ O
contains -X- _ O
several -X- _ O
speakers -X- _ O
and -X- _ O
runs -X- _ O
several -X- _ O
turns -X- _ O
; -X- _ O
thus -X- _ O
, -X- _ O
emotions -X- _ O
can -X- _ O
vary -X- _ O
drastically -X- _ O
during -X- _ O
the -X- _ O
conversation -X- _ O
. -X- _ O
Compared -X- _ O
to -X- _ O
traditional -X- _ O
text -X- _ O
classification -X- _ O
tasks -X- _ O
, -X- _ O
figuring -X- _ O
out -X- _ O
⋆ -X- _ O
Work -X- _ O
done -X- _ O
during -X- _ O
internship -X- _ O
at -X- _ O
Alibaba -X- _ O
Group -X- _ O
. -X- _ O

Contrastive -X- _ O
learning -X- _ O
applied -X- _ O
to -X- _ O
self -X- _ O
- -X- _ O
supervised -X- _ O
representation -X- _ O
learning -X- _ O
has -X- _ O
seen -X- _ O
a -X- _ O
resurgence -X- _ O
in -X- _ O
recent -X- _ O
years -X- _ O
. -X- _ O
Khosla -X- _ O
et -X- _ O
al -X- _ O
. -X- _ O
( -X- _ O
2020 -X- _ O
) -X- _ O
extended -X- _ O
the -X- _ O
self -X- _ O
- -X- _ O
supervised -X- _ O
batch -X- _ O
contrastive -X- _ O
approach -X- _ O
to -X- _ O
the -X- _ O
fully -X- _ O
- -X- _ O
supervised -X- _ O
setting -X- _ O
and -X- _ O
show -X- _ O
outperformance -X- _ O
over -X- _ O
cross -X- _ O
- -X- _ O
entropy -X- _ O
loss -X- _ O
in -X- _ O
several -X- _ O
benchmarks -X- _ O
. -X- _ O
Although -X- _ O
CoG -X- _ B-MethodName
- -X- _ I-MethodName
BART -X- _ I-MethodName
( -X- _ O
Li -X- _ O
et -X- _ O
al -X- _ O
. -X- _ O
, -X- _ O
2021 -X- _ O
) -X- _ O
has -X- _ O
demonstrated -X- _ O
the -X- _ O
effectiveness -X- _ O
of -X- _ O
supervised -X- _ O
contrastive -X- _ O
learning -X- _ O
( -X- _ O
SCL -X- _ O
) -X- _ O
in -X- _ O
the -X- _ O
ERC -X- _ B-TaskName
task -X- _ O
, -X- _ O
there -X- _ O
are -X- _ O
still -X- _ O
two -X- _ O
issues -X- _ O
worth -X- _ O
to -X- _ O
solve -X- _ O
when -X- _ O
building -X- _ O
an -X- _ O
ERC -X- _ B-TaskName
model -X- _ O
with -X- _ O
SCL -X- _ O
: -X- _ O
( -X- _ O
1 -X- _ O
) -X- _ O
As -X- _ O
illustrated -X- _ O
in -X- _ O
Figure -X- _ O
2 -X- _ O
, -X- _ O
existing -X- _ O
ERC -X- _ B-TaskName
datasets -X- _ O
are -X- _ O
often -X- _ O
class -X- _ O
- -X- _ O
imbalanced -X- _ O
and -X- _ O
samples -X- _ O
may -X- _ O
not -X- _ O
be -X- _ O
able -X- _ O
to -X- _ O
meet -X- _ O
appropriate -X- _ O
positive -X- _ O
/ -X- _ O
negative -X- _ O
samples -X- _ O
within -X- _ O
a -X- _ O
mini -X- _ O
- -X- _ O
batch -X- _ O
. -X- _ O
( -X- _ O
2 -X- _ O
) -X- _ O
Existing -X- _ O
ERC -X- _ B-TaskName
datasets -X- _ O
are -X- _ O
usually -X- _ O
collected -X- _ O
in -X- _ O
a -X- _ O
multi -X- _ O
- -X- _ O
modal -X- _ O
manner -X- _ O
. -X- _ O
There -X- _ O
are -X- _ O
some -X- _ O
conversations -X- _ O
whose -X- _ O
textual -X- _ O
information -X- _ O
is -X- _ O
insufficient -X- _ O
to -X- _ O
distinguish -X- _ O
emotions -X- _ O
. -X- _ O
Training -X- _ O
a -X- _ O
textual -X- _ O
ERC -X- _ B-TaskName
model -X- _ O
with -X- _ O
those -X- _ O
extreme -X- _ O
samples -X- _ O
may -X- _ O
lead -X- _ O
to -X- _ O
performance -X- _ O
degradation -X- _ O
. -X- _ O

For -X- _ O
the -X- _ O
first -X- _ O
issue -X- _ O
, -X- _ O
we -X- _ O
propose -X- _ O
a -X- _ O
Supervised -X- _ B-MethodName
Prototypical -X- _ I-MethodName
Contrastive -X- _ I-MethodName
Learning -X- _ I-MethodName
( -X- _ O
SPCL -X- _ B-MethodName
) -X- _ O
loss -X- _ O
, -X- _ O
which -X- _ O
integrates -X- _ O
Prototypical -X- _ O
Network -X- _ O
( -X- _ O
Snell -X- _ O
et -X- _ O
al -X- _ O
. -X- _ O
, -X- _ O
2017 -X- _ O
) -X- _ O
and -X- _ O
supervised -X- _ O
contrastive -X- _ O
learning -X- _ O
. -X- _ O
SPCL -X- _ B-MethodName
maintains -X- _ O
a -X- _ O
representation -X- _ O
queue -X- _ O
for -X- _ O
each -X- _ O
category -X- _ O
. -X- _ O
At -X- _ O
each -X- _ O
training -X- _ O
step -X- _ O
, -X- _ O
SPCL -X- _ B-MethodName
samples -X- _ O
a -X- _ O
certain -X- _ O
number -X- _ O
of -X- _ O
representations -X- _ O
from -X- _ O
these -X- _ O
queues -X- _ O
as -X- _ O
the -X- _ O
support -X- _ O
set -X- _ O
and -X- _ O
calculates -X- _ O
a -X- _ O
temporary -X- _ O
prototype -X- _ O
vector -X- _ O
for -X- _ O
each -X- _ O
emotion -X- _ O
category -X- _ O
. -X- _ O
These -X- _ O
prototype -X- _ O
vectors -X- _ O
are -X- _ O
used -X- _ O
as -X- _ O
samples -X- _ O
of -X- _ O
the -X- _ O
corresponding -X- _ O
class -X- _ O
to -X- _ O
compute -X- _ O
the -X- _ O
loss -X- _ O
. -X- _ O
SPCL -X- _ B-MethodName
ensures -X- _ O
that -X- _ O
each -X- _ O
sample -X- _ O
has -X- _ O
at -X- _ O
least -X- _ O
one -X- _ O
positive -X- _ O
sample -X- _ O
of -X- _ O
the -X- _ O
same -X- _ O
category -X- _ O
and -X- _ O
negative -X- _ O
samples -X- _ O
of -X- _ O
all -X- _ O
other -X- _ O
categories -X- _ O
within -X- _ O
a -X- _ O
mini -X- _ O
- -X- _ O
batch -X- _ O
. -X- _ O
Experiments -X- _ O
show -X- _ O
that -X- _ O
SPCL -X- _ B-MethodName
can -X- _ O
work -X- _ O
well -X- _ O
in -X- _ O
class -X- _ O
- -X- _ O
imbalanced -X- _ O
scenarios -X- _ O
and -X- _ O
is -X- _ O
less -X- _ O
sensitive -X- _ O
to -X- _ O
the -X- _ O
training -X- _ B-HyperparameterName
batch -X- _ I-HyperparameterName
size -X- _ I-HyperparameterName
. -X- _ O

• -X- _ O
We -X- _ O
propose -X- _ O
a -X- _ O
Supervised -X- _ B-MethodName
Prototypical -X- _ I-MethodName
Contrastive -X- _ I-MethodName
Learning -X- _ I-MethodName
( -X- _ O
SPCL -X- _ B-MethodName
) -X- _ O
loss -X- _ O
for -X- _ O
the -X- _ O
ERC -X- _ B-TaskName
task -X- _ O
, -X- _ O
which -X- _ O
can -X- _ O
perform -X- _ O
supervised -X- _ O
contrastive -X- _ O
learning -X- _ O
efficiently -X- _ O
on -X- _ O
classimbalanced -X- _ O
data -X- _ O
and -X- _ O
has -X- _ O
no -X- _ O
need -X- _ O
for -X- _ O
large -X- _ O
batch -X- _ B-HyperparameterName
size -X- _ I-HyperparameterName
. -X- _ O

• -X- _ O
To -X- _ O
the -X- _ O
best -X- _ O
of -X- _ O
our -X- _ O
knowledge -X- _ O
, -X- _ O
we -X- _ O
are -X- _ O
the -X- _ O
first -X- _ O
to -X- _ O
combine -X- _ O
supervised -X- _ O
contrastive -X- _ O
learning -X- _ O
and -X- _ O
curriculum -X- _ O
learning -X- _ O
for -X- _ O
the -X- _ O
ERC -X- _ B-TaskName
task -X- _ O
. -X- _ O

• -X- _ O
We -X- _ O
achieve -X- _ O
state -X- _ O
- -X- _ O
of -X- _ O
- -X- _ O
the -X- _ O
- -X- _ O
art -X- _ O
results -X- _ O
on -X- _ O
three -X- _ O
widely -X- _ O
used -X- _ O
benchmarks -X- _ O
. -X- _ O
Experimental -X- _ O
results -X- _ O
further -X- _ O
demonstrate -X- _ O
the -X- _ O
effectiveness -X- _ O
of -X- _ O
our -X- _ O
proposed -X- _ O
SPCL -X- _ B-MethodName
loss -X- _ O
and -X- _ O
curriculum -X- _ O
learning -X- _ O
strategy -X- _ O
. -X- _ O

Most -X- _ O
existing -X- _ O
approaches -X- _ O
focus -X- _ O
on -X- _ O
context -X- _ O
modeling -X- _ O
. -X- _ O
They -X- _ O
can -X- _ O
be -X- _ O
divided -X- _ O
into -X- _ O
sequence -X- _ O
- -X- _ O
based -X- _ O
, -X- _ O
graph -X- _ O
- -X- _ O
based -X- _ O
, -X- _ O
and -X- _ O
knowledge -X- _ O
- -X- _ O
enhanced -X- _ O
methods -X- _ O
. -X- _ O
Sequence -X- _ O
- -X- _ O
based -X- _ O
methods -X- _ O
consider -X- _ O
contextual -X- _ O
information -X- _ O
as -X- _ O
utterance -X- _ O
sequences -X- _ O
. -X- _ O
ICON -X- _ B-MethodName
( -X- _ O
Hazarika -X- _ O
et -X- _ O
al -X- _ O
. -X- _ O
, -X- _ O
2018 -X- _ O
) -X- _ O
and -X- _ O
HiGRU -X- _ B-MethodName
( -X- _ O
Jiao -X- _ O
et -X- _ O
al -X- _ O
. -X- _ O
, -X- _ O
2019 -X- _ O
) -X- _ O
both -X- _ O
use -X- _ O
the -X- _ O
gated -X- _ O
recurrent -X- _ O
unit -X- _ O
to -X- _ O
capture -X- _ O
the -X- _ O
context -X- _ O
information -X- _ O
. -X- _ O
DialogRNN -X- _ B-MethodName
( -X- _ O
Majumder -X- _ O
et -X- _ O
al -X- _ O
. -X- _ O
, -X- _ O
2019 -X- _ O
) -X- _ O
is -X- _ O
a -X- _ O
recurrence -X- _ O
- -X- _ O
based -X- _ O
method -X- _ O
that -X- _ O
models -X- _ O
dialog -X- _ O
dynamics -X- _ O
with -X- _ O
several -X- _ O
RNNs -X- _ O
. -X- _ O
Dia -X- _ B-MethodName
- -X- _ I-MethodName
logueCRN -X- _ I-MethodName
( -X- _ O
Hu -X- _ O
et -X- _ O
al -X- _ O
. -X- _ O
, -X- _ O
2021 -X- _ O
) -X- _ O
introduces -X- _ O
multi -X- _ O
- -X- _ O
turn -X- _ O
reasoning -X- _ O
modules -X- _ O
to -X- _ O
model -X- _ O
the -X- _ O
ERC -X- _ B-TaskName
task -X- _ O
from -X- _ O
a -X- _ O
cognitive -X- _ O
perspective -X- _ O
. -X- _ O
CoMPM -X- _ B-MethodName
models -X- _ O
the -X- _ O
context -X- _ O
and -X- _ O
speaker -X- _ O
's -X- _ O
memory -X- _ O
via -X- _ O
pretrained -X- _ O
language -X- _ O
models -X- _ O
. -X- _ O
For -X- _ O
those -X- _ O
graph -X- _ O
- -X- _ O
based -X- _ O
methods -X- _ O
, -X- _ O
DialogGCN -X- _ B-MethodName
( -X- _ O
Hu -X- _ O
et -X- _ O
al -X- _ O
. -X- _ O
, -X- _ O
2021 -X- _ O
) -X- _ O
and -X- _ O
RGAT -X- _ B-MethodName
( -X- _ O
Ishiwatari -X- _ O
et -X- _ O
al -X- _ O
. -X- _ O
, -X- _ O
2020 -X- _ O
) -X- _ O
build -X- _ O
a -X- _ O
graph -X- _ O
upon -X- _ O
the -X- _ O
utterances -X- _ O
nodes -X- _ O
. -X- _ O
ConGCN -X- _ B-MethodName
( -X- _ O
Zhang -X- _ O
et -X- _ O
al -X- _ O
. -X- _ O
, -X- _ O
2019 -X- _ O
) -X- _ O
trades -X- _ O
both -X- _ O
speakers -X- _ O
and -X- _ O
utterances -X- _ O
as -X- _ O
nodes -X- _ O
and -X- _ O
builds -X- _ O
a -X- _ O
single -X- _ O
graph -X- _ O
upon -X- _ O
the -X- _ O
whole -X- _ O
ERC -X- _ B-TaskName
dataset -X- _ O
. -X- _ O
DAG -X- _ B-MethodName
- -X- _ I-MethodName
ERC -X- _ I-MethodName
uses -X- _ O
a -X- _ O
directed -X- _ O
acyclic -X- _ O
graph -X- _ O
( -X- _ O
DAG -X- _ O
) -X- _ O
to -X- _ O
model -X- _ O
the -X- _ O
intrinsic -X- _ O
structure -X- _ O
within -X- _ O
a -X- _ O
conversation -X- _ O
. -X- _ O
Knowledgeenhanced -X- _ O
methods -X- _ O
( -X- _ O
Zhong -X- _ O
et -X- _ O
al -X- _ O
. -X- _ O
, -X- _ O
2019 -X- _ O
; -X- _ O
Zhu -X- _ O
et -X- _ O
al -X- _ O
. -X- _ O
, -X- _ O
2021 -X- _ O
; -X- _ O
Ghosal -X- _ O
et -X- _ O
al -X- _ O
. -X- _ O
, -X- _ O
2020 -X- _ O
; -X- _ O
usually -X- _ O
utilize -X- _ O
external -X- _ O
knowledge -X- _ O
from -X- _ O
ATIMOC -X- _ O
( -X- _ O
Sap -X- _ O
et -X- _ O
al -X- _ O
. -X- _ O
, -X- _ O
2019 -X- _ O
) -X- _ O
or -X- _ O
ConceptNet -X- _ O
( -X- _ O
Liu -X- _ O
and -X- _ O
Singh -X- _ O
, -X- _ O
2004 -X- _ O
) -X- _ O
. -X- _ O
Besides -X- _ O
individual -X- _ O
models -X- _ O
, -X- _ O
several -X- _ O
frameworks -X- _ O
have -X- _ O
also -X- _ O
been -X- _ O
proposed -X- _ O
. -X- _ O
developed -X- _ O
an -X- _ O
ERC -X- _ B-TaskName
- -X- _ O
oriented -X- _ O
hybrid -X- _ O
curriculum -X- _ O
learn -X- _ O
- -X- _ O
ing -X- _ O
framework -X- _ O
and -X- _ O
Bao -X- _ O
et -X- _ O
al -X- _ O
. -X- _ O
( -X- _ O
2022 -X- _ O
) -X- _ O
proposed -X- _ O
a -X- _ O
speaker -X- _ O
- -X- _ O
guided -X- _ O
encoder -X- _ O
- -X- _ O
decoder -X- _ O
framework -X- _ O
, -X- _ O
formulating -X- _ O
the -X- _ O
modeling -X- _ O
of -X- _ O
speaker -X- _ O
interactions -X- _ O
as -X- _ O
a -X- _ O
flexible -X- _ O
component -X- _ O
. -X- _ O

In -X- _ O
the -X- _ O
field -X- _ O
of -X- _ O
natural -X- _ O
language -X- _ O
processing -X- _ O
, -X- _ O
Sim -X- _ O
- -X- _ O
CSE -X- _ O
( -X- _ O
Gao -X- _ O
et -X- _ O
al -X- _ O
. -X- _ O
, -X- _ O
2021 -X- _ O
) -X- _ O
is -X- _ O
a -X- _ O
state -X- _ O
- -X- _ O
of -X- _ O
- -X- _ O
the -X- _ O
- -X- _ O
art -X- _ O
contrastive -X- _ O
learning -X- _ O
framework -X- _ O
for -X- _ O
generating -X- _ O
sentence -X- _ O
embeddings -X- _ O
, -X- _ O
it -X- _ O
can -X- _ O
learn -X- _ O
from -X- _ O
unlabeled -X- _ O
sentences -X- _ O
or -X- _ O
annotated -X- _ O
pairs -X- _ O
from -X- _ O
natural -X- _ O
language -X- _ O
inference -X- _ O
datasets -X- _ O
. -X- _ O
Khosla -X- _ O
et -X- _ O
al -X- _ O
. -X- _ O
( -X- _ O
2020 -X- _ O
) -X- _ O
extend -X- _ O
the -X- _ O
self -X- _ O
- -X- _ O
supervised -X- _ O
batch -X- _ O
contrastive -X- _ O
approach -X- _ O
to -X- _ O
the -X- _ O
fully -X- _ O
- -X- _ O
supervised -X- _ O
setting -X- _ O
to -X- _ O
make -X- _ O
full -X- _ O
use -X- _ O
of -X- _ O
label -X- _ O
information -X- _ O
. -X- _ O
Yeh -X- _ O
et -X- _ O
al -X- _ O
. -X- _ O
( -X- _ O
2021 -X- _ O
) -X- _ O
let -X- _ O
the -X- _ O
contrastive -X- _ O
learning -X- _ O
get -X- _ O
rid -X- _ O
of -X- _ O
the -X- _ O
dependence -X- _ O
on -X- _ O
large -X- _ O
batch -X- _ O
size -X- _ O
. -X- _ O
CoG -X- _ B-MethodName
- -X- _ I-MethodName
BART -X- _ I-MethodName
( -X- _ O
Li -X- _ O
et -X- _ O
al -X- _ O
. -X- _ O
, -X- _ O
2021 -X- _ O
) -X- _ O
adapts -X- _ O
supervised -X- _ O
contrastive -X- _ O
learning -X- _ O
to -X- _ O
make -X- _ O
different -X- _ O
emotions -X- _ O
mutually -X- _ O
exclusive -X- _ O
to -X- _ O
identify -X- _ O
similar -X- _ O
emotions -X- _ O
better -X- _ O
. -X- _ O

, -X- _ O
where -X- _ O
s -X- _ O
i -X- _ O
∈ -X- _ O
S -X- _ O
is -X- _ O
the -X- _ O
speaker -X- _ O
and -X- _ O
u -X- _ O
i -X- _ O
is -X- _ O
the -X- _ O
utterance -X- _ O
of -X- _ O
i -X- _ O
- -X- _ O
th -X- _ O
turn -X- _ O
. -X- _ O

In -X- _ O
this -X- _ O
paper -X- _ O
, -X- _ O
we -X- _ O
focus -X- _ O
on -X- _ O
the -X- _ O
real -X- _ O
- -X- _ O
time -X- _ O
settings -X- _ O
of -X- _ O
ERC -X- _ B-TaskName
, -X- _ O
in -X- _ O
which -X- _ O
model -X- _ O
can -X- _ O
only -X- _ O
take -X- _ O
previous -X- _ O
turns -X- _ O
[ -X- _ O
( -X- _ O
s -X- _ O
1 -X- _ O
, -X- _ O
u -X- _ O
1 -X- _ O
) -X- _ O
, -X- _ O
( -X- _ O
s -X- _ O
2 -X- _ O
, -X- _ O
u -X- _ O
2 -X- _ O
) -X- _ O
, -X- _ O
• -X- _ O
• -X- _ O
• -X- _ O
, -X- _ O
( -X- _ O
s -X- _ O
t -X- _ O
, -X- _ O
u -X- _ O
t -X- _ O
) -X- _ O
] -X- _ O
as -X- _ O
input -X- _ O
to -X- _ O
predict -X- _ O
the -X- _ O
emotion -X- _ O
label -X- _ O
y -X- _ O
t -X- _ O
of -X- _ O
t -X- _ O
- -X- _ O
th -X- _ O
turn -X- _ O
. -X- _ O

The -X- _ O
vanilla -X- _ O
supervised -X- _ O
contrastive -X- _ O
learning -X- _ O
computes -X- _ O
the -X- _ O
loss -X- _ O
L -X- _ O
sup -X- _ O
i -X- _ O
for -X- _ O
z -X- _ O
i -X- _ O
as -X- _ O
follows -X- _ O
, -X- _ O

The -X- _ O
object -X- _ O
function -X- _ O
L -X- _ O
sup -X- _ O
introduces -X- _ O
contrastive -X- _ O
learning -X- _ O
into -X- _ O
supervised -X- _ O
learning -X- _ O
scenarios -X- _ O
but -X- _ O
suffers -X- _ O
from -X- _ O
class -X- _ O
- -X- _ O
imbalanced -X- _ O
problem -X- _ O
. -X- _ O
Due -X- _ O
to -X- _ O
the -X- _ O
limitations -X- _ O
of -X- _ O
batch -X- _ B-HyperparameterName
size -X- _ I-HyperparameterName
, -X- _ O
samples -X- _ O
from -X- _ O
the -X- _ O
majority -X- _ O
class -X- _ O
( -X- _ O
e.g. -X- _ O
, -X- _ O
neutral -X- _ O
emotion -X- _ O
) -X- _ O
of -X- _ O
the -X- _ O
dataset -X- _ O
may -X- _ O
see -X- _ O
insufficient -X- _ O
negative -X- _ O
samples -X- _ O
within -X- _ O
a -X- _ O
batch -X- _ O
. -X- _ O
At -X- _ O
the -X- _ O
same -X- _ O
time -X- _ O
, -X- _ O
it -X- _ O
is -X- _ O
hard -X- _ O
for -X- _ O
samples -X- _ O
from -X- _ O
the -X- _ O
minority -X- _ O
class -X- _ O
to -X- _ O
meet -X- _ O
positive -X- _ O
samples -X- _ O
. -X- _ O

Existing -X- _ O
ERC -X- _ B-TaskName
datasets -X- _ O
are -X- _ O
usually -X- _ O
collected -X- _ O
in -X- _ O
a -X- _ O
multi -X- _ O
- -X- _ O
modal -X- _ O
fashion -X- _ O
. -X- _ O
When -X- _ O
building -X- _ O
a -X- _ O
text -X- _ O
- -X- _ O
only -X- _ O
ERC -X- _ B-TaskName
model -X- _ O
, -X- _ O
some -X- _ O
utterances -X- _ O
are -X- _ O
not -X- _ O
informative -X- _ O
enough -X- _ O
to -X- _ O
judge -X- _ O
the -X- _ O
emotions -X- _ O
. -X- _ O
Training -X- _ O
the -X- _ O
model -X- _ O
with -X- _ O
these -X- _ O
extreme -X- _ O
samples -X- _ O
will -X- _ O
lead -X- _ O
to -X- _ O
performance -X- _ O
degradation -X- _ O
. -X- _ O
In -X- _ O
this -X- _ O
paper -X- _ O
, -X- _ O
we -X- _ O
try -X- _ O
to -X- _ O
use -X- _ O
curriculum -X- _ O
learning -X- _ O
to -X- _ O
alleviate -X- _ O
this -X- _ O
issue -X- _ O
. -X- _ O

• -X- _ O
The -X- _ O
closer -X- _ O
the -X- _ O
sample -X- _ O
is -X- _ O
to -X- _ O
the -X- _ O
category -X- _ O
center -X- _ O
, -X- _ O
the -X- _ O
lower -X- _ O
the -X- _ O
difficulty -X- _ O
. -X- _ O

• -X- _ O
For -X- _ O
two -X- _ O
samples -X- _ O
with -X- _ O
the -X- _ O
same -X- _ O
distance -X- _ O
from -X- _ O
the -X- _ O
center -X- _ O
within -X- _ O
the -X- _ O
category -X- _ O
, -X- _ O
the -X- _ O
further -X- _ O
away -X- _ O
from -X- _ O
the -X- _ O
center -X- _ O
of -X- _ O
other -X- _ O
categories -X- _ O
, -X- _ O
the -X- _ O
lower -X- _ O
the -X- _ O
difficulty -X- _ O
. -X- _ O

Experimental -X- _ O
Setup -X- _ O

The -X- _ O
code -X- _ O
framework -X- _ O
and -X- _ O
initial -X- _ O
weight -X- _ O
of -X- _ O
Sim -X- _ O
- -X- _ O
CSE -X- _ O
come -X- _ O
from -X- _ O
Huggingface -X- _ O
's -X- _ O
Transformers -X- _ O
( -X- _ O
Wolf -X- _ O
et -X- _ O
al -X- _ O
. -X- _ O
, -X- _ O
2020 -X- _ O
) -X- _ O
. -X- _ O
We -X- _ O
use -X- _ O
the -X- _ O
AdamW -X- _ O
optimizer -X- _ O
and -X- _ O
cosine -X- _ O
learning -X- _ O
rate -X- _ O
schedule -X- _ O
strategy -X- _ O
. -X- _ O
When -X- _ O
constructing -X- _ O
training -X- _ O
samples -X- _ O
, -X- _ O
we -X- _ O
restrict -X- _ O
their -X- _ O
length -X- _ B-HyperparameterName
to -X- _ O
less -X- _ O
than -X- _ O
256 -X- _ B-MetricValue
. -X- _ O
We -X- _ O
search -X- _ O
the -X- _ O
hyper -X- _ O
- -X- _ O
parameters -X- _ O
on -X- _ O
the -X- _ O
develop -X- _ O
set -X- _ O
. -X- _ O
For -X- _ O
all -X- _ O
experiments -X- _ O
in -X- _ O
this -X- _ O
paper -X- _ O
, -X- _ O
we -X- _ O
keep -X- _ O
the -X- _ O
best -X- _ O
checkpoint -X- _ O
on -X- _ O
the -X- _ O
develop -X- _ O
set -X- _ O
, -X- _ O
then -X- _ O
report -X- _ O
the -X- _ O
results -X- _ O
on -X- _ O
the -X- _ O
test -X- _ O
set -X- _ O
using -X- _ O
the -X- _ O
Models -X- _ O
IEMOCAP -X- _ B-DatasetName
MELD -X- _ B-DatasetName
EmoryNLP -X- _ B-DatasetName
COSMIC -X- _ B-MethodName
( -X- _ O
Ghosal -X- _ O
et -X- _ O
al -X- _ O
. -X- _ O
, -X- _ O
2020 -X- _ O
) -X- _ O
65.28 -X- _ O
65.21 -X- _ O
38.11 -X- _ O
DialogueCRN -X- _ B-MethodName
( -X- _ O
Hu -X- _ O
et -X- _ O
al -X- _ O
. -X- _ O
, -X- _ O
2021 -X- _ O
) -X- _ O
66.46 -X- _ O
63.42 -X- _ O
38.91 -X- _ O
DAG -X- _ B-MethodName
- -X- _ I-MethodName
ERC -X- _ I-MethodName
68.03 -X- _ O
63.65 -X- _ O
39.02 -X- _ O
TODKAT -X- _ B-MethodName
( -X- _ O
Zhu -X- _ O
et -X- _ O
al -X- _ O
. -X- _ O
, -X- _ O
2021 -X- _ O
) -X- _ O
61.33 -X- _ O
65.47 -X- _ O
38.69 -X- _ O
Cog -X- _ B-MethodName
- -X- _ I-MethodName
BART -X- _ I-MethodName
( -X- _ O
Li -X- _ O
et -X- _ O
al -X- _ O
. -X- _ O
, -X- _ O
2021 -X- _ O
) -X- _ O
66 -X- _ O

Datasets -X- _ O

We -X- _ O
conduct -X- _ O
experiments -X- _ O
on -X- _ O
three -X- _ O
widely -X- _ O
used -X- _ O
benchmarks -X- _ O
: -X- _ O
MELD -X- _ B-DatasetName
( -X- _ O
Poria -X- _ O
et -X- _ O
al -X- _ O
. -X- _ O
, -X- _ O
2019a -X- _ O
) -X- _ O
, -X- _ O
EmoryNLP -X- _ B-DatasetName
( -X- _ O
Zahiri -X- _ O
andChoi -X- _ O
, -X- _ O
2018 -X- _ O
) -X- _ O
and -X- _ O
IEMO -X- _ B-DatasetName
- -X- _ I-DatasetName
CAP -X- _ I-DatasetName
( -X- _ O
Busso -X- _ O
et -X- _ O
al -X- _ O
. -X- _ O
, -X- _ O
2008 -X- _ O
) -X- _ O
. -X- _ O

MELD -X- _ B-DatasetName
This -X- _ O
dataset -X- _ O
has -X- _ O
more -X- _ O
than -X- _ O
1400 -X- _ O
dialogues -X- _ O
and -X- _ O
13000 -X- _ O
utterances -X- _ O
from -X- _ O
Friends -X- _ O
TV -X- _ O
series -X- _ O
. -X- _ O
Multiple -X- _ O
speakers -X- _ O
participated -X- _ O
in -X- _ O
the -X- _ O
dialogues -X- _ O
. -X- _ O
Each -X- _ O
utterance -X- _ O
in -X- _ O
a -X- _ O
dialogue -X- _ O
has -X- _ O
been -X- _ O
labeled -X- _ O
by -X- _ O
any -X- _ O
of -X- _ O
these -X- _ O
seven -X- _ O
emotions -X- _ O
-Anger -X- _ O
, -X- _ O
Disgust -X- _ O
, -X- _ O
Sadness -X- _ O
, -X- _ O
Joy -X- _ O
, -X- _ O
Neutral -X- _ O
, -X- _ O
Surprise -X- _ O
and -X- _ O
Fear -X- _ O
. -X- _ O

EmoryNLP -X- _ B-DatasetName
This -X- _ O
dataset -X- _ O
comprises -X- _ O
97 -X- _ O
episodes -X- _ O
, -X- _ O
897 -X- _ O
scenes -X- _ O
, -X- _ O
and -X- _ O
12,606 -X- _ O
utterances -X- _ O
, -X- _ O
where -X- _ O
each -X- _ O
utterance -X- _ O
is -X- _ O
annotated -X- _ O
with -X- _ O
one -X- _ O
of -X- _ O
the -X- _ O
seven -X- _ O
emotions -X- _ O
borrowed -X- _ O
from -X- _ O
the -X- _ O
six -X- _ O
primary -X- _ O
emotions -X- _ O
in -X- _ O
the -X- _ O
Willcox -X- _ O
's -X- _ O
feeling -X- _ O
wheel -X- _ O
( -X- _ O
Willcox -X- _ O
, -X- _ O
1982 -X- _ O
) -X- _ O
, -X- _ O
i.e. -X- _ O
, -X- _ O
Sad -X- _ O
, -X- _ O
Mad -X- _ O
, -X- _ O
Scared -X- _ O
, -X- _ O
Powerful -X- _ O
, -X- _ O
Peaceful -X- _ O
, -X- _ O
Joyful -X- _ O
, -X- _ O
and -X- _ O
a -X- _ O
default -X- _ O
emotion -X- _ O
of -X- _ O
Neutral -X- _ O
. -X- _ O

IEMOCAP -X- _ B-DatasetName
This -X- _ O
dataset -X- _ O
consists -X- _ O
of -X- _ O
151 -X- _ O
videos -X- _ O
of -X- _ O
recorded -X- _ O
dialogues -X- _ O
, -X- _ O
with -X- _ O
2 -X- _ O
speakers -X- _ O
per -X- _ O
session -X- _ O
for -X- _ O
a -X- _ O
total -X- _ O
of -X- _ O
302 -X- _ O
videos -X- _ O
across -X- _ O
the -X- _ O
dataset -X- _ O
. -X- _ O
Each -X- _ O
segment -X- _ O
is -X- _ O
annotated -X- _ O
for -X- _ O
the -X- _ O
presence -X- _ O
of -X- _ O
9 -X- _ O
emotions -X- _ O
( -X- _ O
Angry -X- _ O
, -X- _ O
Excited -X- _ O
, -X- _ O
Fear -X- _ O
, -X- _ O
Sad -X- _ O
, -X- _ O
Surprised -X- _ O
, -X- _ O
Frustrated -X- _ O
, -X- _ O
Happy -X- _ O
, -X- _ O
Disappointed -X- _ O
and -X- _ O
Neutral -X- _ O
) -X- _ O
. -X- _ O
The -X- _ O
dataset -X- _ O
is -X- _ O
recorded -X- _ O
across -X- _ O
5 -X- _ O
sessions -X- _ O
with -X- _ O
5 -X- _ O
pairs -X- _ O
of -X- _ O
speakers -X- _ O
. -X- _ O

From -X- _ O
Figure -X- _ O
2 -X- _ O
we -X- _ O
can -X- _ O
see -X- _ O
class -X- _ O
- -X- _ O
imbalance -X- _ O
in -X- _ O
all -X- _ O
three -X- _ O
benchmarks -X- _ O
, -X- _ O
so -X- _ O
we -X- _ O
use -X- _ O
weighted -X- _ B-MetricName
- -X- _ I-MetricName
F1 -X- _ I-MetricName
score -X- _ O
as -X- _ O
the -X- _ O
metric -X- _ O
for -X- _ O
all -X- _ O
experiments -X- _ O
in -X- _ O
this -X- _ O
paper -X- _ O
. -X- _ O

We -X- _ O
compare -X- _ O
our -X- _ O
proposed -X- _ O
approach -X- _ O
with -X- _ O
stateof -X- _ O
- -X- _ O
the -X- _ O
- -X- _ O
art -X- _ O
text -X- _ O
- -X- _ O
based -X- _ O
ERC -X- _ B-TaskName
methods -X- _ O
, -X- _ O
and -X- _ O
the -X- _ O
results -X- _ O
are -X- _ O
presented -X- _ O
in -X- _ O
Table -X- _ O
1 -X- _ O
. -X- _ O
We -X- _ O
can -X- _ O
see -X- _ O
that -X- _ O
combining -X- _ O
our -X- _ O
proposed -X- _ O
SPCL -X- _ B-MethodName
and -X- _ O
curriculum -X- _ O
learning -X- _ O
strategy -X- _ O
, -X- _ O
we -X- _ O
achieves -X- _ O
state -X- _ O
- -X- _ O
of -X- _ O
- -X- _ O
the -X- _ O
- -X- _ O
art -X- _ O
results -X- _ O
on -X- _ O
three -X- _ O
benchmarks -X- _ O
, -X- _ O
which -X- _ O
outperform -X- _ O
previous -X- _ O
SOTAs -X- _ O
by -X- _ O
0.28 -X- _ B-MetricValue
% -X- _ I-MetricValue
( -X- _ O
CoMPM -X- _ B-MethodName
on -X- _ O
IEMOCAP -X- _ B-MetricValue
) -X- _ O
, -X- _ O
0.73 -X- _ B-MetricValue
% -X- _ I-MetricValue
( -X- _ O
CoMPM -X- _ B-MethodName
on -X- _ O
MELD -X- _ B-DatasetName
) -X- _ O
and -X- _ O
0.7 -X- _ B-MetricValue
% -X- _ I-MetricValue
( -X- _ O
SGED -X- _ B-MethodName
+ -X- _ I-MethodName
DAG -X- _ I-MethodName
- -X- _ I-MethodName
ERC -X- _ I-MethodName
on -X- _ O
EmoryNLP -X- _ B-DatasetName
) -X- _ O
. -X- _ O

To -X- _ O
summary -X- _ O
, -X- _ O
both -X- _ O
our -X- _ O
proposed -X- _ O
SPCL -X- _ B-MethodName
and -X- _ O
curriculum -X- _ O
learning -X- _ O
strategy -X- _ O
contribute -X- _ O
significantly -X- _ O
to -X- _ O
the -X- _ O
results -X- _ O
. -X- _ O

To -X- _ O
demonstrate -X- _ O
the -X- _ O
superiority -X- _ O
of -X- _ O
SPCL -X- _ B-MethodName
on -X- _ O
imbalanced -X- _ O
data -X- _ O
, -X- _ O
we -X- _ O
construct -X- _ O
an -X- _ O
imbalanced -X- _ O
subset -X- _ O
from -X- _ O
MELD -X- _ B-DatasetName
training -X- _ O
set -X- _ O
, -X- _ O
as -X- _ O
illustrated -X- _ O
in -X- _ O
Figure -X- _ O
4 -X- _ O
. -X- _ O
We -X- _ O
sample -X- _ O
1024 -X- _ O
, -X- _ O
128 -X- _ O
, -X- _ O
64 -X- _ O
, -X- _ O
32 -X- _ O
, -X- _ O
32 -X- _ O
, -X- _ O
32 -X- _ O
, -X- _ O
and -X- _ O
32 -X- _ O
samples -X- _ O
of -X- _ O
neutral -X- _ O
, -X- _ O
joy -X- _ O
, -X- _ O
surprise -X- _ O
, -X- _ O
anger -X- _ O
, -X- _ O
sadness -X- _ O
, -X- _ O
disgust -X- _ O
, -X- _ O
and -X- _ O
fear -X- _ O
, -X- _ O
respectively -X- _ O
. -X- _ O
We -X- _ O
ne -X- _ O
ut -X- _ O
ra -X- _ O
l -X- _ O
jo -X- _ O
y -X- _ O
su -X- _ O
pr -X- _ O
is -X- _ O
e -X- _ O
an -X- _ O
ge -X- _ O
r -X- _ O
sa -X- _ O
dn -X- _ O
es -X- _ O
s -X- _ O
di -X- _ O
sg -X- _ O
us -X- _ O
t -X- _ O
fe -X- _ O
ar -X- _ O
train -X- _ O
the -X- _ O
model -X- _ O
using -X- _ O
these -X- _ O
two -X- _ O
loss -X- _ O
functions -X- _ O
on -X- _ O
the -X- _ O
imbalanced -X- _ O
training -X- _ O
set -X- _ O
. -X- _ O
Since -X- _ O
a -X- _ O
small -X- _ O
batch -X- _ B-HyperparameterName
size -X- _ I-HyperparameterName
will -X- _ O
aggravate -X- _ O
the -X- _ O
impact -X- _ O
of -X- _ O
class -X- _ O
- -X- _ O
imbalance -X- _ O
on -X- _ O
contrastive -X- _ O
learning -X- _ O
, -X- _ O
we -X- _ O
conducted -X- _ O
experiments -X- _ O
with -X- _ O
batch -X- _ B-HyperparameterName
size -X- _ I-HyperparameterName
of -X- _ O
4 -X- _ B-HyperparameterValue
, -X- _ O
8 -X- _ B-HyperparameterValue
, -X- _ O
16 -X- _ B-HyperparameterValue
, -X- _ O
and -X- _ O
32 -X- _ B-HyperparameterValue
, -X- _ O
respectively -X- _ O
. -X- _ O
The -X- _ O
results -X- _ O
on -X- _ O
MELD -X- _ B-DatasetName
test -X- _ O
set -X- _ O
are -X- _ O
shown -X- _ O
in -X- _ O
Table -X- _ O
4 -X- _ O
. -X- _ O
We -X- _ O
notice -X- _ O
that -X- _ O
using -X- _ O
SPCL -X- _ B-MethodName
outperforms -X- _ O
using -X- _ O
SupCon -X- _ B-MethodName
in -X- _ O
all -X- _ O
four -X- _ O
sets -X- _ O
of -X- _ O
experiments -X- _ O
. -X- _ O
As -X- _ O
the -X- _ O
batch -X- _ B-HyperparameterName
size -X- _ I-HyperparameterName
decreases -X- _ O
from -X- _ O
32 -X- _ B-HyperparameterValue
to -X- _ O
4 -X- _ B-HyperparameterValue
, -X- _ O
the -X- _ O
weighted -X- _ B-MetricName
- -X- _ I-MetricName
F1 -X- _ I-MetricName
score -X- _ O
of -X- _ O
SupCon -X- _ B-MethodName
loss -X- _ O
drops -X- _ O
6.95 -X- _ B-MetricValue
% -X- _ I-MetricValue
while -X- _ O
SPCL -X- _ B-MethodName
drops -X- _ O
4.1 -X- _ B-MetricValue
% -X- _ I-MetricValue
. -X- _ O
We -X- _ O
can -X- _ O
conclude -X- _ O
that -X- _ O
in -X- _ O
the -X- _ O
class -X- _ O
- -X- _ O
imbalance -X- _ O
scenarios -X- _ O
: -X- _ O
1 -X- _ O
) -X- _ O
both -X- _ O
SupCon -X- _ B-MethodName
and -X- _ O
SPCL -X- _ B-MethodName
need -X- _ O
a -X- _ O
larger -X- _ O
batch -X- _ B-HyperparameterName
size -X- _ I-HyperparameterName
to -X- _ O
reach -X- _ O
satisfied -X- _ O
performances -X- _ O
; -X- _ O
2 -X- _ O
) -X- _ O
introducing -X- _ O
the -X- _ O
prototypical -X- _ O
network -X- _ O
into -X- _ O
contrastive -X- _ O
learning -X- _ O
can -X- _ O
alleviate -X- _ O
the -X- _ O
impact -X- _ O
of -X- _ O
class -X- _ O
- -X- _ O
imbalance -X- _ O
. -X- _ O

Contrastive -X- _ O
learning -X- _ O
approaches -X- _ O
usually -X- _ O
need -X- _ O
a -X- _ O
large -X- _ O
batch -X- _ B-HyperparameterName
size -X- _ I-HyperparameterName
to -X- _ O
ensure -X- _ O
more -X- _ O
positive -X- _ O
/ -X- _ O
negative -X- _ O
pairs -X- _ O
within -X- _ O
a -X- _ O
batch -X- _ O
, -X- _ O
which -X- _ O
leads -X- _ O
high -X- _ O
computational -X- _ O
cost -X- _ O
. -X- _ O
In -X- _ O
the -X- _ O
Section -X- _ O
5.3 -X- _ O
, -X- _ O
we -X- _ O
find -X- _ O
that -X- _ O
both -X- _ O
SupCon -X- _ B-MethodName
and -X- _ O
SPCL -X- _ B-HyperparameterName
relay -X- _ O
on -X- _ O
large -X- _ O
batch -X- _ B-HyperparameterName
sizes -X- _ I-HyperparameterName
. -X- _ O
We -X- _ O
conjecture -X- _ O
that -X- _ O
SPCL -X- _ B-MethodName
's -X- _ O
dependence -X- _ O
on -X- _ O
batch -X- _ B-HyperparameterName
size -X- _ I-HyperparameterName
may -X- _ O
be -X- _ O
because -X- _ O
we -X- _ O
sample -X- _ O
too -X- _ O
few -X- _ O
data -X- _ O
samples -X- _ O
for -X- _ O
some -X- _ O
categories -X- _ O
( -X- _ O
i.e -X- _ O
. -X- _ O
, -X- _ O
32 -X- _ B-HyperparameterValue
for -X- _ O
anger -X- _ O
, -X- _ O
sadness -X- _ O
, -X- _ O
disgust -X- _ O
, -X- _ O
and -X- _ O
fear -X- _ O
) -X- _ O
to -X- _ O
compute -X- _ O
reasonable -X- _ O
prototypes -X- _ O
at -X- _ O
the -X- _ O
beginning -X- _ O
of -X- _ O
the -X- _ O
training -X- _ O
. -X- _ O

In -X- _ O
order -X- _ O
to -X- _ O
further -X- _ O
investigate -X- _ O
the -X- _ O
effect -X- _ O
of -X- _ O
batch -X- _ B-HyperparameterName
sizes -X- _ I-HyperparameterName
on -X- _ O
SPCL -X- _ B-MethodName
, -X- _ O
we -X- _ O
apply -X- _ O
SPCL -X- _ B-MethodName
to -X- _ O
a -X- _ O
more -X- _ O
general -X- _ O
scenario -X- _ O
. -X- _ O
From -X- _ O
Figure -X- _ O
2 -X- _ O
To -X- _ O
conduct -X- _ O
a -X- _ O
qualitative -X- _ O
analysis -X- _ O
of -X- _ O
our -X- _ O
proposed -X- _ O
curriculum -X- _ O
learning -X- _ O
strategy -X- _ O
, -X- _ O
we -X- _ O
generate -X- _ O
a -X- _ O
toy -X- _ O
dataset -X- _ O
that -X- _ O
contains -X- _ O
three -X- _ O
classes -X- _ O
and -X- _ O
visualize -X- _ O
it -X- _ O
in -X- _ O
Figure -X- _ O
5 -X- _ O
( -X- _ O
A -X- _ O
) -X- _ O
. -X- _ O

In -X- _ O
this -X- _ O
paper -X- _ O
, -X- _ O
we -X- _ O
propose -X- _ O
a -X- _ O
novel -X- _ O
loss -X- _ O
function -X- _ O
called -X- _ O
Supervised -X- _ B-MethodName
Prototypical -X- _ I-MethodName
Contrastive -X- _ I-MethodName
Learning -X- _ I-MethodName
( -X- _ O
SPCL -X- _ B-MethodName
) -X- _ O
loss -X- _ O
for -X- _ O
the -X- _ O
emotion -X- _ O
recognition -X- _ O
in -X- _ O
conversation -X- _ O
task -X- _ O
. -X- _ O
Combining -X- _ O
with -X- _ O
Prototypical -X- _ O
Network -X- _ O
, -X- _ O
the -X- _ O
SPCL -X- _ B-MethodName
loss -X- _ O
outperforms -X- _ O
the -X- _ O
traditional -X- _ O
supervised -X- _ O
contrastive -X- _ O
learning -X- _ O
loss -X- _ O
. -X- _ O
It -X- _ O
also -X- _ O
works -X- _ O
well -X- _ O
on -X- _ O
class -X- _ O
- -X- _ O
imbalanced -X- _ O
data -X- _ O
and -X- _ O
is -X- _ O
less -X- _ O
sensitive -X- _ O
to -X- _ O
the -X- _ O
training -X- _ B-HyperparameterName
batch -X- _ I-HyperparameterName
size -X- _ I-HyperparameterName
, -X- _ O
which -X- _ O
reduces -X- _ O
the -X- _ O
requirement -X- _ O
of -X- _ O
computing -X- _ O
resource -X- _ O
. -X- _ O
To -X- _ O
further -X- _ O
exploit -X- _ O
the -X- _ O
power -X- _ O
of -X- _ O
contrastive -X- _ O
learning -X- _ O
on -X- _ O
ERC -X- _ B-TaskName
tasks -X- _ O
, -X- _ O
we -X- _ O
design -X- _ O
a -X- _ O
distance -X- _ O
- -X- _ O
based -X- _ O
difficulty -X- _ O
measure -X- _ O
function -X- _ O
and -X- _ O
introduce -X- _ O
curriculum -X- _ O
learning -X- _ O
to -X- _ O
alleviate -X- _ O
the -X- _ O
impact -X- _ O
of -X- _ O
extreme -X- _ O
samples -X- _ O
. -X- _ O
We -X- _ O
conduct -X- _ O
experiments -X- _ O
on -X- _ O
three -X- _ O
widely -X- _ O
used -X- _ O
benchmarks -X- _ O
: -X- _ O
IEMO -X- _ B-DatasetName
- -X- _ I-DatasetName
CAP -X- _ I-DatasetName
, -X- _ O
MELD -X- _ B-DatasetName
, -X- _ O
and -X- _ O
EmoryNLP -X- _ B-DatasetName
. -X- _ O
Results -X- _ O
show -X- _ O
that -X- _ O
our -X- _ O
approach -X- _ O
achieves -X- _ O
state -X- _ O
- -X- _ O
of -X- _ O
- -X- _ O
the -X- _ O
- -X- _ O
art -X- _ O
performance -X- _ O
on -X- _ O
all -X- _ O
three -X- _ O
datasets -X- _ O
. -X- _ O

This -X- _ O
work -X- _ O
has -X- _ O
three -X- _ O
limitations -X- _ O
: -X- _ O
1 -X- _ O
) -X- _ O
We -X- _ O
introduce -X- _ O
too -X- _ O
many -X- _ O
hyperparameters -X- _ O
, -X- _ O
which -X- _ O
requires -X- _ O
additional -X- _ O
computing -X- _ O
resources -X- _ O
to -X- _ O
search -X- _ O
. -X- _ O
2 -X- _ O
) -X- _ O
Our -X- _ O
proposed -X- _ O
difficulty -X- _ O
measure -X- _ O
function -X- _ O
can -X- _ O
not -X- _ O
be -X- _ O
com -X- _ O
- -X- _ O
bined -X- _ O
with -X- _ O
most -X- _ O
existing -X- _ O
ERC -X- _ B-TaskName
methods -X- _ O
since -X- _ O
it -X- _ O
requires -X- _ O
the -X- _ O
emotion -X- _ O
representations -X- _ O
produced -X- _ O
by -X- _ O
the -X- _ O
ERC -X- _ B-TaskName
model -X- _ O
to -X- _ O
be -X- _ O
distance -X- _ O
- -X- _ O
aware -X- _ O
. -X- _ O
3 -X- _ O
) -X- _ O
We -X- _ O
used -X- _ O
multiple -X- _ O
random -X- _ O
sampling -X- _ O
, -X- _ O
resulting -X- _ O
in -X- _ O
unstable -X- _ O
performance -X- _ O
. -X- _ O
The -X- _ O
results -X- _ O
in -X- _ O
this -X- _ O
paper -X- _ O
are -X- _ O
averaged -X- _ O
with -X- _ O
multiple -X- _ O
seeds -X- _ O
. -X- _ O
In -X- _ O
practice -X- _ O
, -X- _ O
we -X- _ O
found -X- _ O
that -X- _ O
the -X- _ O
results -X- _ O
generated -X- _ O
by -X- _ O
different -X- _ O
seeds -X- _ O
may -X- _ O
have -X- _ O
significant -X- _ O
variance -X- _ O

Robustness -X- _ O
of -X- _ O
machine -X- _ O
learning -X- _ O
models -X- _ O
on -X- _ O
ever -X- _ O
- -X- _ O
changing -X- _ O
real -X- _ O
- -X- _ O
world -X- _ O
data -X- _ O
is -X- _ O
critical -X- _ O
, -X- _ O
especially -X- _ O
for -X- _ O
applications -X- _ O
affecting -X- _ O
human -X- _ O
wellbeing -X- _ O
such -X- _ O
as -X- _ O
content -X- _ O
moderation -X- _ O
. -X- _ O
New -X- _ O
kinds -X- _ O
of -X- _ O
abusive -X- _ O
language -X- _ O
continually -X- _ O
emerge -X- _ O
in -X- _ O
online -X- _ O
discussions -X- _ O
in -X- _ O
response -X- _ O
to -X- _ O
current -X- _ O
events -X- _ O
( -X- _ O
e.g. -X- _ O
, -X- _ O
, -X- _ O
and -X- _ O
the -X- _ O
deployed -X- _ O
abuse -X- _ O
detection -X- _ O
systems -X- _ O
should -X- _ O
be -X- _ O
updated -X- _ O
regularly -X- _ O
to -X- _ O
remain -X- _ O
accurate -X- _ O
. -X- _ O
In -X- _ O
this -X- _ O
paper -X- _ O
, -X- _ O
we -X- _ O
show -X- _ O
that -X- _ O
general -X- _ O
abusive -X- _ O
language -X- _ O
classifiers -X- _ O
tend -X- _ O
to -X- _ O
be -X- _ O
fairly -X- _ O
reliable -X- _ O
in -X- _ O
detecting -X- _ O
out -X- _ O
- -X- _ O
of -X- _ O
- -X- _ O
domain -X- _ O
explicitly -X- _ O
abusive -X- _ O
utterances -X- _ O
but -X- _ O
fail -X- _ O
to -X- _ O
detect -X- _ O
new -X- _ O
types -X- _ O
of -X- _ O
more -X- _ O
subtle -X- _ O
, -X- _ O
implicit -X- _ O
abuse -X- _ O
. -X- _ O
Next -X- _ O
, -X- _ O
we -X- _ O
propose -X- _ O
an -X- _ O
interpretability -X- _ O
technique -X- _ O
, -X- _ O
based -X- _ O
on -X- _ O
the -X- _ O
Testing -X- _ B-MethodName
Concept -X- _ I-MethodName
Activation -X- _ I-MethodName
Vector -X- _ I-MethodName
( -X- _ O
TCAV -X- _ B-MethodName
) -X- _ O
method -X- _ O
from -X- _ O
computer -X- _ O
vision -X- _ O
, -X- _ O
to -X- _ O
quantify -X- _ O
the -X- _ O
sensitivity -X- _ O
of -X- _ O
a -X- _ O
trained -X- _ O
model -X- _ O
to -X- _ O
the -X- _ O
humandefined -X- _ O
concepts -X- _ O
of -X- _ O
explicit -X- _ O
and -X- _ O
implicit -X- _ O
abusive -X- _ O
language -X- _ O
, -X- _ O
and -X- _ O
use -X- _ O
that -X- _ O
to -X- _ O
explain -X- _ O
the -X- _ O
generalizability -X- _ O
of -X- _ O
the -X- _ O
model -X- _ O
on -X- _ O
new -X- _ O
data -X- _ O
, -X- _ O
in -X- _ O
this -X- _ O
case -X- _ O
, -X- _ O
COVID -X- _ O
- -X- _ O
related -X- _ O
anti -X- _ O
- -X- _ O
Asian -X- _ O
hate -X- _ O
speech -X- _ O
. -X- _ O
Extending -X- _ O
this -X- _ O
technique -X- _ O
, -X- _ O
we -X- _ O
introduce -X- _ O
a -X- _ O
novel -X- _ O
metric -X- _ O
, -X- _ O
Degree -X- _ B-MethodName
of -X- _ I-MethodName
Explicitness -X- _ I-MethodName
, -X- _ O
for -X- _ O
a -X- _ O
single -X- _ O
instance -X- _ O
and -X- _ O
show -X- _ O
that -X- _ O
the -X- _ O
new -X- _ O
metric -X- _ O
is -X- _ O
beneficial -X- _ O
in -X- _ O
suggesting -X- _ O
out -X- _ O
- -X- _ O
of -X- _ O
- -X- _ O
domain -X- _ O
unlabeled -X- _ O
examples -X- _ O
to -X- _ O
effectively -X- _ O
enrich -X- _ O
the -X- _ O
training -X- _ O
data -X- _ O
with -X- _ O
informative -X- _ O
, -X- _ O
implicitly -X- _ O
abusive -X- _ O
texts -X- _ O
. -X- _ O

When -X- _ O
machine -X- _ O
learning -X- _ O
models -X- _ O
are -X- _ O
deployed -X- _ O
in -X- _ O
the -X- _ O
real -X- _ O
world -X- _ O
, -X- _ O
they -X- _ O
must -X- _ O
be -X- _ O
constantly -X- _ O
monitored -X- _ O
for -X- _ O
their -X- _ O
robustness -X- _ O
to -X- _ O
new -X- _ O
and -X- _ O
changing -X- _ O
input -X- _ O
data -X- _ O
. -X- _ O
One -X- _ O
area -X- _ O
where -X- _ O
this -X- _ O
is -X- _ O
particularly -X- _ O
important -X- _ O
is -X- _ O
in -X- _ O
abusive -X- _ B-TaskName
language -X- _ I-TaskName
detection -X- _ I-TaskName
( -X- _ O
Schmidt -X- _ O
and -X- _ O
Wiegand -X- _ O
, -X- _ O
2017 -X- _ O
; -X- _ O
Fortuna -X- _ O
and -X- _ O
Nunes -X- _ O
, -X- _ O
2018 -X- _ O
; -X- _ O
Nakov -X- _ O
et -X- _ O
al -X- _ O
. -X- _ O
, -X- _ O
2021 -X- _ O
; -X- _ O
Vidgen -X- _ O
and -X- _ O
Derczynski -X- _ O
, -X- _ O
2020 -X- _ O
) -X- _ O
. -X- _ O
The -X- _ O
content -X- _ O
of -X- _ O
online -X- _ O
conversation -X- _ O
is -X- _ O
constantly -X- _ O
changing -X- _ O
in -X- _ O
response -X- _ O
to -X- _ O
political -X- _ O
and -X- _ O
social -X- _ O
events -X- _ O
. -X- _ O
New -X- _ O
categories -X- _ O
of -X- _ O
abusive -X- _ O
language -X- _ O
emerge -X- _ O
, -X- _ O
encompassing -X- _ O
topics -X- _ O
and -X- _ O
vocabularies -X- _ O
unknown -X- _ O
to -X- _ O
previously -X- _ O
trained -X- _ O
classifiers -X- _ O
. -X- _ O
Here -X- _ O
, -X- _ O
we -X- _ O
tackle -X- _ O
three -X- _ O
main -X- _ O
questions -X- _ O
: -X- _ O
How -X- _ O
can -X- _ O
a -X- _ O
human -X- _ O
user -X- _ O
formalize -X- _ O
new -X- _ O
, -X- _ O
relevant -X- _ O
topics -X- _ O
or -X- _ O
concepts -X- _ O
in -X- _ O
text -X- _ O
? -X- _ O
How -X- _ O
do -X- _ O
we -X- _ O
quantify -X- _ O
the -X- _ O
sensitivity -X- _ O
of -X- _ O
a -X- _ O
trained -X- _ O
classifier -X- _ O
to -X- _ O
these -X- _ O
new -X- _ O
concepts -X- _ O
as -X- _ O
they -X- _ O
emerge -X- _ O
? -X- _ O
And -X- _ O
how -X- _ O
do -X- _ O
we -X- _ O
update -X- _ O
the -X- _ O
classifier -X- _ O
so -X- _ O
that -X- _ O
it -X- _ O
remains -X- _ O
reliable -X- _ O
? -X- _ O

As -X- _ O
a -X- _ O
case -X- _ O
study -X- _ O
, -X- _ O
we -X- _ O
consider -X- _ O
the -X- _ O
rise -X- _ O
of -X- _ O
COVIDrelated -X- _ O
anti -X- _ O
- -X- _ O
Asian -X- _ O
racism -X- _ O
on -X- _ O
social -X- _ O
media -X- _ O
. -X- _ O
The -X- _ O
COVID-19 -X- _ O
pandemic -X- _ O
represented -X- _ O
an -X- _ O
entirely -X- _ O
new -X- _ O
and -X- _ O
unexpected -X- _ O
situation -X- _ O
, -X- _ O
generating -X- _ O
new -X- _ O
vocabulary -X- _ O
coronavirus -X- _ O
, -X- _ O
social -X- _ O
distancing -X- _ O
, -X- _ O
masking -X- _ O
) -X- _ O
, -X- _ O
new -X- _ O
topics -X- _ O
of -X- _ O
conversation -X- _ O
( -X- _ O
dealing -X- _ O
with -X- _ O
isolation -X- _ O
, -X- _ O
working -X- _ O
from -X- _ O
home -X- _ O
) -X- _ O
, -X- _ O
and -X- _ O
-unfortunately -X- _ O
-new -X- _ O
and -X- _ O
renewed -X- _ O
instances -X- _ O
of -X- _ O
hate -X- _ O
speech -X- _ O
directed -X- _ O
towards -X- _ O
Asian -X- _ O
communities -X- _ O
. -X- _ O
We -X- _ O
imagine -X- _ O
the -X- _ O
case -X- _ O
of -X- _ O
an -X- _ O
abusive -X- _ O
language -X- _ O
detection -X- _ O
algorithm -X- _ O
which -X- _ O
had -X- _ O
been -X- _ O
deployed -X- _ O
prior -X- _ O
to -X- _ O
the -X- _ O
pandemic -X- _ O
: -X- _ O
what -X- _ O
are -X- _ O
the -X- _ O
new -X- _ O
types -X- _ O
of -X- _ O
abusive -X- _ O
language -X- _ O
that -X- _ O
have -X- _ O
emerged -X- _ O
with -X- _ O
the -X- _ O
recent -X- _ O
pandemic -X- _ O
? -X- _ O
To -X- _ O
what -X- _ O
extent -X- _ O
can -X- _ O
deployed -X- _ O
classifiers -X- _ O
generalize -X- _ O
to -X- _ O
this -X- _ O
new -X- _ O
data -X- _ O
, -X- _ O
and -X- _ O
how -X- _ O
can -X- _ O
they -X- _ O
be -X- _ O
adapted -X- _ O
? -X- _ O
Although -X- _ O
social -X- _ O
events -X- _ O
can -X- _ O
spark -X- _ O
off -X- _ O
a -X- _ O
specific -X- _ O
type -X- _ O
of -X- _ O
hate -X- _ O
speech -X- _ O
, -X- _ O
they -X- _ O
are -X- _ O
rarely -X- _ O
the -X- _ O
root -X- _ O
cause -X- _ O
of -X- _ O
the -X- _ O
issue -X- _ O
. -X- _ O
Often -X- _ O
such -X- _ O
hateful -X- _ O
beliefs -X- _ O
existed -X- _ O
before -X- _ O
the -X- _ O
event -X- _ O
, -X- _ O
and -X- _ O
are -X- _ O
only -X- _ O
magnified -X- _ O
because -X- _ O
of -X- _ O
it -X- _ O
( -X- _ O
Chou -X- _ O
and -X- _ O
Feagin -X- _ O
, -X- _ O
2015 -X- _ O
) -X- _ O
. -X- _ O
Therefore -X- _ O
, -X- _ O
we -X- _ O
expect -X- _ O
that -X- _ O
the -X- _ O
classifier -X- _ O
should -X- _ O
detect -X- _ O
this -X- _ O
new -X- _ O
variety -X- _ O
of -X- _ O
hate -X- _ O
speech -X- _ O
to -X- _ O
some -X- _ O
extent -X- _ O
. -X- _ O

An -X- _ O
important -X- _ O
factor -X- _ O
in -X- _ O
this -X- _ O
study -X- _ O
is -X- _ O
whether -X- _ O
the -X- _ O
text -X- _ O
expresses -X- _ O
explicit -X- _ O
or -X- _ O
implicit -X- _ O
abuse -X- _ O
( -X- _ O
Waseem -X- _ O
et -X- _ O
al -X- _ O
. -X- _ O
, -X- _ O
2017 -X- _ O
; -X- _ O
Caselli -X- _ O
et -X- _ O
al -X- _ O
. -X- _ O
, -X- _ O
2020 -X- _ O
; -X- _ O
Wiegand -X- _ O
et -X- _ O
al -X- _ O
. -X- _ O
, -X- _ O
2021 -X- _ O
) -X- _ O
. -X- _ O
Explicit -X- _ O
abuse -X- _ O
refers -X- _ O
to -X- _ O
utterances -X- _ O
that -X- _ O
include -X- _ O
direct -X- _ O
insults -X- _ O
or -X- _ O
strong -X- _ O
rudeness -X- _ O
, -X- _ O
often -X- _ O
involving -X- _ O
profanities -X- _ O
, -X- _ O
whereas -X- _ O
implicit -X- _ O
abuse -X- _ O
involves -X- _ O
more -X- _ O
indirect -X- _ O
and -X- _ O
nuanced -X- _ O
language -X- _ O
. -X- _ O
Since -X- _ O
understanding -X- _ O
the -X- _ O
offensive -X- _ O
aspects -X- _ O
of -X- _ O
implicit -X- _ O
abuse -X- _ O
in -X- _ O
our -X- _ O
case -X- _ O
study -X- _ O
may -X- _ O
require -X- _ O
some -X- _ O
knowledge -X- _ O
of -X- _ O
the -X- _ O
context -X- _ O
( -X- _ O
i.e. -X- _ O
, -X- _ O
the -X- _ O
pandemic -X- _ O
) -X- _ O
, -X- _ O
we -X- _ O
expect -X- _ O
that -X- _ O
the -X- _ O
pretrained -X- _ O
classifier -X- _ O
will -X- _ O
find -X- _ O
these -X- _ O
data -X- _ O
especially -X- _ O
difficult -X- _ O
to -X- _ O
handle -X- _ O
. -X- _ O

To -X- _ O
examine -X- _ O
a -X- _ O
classifier -X- _ O
's -X- _ O
ability -X- _ O
to -X- _ O
handle -X- _ O
new -X- _ O
type -X- _ O
of -X- _ O
abusive -X- _ O
text -X- _ O
( -X- _ O
without -X- _ O
access -X- _ O
to -X- _ O
extensive -X- _ O
labeled -X- _ O
data -X- _ O
) -X- _ O
, -X- _ O
we -X- _ O
propose -X- _ O
a -X- _ O
technique -X- _ O
based -X- _ O
on -X- _ O
the -X- _ O
Testing -X- _ B-MethodName
Concept -X- _ I-MethodName
Activation -X- _ I-MethodName
Vector -X- _ I-MethodName
( -X- _ O
TCAV -X- _ B-MethodName
) -X- _ O
method -X- _ O
from -X- _ O
the -X- _ O
interpretability -X- _ O
literature -X- _ O
in -X- _ O
computer -X- _ O
vision -X- _ O
( -X- _ O
Kim -X- _ O
et -X- _ O
al -X- _ O
. -X- _ O
, -X- _ O
2018 -X- _ O
) -X- _ O
. -X- _ O
TCAV -X- _ B-MethodName
is -X- _ O
used -X- _ O
to -X- _ O
explain -X- _ O
whether -X- _ O
a -X- _ O
classifier -X- _ O
associates -X- _ O
a -X- _ O
specific -X- _ O
concept -X- _ O
to -X- _ O
a -X- _ O
class -X- _ O
label -X- _ O
( -X- _ O
e.g. -X- _ O
, -X- _ O
the -X- _ O
concept -X- _ O
of -X- _ O
stripes -X- _ O
is -X- _ O
associated -X- _ O
with -X- _ O
class -X- _ O
zebra -X- _ O
in -X- _ O
image -X- _ O
classification -X- _ O
) -X- _ O
. -X- _ O
Similarly -X- _ O
, -X- _ O
we -X- _ O
define -X- _ O
implicit -X- _ O
and -X- _ O
explicit -X- _ O
COVIDrelated -X- _ O
anti -X- _ O
- -X- _ O
Asian -X- _ O
racism -X- _ O
with -X- _ O
a -X- _ O
small -X- _ O
set -X- _ O
of -X- _ O
humanchosen -X- _ O
textual -X- _ O
examples -X- _ O
, -X- _ O
and -X- _ O
ask -X- _ O
whether -X- _ O
the -X- _ O
pretrained -X- _ O
classifier -X- _ O
associates -X- _ O
these -X- _ O
concepts -X- _ O
with -X- _ O
the -X- _ O
positive -X- _ O
( -X- _ O
abusive -X- _ O
) -X- _ O
class -X- _ O
label -X- _ O
. -X- _ O

Further -X- _ O
, -X- _ O
we -X- _ O
ask -X- _ O
whether -X- _ O
sensitivity -X- _ O
to -X- _ O
humandefined -X- _ O
concepts -X- _ O
can -X- _ O
direct -X- _ O
data -X- _ O
augmentation -X- _ O
1 -X- _ O
to -X- _ O
improve -X- _ O
generalizations -X- _ O
. -X- _ O
Intuitively -X- _ O
, -X- _ O
when -X- _ O
updating -X- _ O
a -X- _ O
classifier -X- _ O
, -X- _ O
data -X- _ O
enrichment -X- _ O
should -X- _ O
focus -X- _ O
on -X- _ O
adding -X- _ O
examples -X- _ O
of -X- _ O
concepts -X- _ O
to -X- _ O
which -X- _ O
the -X- _ O
classifier -X- _ O
is -X- _ O
not -X- _ O
yet -X- _ O
sensitive -X- _ O
. -X- _ O
Conventional -X- _ O
active -X- _ O
learning -X- _ O
frameworks -X- _ O
suggest -X- _ O
examples -X- _ O
with -X- _ O
the -X- _ O
lowest -X- _ O
classification -X- _ O
confidence -X- _ O
as -X- _ O
the -X- _ O
most -X- _ O
informative -X- _ O
augmentation -X- _ O
samples -X- _ O
( -X- _ O
Zhu -X- _ O
et -X- _ O
al -X- _ O
. -X- _ O
, -X- _ O
2008 -X- _ O
; -X- _ O
Chen -X- _ O
et -X- _ O
al -X- _ O
. -X- _ O
, -X- _ O
2019 -X- _ O
) -X- _ O
. -X- _ O
However -X- _ O
, -X- _ O
deep -X- _ O
neural -X- _ O
networks -X- _ O
' -X- _ O
inability -X- _ O
to -X- _ O
provide -X- _ O
reliable -X- _ O
uncertainty -X- _ O
estimates -X- _ O
is -X- _ O
one -X- _ O
of -X- _ O
the -X- _ O
main -X- _ O
barriers -X- _ O
to -X- _ O
adopting -X- _ O
confidence -X- _ O
- -X- _ O
based -X- _ O
sampling -X- _ O
techniques -X- _ O
( -X- _ O
Schröder -X- _ O
and -X- _ O
Niekler -X- _ O
, -X- _ O
2020 -X- _ O
) -X- _ O
. -X- _ O
We -X- _ O
suggest -X- _ O
that -X- _ O
, -X- _ O
in -X- _ O
the -X- _ O
case -X- _ O
of -X- _ O
abuse -X- _ O
detection -X- _ O
, -X- _ O
implicitly -X- _ O
abusive -X- _ O
examples -X- _ O
are -X- _ O
most -X- _ O
informative -X- _ O
for -X- _ O
updating -X- _ O
a -X- _ O
general -X- _ O
classifier -X- _ O
. -X- _ O
However -X- _ O
, -X- _ O
to -X- _ O
the -X- _ O
best -X- _ O
of -X- _ O
our -X- _ O
knowledge -X- _ O
, -X- _ O
there -X- _ O
is -X- _ O
no -X- _ O
quantitative -X- _ O
metric -X- _ O
that -X- _ O
can -X- _ O
measure -X- _ O
the -X- _ O
degree -X- _ O
of -X- _ O
explicitness -X- _ O
of -X- _ O
a -X- _ O
candidate -X- _ O
example -X- _ O
, -X- _ O
given -X- _ O
a -X- _ O
trained -X- _ O
classifier -X- _ O
. -X- _ O
We -X- _ O
extend -X- _ O
the -X- _ O
TCAV -X- _ B-MethodName
technique -X- _ O
to -X- _ O
provide -X- _ O
a -X- _ O
" -X- _ O
degree -X- _ O
of -X- _ O
explicitness -X- _ O
" -X- _ O
measure -X- _ O
at -X- _ O
the -X- _ O
utterance -X- _ O
level -X- _ O
and -X- _ O
use -X- _ O
that -X- _ O
for -X- _ O
efficient -X- _ O
data -X- _ O
augmentation -X- _ O
. -X- _ O

• -X- _ O
We -X- _ O
implement -X- _ O
a -X- _ O
variation -X- _ O
of -X- _ O
the -X- _ O
TCAV -X- _ B-MethodName
framework -X- _ O
for -X- _ O
a -X- _ O
RoBERTa -X- _ O
- -X- _ O
based -X- _ O
classifier -X- _ O
and -X- _ O
show -X- _ O
that -X- _ O
it -X- _ O
can -X- _ O
be -X- _ O
used -X- _ O
to -X- _ O
quantify -X- _ O
the -X- _ O
sensitivity -X- _ O
of -X- _ O
a -X- _ O
trained -X- _ O
classifier -X- _ O
to -X- _ O
a -X- _ O
human -X- _ O
- -X- _ O
understandable -X- _ O
concept -X- _ O
, -X- _ O
defined -X- _ O
through -X- _ O
examples -X- _ O
, -X- _ O
without -X- _ O
access -X- _ O
to -X- _ O
the -X- _ O
training -X- _ O
dataset -X- _ O
of -X- _ O
the -X- _ O
classifier -X- _ O
or -X- _ O
a -X- _ O
large -X- _ O
annotated -X- _ O
dataset -X- _ O
for -X- _ O
the -X- _ O
new -X- _ O
category -X- _ O
. -X- _ O

• -X- _ O
We -X- _ O
analyse -X- _ O
the -X- _ O
performance -X- _ O
of -X- _ O
two -X- _ O
abusive -X- _ O
language -X- _ O
classifiers -X- _ O
and -X- _ O
observe -X- _ O
that -X- _ O
they -X- _ O
generalize -X- _ O
well -X- _ O
to -X- _ O
explicit -X- _ O
COVID -X- _ O
- -X- _ O
related -X- _ O
anti -X- _ O
- -X- _ O
Asian -X- _ O
racism -X- _ O
, -X- _ O
but -X- _ O
are -X- _ O
unable -X- _ O
to -X- _ O
generalize -X- _ O
to -X- _ O
implicit -X- _ O
racism -X- _ O
of -X- _ O
this -X- _ O
type -X- _ O
. -X- _ O
We -X- _ O
show -X- _ O
that -X- _ O
sensitivities -X- _ O
to -X- _ O
the -X- _ O
concepts -X- _ O
of -X- _ O
implicit -X- _ O
and -X- _ O
explicit -X- _ O
abuse -X- _ O
can -X- _ O
explain -X- _ O
the -X- _ O
observed -X- _ O
discrepancies -X- _ O
. -X- _ O

• -X- _ O
We -X- _ O
adjust -X- _ O
the -X- _ O
TCAV -X- _ B-MethodName
method -X- _ O
to -X- _ O
compute -X- _ O
the -X- _ O
degree -X- _ O
of -X- _ O
explicitness -X- _ O
, -X- _ O
for -X- _ O
an -X- _ O
unlabeled -X- _ O
instance -X- _ O
, -X- _ O
as -X- _ O
a -X- _ O
metric -X- _ O
to -X- _ O
guide -X- _ O
data -X- _ O
augmentation -X- _ O
when -X- _ O
updating -X- _ O
a -X- _ O
general -X- _ O
abusive -X- _ O
language -X- _ O
classifier -X- _ O
to -X- _ O
include -X- _ O
a -X- _ O
new -X- _ O
kind -X- _ O
of -X- _ O
abuse -X- _ O
. -X- _ O
We -X- _ O
test -X- _ O
this -X- _ O
method -X- _ O
against -X- _ O
confidence -X- _ O
- -X- _ O
based -X- _ O
augmentation -X- _ O
and -X- _ O
show -X- _ O
that -X- _ O
it -X- _ O
is -X- _ O
able -X- _ O
to -X- _ O
reach -X- _ O
higher -X- _ O
accuracy -X- _ O
with -X- _ O
fewer -X- _ O
training -X- _ O
examples -X- _ O
, -X- _ O
while -X- _ O
maintaining -X- _ O
the -X- _ O
accuracy -X- _ O
on -X- _ O
the -X- _ O
original -X- _ O
data -X- _ O
. -X- _ O
The -X- _ O
implementation -X- _ O
code -X- _ O
and -X- _ O
data -X- _ O
for -X- _ O
the -X- _ O
experiments -X- _ O
are -X- _ O
available -X- _ O
at -X- _ O
https -X- _ O
: -X- _ O
/ -X- _ O
/ -X- _ O
github.com -X- _ O
/ -X- _ O
IsarNejad -X- _ O
/ -X- _ O
TCAV -X- _ O
- -X- _ O
for -X- _ O
- -X- _ O
Text -X- _ O
- -X- _ O
Classifiers -X- _ O
. -X- _ O

We -X- _ O
consider -X- _ O
the -X- _ O
following -X- _ O
four -X- _ O
English -X- _ O
datasets -X- _ O
, -X- _ O
summarized -X- _ O
in -X- _ O
Table -X- _ O
1 -X- _ O
: -X- _ O
Founta -X- _ B-DatasetName
2 -X- _ O
and -X- _ O
Wiki -X- _ B-DatasetName
3 -X- _ O
are -X- _ O
large -X- _ O
, -X- _ O
commonly -X- _ O
- -X- _ O
used -X- _ O
datasets -X- _ O
for -X- _ O
general -X- _ O
abusive -X- _ O
language -X- _ O
detection -X- _ O
, -X- _ O
while -X- _ O
EA -X- _ B-DatasetName
and -X- _ O
CH -X- _ B-DatasetName
specifically -X- _ O
target -X- _ O
COVID -X- _ O
- -X- _ O
related -X- _ O
anti -X- _ O
- -X- _ O
Asian -X- _ O
racism -X- _ O
. -X- _ O
We -X- _ O
binarize -X- _ O
all -X- _ O
datasets -X- _ O
to -X- _ O
two -X- _ O
classes -X- _ O
: -X- _ O
positive -X- _ O
( -X- _ O
i.e. -X- _ O
, -X- _ O
abusive -X- _ O
or -X- _ O
hateful -X- _ O
) -X- _ O
and -X- _ O
negative -X- _ O
. -X- _ O
For -X- _ O
Founta -X- _ B-DatasetName
, -X- _ O
this -X- _ O
means -X- _ O
combining -X- _ O
Abusive -X- _ O
and -X- _ O
Hateful -X- _ O
texts -X- _ O
into -X- _ O
a -X- _ O
single -X- _ O
positive -X- _ O
class -X- _ O
; -X- _ O
for -X- _ O
EA -X- _ B-DatasetName
, -X- _ O
" -X- _ O
Hostility -X- _ O
against -X- _ O
an -X- _ O
East -X- _ O
- -X- _ O
Asian -X- _ O
entity -X- _ O
" -X- _ O
is -X- _ O
considered -X- _ O
positive -X- _ O
, -X- _ O
and -X- _ O
all -X- _ O
other -X- _ O
classes -X- _ O
are -X- _ O
negative -X- _ O
; -X- _ O
and -X- _ O
for -X- _ O
CH -X- _ B-DatasetName
, -X- _ O
all -X- _ O
hate -X- _ O
speech -X- _ O
is -X- _ O
classed -X- _ O
as -X- _ O
positive -X- _ O
, -X- _ O
while -X- _ O
counter -X- _ O
- -X- _ O
hate -X- _ O
and -X- _ O
hate -X- _ O
- -X- _ O
neutral -X- _ O
texts -X- _ O
are -X- _ O
classed -X- _ O
as -X- _ O
negative -X- _ O
. -X- _ O

Central -X- _ O
to -X- _ O
our -X- _ O
research -X- _ O
question -X- _ O
is -X- _ O
the -X- _ O
issue -X- _ O
of -X- _ O
vocabulary -X- _ O
change -X- _ O
as -X- _ O
a -X- _ O
new -X- _ O
abusive -X- _ O
topic -X- _ O
emerges -X- _ O
. -X- _ O
As -X- _ O
the -X- _ O
Wiki -X- _ B-DatasetName
and -X- _ O
Founta -X- _ B-DatasetName
datasets -X- _ O
were -X- _ O
collected -X- _ O
before -X- _ O
the -X- _ O
COVID-19 -X- _ O
pandemic -X- _ O
, -X- _ O
they -X- _ O
do -X- _ O
not -X- _ O
contain -X- _ O
novel -X- _ O
vocabulary -X- _ O
such -X- _ O
as -X- _ O
" -X- _ O
chinavirus -X- _ O
" -X- _ O
or -X- _ O
" -X- _ O
wuhanflu -X- _ O
" -X- _ O
, -X- _ O
and -X- _ O
the -X- _ O
contexts -X- _ O
and -X- _ O
frequencies -X- _ O
for -X- _ O
words -X- _ O
like -X- _ O
" -X- _ O
China -X- _ O
" -X- _ O
and -X- _ O
" -X- _ O
pandemic -X- _ O
" -X- _ O
may -X- _ O
have -X- _ O
changed -X- _ O
. -X- _ O
As -X- _ O
a -X- _ O
demonstration -X- _ O
of -X- _ O
the -X- _ O
differences -X- _ O
in -X- _ O
vocabulary -X- _ O
across -X- _ O
the -X- _ O
different -X- _ O
datasets -X- _ O
, -X- _ O
we -X- _ O
compute -X- _ O
the -X- _ O
top -X- _ O
100 -X- _ O
most -X- _ O
frequent -X- _ O
words -X- _ O
in -X- _ O
the -X- _ O
positive -X- _ O
class -X- _ O
of -X- _ O
each -X- _ O
dataset -X- _ O
( -X- _ O
after -X- _ O
removing -X- _ O
stop -X- _ O
words -X- _ O
4 -X- _ O
) -X- _ O
, -X- _ O
and -X- _ O
then -X- _ O
calculate -X- _ O
the -X- _ O
overlap -X- _ O
between -X- _ O
each -X- _ O
pair -X- _ O
of -X- _ O
datasets -X- _ O
. -X- _ O
We -X- _ O
categorize -X- _ O
the -X- _ O
shared -X- _ O
words -X- _ O
into -X- _ O
three -X- _ O
categories -X- _ O
: -X- _ O
1 -X- _ O
) -X- _ O
generically -X- _ O
profane -X- _ O
and -X- _ O
hateful -X- _ O
words -X- _ O
, -X- _ O
2 -X- _ O
) -X- _ O
COVID -X- _ O
- -X- _ O
related -X- _ O
words -X- _ O
, -X- _ O
and -X- _ O
3 -X- _ O
) -X- _ O
all -X- _ O
other -X- _ O
words -X- _ O
. -X- _ O
Table -X- _ O
2 -X- _ O
shows -X- _ O
the -X- _ O
three -X- _ O
categories -X- _ O
of -X- _ O
shared -X- _ O
words -X- _ O
among -X- _ O
the -X- _ O
100 -X- _ O
most -X- _ O
frequent -X- _ O
words -X- _ O
of -X- _ O
the -X- _ O
positive -X- _ O
classes -X- _ O
in -X- _ O
our -X- _ O
datasets -X- _ O
. -X- _ O
This -X- _ O
analysis -X- _ O
reveals -X- _ O
that -X- _ O
the -X- _ O
two -X- _ O
COVID -X- _ O
- -X- _ O
related -X- _ O
datasets -X- _ O
share -X- _ O
more -X- _ O
words -X- _ O
in -X- _ O
common -X- _ O
: -X- _ O
50 -X- _ O
out -X- _ O
of -X- _ O
the -X- _ O
100 -X- _ O
most -X- _ O
frequent -X- _ O
words -X- _ O
are -X- _ O
common -X- _ O
between -X- _ O
the -X- _ O
two -X- _ O
datasets -X- _ O
. -X- _ O
As -X- _ O
expected -X- _ O
, -X- _ O
a -X- _ O
large -X- _ O
portion -X- _ O
of -X- _ O
their -X- _ O
shared -X- _ O
vocabulary -X- _ O
( -X- _ O
32 -X- _ O
% -X- _ O
) -X- _ O
is -X- _ O
specific -X- _ O
to -X- _ O
the -X- _ O
pandemic -X- _ O
, -X- _ O
has -X- _ O
been -X- _ O
used -X- _ O
more -X- _ O
frequently -X- _ O
during -X- _ O
the -X- _ O
pandemic -X- _ O
or -X- _ O
has -X- _ O
found -X- _ O
new -X- _ O
connotations -X- _ O
because -X- _ O
of -X- _ O
the -X- _ O
pandemic -X- _ O
. -X- _ O
For -X- _ O
all -X- _ O
other -X- _ O
datasets -X- _ O
, -X- _ O
fewer -X- _ O
words -X- _ O
are -X- _ O
shared -X- _ O
, -X- _ O
and -X- _ O
the -X- _ O
shared -X- _ O
words -X- _ O
are -X- _ O
either -X- _ O
related -X- _ O
to -X- _ O
profanity -X- _ O
and -X- _ O
violence -X- _ O
or -X- _ O
are -X- _ O
merely -X- _ O
commonly -X- _ O
used -X- _ O
terms -X- _ O
. -X- _ O
Profanity -X- _ O
and -X- _ O
strongly -X- _ O
negative -X- _ O
words -X- _ O
such -X- _ O
as -X- _ O
" -X- _ O
hate -X- _ O
" -X- _ O
make -X- _ O
up -X- _ O
30 -X- _ O
% -X- _ O
of -X- _ O
the -X- _ O
shared -X- _ O
vocabulary -X- _ O
between -X- _ O
the -X- _ O
Wiki -X- _ B-DatasetName
and -X- _ O
Founta -X- _ B-DatasetName
datasets -X- _ O
. -X- _ O
Interestingly -X- _ O
, -X- _ O
CH -X- _ B-DatasetName
has -X- _ O
a -X- _ O
set -X- _ O
of -X- _ O
profane -X- _ O
words -X- _ O
in -X- _ O
common -X- _ O
with -X- _ O
both -X- _ O
Wiki -X- _ B-DatasetName
and -X- _ O
Founta -X- _ B-DatasetName
( -X- _ O
∼25 -X- _ O
% -X- _ O
of -X- _ O
shared -X- _ O
words -X- _ O
) -X- _ O
, -X- _ O
while -X- _ O
the -X- _ O
words -X- _ O
shared -X- _ O
between -X- _ O
EA -X- _ B-DatasetName
and -X- _ O
the -X- _ O
general -X- _ O
datasets -X- _ O
are -X- _ O
simply -X- _ O
common -X- _ O
words -X- _ O
in -X- _ O
the -X- _ O
English -X- _ O
language -X- _ O
, -X- _ O
such -X- _ O
as -X- _ O
" -X- _ O
people -X- _ O
" -X- _ O
, -X- _ O
" -X- _ O
want -X- _ O
" -X- _ O
, -X- _ O
and -X- _ O
" -X- _ O
need -X- _ O
. -X- _ O
" -X- _ O
We -X- _ O
expect -X- _ O
that -X- _ O
this -X- _ O
vocabulary -X- _ O
shift -X- _ O
between -X- _ O
the -X- _ O
different -X- _ O
datasets -X- _ O
will -X- _ O
have -X- _ O
a -X- _ O
considerable -X- _ O
impact -X- _ O
on -X- _ O
the -X- _ O
generalizability -X- _ O
. -X- _ O

Another -X- _ O
important -X- _ O
factor -X- _ O
in -X- _ O
our -X- _ O
study -X- _ O
is -X- _ O
generalization -X- _ O
with -X- _ O
respect -X- _ O
to -X- _ O
explicit -X- _ O
and -X- _ O
implicit -X- _ O
types -X- _ O
of -X- _ O
abusive -X- _ O
language -X- _ O
. -X- _ O
Above -X- _ O
, -X- _ O
we -X- _ O
observed -X- _ O
that -X- _ O
CH -X- _ B-DatasetName
shares -X- _ O
many -X- _ O
profane -X- _ O
words -X- _ O
with -X- _ O
the -X- _ O
general -X- _ O
datasets -X- _ O
and -X- _ O
, -X- _ O
therefore -X- _ O
, -X- _ O
we -X- _ O
anticipate -X- _ O
it -X- _ O
contains -X- _ O
more -X- _ O
explicitly -X- _ O
abusive -X- _ O
texts -X- _ O
than -X- _ O
EA -X- _ B-DatasetName
does -X- _ O
. -X- _ O
Unfortunately -X- _ O
, -X- _ O
neither -X- _ O
of -X- _ O
the -X- _ O
datasets -X- _ O
has -X- _ O
originally -X- _ O
been -X- _ O
annotated -X- _ O
for -X- _ O
explicitness -X- _ O
of -X- _ O
abuse -X- _ O
. -X- _ O
We -X- _ O
manually -X- _ O
annotate -X- _ O
instances -X- _ O
from -X- _ O
the -X- _ O
positive -X- _ O
class -X- _ O
in -X- _ O
the -X- _ O
CH -X- _ B-DatasetName
dataset -X- _ O
and -X- _ O
the -X- _ O
EA -X- _ B-DatasetName
dev -X- _ O
set -X- _ O
using -X- _ O
the -X- _ O
following -X- _ O
rule -X- _ O
: -X- _ O
instances -X- _ O
that -X- _ O
include -X- _ O
profanity -X- _ O
, -X- _ O
insult -X- _ O
or -X- _ O
rudeness -X- _ O
that -X- _ O
could -X- _ O
be -X- _ O
correctly -X- _ O
identified -X- _ O
as -X- _ O
abusive -X- _ O
without -X- _ O
general -X- _ O
knowledge -X- _ O
about -X- _ O
the -X- _ O
COVID-19 -X- _ O
pandemic -X- _ O
are -X- _ O
labeled -X- _ O
as -X- _ O
explicitly -X- _ O
abusive -X- _ O
; -X- _ O
the -X- _ O
remaining -X- _ O
instances -X- _ O
( -X- _ O
e.g. -X- _ O
, -X- _ O
' -X- _ O
it -X- _ O
is -X- _ O
not -X- _ O
covid -X- _ O
19 -X- _ O
but -X- _ O
wuhanvirus -X- _ O
' -X- _ O
) -X- _ O
are -X- _ O
labeled -X- _ O
as -X- _ O
implicitly -X- _ O
abusive -X- _ O
. -X- _ O
We -X- _ O
find -X- _ O
that -X- _ O
85 -X- _ O
% -X- _ O
of -X- _ O
the -X- _ O
CH -X- _ O
- -X- _ O
positive -X- _ O
class -X- _ O
is -X- _ O
categorized -X- _ O
as -X- _ O
explicit -X- _ O
, -X- _ O
whereas -X- _ O
only -X- _ O
8 -X- _ O
% -X- _ O
of -X- _ O
the -X- _ O
EA -X- _ O
- -X- _ O
positive -X- _ O
class -X- _ O
in -X- _ O
the -X- _ O
EA -X- _ B-DatasetName
dev -X- _ O
set -X- _ O
is -X- _ O
labeled -X- _ O
as -X- _ O
explicit -X- _ O
. -X- _ O
Thus -X- _ O
, -X- _ O
CH -X- _ B-DatasetName
and -X- _ O
EA -X- _ B-DatasetName
share -X- _ O
COVID -X- _ O
- -X- _ O
related -X- _ O
vocabulary -X- _ O
, -X- _ O
but -X- _ O
are -X- _ O
very -X- _ O
different -X- _ O
in -X- _ O
terms -X- _ O
of -X- _ O
explicitness -X- _ O
of -X- _ O
abuse -X- _ O
( -X- _ O
CH -X- _ B-DatasetName
containing -X- _ O
mostly -X- _ O
explicit -X- _ O
abuse -X- _ O
while -X- _ O
EA -X- _ B-DatasetName
containing -X- _ O
mostly -X- _ O
implicit -X- _ O
abuse -X- _ O
) -X- _ O
, -X- _ O
which -X- _ O
makes -X- _ O
them -X- _ O
suitable -X- _ O
test -X- _ O
beds -X- _ O
for -X- _ O
assessing -X- _ O
the -X- _ O
generalizability -X- _ O
of -X- _ O
classifiers -X- _ O
to -X- _ O
a -X- _ O
new -X- _ O
type -X- _ O
of -X- _ O
abusive -X- _ O
language -X- _ O
and -X- _ O
the -X- _ O
impact -X- _ O
of -X- _ O
new -X- _ O
vocabulary -X- _ O
on -X- _ O
the -X- _ O
classification -X- _ O
of -X- _ O
implicit -X- _ O
and -X- _ O
explicit -X- _ O
abuse -X- _ O
. -X- _ O

We -X- _ O
start -X- _ O
by -X- _ O
assessing -X- _ O
the -X- _ O
robustness -X- _ O
of -X- _ O
a -X- _ O
generalpurpose -X- _ O
abusive -X- _ O
language -X- _ O
classifier -X- _ O
on -X- _ O
a -X- _ O
new -X- _ O
domain -X- _ O
of -X- _ O
abusive -X- _ O
language -X- _ O
. -X- _ O
Specifically -X- _ O
, -X- _ O
we -X- _ O
analyze -X- _ O
the -X- _ O
performance -X- _ O
of -X- _ O
classifiers -X- _ O
trained -X- _ O
on -X- _ O
the -X- _ O
Wiki -X- _ B-DatasetName
and -X- _ O
Founta -X- _ B-DatasetName
datasets -X- _ O
( -X- _ O
expected -X- _ O
to -X- _ O
detect -X- _ O
general -X- _ O
toxicity -X- _ O
and -X- _ O
abuse -X- _ O
) -X- _ O
on -X- _ O
COVID -X- _ O
- -X- _ O
related -X- _ O
anti -X- _ O
- -X- _ O
Asian -X- _ O
racism -X- _ O
data -X- _ O
. -X- _ O
In -X- _ O
addition -X- _ O
, -X- _ O
we -X- _ O
want -X- _ O
to -X- _ O
assess -X- _ O
the -X- _ O
impact -X- _ O
of -X- _ O
the -X- _ O
change -X- _ O
of -X- _ O
vocabulary -X- _ O
on -X- _ O
the -X- _ O
generalizibility -X- _ O
of -X- _ O
the -X- _ O
classifiers -X- _ O
to -X- _ O
implicit -X- _ O
and -X- _ O
explicit -X- _ O
abuse -X- _ O
in -X- _ O
the -X- _ O
new -X- _ O
domain -X- _ O
. -X- _ O
We -X- _ O
train -X- _ O
binary -X- _ O
RoBERTa -X- _ O
- -X- _ O
based -X- _ O
classifiers -X- _ O
on -X- _ O
the -X- _ O
Wiki -X- _ B-DatasetName
, -X- _ O
Founta -X- _ B-DatasetName
, -X- _ O
EA -X- _ B-DatasetName
and -X- _ O
CH -X- _ B-DatasetName
datasets -X- _ O
( -X- _ O
referred -X- _ O
to -X- _ O
hereafter -X- _ O
as -X- _ O
the -X- _ O
Wiki -X- _ O
, -X- _ O
Founta -X- _ O
, -X- _ O
EA -X- _ O
and -X- _ O
CH -X- _ O
classifiers -X- _ O
) -X- _ O
, -X- _ O
and -X- _ O
test -X- _ O
them -X- _ O
on -X- _ O
the -X- _ O
EA -X- _ B-DatasetName
as -X- _ O
the -X- _ O
mostly -X- _ O
implicit -X- _ O
COVID -X- _ O
- -X- _ O
related -X- _ O
dataset -X- _ O
and -X- _ O
CH -X- _ B-DatasetName
as -X- _ O
the -X- _ O
mostly -X- _ O
explicit -X- _ O
COVID- -X- _ O
Table -X- _ O
3 -X- _ O
presents -X- _ O
the -X- _ O
Area -X- _ B-MetricName
Under -X- _ I-MetricName
the -X- _ I-MetricName
ROC -X- _ I-MetricName
Curve -X- _ I-MetricName
( -X- _ O
AUC -X- _ B-MetricName
) -X- _ O
and -X- _ O
F1 -X- _ B-MetricName
- -X- _ I-MetricName
scores -X- _ I-MetricName
for -X- _ O
all -X- _ O
the -X- _ O
classifiers -X- _ O
; -X- _ O
precision -X- _ B-MetricName
, -X- _ O
recall -X- _ B-MetricName
, -X- _ O
and -X- _ O
average -X- _ B-MetricName
precision -X- _ I-MetricName
scores -X- _ O
are -X- _ O
provided -X- _ O
in -X- _ O
Appendix -X- _ O
B. -X- _ O
We -X- _ O
first -X- _ O
consider -X- _ O
whether -X- _ O
class -X- _ O
imbalances -X- _ O
can -X- _ O
explain -X- _ O
our -X- _ O
results -X- _ O
. -X- _ O
Note -X- _ O
that -X- _ O
while -X- _ O
abusive -X- _ O
language -X- _ O
is -X- _ O
a -X- _ O
relatively -X- _ O
rare -X- _ O
phenomenon -X- _ O
in -X- _ O
online -X- _ O
communications -X- _ O
, -X- _ O
most -X- _ O
abusive -X- _ O
language -X- _ O
datasets -X- _ O
are -X- _ O
collected -X- _ O
through -X- _ O
boosted -X- _ O
sampling -X- _ O
and -X- _ O
therefore -X- _ O
are -X- _ O
not -X- _ O
subject -X- _ O
to -X- _ O
extreme -X- _ O
class -X- _ O
imbalances -X- _ O
. -X- _ O
The -X- _ O
percentage -X- _ O
of -X- _ O
positive -X- _ O
instances -X- _ O
in -X- _ O
our -X- _ O
datasets -X- _ O
ranges -X- _ O
from -X- _ O
9 -X- _ O
% -X- _ O
to -X- _ O
43 -X- _ O
% -X- _ O

In -X- _ O
Section -X- _ O
3 -X- _ O
, -X- _ O
we -X- _ O
showed -X- _ O
that -X- _ O
when -X- _ O
a -X- _ O
new -X- _ O
domain -X- _ O
emerges -X- _ O
, -X- _ O
the -X- _ O
change -X- _ O
in -X- _ O
vocabulary -X- _ O
mostly -X- _ O
affects -X- _ O
the -X- _ O
classification -X- _ O
of -X- _ O
implicitly -X- _ O
expressed -X- _ O
abuse -X- _ O
. -X- _ O
This -X- _ O
observation -X- _ O
is -X- _ O
in -X- _ O
line -X- _ O
with -X- _ O
findings -X- _ O
by -X- _ O
Fortuna -X- _ O
et -X- _ O
al -X- _ O
. -X- _ O
( -X- _ O
2021 -X- _ O
) -X- _ O
, -X- _ O
and -X- _ O
suggests -X- _ O
that -X- _ O
generalization -X- _ O
should -X- _ O
be -X- _ O
evaluated -X- _ O
on -X- _ O
implicit -X- _ O
and -X- _ O
explicit -X- _ O
abuse -X- _ O
separately -X- _ O
. -X- _ O
However -X- _ O
, -X- _ O
due -X- _ O
to -X- _ O
complexities -X- _ O
of -X- _ O
annotation -X- _ O
of -X- _ O
abusive -X- _ O
content -X- _ O
, -X- _ O
curating -X- _ O
separate -X- _ O
implicit -X- _ O
and -X- _ O
explicit -X- _ O
test -X- _ O
sets -X- _ O
is -X- _ O
too -X- _ O
costly -X- _ O
( -X- _ O
Wiegand -X- _ O
et -X- _ O
al -X- _ O
. -X- _ O
, -X- _ O
2021 -X- _ O
) -X- _ O
. -X- _ O
Instead -X- _ O
, -X- _ O
we -X- _ O
propose -X- _ O
to -X- _ O
adapt -X- _ O
the -X- _ O
Testing -X- _ B-MethodName
Concept -X- _ I-MethodName
Activation -X- _ I-MethodName
Vector -X- _ I-MethodName
( -X- _ O
TCAV -X- _ B-MethodName
) -X- _ O
algorithm -X- _ O
, -X- _ O
originally -X- _ O
developed -X- _ O
for -X- _ O
image -X- _ O
classification -X- _ O
( -X- _ O
Kim -X- _ O
et -X- _ O
al -X- _ O
. -X- _ O
, -X- _ O
2018 -X- _ O
) -X- _ O
, -X- _ O
to -X- _ O
calculate -X- _ O
the -X- _ O
classifiers -X- _ O
' -X- _ O
sensitivity -X- _ O
to -X- _ O
explicit -X- _ O
and -X- _ O
implicit -X- _ O
COVID -X- _ O
- -X- _ O
related -X- _ O
racism -X- _ O
, -X- _ O
using -X- _ O
only -X- _ O
a -X- _ O
small -X- _ O
set -X- _ O
of -X- _ O
examples -X- _ O
. -X- _ O
Then -X- _ O
, -X- _ O
we -X- _ O
show -X- _ O
how -X- _ O
these -X- _ O
sensitivities -X- _ O
can -X- _ O
explain -X- _ O
the -X- _ O
generalizations -X- _ O
observed -X- _ O
in -X- _ O
Table -X- _ O
3 -X- _ O
. -X- _ O

TCAV -X- _ B-MethodName
background -X- _ O
and -X- _ O
implementation -X- _ O

TCAV -X- _ B-MethodName
is -X- _ O
a -X- _ O
post -X- _ O
- -X- _ O
training -X- _ O
interpretability -X- _ O
method -X- _ O
to -X- _ O
measure -X- _ O
how -X- _ O
important -X- _ O
a -X- _ O
user -X- _ O
- -X- _ O
chosen -X- _ O
concept -X- _ O
is -X- _ O
for -X- _ O
a -X- _ O
prediction -X- _ O
, -X- _ O
even -X- _ O
if -X- _ O
the -X- _ O
concept -X- _ O
was -X- _ O
not -X- _ O
directly -X- _ O
used -X- _ O
as -X- _ O
a -X- _ O
feature -X- _ O
during -X- _ O
the -X- _ O
training -X- _ O
. -X- _ O
The -X- _ O
concept -X- _ O
is -X- _ O
defined -X- _ O
with -X- _ O
a -X- _ O
set -X- _ O
of -X- _ O
concept -X- _ O
examples -X- _ O
. -X- _ O

To -X- _ O
illustrate -X- _ O
, -X- _ O
Kim -X- _ O
et -X- _ O
al -X- _ O
. -X- _ O
( -X- _ O
2018 -X- _ O
) -X- _ O
suggest -X- _ O
" -X- _ O
stripes -X- _ O
" -X- _ O
as -X- _ O
a -X- _ O
visual -X- _ O
concept -X- _ O
relevant -X- _ O
to -X- _ O
the -X- _ O
class -X- _ O
" -X- _ O
zebra -X- _ O
" -X- _ O
, -X- _ O
and -X- _ O
then -X- _ O
operationally -X- _ O
define -X- _ O
the -X- _ O
" -X- _ O
stripes -X- _ O
" -X- _ O
concept -X- _ O
by -X- _ O
collecting -X- _ O
examples -X- _ O
of -X- _ O
images -X- _ O
containing -X- _ O
stripes -X- _ O
. -X- _ O

In -X- _ O
our -X- _ O
language -X- _ O
- -X- _ O
based -X- _ O
TCAV -X- _ B-MethodName
method -X- _ O
, -X- _ O
a -X- _ O
concept -X- _ O
is -X- _ O
defined -X- _ O
by -X- _ O
a -X- _ O
set -X- _ O
of -X- _ O
manually -X- _ O
chosen -X- _ O
textual -X- _ O
examples -X- _ O
. -X- _ O

We -X- _ O
collect -X- _ O
examples -X- _ O
from -X- _ O
held -X- _ O
- -X- _ O
out -X- _ O
subsets -X- _ O
or -X- _ O
other -X- _ O
available -X- _ O
data -X- _ O
sources -X- _ O
and -X- _ O
manually -X- _ O
annotate -X- _ O
them -X- _ O
for -X- _ O
the -X- _ O
concept -X- _ O
of -X- _ O
interest -X- _ O
( -X- _ O
for -X- _ O
example -X- _ O
, -X- _ O
explicit -X- _ O
anti -X- _ O
- -X- _ O
Asian -X- _ O
abuse -X- _ O
) -X- _ O
. -X- _ O
Then -X- _ O
, -X- _ O
we -X- _ O
represent -X- _ O
the -X- _ O
concept -X- _ O
by -X- _ O
averaging -X- _ O
the -X- _ O
representations -X- _ O
of -X- _ O
the -X- _ O
examples -X- _ O
that -X- _ O
convey -X- _ O
that -X- _ O
concept -X- _ O
, -X- _ O
similarly -X- _ O
to -X- _ O
how -X- _ O
the -X- _ O
" -X- _ O
stripes -X- _ O
" -X- _ O
concept -X- _ O
is -X- _ O
represented -X- _ O
by -X- _ O
several -X- _ O
images -X- _ O
that -X- _ O
include -X- _ O
stripes -X- _ O
. -X- _ O

Here -X- _ O
, -X- _ O
we -X- _ O
consider -X- _ O
concepts -X- _ O
such -X- _ O
as -X- _ O
COVID-19 -X- _ O
, -X- _ O
hate -X- _ O
speech -X- _ O
, -X- _ O
and -X- _ O
anti -X- _ O
- -X- _ O
Asian -X- _ O
abuse -X- _ O
, -X- _ O
but -X- _ O
the -X- _ O
approach -X- _ O
generalizes -X- _ O
to -X- _ O
any -X- _ O
concept -X- _ O
that -X- _ O
can -X- _ O
be -X- _ O
defined -X- _ O
through -X- _ O
a -X- _ O
set -X- _ O
of -X- _ O
example -X- _ O
texts -X- _ O
. -X- _ O
Using -X- _ O
these -X- _ O
examples -X- _ O
, -X- _ O
a -X- _ O
Concept -X- _ O
Activation -X- _ O
Vector -X- _ O
( -X- _ O
CAV -X- _ O
) -X- _ O
is -X- _ O
learned -X- _ O
to -X- _ O
represent -X- _ O
the -X- _ O
concept -X- _ O
in -X- _ O
the -X- _ O
activation -X- _ O
space -X- _ O
of -X- _ O
the -X- _ O
classifier -X- _ O
. -X- _ O
Then -X- _ O
, -X- _ O
directional -X- _ O
derivatives -X- _ O
are -X- _ O
used -X- _ O
to -X- _ O
calculate -X- _ O
the -X- _ O
sensitivity -X- _ O
of -X- _ O
predictions -X- _ O
to -X- _ O
changes -X- _ O
in -X- _ O
inputs -X- _ O
towards -X- _ O
the -X- _ O
direction -X- _ O
of -X- _ O
the -X- _ O
concept -X- _ O
, -X- _ O
at -X- _ O
the -X- _ O
neural -X- _ O
activation -X- _ O
layer -X- _ O
. -X- _ O

We -X- _ O
adapt -X- _ O
the -X- _ O
TCAV -X- _ B-MethodName
procedure -X- _ O
for -X- _ O
a -X- _ O
binary -X- _ O
RoBERTa -X- _ O
- -X- _ O
based -X- _ O
classifier -X- _ O
to -X- _ O
measure -X- _ O
the -X- _ O
importance -X- _ O
of -X- _ O
a -X- _ O
concept -X- _ O
to -X- _ O
the -X- _ O
positive -X- _ O
class -X- _ O
. -X- _ O
For -X- _ O
any -X- _ O
input -X- _ O
text -X- _ O
, -X- _ O
x -X- _ O
∈ -X- _ O
R -X- _ O
k×n -X- _ O
, -X- _ O
with -X- _ O
k -X- _ O
words -X- _ O
in -X- _ O
the -X- _ O
ndimensional -X- _ O
input -X- _ O
space -X- _ O
, -X- _ O
we -X- _ O
consider -X- _ O
the -X- _ O
RoBERTa -X- _ O
encoder -X- _ O
of -X- _ O
the -X- _ O
classifier -X- _ O
as -X- _ O
f -X- _ O
emb -X- _ O
: -X- _ O
R -X- _ O
k×n -X- _ O
→ -X- _ O
R -X- _ O
m -X- _ O
, -X- _ O
which -X- _ O
maps -X- _ O
the -X- _ O
input -X- _ O
text -X- _ O
to -X- _ O
its -X- _ O
RoBERTa -X- _ O
representation -X- _ O
( -X- _ O
the -X- _ O
representation -X- _ O
for -X- _ O
[ -X- _ O
CLS -X- _ O
] -X- _ O
token -X- _ O
) -X- _ O
, -X- _ O
r -X- _ O
∈ -X- _ O
R -X- _ O
m -X- _ O
. -X- _ O
For -X- _ O
each -X- _ O
concept -X- _ O
, -X- _ O
C -X- _ O
, -X- _ O
we -X- _ O
collect -X- _ O
N -X- _ O
C -X- _ O
concept -X- _ O
examples -X- _ O
, -X- _ O
and -X- _ O
map -X- _ O
them -X- _ O
to -X- _ O
RoBERTa -X- _ O
representations -X- _ O
r -X- _ O
j -X- _ O
C -X- _ O
, -X- _ O
j -X- _ O
= -X- _ O
1 -X- _ O
, -X- _ O
... -X- _ O
, -X- _ O
N -X- _ O
C -X- _ O
. -X- _ O
To -X- _ O
represent -X- _ O
C -X- _ O
in -X- _ O
the -X- _ O
activation -X- _ O
space -X- _ O
, -X- _ O
we -X- _ O
calculate -X- _ O
P -X- _ O
number -X- _ O
of -X- _ O
CAVs -X- _ O
, -X- _ O
υ -X- _ O
p -X- _ O
C -X- _ O
, -X- _ O
by -X- _ O
averaging -X- _ O
6 -X- _ O
the -X- _ O
RoBERTa -X- _ O
representations -X- _ O
of -X- _ O
N -X- _ O
υ -X- _ O
randomly -X- _ O
chosen -X- _ O
concept -X- _ O
examples -X- _ O
: -X- _ O
6 -X- _ O
In -X- _ O
the -X- _ O
original -X- _ O
TCAV -X- _ O
algorithm -X- _ O
, -X- _ O
a -X- _ O
linear -X- _ O
classifier -X- _ O
is -X- _ O
trained -X- _ O
to -X- _ O
separate -X- _ O
representations -X- _ O
of -X- _ O
concept -X- _ O
examples -X- _ O
and -X- _ O
random -X- _ O
examples -X- _ O
. -X- _ O
Then -X- _ O
, -X- _ O
the -X- _ O
vector -X- _ O
orthogonal -X- _ O
to -X- _ O
the -X- _ O
decision -X- _ O
boundary -X- _ O
of -X- _ O
this -X- _ O
classifier -X- _ O
is -X- _ O
used -X- _ O
as -X- _ O
the -X- _ O
CAV -X- _ O
. -X- _ O
We -X- _ O
experimented -X- _ O
with -X- _ O
training -X- _ O
a -X- _ O
linear -X- _ O
classifier -X- _ O
and -X- _ O
found -X- _ O
that -X- _ O
the -X- _ O
choice -X- _ O
of -X- _ O
random -X- _ O
utterances -X- _ O
has -X- _ O
a -X- _ O
huge -X- _ O
impact -X- _ O
on -X- _ O
the -X- _ O
results -X- _ O
to -X- _ O
the -X- _ O
point -X- _ O
that -X- _ O
the -X- _ O
results -X- _ O
are -X- _ O
not -X- _ O
reproducible -X- _ O
. -X- _ O
More -X- _ O
stable -X- _ O
results -X- _ O
are -X- _ O
obtained -X- _ O
when -X- _ O
CAVs -X- _ O
are -X- _ O
produced -X- _ O
by -X- _ O
averaging -X- _ O
the -X- _ O
RoBERTa -X- _ O
representations -X- _ O
. -X- _ O

υ -X- _ O
p -X- _ O
C -X- _ O
= -X- _ O
1 -X- _ O
Nυ -X- _ O
Nυ -X- _ O
j=1 -X- _ O
r -X- _ O
j -X- _ O
C -X- _ O
p -X- _ O
= -X- _ O
1 -X- _ O
, -X- _ O
.. -X- _ O
, -X- _ O
P -X- _ O
( -X- _ O
1 -X- _ O
) -X- _ O

where -X- _ O
N -X- _ O
υ -X- _ O
< -X- _ O
N -X- _ O
C -X- _ O
. -X- _ O
The -X- _ O
conceptual -X- _ O
sensitivity -X- _ O
of -X- _ O
the -X- _ O
positive -X- _ O
class -X- _ O
to -X- _ O
the -X- _ O
υ -X- _ O
p -X- _ O
C -X- _ O
, -X- _ O
at -X- _ O
input -X- _ O
x -X- _ O
can -X- _ O
be -X- _ O
computed -X- _ O
as -X- _ O
the -X- _ O
directional -X- _ O
derivative -X- _ O
S -X- _ O
C -X- _ O
, -X- _ O
p -X- _ O
( -X- _ O
x -X- _ O
) -X- _ O
: -X- _ O

S -X- _ O
C -X- _ O
, -X- _ O
p -X- _ O
( -X- _ O
x -X- _ O
) -X- _ O
= -X- _ O
lim -X- _ O
ϵ→0 -X- _ O
h -X- _ O
( -X- _ O
f -X- _ O
emb -X- _ O
( -X- _ O
x -X- _ O
) -X- _ O
+ϵυ -X- _ O
p -X- _ O
C -X- _ O
) -X- _ O
−h -X- _ O
( -X- _ O
f -X- _ O
emb -X- _ O
( -X- _ O
x -X- _ O
) -X- _ O
) -X- _ O
ϵ -X- _ O
= -X- _ O
▽ -X- _ O
h -X- _ O
( -X- _ O
f -X- _ O
emb -X- _ O
( -X- _ O
x -X- _ O
) -X- _ O
) -X- _ O
.υ -X- _ O
p -X- _ O
C -X- _ O
( -X- _ O
2 -X- _ O

) -X- _ O

A -X- _ O
TCAV -X- _ B-MethodName
score -X- _ O
close -X- _ O
to -X- _ O
one -X- _ O
indicates -X- _ O
that -X- _ O
for -X- _ O
the -X- _ O
majority -X- _ O
of -X- _ O
input -X- _ O
examples -X- _ O
the -X- _ O
logit -X- _ O
value -X- _ O
increases -X- _ O
. -X- _ O
Equation -X- _ O
3 -X- _ O
defines -X- _ O
a -X- _ O
distribution -X- _ O
of -X- _ O
scores -X- _ O
for -X- _ O
the -X- _ O
concept -X- _ O
C -X- _ O
; -X- _ O
we -X- _ O
compute -X- _ O
the -X- _ O
mean -X- _ O
and -X- _ O
standard -X- _ O
deviation -X- _ O
of -X- _ O
this -X- _ O
distribution -X- _ O
to -X- _ O
determine -X- _ O
the -X- _ O
overall -X- _ O
sensitivity -X- _ O
of -X- _ O
the -X- _ O
classifier -X- _ O
to -X- _ O
the -X- _ O
concept -X- _ O
C -X- _ O
. -X- _ O

We -X- _ O
define -X- _ O
each -X- _ O
concept -X- _ O
C -X- _ O
with -X- _ O
N -X- _ O
C -X- _ O
= -X- _ O
100 -X- _ O
manually -X- _ O
chosen -X- _ O
examples -X- _ O
, -X- _ O
and -X- _ O
experiment -X- _ O
with -X- _ O
six -X- _ O
concepts -X- _ O
described -X- _ O
in -X- _ O
random -X- _ O
tweets -X- _ O
collected -X- _ O
with -X- _ O
stopwords -X- _ O
as -X- _ O
input -X- _ O
examples -X- _ O
X -X- _ O
( -X- _ O
see -X- _ O
Equation -X- _ O
3 -X- _ O
) -X- _ O
. -X- _ O
7 -X- _ O
Table -X- _ O
5 -X- _ O
presents -X- _ O
the -X- _ O
means -X- _ O
and -X- _ O
standard -X- _ O
deviations -X- _ O
of -X- _ O
the -X- _ O
TCAV -X- _ B-MethodName
score -X- _ O
distributions -X- _ O
for -X- _ O
the -X- _ O
classifiers -X- _ O
trained -X- _ O
on -X- _ O
Wiki -X- _ B-DatasetName
, -X- _ O
Founta -X- _ B-DatasetName
, -X- _ O
EA -X- _ B-DatasetName
, -X- _ O
and -X- _ O
CH -X- _ B-DatasetName
datasets -X- _ O
, -X- _ O
respectively -X- _ O
. -X- _ O
First -X- _ O
, -X- _ O
we -X- _ O
observe -X- _ O
that -X- _ O
all -X- _ O
TCAV -X- _ B-MethodName
scores -X- _ O
calculated -X- _ O
for -X- _ O
a -X- _ O
random -X- _ O
, -X- _ O
non -X- _ O
- -X- _ O
coherent -X- _ O
set -X- _ O
of -X- _ O
examples -X- _ O
are -X- _ O
zero -X- _ O
; -X- _ O
i.e. -X- _ O
, -X- _ O
as -X- _ O
expected -X- _ O
, -X- _ O
the -X- _ O
TCAV -X- _ B-MethodName
scores -X- _ O
do -X- _ O
not -X- _ O
indicate -X- _ O
any -X- _ O
association -X- _ O
between -X- _ O
a -X- _ O
non -X- _ O
- -X- _ O
coherent -X- _ O
concept -X- _ O
and -X- _ O
the -X- _ O
positive -X- _ O
class -X- _ O
. -X- _ O
Also -X- _ O
, -X- _ O
as -X- _ O
expected -X- _ O
, -X- _ O
none -X- _ O
of -X- _ O
the -X- _ O
classifiers -X- _ O
associate -X- _ O
the -X- _ O
non -X- _ O
- -X- _ O
hateful -X- _ O
COVID -X- _ O
- -X- _ O
related -X- _ O
concept -X- _ O
to -X- _ O
the -X- _ O
positive -X- _ O
class -X- _ O
. -X- _ O
Note -X- _ O
that -X- _ O
a -X- _ O
zero -X- _ O
TCAV -X- _ B-MethodName
score -X- _ O
can -X- _ O
be -X- _ O
due -X- _ O
to -X- _ O
the -X- _ O
absence -X- _ O
of -X- _ O
that -X- _ O
concept -X- _ O
in -X- _ O
the -X- _ O
training -X- _ O
data -X- _ O
( -X- _ O
e.g. -X- _ O
, -X- _ O
the -X- _ O
COVID -X- _ O
concept -X- _ O
for -X- _ O
the -X- _ O
Wiki -X- _ B-DatasetName
and -X- _ O
Founta -X- _ B-DatasetName
classifiers -X- _ O
) -X- _ O
, -X- _ O
insignificance -X- _ O
of -X- _ O
the -X- _ O
topic -X- _ O
for -X- _ O
predicting -X- _ O
the -X- _ O
positive -X- _ O
label -X- _ O
( -X- _ O
e.g. -X- _ O
, -X- _ O
the -X- _ O
COVID -X- _ O
concept -X- _ O
for -X- _ O
the -X- _ O
EA -X- _ B-DatasetName
classifier -X- _ O
) -X- _ O
, -X- _ O
or -X- _ O
the -X- _ O
lack -X- _ O
of -X- _ O
coherence -X- _ O
among -X- _ O
the -X- _ O
concept -X- _ O
examples -X- _ O
( -X- _ O
such -X- _ O
as -X- _ O
the -X- _ O
concept -X- _ O
defined -X- _ O
by -X- _ O
random -X- _ O
examples -X- _ O
) -X- _ O
. -X- _ O
A -X- _ O
TCAV -X- _ B-MethodName
score -X- _ O
close -X- _ O
to -X- _ O
1 -X- _ O
, -X- _ O
on -X- _ O
the -X- _ O
other -X- _ O
hand -X- _ O
, -X- _ O
indicates -X- _ O
the -X- _ O
importance -X- _ O
of -X- _ O
a -X- _ O
concept -X- _ O
for -X- _ O
positive -X- _ O
prediction -X- _ O
. -X- _ O
These -X- _ O
observations -X- _ O
set -X- _ O
a -X- _ O
solid -X- _ O
baseline -X- _ O
for -X- _ O
interpreting -X- _ O
the -X- _ O
TCAV -X- _ B-MethodName
scores -X- _ O
, -X- _ O
calculated -X- _ O
for -X- _ O
other -X- _ O
concepts -X- _ O
. -X- _ O
Here -X- _ O
we -X- _ O
ask -X- _ O
whether -X- _ O
the -X- _ O
generated -X- _ O
TCAV -X- _ B-MethodName
scores -X- _ O
can -X- _ O
explain -X- _ O
the -X- _ O
generalization -X- _ O
performances -X- _ O
observed -X- _ O
in -X- _ O
Table -X- _ O
3 -X- _ O
. -X- _ O

We -X- _ O
consider -X- _ O
a -X- _ O
classifier -X- _ O
to -X- _ O
be -X- _ O
sensitive -X- _ O
to -X- _ O
a -X- _ O
concept -X- _ O
if -X- _ O
its -X- _ O
average -X- _ O
TCAV -X- _ B-MethodName
score -X- _ O
is -X- _ O
significantly -X- _ O
different -X- _ O
( -X- _ O
according -X- _ O
to -X- _ O
the -X- _ O
t -X- _ O
- -X- _ O
test -X- _ O
with -X- _ O
p -X- _ O
< -X- _ O
0.001 -X- _ O
) -X- _ O
from -X- _ O
the -X- _ O
average -X- _ O
TCAV -X- _ B-MethodName
score -X- _ O
of -X- _ O
a -X- _ O
non -X- _ O
- -X- _ O
coherent -X- _ O
random -X- _ O
concept -X- _ O
. -X- _ O
First -X- _ O
, -X- _ O
we -X- _ O
observe -X- _ O
that -X- _ O
the -X- _ O
general -X- _ O
classifiers -X- _ O
are -X- _ O
only -X- _ O
sensitive -X- _ O
to -X- _ O
the -X- _ O
explicit -X- _ O
type -X- _ O
of -X- _ O
COVID -X- _ O
- -X- _ O
related -X- _ O
abusive -X- _ O
language -X- _ O
. -X- _ O
This -X- _ O
confirms -X- _ O
that -X- _ O
the -X- _ O
classifiers -X- _ O
generalize -X- _ O
better -X- _ O
to -X- _ O
the -X- _ O
explicit -X- _ O
type -X- _ O
of -X- _ O
an -X- _ O
emerging -X- _ O
domain -X- _ O
of -X- _ O
abusive -X- _ O
language -X- _ O
. -X- _ O
We -X- _ O
also -X- _ O
note -X- _ O
that -X- _ O
Wiki -X- _ O
- -X- _ O
exp -X- _ O
, -X- _ O
is -X- _ O
sensitive -X- _ O
to -X- _ O
the -X- _ O
explicit -X- _ O
anti -X- _ O
- -X- _ O
Asian -X- _ O
concept -X- _ O
. -X- _ O

Second -X- _ O
, -X- _ O
the -X- _ O
classifier -X- _ O
trained -X- _ O
with -X- _ O
mostly -X- _ O
explicit -X- _ O
COVID -X- _ O
- -X- _ O
related -X- _ O
data -X- _ O
( -X- _ O
CH -X- _ B-DatasetName
) -X- _ O
is -X- _ O
not -X- _ O
sensitive -X- _ O
to -X- _ O
the -X- _ O
implicit -X- _ O
abuse -X- _ O
concept -X- _ O
. -X- _ O
8 -X- _ O
The -X- _ O
only -X- _ O
classifier -X- _ O
that -X- _ O
is -X- _ O
sensitive -X- _ O
to -X- _ O
the -X- _ O
explicit -X- _ O
and -X- _ O
both -X- _ O
implicit -X- _ O
COVID -X- _ O
- -X- _ O
related -X- _ O
abusive -X- _ O
concepts -X- _ O
is -X- _ O
the -X- _ O
EA -X- _ B-DatasetName
classifier -X- _ O
. -X- _ O
Classifiers -X- _ O
trained -X- _ O
on -X- _ O
the -X- _ O
COVID -X- _ O
datasets -X- _ O
are -X- _ O
also -X- _ O
not -X- _ O
sensitive -X- _ O
to -X- _ O
the -X- _ O
generic -X- _ O
hate -X- _ O
concept -X- _ O
, -X- _ O
which -X- _ O
encompasses -X- _ O
a -X- _ O
much -X- _ O
broader -X- _ O
range -X- _ O
of -X- _ O
target -X- _ O
groups -X- _ O
. -X- _ O
Overall -X- _ O
, -X- _ O
these -X- _ O
findings -X- _ O
stress -X- _ O
the -X- _ O
importance -X- _ O
of -X- _ O
including -X- _ O
implicitly -X- _ O
abusive -X- _ O
examples -X- _ O
in -X- _ O
the -X- _ O
training -X- _ O
data -X- _ O
for -X- _ O
better -X- _ O
generalizability -X- _ O
within -X- _ O
and -X- _ O
across -X- _ O
domains -X- _ O
. -X- _ O

Here -X- _ O
, -X- _ O
we -X- _ O
suggest -X- _ O
that -X- _ O
implicit -X- _ O
examples -X- _ O
are -X- _ O
more -X- _ O
informative -X- _ O
( -X- _ O
less -X- _ O
redundant -X- _ O
) -X- _ O
for -X- _ O
updating -X- _ O
a -X- _ O
general -X- _ O
classifier -X- _ O
and -X- _ O
provide -X- _ O
a -X- _ O
quantitative -X- _ O
metric -X- _ O
to -X- _ O
guide -X- _ O
the -X- _ O
data -X- _ O
augmentation -X- _ O
process -X- _ O
. -X- _ O
We -X- _ O
extend -X- _ O
the -X- _ O
TCAV -X- _ B-MethodName
methodology -X- _ O
to -X- _ O
estimate -X- _ O
the -X- _ O
Degree -X- _ B-MethodName
of -X- _ I-MethodName
Explicitness -X- _ I-MethodName
or -X- _ O
DoE -X- _ B-MethodName
of -X- _ O
an -X- _ O
utterance -X- _ O
. -X- _ O
We -X- _ O
showed -X- _ O
that -X- _ O
the -X- _ O
average -X- _ O
TCAV -X- _ B-MethodName
score -X- _ O
of -X- _ O
the -X- _ O
positive -X- _ O
class -X- _ O
for -X- _ O
the -X- _ O
explicit -X- _ O
concept -X- _ O
is -X- _ O
close -X- _ O
to -X- _ O
1 -X- _ O
. -X- _ O
DoE -X- _ B-MethodName
is -X- _ O
based -X- _ O
on -X- _ O
the -X- _ O
idea -X- _ O
that -X- _ O
adding -X- _ O
one -X- _ O
example -X- _ O
to -X- _ O
an -X- _ O
explicit -X- _ O
concept -X- _ O
will -X- _ O
not -X- _ O
affect -X- _ O
its -X- _ O
average -X- _ O
TCAV -X- _ B-MethodName
score -X- _ O
( -X- _ O
i.e. -X- _ O
, -X- _ O
it -X- _ O
will -X- _ O
still -X- _ O
be -X- _ O
close -X- _ O
to -X- _ O
1 -X- _ O
) -X- _ O
, -X- _ O
if -X- _ O
the -X- _ O
added -X- _ O
example -X- _ O
is -X- _ O
explicitly -X- _ O
abusive -X- _ O
. -X- _ O
However -X- _ O
, -X- _ O
adding -X- _ O
an -X- _ O
implicit -X- _ O
example -X- _ O
presumably -X- _ O
will -X- _ O
change -X- _ O
the -X- _ O
direction -X- _ O
of -X- _ O
all -X- _ O
CAVs -X- _ O
and -X- _ O
reduce -X- _ O
the -X- _ O
sensitivity -X- _ O
of -X- _ O
the -X- _ O
classifier -X- _ O
to -X- _ O
this -X- _ O
modified -X- _ O
concept -X- _ O
. -X- _ O
Here -X- _ O
, -X- _ O
we -X- _ O
modify -X- _ O
Equation -X- _ O
1and -X- _ O
calculate -X- _ O
each -X- _ O
CAV -X- _ O
by -X- _ O
averaging -X- _ O
the -X- _ O
RoBERTa -X- _ O
representations -X- _ O
of -X- _ O
N -X- _ O
υ -X- _ O
− -X- _ O
1 -X- _ O
explicit -X- _ O
concept -X- _ O
examples -X- _ O
, -X- _ O
and -X- _ O
the -X- _ O
new -X- _ O
utterance -X- _ O
for -X- _ O
which -X- _ O
we -X- _ O
want -X- _ O
the -X- _ O
degree -X- _ O
of -X- _ O
explicitness -X- _ O
, -X- _ O
x -X- _ O
new -X- _ O
, -X- _ O
with -X- _ O
representation -X- _ O
r -X- _ O
new -X- _ O
. -X- _ O
Thus -X- _ O
, -X- _ O
8 -X- _ O
We -X- _ O
do -X- _ O
not -X- _ O
measure -X- _ O
the -X- _ O
sensitivity -X- _ O
of -X- _ O
this -X- _ O
classifier -X- _ O
to -X- _ O
the -X- _ O
explicit -X- _ O
anti -X- _ O
- -X- _ O
Asian -X- _ O
and -X- _ O
implicit -X- _ O
CH -X- _ O
concepts -X- _ O
, -X- _ O
since -X- _ O
their -X- _ O
concept -X- _ O
examples -X- _ O
are -X- _ O
included -X- _ O
in -X- _ O
the -X- _ O
training -X- _ O
set -X- _ O
of -X- _ O
the -X- _ O
classifier -X- _ O
. -X- _ O

υ -X- _ O
p -X- _ O
new -X- _ O
= -X- _ O
1 -X- _ O
N -X- _ O
υ -X- _ O
( -X- _ O
Nυ−1 -X- _ O
j=1 -X- _ O
r -X- _ O
j -X- _ O
C -X- _ O
+ -X- _ O
r -X- _ O
new -X- _ O
) -X- _ O
, -X- _ O
p -X- _ O
= -X- _ O
1 -X- _ O
, -X- _ O
.. -X- _ O
, -X- _ O
P -X- _ O

We -X- _ O
then -X- _ O
calculate -X- _ O
the -X- _ O
average -X- _ O
TCAV -X- _ B-MethodName
score -X- _ O
for -X- _ O
each -X- _ O
x -X- _ O
new -X- _ O
as -X- _ O
its -X- _ O
DoE -X- _ B-MethodName
score -X- _ O
. -X- _ O
If -X- _ O
the -X- _ O
new -X- _ O
utterance -X- _ O
, -X- _ O
x -X- _ O
new -X- _ O
, -X- _ O
is -X- _ O
explicitly -X- _ O
abusive -X- _ O
, -X- _ O
υ -X- _ O
p -X- _ O
new -X- _ O
will -X- _ O
represent -X- _ O
an -X- _ O
explicit -X- _ O
concept -X- _ O
, -X- _ O
and -X- _ O
the -X- _ O
average -X- _ O
TCAV -X- _ B-MethodName
score -X- _ O
, -X- _ O
i.e. -X- _ O
, -X- _ O
mean -X- _ O
( -X- _ O
T -X- _ O
CAV -X- _ O
C -X- _ O
, -X- _ O
p -X- _ O
) -X- _ O
will -X- _ O
remain -X- _ O
close -X- _ O
to -X- _ O
1 -X- _ O
. -X- _ O
However -X- _ O
, -X- _ O
the -X- _ O
less -X- _ O
explicit -X- _ O
the -X- _ O
new -X- _ O
example -X- _ O
is -X- _ O
, -X- _ O
the -X- _ O
more -X- _ O
υ -X- _ O
p -X- _ O
new -X- _ O
will -X- _ O
diverge -X- _ O
from -X- _ O
representations -X- _ O
of -X- _ O
explicit -X- _ O
abuse -X- _ O
, -X- _ O
and -X- _ O
the -X- _ O
average -X- _ O
score -X- _ O
will -X- _ O
drop -X- _ O
. -X- _ O
We -X- _ O
use -X- _ O
N -X- _ O
υ -X- _ O
= -X- _ O
3 -X- _ O
in -X- _ O
the -X- _ O
following -X- _ O
experiments -X- _ O
. -X- _ O

Data -X- _ O
Augmentation -X- _ O
with -X- _ O
DoE -X- _ B-MethodName
score -X- _ O

We -X- _ O
now -X- _ O
use -X- _ O
the -X- _ O
DoE -X- _ B-MethodName
score -X- _ O
to -X- _ O
direct -X- _ O
data -X- _ O
augmentation -X- _ O
. -X- _ O
We -X- _ O
consider -X- _ O
a -X- _ O
scenario -X- _ O
where -X- _ O
a -X- _ O
general -X- _ O
classifier -X- _ O
should -X- _ O
be -X- _ O
re -X- _ O
- -X- _ O
trained -X- _ O
with -X- _ O
an -X- _ O
augmented -X- _ O
dataset -X- _ O
to -X- _ O
include -X- _ O
emerging -X- _ O
types -X- _ O
of -X- _ O
abusive -X- _ O
language -X- _ O
. -X- _ O
As -X- _ O
we -X- _ O
showed -X- _ O
, -X- _ O
general -X- _ O
classifiers -X- _ O
are -X- _ O
already -X- _ O
sensitive -X- _ O
to -X- _ O
explicit -X- _ O
abuse -X- _ O
. -X- _ O
Therefore -X- _ O
, -X- _ O
we -X- _ O
hypothesize -X- _ O
that -X- _ O
implicit -X- _ O
examples -X- _ O
are -X- _ O
more -X- _ O
benefi- -X- _ O
cial -X- _ O
for -X- _ O
updating -X- _ O
the -X- _ O
classifier -X- _ O
. -X- _ O
Here -X- _ O
, -X- _ O
we -X- _ O
describe -X- _ O
a -X- _ O
novel -X- _ O
DoE -X- _ O
- -X- _ O
based -X- _ O
augmentation -X- _ O
approach -X- _ O
and -X- _ O
contrast -X- _ O
it -X- _ O
with -X- _ O
the -X- _ O
conventional -X- _ O
process -X- _ O
of -X- _ O
choosing -X- _ O
augmentation -X- _ O
examples -X- _ O
based -X- _ O
on -X- _ O
the -X- _ O
classification -X- _ O
confidence -X- _ O
( -X- _ O
Zhu -X- _ O
et -X- _ O
al -X- _ O
. -X- _ O
, -X- _ O
2008 -X- _ O
; -X- _ O
Chen -X- _ O
et -X- _ O
al -X- _ O
. -X- _ O
, -X- _ O
2019 -X- _ O
) -X- _ O
. -X- _ O

We -X- _ O
consider -X- _ O
the -X- _ O
general -X- _ O
Wiki -X- _ B-DatasetName
classifier -X- _ O
. -X- _ O
Our -X- _ O
goal -X- _ O
is -X- _ O
to -X- _ O
find -X- _ O
a -X- _ O
small -X- _ O
but -X- _ O
sufficient -X- _ O
portion -X- _ O
of -X- _ O
the -X- _ O
EA -X- _ B-DatasetName
train -X- _ O
set -X- _ O
to -X- _ O
augment -X- _ O
the -X- _ O
original -X- _ O
Wiki -X- _ B-DatasetName
train -X- _ O
set -X- _ O
, -X- _ O
so -X- _ O
that -X- _ O
the -X- _ O
classifier -X- _ O
is -X- _ O
able -X- _ O
to -X- _ O
handle -X- _ O
COVID -X- _ O
- -X- _ O
related -X- _ O
anti -X- _ O
- -X- _ O
Asian -X- _ O
hate -X- _ O
speech -X- _ O
. -X- _ O
We -X- _ O
calculate -X- _ O
the -X- _ O
DoE -X- _ B-MethodName
and -X- _ O
confidence -X- _ O
scores -X- _ O
for -X- _ O
all -X- _ O
the -X- _ O
examples -X- _ O
in -X- _ O
the -X- _ O
EA -X- _ B-DatasetName
train -X- _ O
set -X- _ O
and -X- _ O
add -X- _ O
the -X- _ O
N -X- _ O
examples -X- _ O
with -X- _ O
the -X- _ O
lowest -X- _ O
scores -X- _ O
to -X- _ O
the -X- _ O
original -X- _ O
Wiki -X- _ O
train -X- _ O
set -X- _ O
. -X- _ O
We -X- _ O
vary -X- _ O
N -X- _ O
from -X- _ O
1 -X- _ O
K -X- _ O
to -X- _ O
6 -X- _ O
K -X- _ O
, -X- _ O
with -X- _ O
a -X- _ O
1 -X- _ O
K -X- _ O
step -X- _ O
. -X- _ O
After -X- _ O
the -X- _ O
augmentation -X- _ O
data -X- _ O
size -X- _ O
reaches -X- _ O
6 -X- _ O
K -X- _ O
, -X- _ O
the -X- _ O
classifier -X- _ O
performance -X- _ O
on -X- _ O
the -X- _ O
original -X- _ O
Wiki -X- _ O
test -X- _ O
set -X- _ O
drops -X- _ O
substantially -X- _ O
for -X- _ O
both -X- _ O
techniques -X- _ O
. -X- _ O
Also -X- _ O
, -X- _ O
note -X- _ O
that -X- _ O
as -X- _ O
the -X- _ O
size -X- _ O
of -X- _ O
the -X- _ O
augmentation -X- _ O
dataset -X- _ O
increases -X- _ O
, -X- _ O
the -X- _ O
two -X- _ O
methods -X- _ O
converge -X- _ O
to -X- _ O
the -X- _ O
same -X- _ O
performance -X- _ O
. -X- _ O

Figure -X- _ O
2 -X- _ O
shows -X- _ O
the -X- _ O
F1 -X- _ B-MetricName
- -X- _ O
score -X- _ O
of -X- _ O
the -X- _ O
classifiers -X- _ O
updated -X- _ O
using -X- _ O
the -X- _ O
DoE -X- _ B-MethodName
and -X- _ O
confidence -X- _ O
- -X- _ O
based -X- _ O
augmentation -X- _ O
methods -X- _ O
on -X- _ O
the -X- _ O
original -X- _ O
test -X- _ O
set -X- _ O
( -X- _ O
Wiki -X- _ B-DatasetName
) -X- _ O
and -X- _ O
the -X- _ O
new -X- _ O
test -X- _ O
set -X- _ O
( -X- _ O
EA -X- _ B-DatasetName
) -X- _ O
for -X- _ O
different -X- _ O
augmentation -X- _ O
sizes -X- _ O
. -X- _ O
( -X- _ O
Precision -X- _ O
and -X- _ O
recall -X- _ O
figures -X- _ O
are -X- _ O
provided -X- _ O
in -X- _ O
Appendix -X- _ O
D. -X- _ O
) -X- _ O
Since -X- _ O
only -X- _ O
EA -X- _ B-DatasetName
is -X- _ O
used -X- _ O
for -X- _ O
augmentation -X- _ O
, -X- _ O
we -X- _ O
evaluate -X- _ O
the -X- _ O
classifiers -X- _ O
on -X- _ O
this -X- _ O
dataset -X- _ O
to -X- _ O
find -X- _ O
the -X- _ O
optimum -X- _ O
size -X- _ O
for -X- _ O
the -X- _ O
augmented -X- _ O
training -X- _ O
set -X- _ O
and -X- _ O
only -X- _ O
evaluate -X- _ O
the -X- _ O
best -X- _ O
performing -X- _ O
classifiers -X- _ O
on -X- _ O
CH -X- _ B-DatasetName
. -X- _ O
We -X- _ O
expect -X- _ O
that -X- _ O
an -X- _ O
efficient -X- _ O
augmentation -X- _ O
should -X- _ O
maintain -X- _ O
the -X- _ O
performance -X- _ O
on -X- _ O
Wiki -X- _ O
and -X- _ O
reach -X- _ O
acceptable -X- _ O
results -X- _ O
on -X- _ O
EA -X- _ B-DatasetName
test -X- _ O
set -X- _ O
. -X- _ O
DoE -X- _ B-MethodName
is -X- _ O
better -X- _ O
at -X- _ O
learning -X- _ O
the -X- _ O
new -X- _ O
type -X- _ O
of -X- _ O
abuse -X- _ O
: -X- _ O
On -X- _ O
the -X- _ O
EA -X- _ B-DatasetName
dataset -X- _ O
, -X- _ O
DoE -X- _ B-MethodName
achieves -X- _ O
better -X- _ O
results -X- _ O
than -X- _ O
the -X- _ O
confidence -X- _ O
- -X- _ O
based -X- _ O
augmentation -X- _ O
method -X- _ O
for -X- _ O
all -X- _ O
augmentation -X- _ O
sizes -X- _ O
, -X- _ O
except -X- _ O
for -X- _ O
N= -X- _ O
5 -X- _ O
K -X- _ O
, -X- _ O
where -X- _ O
the -X- _ O
performances -X- _ O
of -X- _ O
the -X- _ O
two -X- _ O
methods -X- _ O
are -X- _ O
comparable -X- _ O
. -X- _ O
DoE -X- _ B-MethodName
is -X- _ O
better -X- _ O
at -X- _ O
maintaining -X- _ O
performance -X- _ O
on -X- _ O
the -X- _ O
original -X- _ O
dataset -X- _ O
: -X- _ O
DoE -X- _ B-MethodName
outperforms -X- _ O
the -X- _ O
confidencebased -X- _ O
method -X- _ O
on -X- _ O
the -X- _ O
Wiki -X- _ B-DatasetName
dataset -X- _ O
. -X- _ O
For -X- _ O
all -X- _ O
augmentation -X- _ O
sizes -X- _ O
, -X- _ O
the -X- _ O
performance -X- _ O
of -X- _ O
the -X- _ O
DoE -X- _ B-MethodName
- -X- _ O
augmented -X- _ O
classifier -X- _ O
on -X- _ O
this -X- _ O
class -X- _ O
stays -X- _ O
within -X- _ O
2 -X- _ B-MetricValue
% -X- _ I-MetricValue
of -X- _ O
the -X- _ O
baseline -X- _ O
( -X- _ O
the -X- _ O
F1 -X- _ B-MetricName
- -X- _ I-MetricName
score -X- _ I-MetricName
of -X- _ O
the -X- _ O
classifier -X- _ O
trained -X- _ O
just -X- _ O
on -X- _ O
the -X- _ O
Wiki -X- _ O
data -X- _ O
) -X- _ O
, -X- _ O
whereas -X- _ O
for -X- _ O
the -X- _ O
confidence -X- _ O
- -X- _ O
based -X- _ O
augmentation -X- _ O
, -X- _ O
we -X- _ O
observe -X- _ O
up -X- _ O
to -X- _ O
6 -X- _ B-MetricValue
% -X- _ I-MetricValue
drop -X- _ O
depending -X- _ O
on -X- _ O
the -X- _ O
size -X- _ O
of -X- _ O
the -X- _ O
added -X- _ O
data -X- _ O
. -X- _ O
DoE -X- _ O
is -X- _ O
better -X- _ O
overall -X- _ O
: -X- _ O
Table -X- _ O
6 -X- _ O
presents -X- _ O
the -X- _ O
best -X- _ O
results -X- _ O
achieved -X- _ O
by -X- _ O
the -X- _ O
two -X- _ O
augmentation -X- _ O
methods -X- _ O
on -X- _ O
the -X- _ O
EA -X- _ O
test -X- _ O
set -X- _ O
: -X- _ O
AUC -X- _ B-MetricName
score -X- _ O
of -X- _ O
0.81 -X- _ B-MetricValue
for -X- _ O
the -X- _ O
DoEbased -X- _ B-MethodName
augmentation -X- _ O
obtained -X- _ O
with -X- _ O
3 -X- _ O
K -X- _ O
added -X- _ O
examples -X- _ O
, -X- _ O
and -X- _ O
AUC -X- _ B-MetricName
score -X- _ O
of -X- _ O
0.69 -X- _ B-MetricValue
for -X- _ O
the -X- _ O
confidencebased -X- _ O
augmentation -X- _ O
obtained -X- _ O
with -X- _ O
4 -X- _ O
K -X- _ O
added -X- _ O
examples -X- _ O
. -X- _ O
For -X- _ O
comparison -X- _ O
, -X- _ O
we -X- _ O
also -X- _ O
show -X- _ O
the -X- _ O
baseline -X- _ O
results -X- _ O
for -X- _ O
the -X- _ O
original -X- _ O
Wiki -X- _ B-DatasetName
classifier -X- _ O
and -X- _ O
the -X- _ O
classifier -X- _ O
trained -X- _ O
on -X- _ O
the -X- _ O
combined -X- _ O
Wiki -X- _ B-DatasetName
and -X- _ O
full -X- _ O
EA -X- _ B-DatasetName
train -X- _ O
sets -X- _ O
. -X- _ O
Although -X- _ O
we -X- _ O
did -X- _ O
not -X- _ O
optimize -X- _ O
the -X- _ O
augmentation -X- _ O
for -X- _ O
the -X- _ O
CH -X- _ B-DatasetName
dataset -X- _ O
, -X- _ O
our -X- _ O
evaluation -X- _ O
shows -X- _ O
that -X- _ O
DoE -X- _ B-MethodName
performs -X- _ O
favourably -X- _ O
on -X- _ O
this -X- _ O
dataset -X- _ O
, -X- _ O
as -X- _ O
well -X- _ O
. -X- _ O
We -X- _ O
conclude -X- _ O
that -X- _ O
the -X- _ O
new -X- _ O
DoE -X- _ B-MethodName
- -X- _ O
based -X- _ O
augmentation -X- _ O
method -X- _ O
maintains -X- _ O
the -X- _ O
classification -X- _ O
performance -X- _ O
on -X- _ O
the -X- _ O
original -X- _ O
dataset -X- _ O
, -X- _ O
while -X- _ O
outperforming -X- _ O
the -X- _ O
other -X- _ O
method -X- _ O
on -X- _ O
the -X- _ O
new -X- _ O
data -X- _ O
. -X- _ O

We -X- _ O
also -X- _ O
qualitatively -X- _ O
assess -X- _ O
the -X- _ O
classifier -X- _ O
's -X- _ O
output -X- _ O
before -X- _ O
and -X- _ O
after -X- _ O
data -X- _ O
augmentation -X- _ O
with -X- _ O
DoE. -X- _ B-MethodName
While -X- _ O
explicitly -X- _ O
abusive -X- _ O
utterances -X- _ O
( -X- _ O
e.g. -X- _ O
, -X- _ O
" -X- _ O
f*ck -X- _ O
you -X- _ O
china -X- _ O
and -X- _ O
your -X- _ O
chinese -X- _ O
virus -X- _ O
" -X- _ O
) -X- _ O
are -X- _ O
often -X- _ O
correctly -X- _ O
classified -X- _ O
both -X- _ O
before -X- _ O
and -X- _ O
after -X- _ O
re -X- _ O
- -X- _ O
training -X- _ O
, -X- _ O
many -X- _ O
implicitly -X- _ O
abusive -X- _ O
examples -X- _ O
( -X- _ O
e.g. -X- _ O
, -X- _ O
" -X- _ O
it -X- _ O
is -X- _ O
not -X- _ O
covid -X- _ O
19 -X- _ O
but -X- _ O
wuhanvirus -X- _ O
" -X- _ O
) -X- _ O
are -X- _ O
handled -X- _ O
correctly -X- _ O
by -X- _ O
the -X- _ O
classifier -X- _ O
only -X- _ O
after -X- _ O
re -X- _ O
- -X- _ O
training -X- _ O
. -X- _ O

Generalizability -X- _ O
has -X- _ O
been -X- _ O
an -X- _ O
active -X- _ O
research -X- _ O
area -X- _ O
in -X- _ O
NLP -X- _ O
( -X- _ O
Ettinger -X- _ O
et -X- _ O
al -X- _ O
. -X- _ O
, -X- _ O
2017 -X- _ O
; -X- _ O
Hendrycks -X- _ O
et -X- _ O
al -X- _ O
. -X- _ O
, -X- _ O
2020 -X- _ O
) -X- _ O
. -X- _ O
In -X- _ O
a -X- _ O
recent -X- _ O
review -X- _ O
, -X- _ O
Yin -X- _ O
and -X- _ O
Zubiaga -X- _ O
( -X- _ O
2021 -X- _ O
) -X- _ O
hate -X- _ O
speech -X- _ O
detection -X- _ O
systems -X- _ O
and -X- _ O
recommended -X- _ O
possible -X- _ O
future -X- _ O
directions -X- _ O
, -X- _ O
including -X- _ O
improving -X- _ O
data -X- _ O
quality -X- _ O
and -X- _ O
reducing -X- _ O
overfitting -X- _ O
through -X- _ O
transfer -X- _ O
learning -X- _ O
. -X- _ O
Several -X- _ O
studies -X- _ O
evaluated -X- _ O
generalizability -X- _ O
in -X- _ O
abuse -X- _ O
detection -X- _ O
through -X- _ O
cross -X- _ O
- -X- _ O
dataset -X- _ O
evaluation -X- _ O
( -X- _ O
Swamy -X- _ O
et -X- _ O
al -X- _ O
. -X- _ O
, -X- _ O
2019 -X- _ O
; -X- _ O
Wiegand -X- _ O
et -X- _ O
al -X- _ O
. -X- _ O
, -X- _ O
2019 -X- _ O
) -X- _ O
, -X- _ O
direct -X- _ O
dataset -X- _ O
analysis -X- _ O
( -X- _ O
Fortuna -X- _ O
et -X- _ O
al -X- _ O
. -X- _ O
, -X- _ O
2020 -X- _ O
) -X- _ O
or -X- _ O
topic -X- _ O
modeling -X- _ O
on -X- _ O
the -X- _ O
training -X- _ O
data -X- _ O
( -X- _ O
Nejadgholi -X- _ O
and -X- _ O
Kiritchenko -X- _ O
, -X- _ O
2020 -X- _ O
) -X- _ O
. -X- _ O
Fortuna -X- _ O
et -X- _ O
al -X- _ O
. -X- _ O
( -X- _ O
2021 -X- _ O
) -X- _ O
showed -X- _ O
that -X- _ O
the -X- _ O
lack -X- _ O
of -X- _ O
generalizability -X- _ O
is -X- _ O
rooted -X- _ O
in -X- _ O
the -X- _ O
imbalances -X- _ O
between -X- _ O
implicit -X- _ O
and -X- _ O
explicit -X- _ O
examples -X- _ O
in -X- _ O
training -X- _ O
data -X- _ O
. -X- _ O

The -X- _ O
distinction -X- _ O
between -X- _ O
explicit -X- _ O
and -X- _ O
implicit -X- _ O
abuse -X- _ O
has -X- _ O
been -X- _ O
recognized -X- _ O
as -X- _ O
an -X- _ O
important -X- _ O
factor -X- _ O
in -X- _ O
abuse -X- _ O
detection -X- _ O
( -X- _ O
Waseem -X- _ O
et -X- _ O
al -X- _ O
. -X- _ O
, -X- _ O
2017 -X- _ O
; -X- _ O
Caselli -X- _ O
et -X- _ O
al -X- _ O
. -X- _ O
, -X- _ O
2020 -X- _ O
) -X- _ O
. -X- _ O
Wiegand -X- _ O
et -X- _ O
al -X- _ O
. -X- _ O
( -X- _ O
2019 -X- _ O
) -X- _ O
showed -X- _ O
that -X- _ O
lexiconbased -X- _ O
sampling -X- _ O
strategies -X- _ O
fail -X- _ O
to -X- _ O
collect -X- _ O
implicit -X- _ O
abuse -X- _ O
and -X- _ O
most -X- _ O
of -X- _ O
the -X- _ O
annotated -X- _ O
datasets -X- _ O
are -X- _ O
overwhelmed -X- _ O
with -X- _ O
explicit -X- _ O
examples -X- _ O
. -X- _ O
Breitfeller -X- _ O
et -X- _ O
al -X- _ O
. -X- _ O
( -X- _ O
2019 -X- _ O
) -X- _ O
showed -X- _ O
that -X- _ O
inter -X- _ O
- -X- _ O
annotation -X- _ O
agreement -X- _ O
is -X- _ O
low -X- _ O
when -X- _ O
labeling -X- _ O
the -X- _ O
implicit -X- _ O
abuse -X- _ O
utterances -X- _ O
, -X- _ O
as -X- _ O
sometimes -X- _ O
specific -X- _ O
knowledge -X- _ O
is -X- _ O
required -X- _ O
in -X- _ O
order -X- _ O
to -X- _ O
understand -X- _ O
the -X- _ O
implicit -X- _ O
statements -X- _ O
. -X- _ O
For -X- _ O
better -X- _ O
detection -X- _ O
of -X- _ O
implicitly -X- _ O
stated -X- _ O
abuse -X- _ O
, -X- _ O
large -X- _ O
annotated -X- _ O
datasets -X- _ O
with -X- _ O
hierarchical -X- _ O
annotations -X- _ O
are -X- _ O
needed -X- _ O
( -X- _ O
Sap -X- _ O
et -X- _ O
al -X- _ O
. -X- _ O
, -X- _ O
2020 -X- _ O
) -X- _ O
, -X- _ O
so -X- _ O
that -X- _ O
automatic -X- _ O
detection -X- _ O
systems -X- _ O
can -X- _ O
learn -X- _ O
from -X- _ O
a -X- _ O
wide -X- _ O
variety -X- _ O
of -X- _ O
such -X- _ O
training -X- _ O
examples -X- _ O
. -X- _ O
Field -X- _ O
and -X- _ O
Tsvetkov -X- _ O
( -X- _ O
2020 -X- _ O
) -X- _ O
proposed -X- _ O
propensity -X- _ O
matching -X- _ O
and -X- _ O
adversarial -X- _ O
learning -X- _ O
to -X- _ O
force -X- _ O
the -X- _ O
model -X- _ O
to -X- _ O
focus -X- _ O
on -X- _ O
signs -X- _ O
of -X- _ O
implicit -X- _ O
bias -X- _ O
. -X- _ O
Wiegand -X- _ O
et -X- _ O
al -X- _ O
. -X- _ O
( -X- _ O
2021 -X- _ O
) -X- _ O
created -X- _ O
a -X- _ O
novel -X- _ O
dataset -X- _ O
for -X- _ O
studying -X- _ O
implicit -X- _ O
abuse -X- _ O
and -X- _ O
presented -X- _ O
a -X- _ O
range -X- _ O
of -X- _ O
linguistic -X- _ O
features -X- _ O
for -X- _ O
contrastive -X- _ O
analysis -X- _ O
of -X- _ O
abusive -X- _ O
content -X- _ O
. -X- _ O
We -X- _ O
define -X- _ O
explicitness -X- _ O
as -X- _ O
obvious -X- _ O
rudeness -X- _ O
and -X- _ O
hateful -X- _ O
language -X- _ O
regardless -X- _ O
of -X- _ O
the -X- _ O
social -X- _ O
context -X- _ O
and -X- _ O
introduce -X- _ O
a -X- _ O
quantitative -X- _ O
measure -X- _ O
of -X- _ O
explicitness -X- _ O
from -X- _ O
a -X- _ O
trained -X- _ O
classifier -X- _ O
's -X- _ O
point -X- _ O
of -X- _ O
view -X- _ O
. -X- _ O

Data -X- _ O
augmentation -X- _ O
has -X- _ O
been -X- _ O
used -X- _ O
to -X- _ O
improve -X- _ O
the -X- _ O
robustness -X- _ O
of -X- _ O
abuse -X- _ O
detection -X- _ O
classifiers -X- _ O
. -X- _ O
To -X- _ O
mitigate -X- _ O
biases -X- _ O
towards -X- _ O
specific -X- _ O
terms -X- _ O
( -X- _ O
e.g. -X- _ O
, -X- _ O
identity -X- _ O
terms -X- _ O
) -X- _ O
, -X- _ O
one -X- _ O
strategy -X- _ O
is -X- _ O
to -X- _ O
add -X- _ O
benign -X- _ O
examples -X- _ O
con -X- _ O
- -X- _ O
taining -X- _ O
the -X- _ O
biased -X- _ O
terms -X- _ O
to -X- _ O
the -X- _ O
training -X- _ O
data -X- _ O
( -X- _ O
Dixon -X- _ O
et -X- _ O
al -X- _ O
. -X- _ O
, -X- _ O
2018 -X- _ O
; -X- _ O
Badjatiya -X- _ O
et -X- _ O
al -X- _ O
. -X- _ O
, -X- _ O
2019 -X- _ O
) -X- _ O
. -X- _ O
Other -X- _ O
works -X- _ O
combined -X- _ O
multiple -X- _ O
datasets -X- _ O
to -X- _ O
achieve -X- _ O
better -X- _ O
generalizations -X- _ O
, -X- _ O
using -X- _ O
a -X- _ O
set -X- _ O
of -X- _ O
probing -X- _ O
instances -X- _ O
( -X- _ O
Han -X- _ O
and -X- _ O
Tsvetkov -X- _ O
, -X- _ O
2020 -X- _ O
) -X- _ O
, -X- _ O
multi -X- _ O
- -X- _ O
task -X- _ O
training -X- _ O
( -X- _ O
Waseem -X- _ O
et -X- _ O
al -X- _ O
. -X- _ O
, -X- _ O
2018 -X- _ O
) -X- _ O
, -X- _ O
and -X- _ O
domain -X- _ O
adaptation -X- _ O
( -X- _ O
Karan -X- _ O
and -X- _ O
Šnajder -X- _ O
, -X- _ O
2018 -X- _ O
) -X- _ O
. -X- _ O
In -X- _ O
contrast -X- _ O
to -X- _ O
these -X- _ O
works -X- _ O
, -X- _ O
we -X- _ O
take -X- _ O
an -X- _ O
interpretability -X- _ O
- -X- _ O
based -X- _ O
approach -X- _ O
and -X- _ O
guide -X- _ O
the -X- _ O
data -X- _ O
collection -X- _ O
process -X- _ O
by -X- _ O
mapping -X- _ O
the -X- _ O
new -X- _ O
data -X- _ O
on -X- _ O
the -X- _ O
implicit -X- _ O
vs. -X- _ O
explicit -X- _ O
spectrum -X- _ O
. -X- _ O

As -X- _ O
real -X- _ O
- -X- _ O
world -X- _ O
data -X- _ O
evolves -X- _ O
, -X- _ O
we -X- _ O
would -X- _ O
like -X- _ O
to -X- _ O
be -X- _ O
able -X- _ O
to -X- _ O
query -X- _ O
a -X- _ O
trained -X- _ O
model -X- _ O
to -X- _ O
determine -X- _ O
whether -X- _ O
it -X- _ O
generalizes -X- _ O
to -X- _ O
the -X- _ O
new -X- _ O
data -X- _ O
, -X- _ O
without -X- _ O
the -X- _ O
need -X- _ O
for -X- _ O
a -X- _ O
large -X- _ O
, -X- _ O
annotated -X- _ O
test -X- _ O
set -X- _ O
. -X- _ O
We -X- _ O
adopted -X- _ O
the -X- _ O
TCAV -X- _ B-MethodName
algorithm -X- _ O
to -X- _ O
quantify -X- _ O
the -X- _ O
sensitivity -X- _ O
of -X- _ O
text -X- _ O
classifiers -X- _ O
to -X- _ O
human -X- _ O
- -X- _ O
chosen -X- _ O
concepts -X- _ O
, -X- _ O
defined -X- _ O
with -X- _ O
a -X- _ O
small -X- _ O
set -X- _ O
of -X- _ O
examples -X- _ O
. -X- _ O
We -X- _ O
used -X- _ O
this -X- _ O
technique -X- _ O
to -X- _ O
compare -X- _ O
the -X- _ O
generalizations -X- _ O
of -X- _ O
abusive -X- _ O
language -X- _ O
classifiers -X- _ O
, -X- _ O
trained -X- _ O
with -X- _ O
pre -X- _ O
- -X- _ O
pandemic -X- _ O
data -X- _ O
, -X- _ O
to -X- _ O
explicit -X- _ O
and -X- _ O
implicit -X- _ O
COVID -X- _ O
- -X- _ O
related -X- _ O
anti -X- _ O
- -X- _ O
Asian -X- _ O
racism -X- _ O
. -X- _ O

We -X- _ O
then -X- _ O
proposed -X- _ O
a -X- _ O
sensitivity -X- _ O
- -X- _ O
based -X- _ O
data -X- _ O
augmentation -X- _ O
approach -X- _ O
, -X- _ O
to -X- _ O
improve -X- _ O
generalizability -X- _ O
to -X- _ O
emerging -X- _ O
categories -X- _ O
. -X- _ O
We -X- _ O
showed -X- _ O
that -X- _ O
in -X- _ O
the -X- _ O
case -X- _ O
of -X- _ O
abuse -X- _ B-TaskName
detection -X- _ I-TaskName
, -X- _ O
the -X- _ O
most -X- _ O
informative -X- _ O
examples -X- _ O
are -X- _ O
implicitly -X- _ O
abusive -X- _ O
utterances -X- _ O
from -X- _ O
the -X- _ O
new -X- _ O
category -X- _ O
. -X- _ O
Our -X- _ O
approach -X- _ O
collects -X- _ O
implicit -X- _ O
augmentation -X- _ O
examples -X- _ O
and -X- _ O
achieves -X- _ O
higher -X- _ O
generalization -X- _ O
to -X- _ O
the -X- _ O
new -X- _ O
category -X- _ O
compared -X- _ O
to -X- _ O
confidence -X- _ O
- -X- _ O
based -X- _ O
sampling -X- _ O
. -X- _ O
Strategies -X- _ O
for -X- _ O
choosing -X- _ O
the -X- _ O
optimal -X- _ O
set -X- _ O
of -X- _ O
concept -X- _ O
examples -X- _ O
should -X- _ O
be -X- _ O
explored -X- _ O
in -X- _ O
the -X- _ O
future -X- _ O
. -X- _ O

Content -X- _ O
moderation -X- _ O
is -X- _ O
a -X- _ O
critical -X- _ O
application -X- _ O
with -X- _ O
potential -X- _ O
of -X- _ O
significant -X- _ O
benefits -X- _ O
, -X- _ O
but -X- _ O
also -X- _ O
harms -X- _ O
to -X- _ O
human -X- _ O
well -X- _ O
- -X- _ O
being -X- _ O
. -X- _ O
Therefore -X- _ O
, -X- _ O
ethics -X- _ O
- -X- _ O
related -X- _ O
issues -X- _ O
in -X- _ O
content -X- _ O
moderation -X- _ O
have -X- _ O
been -X- _ O
actively -X- _ O
studied -X- _ O
in -X- _ O
NLP -X- _ O
and -X- _ O
other -X- _ O
disciplines -X- _ O
( -X- _ O
Vidgen -X- _ O
et -X- _ O
al -X- _ O
. -X- _ O
, -X- _ O
2019 -X- _ O
; -X- _ O
Wiegand -X- _ O
et -X- _ O
al -X- _ O
. -X- _ O
, -X- _ O
2019 -X- _ O
; -X- _ O
Kiritchenko -X- _ O
et -X- _ O
al -X- _ O
. -X- _ O
, -X- _ O
2021 -X- _ O
; -X- _ O
Vidgen -X- _ O
and -X- _ O
Derczynski -X- _ O
, -X- _ O
2020 -X- _ O
) -X- _ O
. -X- _ O
These -X- _ O
include -X- _ O
sampling -X- _ O
and -X- _ O
annotation -X- _ O
biases -X- _ O
in -X- _ O
data -X- _ O
collection -X- _ O
, -X- _ O
al -X- _ O
- -X- _ O
gorithmic -X- _ O
bias -X- _ O
amplification -X- _ O
, -X- _ O
user -X- _ O
privacy -X- _ O
, -X- _ O
system -X- _ O
safety -X- _ O
and -X- _ O
security -X- _ O
, -X- _ O
and -X- _ O
human -X- _ O
control -X- _ O
of -X- _ O
technology -X- _ O
, -X- _ O
among -X- _ O
others -X- _ O
. -X- _ O
Our -X- _ O
work -X- _ O
aims -X- _ O
to -X- _ O
address -X- _ O
the -X- _ O
aspects -X- _ O
of -X- _ O
system -X- _ O
safety -X- _ O
and -X- _ O
fairness -X- _ O
by -X- _ O
adapting -X- _ O
the -X- _ O
model -X- _ O
to -X- _ O
newly -X- _ O
emerged -X- _ O
or -X- _ O
not -X- _ O
previously -X- _ O
covered -X- _ O
types -X- _ O
of -X- _ O
online -X- _ O
abuse -X- _ O
, -X- _ O
often -X- _ O
directed -X- _ O
against -X- _ O
marginalized -X- _ O
communities -X- _ O
. -X- _ O
We -X- _ O
employ -X- _ O
existing -X- _ O
datasets -X- _ O
( -X- _ O
with -X- _ O
all -X- _ O
their -X- _ O
limitations -X- _ O
) -X- _ O
and -X- _ O
use -X- _ O
them -X- _ O
only -X- _ O
for -X- _ O
illustration -X- _ O
purposes -X- _ O
and -X- _ O
preliminary -X- _ O
evaluation -X- _ O
of -X- _ O
the -X- _ O
proposed -X- _ O
methodology -X- _ O
. -X- _ O
When -X- _ O
deploying -X- _ O
the -X- _ O
technology -X- _ O
care -X- _ O
should -X- _ O
be -X- _ O
taken -X- _ O
to -X- _ O
adequately -X- _ O
address -X- _ O
other -X- _ O
ethics -X- _ O
- -X- _ O
related -X- _ O
issues -X- _ O
. -X- _ O
and -X- _ O
misclassified -X- _ O
if -X- _ O
positive -X- _ O
( -X- _ O
implicit -X- _ O
abuse -X- _ O
) -X- _ O
. -X- _ O
In -X- _ O
contrast -X- _ O
, -X- _ O
high -X- _ O
DoE -X- _ B-MethodName
examples -X- _ O
are -X- _ O
misclassified -X- _ O
if -X- _ O
negative -X- _ O
and -X- _ O
correctly -X- _ O
classified -X- _ O
if -X- _ O
positive -X- _ O
( -X- _ O
explicit -X- _ O
abuse -X- _ O
) -X- _ O
. -X- _ O
In -X- _ O
Section -X- _ O
6 -X- _ O
, -X- _ O
we -X- _ O
compare -X- _ O
the -X- _ O
classifiers -X- _ O
updated -X- _ O
with -X- _ O
DoE -X- _ B-MethodName
and -X- _ O
confidence -X- _ O
- -X- _ O
based -X- _ O
methods -X- _ O
using -X- _ O
classification -X- _ O
F1 -X- _ B-MetricName
- -X- _ O
score -X- _ O
. -X- _ O
Here -X- _ O
, -X- _ O
we -X- _ O
provide -X- _ O
a -X- _ O
more -X- _ O
finegrained -X- _ O
analysis -X- _ O
based -X- _ O
on -X- _ O
recall -X- _ O
and -X- _ O
precision -X- _ O
. -X- _ O
Figure -X- _ O
D.1 -X- _ O
shows -X- _ O
the -X- _ O
recall -X- _ O
and -X- _ O
precision -X- _ O
of -X- _ O
the -X- _ O
updated -X- _ O
classifiers -X- _ O
on -X- _ O
the -X- _ O
EA -X- _ B-DatasetName
dataset -X- _ O
. -X- _ O
This -X- _ O
figure -X- _ O
indicates -X- _ O
that -X- _ O
the -X- _ O
classifiers -X- _ O
updated -X- _ O
with -X- _ O
DoE -X- _ B-MethodName
are -X- _ O
much -X- _ O
more -X- _ O
successful -X- _ O
in -X- _ O
recognizing -X- _ O
abusive -X- _ O
utterances -X- _ O
than -X- _ O
the -X- _ O
classifiers -X- _ O
updated -X- _ O
with -X- _ O
confidence -X- _ O
, -X- _ O
but -X- _ O
misclassify -X- _ O
more -X- _ O
non -X- _ O
- -X- _ O
abusive -X- _ O
sentences -X- _ O
, -X- _ O
which -X- _ O
results -X- _ O
in -X- _ O
substantially -X- _ O
higher -X- _ O
recall -X- _ O
scores -X- _ O
, -X- _ O
but -X- _ O
slightly -X- _ O
lower -X- _ O
precision -X- _ O
scores -X- _ O
. -X- _ O
Note -X- _ O
that -X- _ O
in -X- _ O
computer -X- _ O
- -X- _ O
assisted -X- _ O
content -X- _ O
moderation -X- _ O
, -X- _ O
recall -X- _ B-MetricName
is -X- _ O
more -X- _ O
important -X- _ O
than -X- _ O
precision -X- _ B-MetricName
, -X- _ O
since -X- _ O
automatically -X- _ O
flagged -X- _ O
posts -X- _ O
are -X- _ O
assessed -X- _ O
by -X- _ O
human -X- _ O
moderators -X- _ O
to -X- _ O
make -X- _ O
the -X- _ O
final -X- _ O
decision -X- _ O
. -X- _ O

We -X- _ O
argue -X- _ O
that -X- _ O
the -X- _ O
higher -X- _ O
recall -X- _ O
and -X- _ O
lower -X- _ O
precision -X- _ O
of -X- _ O
classifiers -X- _ O
updated -X- _ O
with -X- _ O
DoE -X- _ B-MethodName
is -X- _ O
due -X- _ O
to -X- _ O
the -X- _ O
discrepancies -X- _ O
in -X- _ O
the -X- _ O
definitions -X- _ O
of -X- _ O
the -X- _ O
negative -X- _ O
classes -X- _ O
for -X- _ O
the -X- _ O
Wiki -X- _ B-DatasetName
and -X- _ O
EA -X- _ B-DatasetName
datasets -X- _ O
. -X- _ O
Previous -X- _ O
work -X- _ O
has -X- _ O
commented -X- _ O
on -X- _ O
the -X- _ O
difficulty -X- _ O
of -X- _ O
aligning -X- _ O
annotations -X- _ O
of -X- _ O
abusive -X- _ O
, -X- _ O
offensive -X- _ O
, -X- _ O
hateful -X- _ O
, -X- _ O
and -X- _ O
toxic -X- _ O
speech -X- _ O
across -X- _ O
different -X- _ O
datasets -X- _ O
( -X- _ O
Swamy -X- _ O
et -X- _ O
al -X- _ O
. -X- _ O
, -X- _ O
2019 -X- _ O
; -X- _ O
Kolhatkar -X- _ O
et -X- _ O
al -X- _ O
. -X- _ O
, -X- _ O
2019 -X- _ O
; -X- _ O
Fortuna -X- _ O
et -X- _ O
al -X- _ O
. -X- _ O
, -X- _ O
2021 -X- _ O
) -X- _ O
. -X- _ O
Here -X- _ O
, -X- _ O
we -X- _ O
also -X- _ O
observe -X- _ O
that -X- _ O
the -X- _ O
definitions -X- _ O
of -X- _ O
positive -X- _ O
( -X- _ O
abusive -X- _ O
) -X- _ O
and -X- _ O
negative -X- _ O
classes -X- _ O
differ -X- _ O
significantly -X- _ O
between -X- _ O
the -X- _ O
generalized -X- _ O
and -X- _ O
COVID -X- _ O
- -X- _ O
related -X- _ O
data -X- _ O
. -X- _ O
In -X- _ O
the -X- _ O
Wiki -X- _ B-DatasetName
and -X- _ O
Founta -X- _ B-DatasetName
datasets -X- _ O
, -X- _ O
the -X- _ O
positive -X- _ O
class -X- _ O
encompasses -X- _ O
a -X- _ O
wide -X- _ O
range -X- _ O
of -X- _ O
offensive -X- _ O
language -X- _ O
, -X- _ O
while -X- _ O
in -X- _ O
the -X- _ O
EA -X- _ B-DatasetName
and -X- _ O
CH -X- _ B-DatasetName
datasets -X- _ O
, -X- _ O
the -X- _ O
positive -X- _ O
class -X- _ O
is -X- _ O
restricted -X- _ O
to -X- _ O
hate -X- _ O
speech -X- _ O
and -X- _ O
other -X- _ O
more -X- _ O
intense -X- _ O
cases -X- _ O
of -X- _ O
expressed -X- _ O
negativity -X- _ O
. -X- _ O
Further -X- _ O
, -X- _ O
the -X- _ O
negative -X- _ O
class -X- _ O
in -X- _ O
Wiki -X- _ B-DatasetName
and -X- _ O
Founta -X- _ B-DatasetName
datasets -X- _ O
comprise -X- _ O
nonabusive -X- _ O
, -X- _ O
neutral -X- _ O
, -X- _ O
or -X- _ O
friendly -X- _ O
instances -X- _ O
while -X- _ O
in -X- _ O
the -X- _ O
EA -X- _ B-DatasetName
and -X- _ O
CH -X- _ B-DatasetName
datasets -X- _ O
the -X- _ O
negative -X- _ O
class -X- _ O
may -X- _ O
also -X- _ O
include -X- _ O
rude -X- _ O
and -X- _ O
offensive -X- _ O
texts -X- _ O
as -X- _ O
long -X- _ O
as -X- _ O
they -X- _ O
do -X- _ O
not -X- _ O
constitute -X- _ O
hate -X- _ O
speech -X- _ O
against -X- _ O
Asian -X- _ O
people -X- _ O
or -X- _ O
entities -X- _ O
. -X- _ O

In -X- _ O
Appendix -X- _ O
C -X- _ O
, -X- _ O
we -X- _ O
observe -X- _ O
that -X- _ O
low -X- _ O
DoE -X- _ B-MethodName
examples -X- _ O
are -X- _ O
correctly -X- _ O
classified -X- _ O
if -X- _ O
negative -X- _ O
and -X- _ O
misclassified -X- _ O
if -X- _ O
positive -X- _ O
( -X- _ O
implicit -X- _ O
abuse -X- _ O
) -X- _ O
. -X- _ O
In -X- _ O
contrast -X- _ O
, -X- _ O
high -X- _ O
DoE -X- _ B-MethodName
examples -X- _ O
are -X- _ O
misclassified -X- _ O
if -X- _ O
negative -X- _ O
and -X- _ O
correctly -X- _ O
classified -X- _ O
if -X- _ O
positive -X- _ O
( -X- _ O
explicit -X- _ O
abuse -X- _ O
) -X- _ O
. -X- _ O
We -X- _ O
use -X- _ O
this -X- _ O
observation -X- _ O
to -X- _ O
explain -X- _ O
higher -X- _ O
recall -X- _ O
of -X- _ O
the -X- _ O
confidence -X- _ O
- -X- _ O
based -X- _ O
method -X- _ O
in -X- _ O
comparison -X- _ O
with -X- _ O
the -X- _ O
DoE -X- _ B-MethodName
- -X- _ O
based -X- _ O
method -X- _ O
for -X- _ O
the -X- _ O
EA -X- _ O
- -X- _ O
negative -X- _ O
class -X- _ O
. -X- _ O
As -X- _ O
mentioned -X- _ O
before -X- _ O
, -X- _ O
while -X- _ O
EA -X- _ O
- -X- _ O
positive -X- _ O
fits -X- _ O
under -X- _ O
the -X- _ O
definition -X- _ O
of -X- _ O
' -X- _ O
toxicity -X- _ O
' -X- _ O
in -X- _ O
Wiki -X- _ O
- -X- _ O
positive -X- _ O
, -X- _ O
the -X- _ O
definition -X- _ O
of -X- _ O
EA -X- _ O
- -X- _ O
negative -X- _ O
is -X- _ O
inconsistent -X- _ O
with -X- _ O
the -X- _ O
definition -X- _ O
of -X- _ O
Wiki -X- _ O
- -X- _ O
negative -X- _ O
. -X- _ O
In -X- _ O
other -X- _ O
words -X- _ O
, -X- _ O
DoE -X- _ B-MethodName
tends -X- _ O
to -X- _ O
choose -X- _ O
negative -X- _ O
examples -X- _ O
that -X- _ O
the -X- _ O
Wiki -X- _ O
classifier -X- _ O
already -X- _ O
recognizes -X- _ O
as -X- _ O
negative -X- _ O
, -X- _ O
whereas -X- _ O
the -X- _ O
confidence -X- _ O
- -X- _ O
based -X- _ O
data -X- _ O
augmentation -X- _ O
selects -X- _ O
negative -X- _ O
examples -X- _ O
that -X- _ O
are -X- _ O
unknown -X- _ O
to -X- _ O
the -X- _ O
classifier -X- _ O
. -X- _ O
Therefore -X- _ O
, -X- _ O
the -X- _ O
classifier -X- _ O
augmented -X- _ O
with -X- _ O
low -X- _ O
confidence -X- _ O
scores -X- _ O
adapts -X- _ O
better -X- _ O
to -X- _ O
the -X- _ O
new -X- _ O
definition -X- _ O
of -X- _ O
negative -X- _ O
examples -X- _ O
than -X- _ O
the -X- _ O
classifier -X- _ O
updated -X- _ O
with -X- _ O
low -X- _ O
DoE -X- _ B-MethodName
scores -X- _ O
. -X- _ O
In -X- _ O
a -X- _ O
real -X- _ O
- -X- _ O
life -X- _ O
scenario -X- _ O
, -X- _ O
we -X- _ O
do -X- _ O
not -X- _ O
expect -X- _ O
the -X- _ O
definition -X- _ O
of -X- _ O
the -X- _ O
negative -X- _ O
class -X- _ O
to -X- _ O
change -X- _ O
over -X- _ O
time -X- _ O
, -X- _ O
so -X- _ O
precision -X- _ O
for -X- _ O
DoE -X- _ O
- -X- _ O
base -X- _ O
augmentation -X- _ O
should -X- _ O
not -X- _ O
suffer -X- _ O
. -X- _ O

All -X- _ O
of -X- _ O
our -X- _ O
models -X- _ O
are -X- _ O
binary -X- _ O
RoBERTa -X- _ O
- -X- _ O
based -X- _ O
classifiers -X- _ O
trained -X- _ O
with -X- _ O
the -X- _ O
default -X- _ O
settings -X- _ O
of -X- _ O
the -X- _ O
Trainer -X- _ O
module -X- _ O
from -X- _ O
the -X- _ O
Huggingface -X- _ O
library -X- _ O
9 -X- _ O
for -X- _ O
3 -X- _ O
training -X- _ O
epochs -X- _ O
, -X- _ O
on -X- _ O
a -X- _ O
Tesla -X- _ O
V100 -X- _ O
- -X- _ O
SXM2 -X- _ O
GPU -X- _ O
machine -X- _ O
, -X- _ O
batch -X- _ B-HyperparameterName
size -X- _ I-HyperparameterName
of -X- _ O
16 -X- _ B-HyperparameterValue
, -X- _ O
warm -X- _ B-HyperparameterName
- -X- _ I-HyperparameterName
up -X- _ I-HyperparameterName
steps -X- _ I-HyperparameterName
of -X- _ O
500 -X- _ B-HyperparameterValue
and -X- _ O
weight -X- _ B-HyperparameterName
decay -X- _ I-HyperparameterName
of -X- _ O
0.01 -X- _ B-HyperparameterValue
. -X- _ O
We -X- _ O
use -X- _ O
Roberta -X- _ O
- -X- _ O
base -X- _ O
model -X- _ O
, -X- _ O
which -X- _ O
includes -X- _ O
12 -X- _ O
layers -X- _ O
, -X- _ O
768 -X- _ O
hidden -X- _ O
nodes -X- _ O
, -X- _ O
12 -X- _ O
head -X- _ O
nodes -X- _ O
, -X- _ O
125 -X- _ O
M -X- _ O
parameters -X- _ O
, -X- _ O
and -X- _ O
add -X- _ O
a -X- _ O
linear -X- _ O
layer -X- _ O
with -X- _ O
two -X- _ O
nodes -X- _ O
for -X- _ O
binary -X- _ O
classification -X- _ O
. -X- _ O
Training -X- _ O
these -X- _ O
classifiers -X- _ O
takes -X- _ O
several -X- _ O
hours -X- _ O
depending -X- _ O
on -X- _ O
the -X- _ O
size -X- _ O
of -X- _ O
the -X- _ O
training -X- _ O
dataset -X- _ O
. -X- _ O

Besides -X- _ O
the -X- _ O
commonly -X- _ O
used -X- _ O
metrics -X- _ O
, -X- _ O
precision -X- _ O
and -X- _ O
recall -X- _ O
, -X- _ O
we -X- _ O
measure -X- _ O
averaged -X- _ B-MetricName
precision -X- _ I-MetricName
score -X- _ O
to -X- _ O
count -X- _ O
for -X- _ O
potential -X- _ O
threshold -X- _ O
adjustments -X- _ O
. -X- _ O
Averaged -X- _ B-MetricName
precision -X- _ I-MetricName
score -X- _ O
summarizes -X- _ O
a -X- _ O
precision -X- _ O
- -X- _ O
recall -X- _ O
curve -X- _ O
as -X- _ O
the -X- _ O
weighted -X- _ O
mean -X- _ O
of -X- _ O
precisions -X- _ O
at -X- _ O
each -X- _ O
threshold -X- _ O
, -X- _ O
weighted -X- _ O
by -X- _ O
the -X- _ O
increase -X- _ O
in -X- _ O
recall -X- _ O
from -X- _ O
the -X- _ O
previous -X- _ O
threshold -X- _ O
. -X- _ O
The -X- _ O
results -X- _ O
are -X- _ O
consistent -X- _ O
with -X- _ O
AUC -X- _ B-MetricName
and -X- _ O
F1 -X- _ B-MetricName
- -X- _ O
scores -X- _ O
reported -X- _ O
in -X- _ O
Table -X- _ O
3 -X- _ O
. -X- _ O

RelU -X- _ B-MethodName
- -X- _ I-MethodName
Net -X- _ I-MethodName
: -X- _ O
Syntax -X- _ O
- -X- _ O
aware -X- _ O
Graph -X- _ O
U -X- _ O
- -X- _ O
Net -X- _ O
for -X- _ O
Relational -X- _ B-TaskName
Triple -X- _ I-TaskName
Extraction -X- _ I-TaskName

Relational -X- _ B-TaskName
triple -X- _ I-TaskName
extraction -X- _ I-TaskName
is -X- _ O
a -X- _ O
critical -X- _ O
task -X- _ O
for -X- _ O
natural -X- _ O
language -X- _ O
processing -X- _ O
. -X- _ O
Existing -X- _ O
methods -X- _ O
mainly -X- _ O
focused -X- _ O
on -X- _ O
capturing -X- _ O
semantic -X- _ O
information -X- _ O
, -X- _ O
but -X- _ O
suffered -X- _ O
from -X- _ O
ignoring -X- _ O
the -X- _ O
syntactic -X- _ O
structure -X- _ O
of -X- _ O
the -X- _ O
sentence -X- _ O
, -X- _ O
which -X- _ O
is -X- _ O
proved -X- _ O
in -X- _ O
the -X- _ O
relation -X- _ O
classification -X- _ O
task -X- _ O
to -X- _ O
contain -X- _ O
rich -X- _ O
relational -X- _ O
information -X- _ O
. -X- _ O
This -X- _ O
is -X- _ O
due -X- _ O
to -X- _ O
the -X- _ O
absence -X- _ O
of -X- _ O
entity -X- _ O
locations -X- _ O
, -X- _ O
which -X- _ O
is -X- _ O
the -X- _ O
prerequisite -X- _ O
for -X- _ O
pruning -X- _ O
noisy -X- _ O
edges -X- _ O
from -X- _ O
the -X- _ O
dependency -X- _ O
tree -X- _ O
, -X- _ O
when -X- _ O
extracting -X- _ O
relational -X- _ O
triples -X- _ O
. -X- _ O
In -X- _ O
this -X- _ O
paper -X- _ O
, -X- _ O
we -X- _ O
propose -X- _ O
a -X- _ O
unified -X- _ O
framework -X- _ O
to -X- _ O
tackle -X- _ O
this -X- _ O
challenge -X- _ O
and -X- _ O
incorporate -X- _ O
syntactic -X- _ O
information -X- _ O
for -X- _ O
relational -X- _ O
triple -X- _ O
extraction -X- _ O
. -X- _ O
First -X- _ O
, -X- _ O
we -X- _ O
propose -X- _ O
to -X- _ O
automatically -X- _ O
contract -X- _ O
the -X- _ O
dependency -X- _ O
tree -X- _ O
into -X- _ O
a -X- _ O
core -X- _ O
relational -X- _ O
topology -X- _ O
and -X- _ O
eliminate -X- _ O
redundant -X- _ O
information -X- _ O
with -X- _ O
graph -X- _ O
pooling -X- _ O
operations -X- _ O
. -X- _ O
Then -X- _ O
, -X- _ O
we -X- _ O
propose -X- _ O
a -X- _ O
symmetrical -X- _ O
expanding -X- _ O
path -X- _ O
with -X- _ O
graph -X- _ O
unpooling -X- _ O
operations -X- _ O
to -X- _ O
fuse -X- _ O
the -X- _ O
contracted -X- _ O
core -X- _ O
syntactic -X- _ O
interactions -X- _ O
with -X- _ O
the -X- _ O
original -X- _ O
sentence -X- _ O
context -X- _ O
. -X- _ O
We -X- _ O
also -X- _ O
propose -X- _ O
a -X- _ O
bipartite -X- _ O
graph -X- _ O
matching -X- _ O
objective -X- _ O
function -X- _ O
to -X- _ O
capture -X- _ O
the -X- _ O
reflections -X- _ O
between -X- _ O
the -X- _ O
core -X- _ O
topology -X- _ O
and -X- _ O
golden -X- _ O
relational -X- _ O
facts -X- _ O
. -X- _ O
Since -X- _ O
our -X- _ O
model -X- _ O
shares -X- _ O
similar -X- _ O
contracting -X- _ O
and -X- _ O
expanding -X- _ O
paths -X- _ O
with -X- _ O
encoder -X- _ O
- -X- _ O
decoder -X- _ O
models -X- _ O
like -X- _ O
U -X- _ O
- -X- _ O
Net -X- _ O
, -X- _ O
we -X- _ O
name -X- _ O
our -X- _ O
model -X- _ O
as -X- _ O
Relation -X- _ B-MethodName
U -X- _ I-MethodName
- -X- _ I-MethodName
Net -X- _ I-MethodName
( -X- _ O
RelU -X- _ B-MethodName
- -X- _ I-MethodName
Net -X- _ I-MethodName
) -X- _ O
. -X- _ O
We -X- _ O
conduct -X- _ O
experiments -X- _ O
on -X- _ O
several -X- _ O
datasets -X- _ O
and -X- _ O
the -X- _ O
results -X- _ O
prove -X- _ O
the -X- _ O
effectiveness -X- _ O
of -X- _ O
our -X- _ O
method -X- _ O
. -X- _ O

Relational -X- _ B-TaskName
Triple -X- _ I-TaskName
Extraction -X- _ I-TaskName
( -X- _ O
RTE -X- _ B-TaskName
) -X- _ O
is -X- _ O
defined -X- _ O
as -X- _ O
automatically -X- _ O
recognizing -X- _ O
entity -X- _ O
pairs -X- _ O
and -X- _ O
the -X- _ O
semantic -X- _ O
relations -X- _ O
in -X- _ O
the -X- _ O
form -X- _ O
of -X- _ O
( -X- _ O
subject -X- _ O
, -X- _ O
relation -X- _ O
, -X- _ O
object -X- _ O
) -X- _ O
from -X- _ O
unstructured -X- _ O
text -X- _ O
. -X- _ O
It -X- _ O
is -X- _ O
a -X- _ O
critical -X- _ O
task -X- _ O
for -X- _ O
natural -X- _ O
language -X- _ O
processing -X- _ O
, -X- _ O
especially -X- _ O
for -X- _ O
constructing -X- _ O
large -X- _ O
- -X- _ O
scale -X- _ O
Knowledge -X- _ O
Graphs -X- _ O
( -X- _ O
KGs -X- _ O
) -X- _ O
from -X- _ O
unlabeled -X- _ O
corpus -X- _ O
( -X- _ O
Dong -X- _ O
et -X- _ O
al -X- _ O
. -X- _ O
, -X- _ O
2014 -X- _ O
) -X- _ O
. -X- _ O

Recent -X- _ O
work -X- _ O
proposed -X- _ O
several -X- _ O
neural -X- _ O
network -X- _ O
methods -X- _ O
to -X- _ O
extract -X- _ O
relational -X- _ O
triples -X- _ O
. -X- _ O
For -X- _ O
example -X- _ O
, -X- _ O
Zheng -X- _ O
et -X- _ O
al -X- _ O
. -X- _ O
( -X- _ O
2017 -X- _ O
) -X- _ O
formulated -X- _ O
this -X- _ O
task -X- _ O
as -X- _ O
sequence -X- _ O
tagging -X- _ O
problems -X- _ O
but -X- _ O
failed -X- _ O
to -X- _ O
extract -X- _ O
overlapping -X- _ O
triples -X- _ O
. -X- _ O
Wei -X- _ O
et -X- _ O
al -X- _ O
. -X- _ O
( -X- _ O
2020 -X- _ O
) -X- _ O
proposed -X- _ O
a -X- _ O
cascade -X- _ O
tagging -X- _ O
framework -X- _ O
to -X- _ O
solve -X- _ O
the -X- _ O
overlapping -X- _ O
problem -X- _ O
. -X- _ O
proposed -X- _ O
to -X- _ O
extract -X- _ O
the -X- _ O
implicit -X- _ O
relational -X- _ O
triples -X- _ O
which -X- _ O
are -X- _ O
not -X- _ O
explicitly -X- _ O
expressed -X- _ O
in -X- _ O
the -X- _ O
sentence -X- _ O
with -X- _ O
a -X- _ O
binary -X- _ O
pointer -X- _ O
network -X- _ O
. -X- _ O

Existing -X- _ O
methods -X- _ O
achieved -X- _ O
considerable -X- _ O
success -X- _ O
in -X- _ O
capturing -X- _ O
semantic -X- _ O
information -X- _ O
from -X- _ O
relational -X- _ O
mentions -X- _ O
. -X- _ O
However -X- _ O
, -X- _ O
they -X- _ O
usually -X- _ O
failed -X- _ O
to -X- _ O
incorporate -X- _ O
syntactic -X- _ O
structures -X- _ O
of -X- _ O
the -X- _ O
sentence -X- _ O
, -X- _ O
which -X- _ O
is -X- _ O
proved -X- _ O
to -X- _ O
contain -X- _ O
rich -X- _ O
relational -X- _ O
information -X- _ O
in -X- _ O
the -X- _ O
Relation -X- _ O
Classification -X- _ O
( -X- _ O
RC -X- _ O
) -X- _ O
task -X- _ O
( -X- _ O
Zhang -X- _ O
et -X- _ O
al -X- _ O
. -X- _ O
, -X- _ O
2018 -X- _ O
; -X- _ O
Guo -X- _ O
et -X- _ O
al -X- _ O
. -X- _ O
, -X- _ O
2019 -X- _ O
) -X- _ O
. -X- _ O
These -X- _ O
syntax -X- _ O
- -X- _ O
aware -X- _ O
RC -X- _ O
methods -X- _ O
usually -X- _ O
pruned -X- _ O
irrelevant -X- _ O
dependency -X- _ O
edges -X- _ O
according -X- _ O
to -X- _ O
the -X- _ O
known -X- _ O
locations -X- _ O
of -X- _ O
the -X- _ O
entity -X- _ O
pair -X- _ O
to -X- _ O
eliminate -X- _ O
the -X- _ O
noise -X- _ O
of -X- _ O
the -X- _ O
dependency -X- _ O
tree -X- _ O
. -X- _ O
For -X- _ O
example -X- _ O
, -X- _ O
the -X- _ O
relational -X- _ O
facts -X- _ O
in -X- _ O
Figure -X- _ O
1 -X- _ O
( -X- _ O
top -X- _ O
) -X- _ O
can -X- _ O
be -X- _ O
easily -X- _ O
inferred -X- _ O
given -X- _ O
the -X- _ O
dependency -X- _ O
paths -X- _ O
, -X- _ O
which -X- _ O
are -X- _ O
pruned -X- _ O
from -X- _ O
the -X- _ O
original -X- _ O
dependency -X- _ O
tree -X- _ O
using -X- _ O
the -X- _ O
locations -X- _ O
of -X- _ O
the -X- _ O
known -X- _ O
entity -X- _ O
pairs -X- _ O
. -X- _ O
Unfortunately -X- _ O
, -X- _ O
the -X- _ O
locations -X- _ O
of -X- _ O
entities -X- _ O
are -X- _ O
unknown -X- _ O
in -X- _ O
the -X- _ O
RTE -X- _ B-TaskName
task -X- _ O
, -X- _ O
as -X- _ O
shown -X- _ O
in -X- _ O
Figure -X- _ O
1 -X- _ O
( -X- _ O
bottom -X- _ O
) -X- _ O
. -X- _ O
This -X- _ O
absence -X- _ O
makes -X- _ O
it -X- _ O
difficult -X- _ O
to -X- _ O
prune -X- _ O
dependency -X- _ O
noise -X- _ O
thus -X- _ O
leads -X- _ O
to -X- _ O
an -X- _ O
insufficient -X- _ O
exploration -X- _ O
of -X- _ O
syntactic -X- _ O
and -X- _ O
relational -X- _ O
information -X- _ O
. -X- _ O

In -X- _ O
this -X- _ O
paper -X- _ O
, -X- _ O
we -X- _ O
propose -X- _ O
a -X- _ O
unified -X- _ O
framework -X- _ O
to -X- _ O
tackle -X- _ O
this -X- _ O
challenge -X- _ O
and -X- _ O
incorporate -X- _ O
syntactic -X- _ O
information -X- _ O
for -X- _ O
relational -X- _ B-TaskName
triple -X- _ I-TaskName
extraction -X- _ I-TaskName
. -X- _ O
First -X- _ O
, -X- _ O
we -X- _ O
propose -X- _ O
to -X- _ O
reduce -X- _ O
the -X- _ O
dependency -X- _ O
tree -X- _ O
and -X- _ O
eliminate -X- _ O
syntactic -X- _ O
noise -X- _ O
with -X- _ O
graph -X- _ O
pooling -X- _ O
operations -X- _ O
( -X- _ O
Figure -X- _ O
1 -X- _ O
) -X- _ O
. -X- _ O
We -X- _ O
utilize -X- _ O
MinCut -X- _ O
pooling -X- _ O
( -X- _ O
Bianchi -X- _ O
et -X- _ O
al -X- _ O
. -X- _ O
, -X- _ O
2020 -X- _ O
) -X- _ O
to -X- _ O
cluster -X- _ O
similar -X- _ O
nodes -X- _ O
( -X- _ O
words -X- _ O
) -X- _ O
and -X- _ O
hence -X- _ O
obtain -X- _ O
a -X- _ O
core -X- _ O
relational -X- _ O
topology -X- _ O
. -X- _ O
Next -X- _ O
, -X- _ O
we -X- _ O
apply -X- _ O
the -X- _ O
inductive -X- _ O
GraphSAGE -X- _ O
algorithm -X- _ O
( -X- _ O
Hamilton -X- _ O
et -X- _ O
al -X- _ O
. -X- _ O
, -X- _ O
2017 -X- _ O
) -X- _ O
to -X- _ O
propagate -X- _ O
cluster -X- _ O
information -X- _ O
and -X- _ O
capture -X- _ O
the -X- _ O
syntactic -X- _ O
interactions -X- _ O
underlying -X- _ O
the -X- _ O
core -X- _ O
topology -X- _ O
. -X- _ O
Then -X- _ O
, -X- _ O
we -X- _ O
propose -X- _ O
to -X- _ O
symmetrically -X- _ O
expand -X- _ O
the -X- _ O
core -X- _ O
topology -X- _ O
with -X- _ O
graph -X- _ O
unpooling -X- _ O
operations -X- _ O
to -X- _ O
integrate -X- _ O
the -X- _ O
syntactic -X- _ O
interactions -X- _ O
with -X- _ O
the -X- _ O
original -X- _ O
sentence -X- _ O
context -X- _ O
. -X- _ O
Finally -X- _ O
, -X- _ O
we -X- _ O
propose -X- _ O
a -X- _ O
bipartite -X- _ O
graph -X- _ O
matching -X- _ O
loss -X- _ O
to -X- _ O
induce -X- _ O
the -X- _ O
connections -X- _ O
in -X- _ O
the -X- _ O
core -X- _ O
topology -X- _ O
to -X- _ O
reflect -X- _ O
golden -X- _ O
relational -X- _ O
facts -X- _ O
, -X- _ O
which -X- _ O
is -X- _ O
similar -X- _ O
to -X- _ O
the -X- _ O
reflections -X- _ O
between -X- _ O
the -X- _ O
dependency -X- _ O
paths -X- _ O
and -X- _ O
golden -X- _ O
facts -X- _ O
( -X- _ O
e.g. -X- _ O
Figure -X- _ O
1 -X- _ O
) -X- _ O
in -X- _ O
the -X- _ O
RC -X- _ O
task -X- _ O
. -X- _ O
Since -X- _ O
our -X- _ O
model -X- _ O
shares -X- _ O
similar -X- _ O
contracting -X- _ O
and -X- _ O
expanding -X- _ O
paths -X- _ O
with -X- _ O
encoder -X- _ O
- -X- _ O
decoder -X- _ O
models -X- _ O
like -X- _ O
U -X- _ O
- -X- _ O
Net -X- _ O
( -X- _ O
Ronneberger -X- _ O
et -X- _ O
al -X- _ O
. -X- _ O
, -X- _ O
2015 -X- _ O
) -X- _ O
, -X- _ O
we -X- _ O
name -X- _ O
our -X- _ O
model -X- _ O
as -X- _ O
Relation -X- _ B-MethodName
U -X- _ I-MethodName
- -X- _ I-MethodName
Net -X- _ I-MethodName
( -X- _ O
RelU -X- _ B-MethodName
- -X- _ I-MethodName
Net -X- _ I-MethodName
) -X- _ O
. -X- _ O

• -X- _ O
To -X- _ O
eliminate -X- _ O
disturbance -X- _ O
caused -X- _ O
by -X- _ O
irrelevant -X- _ O
syntactic -X- _ O
information -X- _ O
, -X- _ O
we -X- _ O
propose -X- _ O
to -X- _ O
automatically -X- _ O
contract -X- _ O
the -X- _ O
dependency -X- _ O
tree -X- _ O
into -X- _ O
a -X- _ O
core -X- _ O
topology -X- _ O
with -X- _ O
graph -X- _ O
pooling -X- _ O
operations -X- _ O
. -X- _ O

• -X- _ O
To -X- _ O
fuse -X- _ O
the -X- _ O
syntactic -X- _ O
interactions -X- _ O
underlying -X- _ O
the -X- _ O
core -X- _ O
topology -X- _ O
with -X- _ O
the -X- _ O
original -X- _ O
sentence -X- _ O
context -X- _ O
, -X- _ O
we -X- _ O
propose -X- _ O
a -X- _ O
symmetrical -X- _ O
expanding -X- _ O
path -X- _ O
with -X- _ O
graph -X- _ O
unpooling -X- _ O
operations -X- _ O
. -X- _ O

• -X- _ O
To -X- _ O
establish -X- _ O
reflections -X- _ O
between -X- _ O
core -X- _ O
topology -X- _ O
connections -X- _ O
and -X- _ O
golden -X- _ O
relational -X- _ O
facts -X- _ O
, -X- _ O
we -X- _ O
propose -X- _ O
a -X- _ O
bipartite -X- _ O
graph -X- _ O
matching -X- _ O
loss -X- _ O
. -X- _ O

In -X- _ O
the -X- _ O
early -X- _ O
work -X- _ O
of -X- _ O
relational -X- _ B-TaskName
triple -X- _ I-TaskName
extraction -X- _ I-TaskName
, -X- _ O
the -X- _ O
task -X- _ O
is -X- _ O
addressed -X- _ O
in -X- _ O
a -X- _ O
pipelined -X- _ O
manner -X- _ O
( -X- _ O
Zelenko -X- _ O
et -X- _ O
al -X- _ O
. -X- _ O
, -X- _ O
2003 -X- _ O
; -X- _ O
Zhou -X- _ O
et -X- _ O
al -X- _ O
. -X- _ O
, -X- _ O
2005 -X- _ O
; -X- _ O
Chan -X- _ O
and -X- _ O
Roth -X- _ O
, -X- _ O
2011 -X- _ O
; -X- _ O
Gormley -X- _ O
et -X- _ O
al -X- _ O
. -X- _ O
, -X- _ O
2015 -X- _ O
) -X- _ O
. -X- _ O
They -X- _ O
recognized -X- _ O
all -X- _ O
entities -X- _ O
in -X- _ O
the -X- _ O
sentence -X- _ O
and -X- _ O
classified -X- _ O
the -X- _ O
relations -X- _ O
between -X- _ O
pairs -X- _ O
of -X- _ O
extracted -X- _ O
entities -X- _ O
separately -X- _ O
. -X- _ O
However -X- _ O
, -X- _ O
the -X- _ O
pipeline -X- _ O
methods -X- _ O
usually -X- _ O
suffered -X- _ O
from -X- _ O
error -X- _ O
propagation -X- _ O
and -X- _ O
failed -X- _ O
to -X- _ O
capture -X- _ O
the -X- _ O
interactions -X- _ O
between -X- _ O
the -X- _ O
entities -X- _ O
and -X- _ O
relations -X- _ O
. -X- _ O

To -X- _ O
address -X- _ O
these -X- _ O
issues -X- _ O
, -X- _ O
end -X- _ O
- -X- _ O
to -X- _ O
- -X- _ O
end -X- _ O
models -X- _ O
for -X- _ O
joint -X- _ O
extraction -X- _ O
of -X- _ O
entities -X- _ O
and -X- _ O
relations -X- _ O
have -X- _ O
become -X- _ O
the -X- _ O
dominant -X- _ O
paradigm -X- _ O
of -X- _ O
this -X- _ O
task -X- _ O
, -X- _ O
including -X- _ O
feature -X- _ O
- -X- _ O
based -X- _ O
models -X- _ O
( -X- _ O
Yu -X- _ O
and -X- _ O
Lam -X- _ O
, -X- _ O
2010 -X- _ O
; -X- _ O
Li -X- _ O
and -X- _ O
Ji -X- _ O
, -X- _ O
2014 -X- _ O
; -X- _ O
Ren -X- _ O
et -X- _ O
al -X- _ O
. -X- _ O
, -X- _ O
2017 -X- _ O
) -X- _ O
and -X- _ O
neural -X- _ O
network -X- _ O
- -X- _ O
based -X- _ O
models -X- _ O
( -X- _ O
Miwa -X- _ O
and -X- _ O
Sasaki -X- _ O
, -X- _ O
2014 -X- _ O
; -X- _ O
Gupta -X- _ O
et -X- _ O
al -X- _ O
. -X- _ O
, -X- _ O
2016 -X- _ O
; -X- _ O
Miwa -X- _ O
and -X- _ O
Bansal -X- _ O
, -X- _ O
2016 -X- _ O
; -X- _ O
Zheng -X- _ O
et -X- _ O
al -X- _ O
. -X- _ O
, -X- _ O
2017 -X- _ O
) -X- _ O
. -X- _ O
For -X- _ O
example -X- _ O
, -X- _ O
Ren -X- _ O
et -X- _ O
al -X- _ O
. -X- _ O
( -X- _ O
2017 -X- _ O
) -X- _ O
proposed -X- _ O
to -X- _ O
detect -X- _ O
relation -X- _ O
mentions -X- _ O
and -X- _ O
their -X- _ O
entity -X- _ O
arguments -X- _ O
with -X- _ O
distant -X- _ O
supervision -X- _ O
. -X- _ O
Gupta -X- _ O
et -X- _ O
al -X- _ O
. -X- _ O
( -X- _ O
2016 -X- _ O
) -X- _ O
proposed -X- _ O
to -X- _ O
model -X- _ O
the -X- _ O
inter -X- _ O
- -X- _ O
dependencies -X- _ O
of -X- _ O
entities -X- _ O
and -X- _ O
relations -X- _ O
through -X- _ O
the -X- _ O
entity -X- _ O
- -X- _ O
relation -X- _ O
table -X- _ O
proposed -X- _ O
by -X- _ O
( -X- _ O
Miwa -X- _ O
and -X- _ O
Sasaki -X- _ O
, -X- _ O
2014 -X- _ O
) -X- _ O
. -X- _ O
Zheng -X- _ O
et -X- _ O
al -X- _ O
. -X- _ O
( -X- _ O
2017 -X- _ O
) -X- _ O
first -X- _ O
formulated -X- _ O
this -X- _ O
task -X- _ O
as -X- _ O
a -X- _ O
sequence -X- _ O
tagging -X- _ O
problem -X- _ O
, -X- _ O
but -X- _ O
they -X- _ O
failed -X- _ O
to -X- _ O
extract -X- _ O
overlapping -X- _ O
triples -X- _ O
. -X- _ O

More -X- _ O
recent -X- _ O
work -X- _ O
developed -X- _ O
several -X- _ O
strategies -X- _ O
to -X- _ O
address -X- _ O
the -X- _ O
overlapping -X- _ O
triple -X- _ O
problem -X- _ O
, -X- _ O
including -X- _ O
sequence -X- _ O
tagging -X- _ O
based -X- _ O
models -X- _ O
( -X- _ O
Wei -X- _ O
et -X- _ O
al -X- _ O
. -X- _ O
, -X- _ O
2020 -X- _ O
; -X- _ O
Zheng -X- _ O
et -X- _ O
al -X- _ O
. -X- _ O
, -X- _ O
2021 -X- _ O
; -X- _ O
and -X- _ O
triple -X- _ O
generation -X- _ O
based -X- _ O
models -X- _ O
( -X- _ O
Zeng -X- _ O
et -X- _ O
al -X- _ O
. -X- _ O
, -X- _ O
2018 -X- _ O
( -X- _ O
Zeng -X- _ O
et -X- _ O
al -X- _ O
. -X- _ O
, -X- _ O
, -X- _ O
2019 -X- _ O
( -X- _ O
Zeng -X- _ O
et -X- _ O
al -X- _ O
. -X- _ O
, -X- _ O
, -X- _ O
2020Sui -X- _ O
et -X- _ O
al -X- _ O
. -X- _ O
, -X- _ O
2020 -X- _ O
; -X- _ O
Huguet -X- _ O
Cabot -X- _ O
and -X- _ O
Navigli -X- _ O
, -X- _ O
2021 -X- _ O
) -X- _ O
. -X- _ O
For -X- _ O
example -X- _ O
, -X- _ O
Wei -X- _ O
et -X- _ O
al -X- _ O
. -X- _ O
( -X- _ O
2020 -X- _ O
) -X- _ O
proposed -X- _ O
a -X- _ O
cascade -X- _ O
tagging -X- _ O
scheme -X- _ O
to -X- _ O
simultaneously -X- _ O
identify -X- _ O
all -X- _ O
possible -X- _ O
overlapping -X- _ O
triples -X- _ O
. -X- _ O
proposed -X- _ O
a -X- _ O
binary -X- _ O
pointer -X- _ O
network -X- _ O
to -X- _ O
extract -X- _ O
overlapping -X- _ O
relational -X- _ O
triples -X- _ O
and -X- _ O
introduced -X- _ O
a -X- _ O
relational -X- _ O
network -X- _ O
to -X- _ O
capture -X- _ O
relational -X- _ O
reasoning -X- _ O
patterns -X- _ O
for -X- _ O
this -X- _ O
task -X- _ O
. -X- _ O
Zeng -X- _ O
et -X- _ O
al -X- _ O
. -X- _ O
( -X- _ O
2018 -X- _ O
) -X- _ O
proposed -X- _ O
a -X- _ O
sequence -X- _ O
- -X- _ O
tosequence -X- _ O
triple -X- _ O
generation -X- _ O
model -X- _ O
with -X- _ O
copy -X- _ O
mechanism -X- _ O
, -X- _ O
while -X- _ O
Sui -X- _ O
et -X- _ O
al -X- _ O
. -X- _ O
( -X- _ O
2020 -X- _ O
) -X- _ O
proposed -X- _ O
to -X- _ O
treat -X- _ O
this -X- _ O
task -X- _ O
as -X- _ O
a -X- _ O
direct -X- _ O
set -X- _ O
prediction -X- _ O
problem -X- _ O
. -X- _ O
However -X- _ O
, -X- _ O
these -X- _ O
methods -X- _ O
mainly -X- _ O
focused -X- _ O
on -X- _ O
learning -X- _ O
semantic -X- _ O
information -X- _ O
of -X- _ O
the -X- _ O
sentence -X- _ O
and -X- _ O
usually -X- _ O
suffered -X- _ O
from -X- _ O
ignoring -X- _ O
syntactic -X- _ O
patterns -X- _ O
of -X- _ O
the -X- _ O
sentence -X- _ O
. -X- _ O
Although -X- _ O
Fu -X- _ O
et -X- _ O
al -X- _ O
. -X- _ O
( -X- _ O
2019 -X- _ O
) -X- _ O
applied -X- _ O
the -X- _ O
dependency -X- _ O
tree -X- _ O
to -X- _ O
extract -X- _ O
regional -X- _ O
features -X- _ O
of -X- _ O
the -X- _ O
text -X- _ O
, -X- _ O
they -X- _ O
did -X- _ O
not -X- _ O
prune -X- _ O
irrelevant -X- _ O
contents -X- _ O
from -X- _ O
the -X- _ O
dependency -X- _ O
tree -X- _ O
, -X- _ O
which -X- _ O
may -X- _ O
be -X- _ O
sub -X- _ O
- -X- _ O
optimal -X- _ O
. -X- _ O

Different -X- _ O
from -X- _ O
previous -X- _ O
work -X- _ O
, -X- _ O
we -X- _ O
propose -X- _ O
to -X- _ O
remove -X- _ O
redundant -X- _ O
information -X- _ O
from -X- _ O
the -X- _ O
dependency -X- _ O
tree -X- _ O
with -X- _ O
graph -X- _ O
pooling -X- _ O
operations -X- _ O
and -X- _ O
integrate -X- _ O
core -X- _ O
syntactic -X- _ O
connections -X- _ O
with -X- _ O
the -X- _ O
original -X- _ O
sentence -X- _ O
context -X- _ O
with -X- _ O
graph -X- _ O
unpooling -X- _ O
operations -X- _ O
. -X- _ O
We -X- _ O
also -X- _ O
propose -X- _ O
a -X- _ O
bipartite -X- _ O
matching -X- _ O
loss -X- _ O
to -X- _ O
guide -X- _ O
the -X- _ O
core -X- _ O
syntactic -X- _ O
connections -X- _ O
to -X- _ O
reflect -X- _ O
golden -X- _ O
relational -X- _ O
facts -X- _ O
, -X- _ O
like -X- _ O
in -X- _ O
the -X- _ O
RC -X- _ O
task -X- _ O
. -X- _ O
Experimental -X- _ O
results -X- _ O
on -X- _ O
several -X- _ O
benchmark -X- _ O
datasets -X- _ O
prove -X- _ O
the -X- _ O
effectiveness -X- _ O
of -X- _ O
our -X- _ O
method -X- _ O
. -X- _ O

The -X- _ O
overall -X- _ O
framework -X- _ O
of -X- _ O
our -X- _ O
approach -X- _ O
is -X- _ O
illustrated -X- _ O
in -X- _ O
Figure -X- _ O
2 -X- _ O
. -X- _ O
We -X- _ O
introduce -X- _ O
the -X- _ O
Relation -X- _ B-MethodName
U -X- _ I-MethodName
- -X- _ I-MethodName
Net -X- _ I-MethodName
, -X- _ O
the -X- _ O
triple -X- _ O
extractor -X- _ O
and -X- _ O
the -X- _ O
details -X- _ O
of -X- _ O
model -X- _ O
training -X- _ O
in -X- _ O
Section -X- _ O
3.1 -X- _ O
, -X- _ O
3.2 -X- _ O
and -X- _ O
3.3 -X- _ O
, -X- _ O
respectively -X- _ O
. -X- _ O

The -X- _ O
syntactic -X- _ O
structure -X- _ O
of -X- _ O
the -X- _ O
sentence -X- _ O
has -X- _ O
already -X- _ O
been -X- _ O
proved -X- _ O
to -X- _ O
contain -X- _ O
rich -X- _ O
relational -X- _ O
information -X- _ O
by -X- _ O
existing -X- _ O
RC -X- _ O
methods -X- _ O
( -X- _ O
Zhang -X- _ O
et -X- _ O
al -X- _ O
. -X- _ O
, -X- _ O
2018 -X- _ O
; -X- _ O
Guo -X- _ O
et -X- _ O
al -X- _ O
. -X- _ O
, -X- _ O
2019 -X- _ O
; -X- _ O
Yu -X- _ O
et -X- _ O
al -X- _ O
. -X- _ O
, -X- _ O
2020 -X- _ O
) -X- _ O
. -X- _ O
They -X- _ O
usually -X- _ O
pruned -X- _ O
irrelevant -X- _ O
contents -X- _ O
from -X- _ O
the -X- _ O
dependency -X- _ O
tree -X- _ O
to -X- _ O
eliminate -X- _ O
noise -X- _ O
according -X- _ O
to -X- _ O
the -X- _ O
known -X- _ O
locations -X- _ O
of -X- _ O
each -X- _ O
entity -X- _ O
pair -X- _ O
( -X- _ O
Figure -X- _ O
1 -X- _ O
) -X- _ O
. -X- _ O
However -X- _ O
, -X- _ O
the -X- _ O
locations -X- _ O
of -X- _ O
entities -X- _ O
are -X- _ O
unknown -X- _ O
in -X- _ O
RTE -X- _ B-TaskName
, -X- _ O
which -X- _ O
makes -X- _ O
it -X- _ O
challenging -X- _ O
to -X- _ O
prune -X- _ O
noisy -X- _ O
dependency -X- _ O
edges -X- _ O
and -X- _ O
sufficiently -X- _ O
exploit -X- _ O
syntactic -X- _ O
information -X- _ O
. -X- _ O
To -X- _ O
tackle -X- _ O
this -X- _ O
challenge -X- _ O
, -X- _ O
we -X- _ O
first -X- _ O
down -X- _ O
- -X- _ O
sample -X- _ O
the -X- _ O
dependency -X- _ O
tree -X- _ O
to -X- _ O
summarize -X- _ O
informative -X- _ O
structures -X- _ O
and -X- _ O
reduce -X- _ O
noise -X- _ O
. -X- _ O
The -X- _ O
down -X- _ O
- -X- _ O
sampled -X- _ O
core -X- _ O
topology -X- _ O
contains -X- _ O
relation -X- _ O
- -X- _ O
relevant -X- _ O
syntactic -X- _ O
information -X- _ O
of -X- _ O
the -X- _ O
sentence -X- _ O
. -X- _ O
Then -X- _ O
, -X- _ O
we -X- _ O
symmetrically -X- _ O
up -X- _ O
- -X- _ O
sample -X- _ O
the -X- _ O
core -X- _ O
topology -X- _ O
to -X- _ O
enable -X- _ O
precise -X- _ O
triple -X- _ O
localization -X- _ O
. -X- _ O
Our -X- _ O
model -X- _ O
has -X- _ O
a -X- _ O
contracting -X- _ O
and -X- _ O
expanding -X- _ O
path -X- _ O
of -X- _ O
the -X- _ O
dependency -X- _ O
tree -X- _ O
, -X- _ O
which -X- _ O
shares -X- _ O
similar -X- _ O
architecture -X- _ O
with -X- _ O
encoder -X- _ O
- -X- _ O
decoder -X- _ O
models -X- _ O
like -X- _ O
U -X- _ O
- -X- _ O
Net -X- _ O
( -X- _ O
Ronneberger -X- _ O
et -X- _ O
al -X- _ O
. -X- _ O
, -X- _ O
2015 -X- _ O
) -X- _ O
. -X- _ O
Therefore -X- _ O
, -X- _ O
we -X- _ O
propose -X- _ O
Relation -X- _ B-MethodName
U -X- _ I-MethodName
- -X- _ I-MethodName
Net -X- _ I-MethodName
, -X- _ O
named -X- _ O
as -X- _ O
RelU -X- _ B-MethodName
- -X- _ I-MethodName
Net -X- _ I-MethodName
, -X- _ O
to -X- _ O
incorporate -X- _ O
syntactic -X- _ O
information -X- _ O
for -X- _ O
RTE -X- _ B-TaskName
. -X- _ O
We -X- _ O
first -X- _ O
propose -X- _ O
to -X- _ O
automatically -X- _ O
reduce -X- _ O
the -X- _ O
dependency -X- _ O
tree -X- _ O
into -X- _ O
a -X- _ O
core -X- _ O
relational -X- _ O
topology -X- _ O
with -X- _ O
graph -X- _ O
pooling -X- _ O
operations -X- _ O
( -X- _ O
Section -X- _ O
3.1.1 -X- _ O
) -X- _ O
. -X- _ O
Then -X- _ O
, -X- _ O
we -X- _ O
adopt -X- _ O
inductive -X- _ O
graph -X- _ O
convolutions -X- _ O
to -X- _ O
capture -X- _ O
the -X- _ O
syntactic -X- _ O
interactions -X- _ O
underlying -X- _ O
the -X- _ O
core -X- _ O
topology -X- _ O
( -X- _ O
Section -X- _ O
3.1.2 -X- _ O
) -X- _ O
. -X- _ O
Finally -X- _ O
, -X- _ O
we -X- _ O
propose -X- _ O
to -X- _ O
expand -X- _ O
the -X- _ O
core -X- _ O
topology -X- _ O
with -X- _ O
graph -X- _ O
unpooling -X- _ O
operations -X- _ O
for -X- _ O
the -X- _ O
fusion -X- _ O
of -X- _ O
the -X- _ O
syntactic -X- _ O
interactions -X- _ O
and -X- _ O
the -X- _ O
semantic -X- _ O
context -X- _ O
( -X- _ O
Section -X- _ O
3.1.3 -X- _ O
) -X- _ O
. -X- _ O

Given -X- _ O
the -X- _ O
input -X- _ O
sentence -X- _ O
{ -X- _ O
w -X- _ O
1 -X- _ O
, -X- _ O
. -X- _ O
. -X- _ O
. -X- _ O
, -X- _ O
w -X- _ O
n -X- _ O
} -X- _ O
and -X- _ O
its -X- _ O
dependency -X- _ O
tree -X- _ O
, -X- _ O
we -X- _ O
first -X- _ O
convert -X- _ O
the -X- _ O
words -X- _ O
( -X- _ O
nodes -X- _ O
) -X- _ O
into -X- _ O
contextual -X- _ O
representations -X- _ O
with -X- _ O
a -X- _ O
text -X- _ O
encoder -X- _ O
such -X- _ O
as -X- _ O
BERT -X- _ O
( -X- _ O
Devlin -X- _ O
et -X- _ O
al -X- _ O
. -X- _ O
, -X- _ O
2019 -X- _ O
) -X- _ O
, -X- _ O
whose -X- _ O
output -X- _ O
denoted -X- _ O
as -X- _ O
E -X- _ O
= -X- _ O
[ -X- _ O
E -X- _ O
1 -X- _ O
, -X- _ O
. -X- _ O
. -X- _ O
. -X- _ O
, -X- _ O
E -X- _ O
n -X- _ O
] -X- _ O
. -X- _ O
Then -X- _ O
, -X- _ O
we -X- _ O
represent -X- _ O
the -X- _ O
dependency -X- _ O
tree -X- _ O
with -X- _ O
an -X- _ O
adjacency -X- _ O
matrix -X- _ O
A -X- _ O
Dep -X- _ O
, -X- _ O
where -X- _ O
( -X- _ O
A -X- _ O
Dep -X- _ O
) -X- _ O
i -X- _ O
, -X- _ O
j -X- _ O
= -X- _ O
1 -X- _ O
if -X- _ O
there -X- _ O
exists -X- _ O
a -X- _ O
dependency -X- _ O
edge -X- _ O
between -X- _ O
the -X- _ O
i -X- _ O
- -X- _ O
th -X- _ O
and -X- _ O
the -X- _ O
j -X- _ O
- -X- _ O
th -X- _ O
word -X- _ O
otherwise -X- _ O
0 -X- _ O
1 -X- _ O
. -X- _ O
Next -X- _ O
, -X- _ O
we -X- _ O
utilize -X- _ O
the -X- _ O
spectral -X- _ O
- -X- _ O
clustering -X- _ O
MinCut -X- _ O
pooling -X- _ O
( -X- _ O
Bianchi -X- _ O
et -X- _ O
al -X- _ O
. -X- _ O
, -X- _ O
2020 -X- _ O
) -X- _ O
operations -X- _ O
to -X- _ O
aggregate -X- _ O
nodes -X- _ O
with -X- _ O
strong -X- _ O
syntactic -X- _ O
connections -X- _ O
and -X- _ O
similar -X- _ O
semantic -X- _ O
features -X- _ O
. -X- _ O
By -X- _ O
clustering -X- _ O
dependency -X- _ O
nodes -X- _ O
, -X- _ O
we -X- _ O
merge -X- _ O
all -X- _ O
irrelevant -X- _ O
edges -X- _ O
into -X- _ O
the -X- _ O
supernodes -X- _ O
, -X- _ O
guiding -X- _ O
our -X- _ O
model -X- _ O
to -X- _ O
focus -X- _ O
more -X- _ O
on -X- _ O
critical -X- _ O
syntactic -X- _ O
interactions -X- _ O
between -X- _ O
the -X- _ O
supernodes -X- _ O
, -X- _ O
thus -X- _ O
reducing -X- _ O
the -X- _ O
negative -X- _ O
impact -X- _ O
of -X- _ O
noisy -X- _ O
contents -X- _ O
. -X- _ O
Specifically -X- _ O
, -X- _ O
MinCut -X- _ O
pooling -X- _ O
( -X- _ O
denoted -X- _ O
as -X- _ O
gPool -X- _ O
) -X- _ O
captures -X- _ O
syntactic -X- _ O
interactions -X- _ O
with -X- _ O
a -X- _ O
Graph -X- _ O
Convolution -X- _ O
Network -X- _ O
( -X- _ O
GCN -X- _ O
, -X- _ O
Section -X- _ O
3.1.2 -X- _ O
) -X- _ O
and -X- _ O
uses -X- _ O
a -X- _ O
Multi -X- _ O
- -X- _ O
Layer -X- _ O
Perceptron -X- _ O
( -X- _ O
MLP -X- _ O
) -X- _ O
to -X- _ O
learn -X- _ O
a -X- _ O
cluster -X- _ O
assignment -X- _ O
matrix -X- _ O
S -X- _ O
∈ -X- _ O
R -X- _ O
N -X- _ O
×C -X- _ O
: -X- _ O

where -X- _ O
N -X- _ O
, -X- _ O
C -X- _ O
are -X- _ O
numbers -X- _ O
of -X- _ O
input -X- _ O
nodes -X- _ O
and -X- _ O
output -X- _ O
clusters -X- _ O
, -X- _ O
X -X- _ O
∈ -X- _ O
R -X- _ O
N -X- _ O
×d -X- _ O
, -X- _ O
A -X- _ O
∈ -X- _ O
R -X- _ O
N -X- _ O
×N -X- _ O
are -X- _ O
the -X- _ O
input -X- _ O
node -X- _ O
features -X- _ O
and -X- _ O
adjacency -X- _ O
matrix -X- _ O
, -X- _ O
and -X- _ O
the -X- _ O
softmax -X- _ O
operation -X- _ O
is -X- _ O
to -X- _ O
normalize -X- _ O
the -X- _ O
contributions -X- _ O
of -X- _ O
all -X- _ O
input -X- _ O
nodes -X- _ O
to -X- _ O
each -X- _ O
output -X- _ O
cluster -X- _ O
. -X- _ O
Then -X- _ O
we -X- _ O
compute -X- _ O
the -X- _ O
pooled -X- _ O
node -X- _ O
features -X- _ O
X -X- _ O
gPool -X- _ O
and -X- _ O
adjacency -X- _ O
matrix -X- _ O
A -X- _ O
gPool -X- _ O
: -X- _ O

X -X- _ O
gPool -X- _ O
= -X- _ O
S -X- _ O
⊤ -X- _ O
X -X- _ O
, -X- _ O
A -X- _ O
gPool -X- _ O
= -X- _ O
S -X- _ O
⊤ -X- _ O
AS -X- _ O
( -X- _ O
2 -X- _ O
) -X- _ O

A -X- _ O
gPool -X- _ O
= -X- _ O
A -X- _ O
gPool -X- _ O
− -X- _ O
I -X- _ O
K -X- _ O
diag -X- _ O
( -X- _ O
A -X- _ O
gPool -X- _ O
) -X- _ O
A -X- _ O
gPool -X- _ O
=D -X- _ O
− -X- _ O
1 -X- _ O
2Â -X- _ O
gPoolD -X- _ O
− -X- _ O
1 -X- _ O
2 -X- _ O

( -X- _ O
3 -X- _ O
) -X- _ O
whereD -X- _ O
is -X- _ O
the -X- _ O
degree -X- _ O
matrix -X- _ O
ofÂ -X- _ O
gPool -X- _ O
. -X- _ O
Since -X- _ O
these -X- _ O
pooling -X- _ O
operations -X- _ O
are -X- _ O
fully -X- _ O
differentiable -X- _ O
, -X- _ O
the -X- _ O
MinCut -X- _ O
layer -X- _ O
can -X- _ O
be -X- _ O
stacked -X- _ O
multiple -X- _ O
times -X- _ O
: -X- _ O

X -X- _ O
( -X- _ O
l+1 -X- _ O
) -X- _ O
= -X- _ O
ReLU -X- _ O
( -X- _ O
X -X- _ O
( -X- _ O
l -X- _ O
) -X- _ O
gPool -X- _ O
) -X- _ O
, -X- _ O
A -X- _ O
( -X- _ O
l+1 -X- _ O
) -X- _ O
= -X- _ O
A -X- _ O
( -X- _ O
l -X- _ O
) -X- _ O
gPool -X- _ O
( -X- _ O
4 -X- _ O
) -X- _ O

where -X- _ O
X -X- _ O
( -X- _ O
1 -X- _ O
) -X- _ O
= -X- _ O
E -X- _ O
, -X- _ O
A -X- _ O
( -X- _ O
1 -X- _ O
) -X- _ O
= -X- _ O
A -X- _ O
Dep -X- _ O
. -X- _ O
We -X- _ O
perform -X- _ O
L -X- _ O
times -X- _ O
pooling -X- _ O
on -X- _ O
the -X- _ O
raw -X- _ O
dependency -X- _ O
tree -X- _ O
and -X- _ O
obtain -X- _ O
a -X- _ O
core -X- _ O
topology -X- _ O
G -X- _ O
Core -X- _ O
= -X- _ O
{ -X- _ O
X -X- _ O
( -X- _ O
L -X- _ O
) -X- _ O
, -X- _ O
A -X- _ O
( -X- _ O
L -X- _ O
) -X- _ O
} -X- _ O
, -X- _ O
as -X- _ O
shown -X- _ O
in -X- _ O
Figure -X- _ O
2 -X- _ O
( -X- _ O
left -X- _ O
) -X- _ O
. -X- _ O
Note -X- _ O
that -X- _ O
our -X- _ O
model -X- _ O
is -X- _ O
similar -X- _ O
to -X- _ O
the -X- _ O
multi -X- _ O
- -X- _ O
layer -X- _ O
graph -X- _ O
pooling -X- _ O
proposed -X- _ O
by -X- _ O
Gao -X- _ O
and -X- _ O
Ji -X- _ O
( -X- _ O
2019 -X- _ O
) -X- _ O
, -X- _ O
but -X- _ O
we -X- _ O
do -X- _ O
not -X- _ O
use -X- _ O
their -X- _ O
top -X- _ O
- -X- _ O
K -X- _ O
graph -X- _ O
pooling -X- _ O
. -X- _ O
This -X- _ O
is -X- _ O
because -X- _ O
the -X- _ O
top -X- _ O
- -X- _ O
K -X- _ O
pooling -X- _ O
reduces -X- _ O
graph -X- _ O
size -X- _ O
by -X- _ O
simply -X- _ O
removing -X- _ O
nodes -X- _ O
, -X- _ O
but -X- _ O
the -X- _ O
RTE -X- _ B-TaskName
task -X- _ O
involves -X- _ O
node -X- _ O
merging -X- _ O
, -X- _ O
such -X- _ O
as -X- _ O
multi -X- _ O
- -X- _ O
word -X- _ O
entities -X- _ O
. -X- _ O

We -X- _ O
apply -X- _ O
multi -X- _ O
- -X- _ O
layer -X- _ O
graph -X- _ O
convolutions -X- _ O
to -X- _ O
capture -X- _ O
the -X- _ O
syntactic -X- _ O
interactions -X- _ O
underlying -X- _ O
the -X- _ O
core -X- _ O
topology -X- _ O
. -X- _ O
However -X- _ O
, -X- _ O
this -X- _ O
pooled -X- _ O
topology -X- _ O
changes -X- _ O
dynamically -X- _ O
with -X- _ O
the -X- _ O
parameter -X- _ O
updates -X- _ O
during -X- _ O
training -X- _ O
, -X- _ O
thus -X- _ O
making -X- _ O
the -X- _ O
conventional -X- _ O
transductive -X- _ O
graph -X- _ O
convolution -X- _ O
methods -X- _ O
( -X- _ O
Kipf -X- _ O
and -X- _ O
Welling -X- _ O
, -X- _ O
2016 -X- _ O
) -X- _ O
not -X- _ O
suitable -X- _ O
to -X- _ O
our -X- _ O
model -X- _ O
. -X- _ O
Therefore -X- _ O
, -X- _ O
we -X- _ O
adopt -X- _ O
the -X- _ O
inductive -X- _ O
GraphSAGE -X- _ O
( -X- _ O
Hamilton -X- _ O
et -X- _ O
al -X- _ O
. -X- _ O
, -X- _ O
2017 -X- _ O
) -X- _ O
algorithm -X- _ O
, -X- _ O
which -X- _ O
first -X- _ O
uniformly -X- _ O
samples -X- _ O
neighbor -X- _ O
nodes -X- _ O
w.r.t -X- _ O
. -X- _ O
each -X- _ O
node -X- _ O
and -X- _ O
then -X- _ O
aggregates -X- _ O
the -X- _ O
features -X- _ O
of -X- _ O
the -X- _ O
sampled -X- _ O
nodes -X- _ O
. -X- _ O
Formally -X- _ O
, -X- _ O
the -X- _ O
convolution -X- _ O
of -X- _ O
the -X- _ O
p -X- _ O
- -X- _ O
th -X- _ O
layer -X- _ O
is -X- _ O
formulated -X- _ O
as -X- _ O
: -X- _ O

G -X- _ O
( -X- _ O
p+1 -X- _ O
) -X- _ O
i -X- _ O
= -X- _ O
ReLU -X- _ O
W -X- _ O
( -X- _ O
p -X- _ O
) -X- _ O
[ -X- _ O
G -X- _ O
( -X- _ O
p -X- _ O
) -X- _ O
i -X- _ O
; -X- _ O
Ave -X- _ O
( -X- _ O
G -X- _ O
( -X- _ O
p -X- _ O
) -X- _ O
S -X- _ O
i -X- _ O
) -X- _ O
] -X- _ O
( -X- _ O
5 -X- _ O
) -X- _ O

where -X- _ O
W -X- _ O
( -X- _ O
p -X- _ O
) -X- _ O
stands -X- _ O
for -X- _ O
the -X- _ O
parameters -X- _ O
of -X- _ O
the -X- _ O
p -X- _ O
- -X- _ O
th -X- _ O
layer -X- _ O
, -X- _ O
S -X- _ O
i -X- _ O
denotes -X- _ O
the -X- _ O
i -X- _ O
- -X- _ O
th -X- _ O
node -X- _ O
's -X- _ O
sampled -X- _ O
neighbors -X- _ O
in -X- _ O
the -X- _ O
topology -X- _ O
, -X- _ O
and -X- _ O
G -X- _ O
( -X- _ O
1 -X- _ O
) -X- _ O
= -X- _ O
X -X- _ O
( -X- _ O
L -X- _ O
) -X- _ O
. -X- _ O
We -X- _ O
also -X- _ O
use -X- _ O
GraphSAGE -X- _ O
in -X- _ O
the -X- _ O
GCN -X- _ O
of -X- _ O
graph -X- _ O
pooling -X- _ O
( -X- _ O
Equation -X- _ O
1 -X- _ O
) -X- _ O
because -X- _ O
the -X- _ O
intermediate -X- _ O
graphs -X- _ O
of -X- _ O
the -X- _ O
pooling -X- _ O
path -X- _ O
are -X- _ O
also -X- _ O
dynamic -X- _ O
. -X- _ O

S -X- _ O
′ -X- _ O
= -X- _ O
softmax -X- _ O
( -X- _ O
MLP -X- _ O
( -X- _ O
GCN -X- _ O
( -X- _ O
X -X- _ O
, -X- _ O
A -X- _ O
) -X- _ O
; -X- _ O
Θ -X- _ O
′ -X- _ O
) -X- _ O
) -X- _ O
. -X- _ O

L -X- _ O
t -X- _ O
= -X- _ O
* -X- _ O
∈ -X- _ O
{ -X- _ O
s -X- _ O
, -X- _ O
e -X- _ O
} -X- _ O
( -X- _ O
f -X- _ O
( -X- _ O
y -X- _ O
s -X- _ O
* -X- _ O
, -X- _ O
p -X- _ O
s -X- _ O
* -X- _ O
) -X- _ O
+ -X- _ O
r -X- _ O
, -X- _ O
k -X- _ O
f -X- _ O
( -X- _ O
y -X- _ O
o -X- _ O
, -X- _ O
r -X- _ O
* -X- _ O
, -X- _ O
k -X- _ O
, -X- _ O
p -X- _ O
o -X- _ O
, -X- _ O
r -X- _ O
* -X- _ O
, -X- _ O
k -X- _ O
) -X- _ O
) -X- _ O
, -X- _ O
( -X- _ O
7 -X- _ O

In -X- _ O
addition -X- _ O
, -X- _ O
we -X- _ O
observe -X- _ O
from -X- _ O
the -X- _ O
RC -X- _ O
task -X- _ O
that -X- _ O
a -X- _ O
dependency -X- _ O
path -X- _ O
connecting -X- _ O
two -X- _ O
entities -X- _ O
reflects -X- _ O
a -X- _ O
relational -X- _ O
fact -X- _ O
( -X- _ O
Figure -X- _ O
1 -X- _ O
) -X- _ O
. -X- _ O
Similarly -X- _ O
, -X- _ O
we -X- _ O
expect -X- _ O
the -X- _ O
connections -X- _ O
in -X- _ O
the -X- _ O
core -X- _ O
topology -X- _ O
to -X- _ O
have -X- _ O
reflections -X- _ O
to -X- _ O
the -X- _ O
golden -X- _ O
relational -X- _ O
facts -X- _ O
. -X- _ O
Therefore -X- _ O
, -X- _ O
we -X- _ O
propose -X- _ O
an -X- _ O
objective -X- _ O
function -X- _ O
that -X- _ O
minimizes -X- _ O
the -X- _ O
adjacency -X- _ O
similarity -X- _ O
between -X- _ O
the -X- _ O
core -X- _ O
topology -X- _ O
and -X- _ O
the -X- _ O
golden -X- _ O
relational -X- _ O
triples -X- _ O
. -X- _ O
We -X- _ O
represent -X- _ O
the -X- _ O
golden -X- _ O
triples -X- _ O
with -X- _ O
a -X- _ O
relational -X- _ O
graph -X- _ O
G -X- _ O
Gold -X- _ O
= -X- _ O
{ -X- _ O
X -X- _ O
G -X- _ O
, -X- _ O
A -X- _ O
G -X- _ O
} -X- _ O
, -X- _ O
whose -X- _ O
nodes -X- _ O
are -X- _ O
subject -X- _ O
and -X- _ O
object -X- _ O
entities -X- _ O
, -X- _ O
X -X- _ O
G -X- _ O
is -X- _ O
computed -X- _ O
by -X- _ O
averaging -X- _ O
the -X- _ O
word -X- _ O
representations -X- _ O
E -X- _ O
corresponding -X- _ O
to -X- _ O
the -X- _ O
nodes -X- _ O
' -X- _ O
entities -X- _ O
, -X- _ O
and -X- _ O
A -X- _ O
G -X- _ O
i -X- _ O
, -X- _ O
j -X- _ O
= -X- _ O
1 -X- _ O
if -X- _ O
there -X- _ O
exists -X- _ O
a -X- _ O
golden -X- _ O
triple -X- _ O
between -X- _ O
the -X- _ O
i -X- _ O
- -X- _ O
th -X- _ O
and -X- _ O
the -X- _ O
j -X- _ O
- -X- _ O
th -X- _ O
node -X- _ O
otherwise -X- _ O
0 -X- _ O
. -X- _ O
However -X- _ O
, -X- _ O
the -X- _ O
node -X- _ O
orders -X- _ O
of -X- _ O
G -X- _ O
Core -X- _ O
and -X- _ O
G -X- _ O
Gold -X- _ O
may -X- _ O
mismatch -X- _ O
, -X- _ O
making -X- _ O
it -X- _ O
difficult -X- _ O
to -X- _ O
directly -X- _ O
compare -X- _ O
their -X- _ O
adjacency -X- _ O
matrices -X- _ O
because -X- _ O
they -X- _ O
are -X- _ O
sensitive -X- _ O
to -X- _ O
node -X- _ O
permutations -X- _ O
. -X- _ O

To -X- _ O
address -X- _ O
this -X- _ O
issue -X- _ O
, -X- _ O
we -X- _ O
propose -X- _ O
to -X- _ O
find -X- _ O
the -X- _ O
optimal -X- _ O
bipartite -X- _ O
matching -X- _ O
between -X- _ O
two -X- _ O
sets -X- _ O
of -X- _ O
graph -X- _ O
nodes -X- _ O
and -X- _ O
compute -X- _ O
the -X- _ O
similarity -X- _ O
score -X- _ O
between -X- _ O
the -X- _ O
core -X- _ O
topology -X- _ O
and -X- _ O
the -X- _ O
permuted -X- _ O
golden -X- _ O
graph -X- _ O
, -X- _ O
as -X- _ O
illustrated -X- _ O
in -X- _ O
Figure -X- _ O
2 -X- _ O
( -X- _ O
top -X- _ O
) -X- _ O
. -X- _ O
We -X- _ O
formulate -X- _ O
the -X- _ O
optimal -X- _ O
bipartite -X- _ O
matching -X- _ O
as -X- _ O
a -X- _ O
permutation -X- _ O
π -X- _ O
* -X- _ O
with -X- _ O
the -X- _ O
minimum -X- _ O
cost -X- _ O
: -X- _ O

We -X- _ O
train -X- _ O
our -X- _ O
RelU -X- _ B-MethodName
- -X- _ I-MethodName
Net -X- _ I-MethodName
with -X- _ O
the -X- _ O
joint -X- _ O
loss -X- _ O
L -X- _ O
= -X- _ O
L -X- _ O
t -X- _ O
+ -X- _ O
αL -X- _ O
Bipartite -X- _ O
+ -X- _ O
βL -X- _ O
Graph -X- _ O
, -X- _ O
in -X- _ O
which -X- _ O
α -X- _ O
and -X- _ O
β -X- _ O
are -X- _ O
hyper -X- _ O
- -X- _ O
parameters -X- _ O
. -X- _ O

We -X- _ O
evaluate -X- _ O
our -X- _ O
method -X- _ O
on -X- _ O
two -X- _ O
widely -X- _ O
- -X- _ O
used -X- _ O
benchmark -X- _ O
datasets -X- _ O
: -X- _ O
NYT -X- _ B-DatasetName
( -X- _ O
Riedel -X- _ O
et -X- _ O
al -X- _ O
. -X- _ O
, -X- _ O
2010 -X- _ O
) -X- _ O
and -X- _ O
WebNLG -X- _ B-DatasetName
( -X- _ O
Gardent -X- _ O
et -X- _ O
al -X- _ O
. -X- _ O
, -X- _ O
2017 -X- _ O
) -X- _ O
. -X- _ O
NYT -X- _ B-DatasetName
consists -X- _ O
of -X- _ O
sentences -X- _ O
sampled -X- _ O
from -X- _ O
New -X- _ O
York -X- _ O
Times -X- _ O
news -X- _ O
articles -X- _ O
and -X- _ O
contains -X- _ O
24 -X- _ O
relation -X- _ O
types -X- _ O
. -X- _ O
WebNLG -X- _ B-DatasetName
was -X- _ O
originally -X- _ O
proposed -X- _ O
for -X- _ O
natural -X- _ O
language -X- _ O
generation -X- _ O
and -X- _ O
first -X- _ O
introduced -X- _ O
in -X- _ O
the -X- _ O
RTE -X- _ O
task -X- _ O
by -X- _ O
Zeng -X- _ O
et -X- _ O
al -X- _ O
. -X- _ O
( -X- _ O
2018 -X- _ O
) -X- _ O
, -X- _ O
which -X- _ O
contains -X- _ O
171 -X- _ O
relation -X- _ O
types -X- _ O
. -X- _ O

Following -X- _ O
previous -X- _ O
work -X- _ O
( -X- _ O
Zeng -X- _ O
et -X- _ O
al -X- _ O
. -X- _ O
, -X- _ O
2018 -X- _ O
; -X- _ O
Wei -X- _ O
et -X- _ O
al -X- _ O
. -X- _ O
, -X- _ O
2020 -X- _ O
; -X- _ O
, -X- _ O
we -X- _ O
divide -X- _ O
the -X- _ O
sentences -X- _ O
into -X- _ O
three -X- _ O
classes -X- _ O
: -X- _ O
Normal -X- _ O
, -X- _ O
EntitypairOverlap -X- _ O
( -X- _ O
EPO -X- _ O
) -X- _ O
and -X- _ O
SingleEntityOverlap -X- _ O
( -X- _ O
SEO -X- _ O
) -X- _ O
according -X- _ O
to -X- _ O
different -X- _ O
overlapping -X- _ O
patterns -X- _ O
of -X- _ O
triples -X- _ O
, -X- _ O
as -X- _ O
shown -X- _ O
in -X- _ O
Table -X- _ O
1 -X- _ O
. -X- _ O
We -X- _ O
adopt -X- _ O
the -X- _ O
same -X- _ O
partial -X- _ O
match -X- _ O
score -X- _ O
following -X- _ O
previous -X- _ O
work -X- _ O
( -X- _ O
Zheng -X- _ O
et -X- _ O
al -X- _ O
. -X- _ O
, -X- _ O
2017 -X- _ O
; -X- _ O
Wei -X- _ O
et -X- _ O
al -X- _ O
. -X- _ O
, -X- _ O
2020 -X- _ O
; -X- _ O
for -X- _ O
evaluation -X- _ O
. -X- _ O
We -X- _ O
regard -X- _ O
the -X- _ O
extracted -X- _ O
triple -X- _ O
as -X- _ O
correct -X- _ O
if -X- _ O
and -X- _ O
only -X- _ O
if -X- _ O
the -X- _ O
relation -X- _ O
and -X- _ O
the -X- _ O
heads -X- _ O
of -X- _ O
subject -X- _ O
and -X- _ O
object -X- _ O
are -X- _ O
all -X- _ O
correct -X- _ O
. -X- _ O
We -X- _ O
report -X- _ O
the -X- _ O
standard -X- _ O
micro -X- _ B-MetricName
precision -X- _ I-MetricName
, -X- _ O
recall -X- _ B-MetricName
, -X- _ O
and -X- _ O
F -X- _ B-MetricName
1 -X- _ I-MetricName
scores -X- _ O
on -X- _ O
both -X- _ O
datasets -X- _ O
. -X- _ O

the -X- _ O
graph -X- _ O
pooling -X- _ O
layers -X- _ O
are -X- _ O
set -X- _ O
to -X- _ O
16 -X- _ O
and -X- _ O
8 -X- _ O
, -X- _ O
respectively -X- _ O
. -X- _ O
The -X- _ O
weights -X- _ O
α -X- _ O
and -X- _ O
β -X- _ O
of -X- _ O
bipartite -X- _ O
matching -X- _ O
loss -X- _ O
and -X- _ O
graph -X- _ O
similarity -X- _ O
loss -X- _ O
are -X- _ O
set -X- _ O
to -X- _ O
1.0 -X- _ O
and -X- _ O
0.1 -X- _ O
, -X- _ O
respectively -X- _ O
. -X- _ O
We -X- _ O
use -X- _ O
Adam -X- _ B-HyperparameterValue
optimizer -X- _ B-HyperparameterName
( -X- _ O
Kingma -X- _ O
and -X- _ O
Ba -X- _ O
, -X- _ O
2014 -X- _ O
) -X- _ O
to -X- _ O
fine -X- _ O
- -X- _ O
tune -X- _ O
the -X- _ O
pre -X- _ O
- -X- _ O
trained -X- _ O
BERT -X- _ O
weights -X- _ O
with -X- _ O
the -X- _ O
learning -X- _ B-HyperparameterName
rate -X- _ I-HyperparameterName
of -X- _ O
10 -X- _ B-HyperparameterValue
−5 -X- _ I-HyperparameterValue
and -X- _ O
train -X- _ O
other -X- _ O
parameters -X- _ O
with -X- _ O
the -X- _ O
learning -X- _ B-HyperparameterName
rate -X- _ I-HyperparameterName
of -X- _ O
5 -X- _ B-HyperparameterValue
× -X- _ I-HyperparameterValue
10 -X- _ I-HyperparameterValue
−4 -X- _ I-HyperparameterValue
. -X- _ O
We -X- _ O
train -X- _ O
our -X- _ O
model -X- _ O
for -X- _ O
200 -X- _ O
epochs -X- _ O
with -X- _ O
batch -X- _ B-HyperparameterName
size -X- _ I-HyperparameterName
as -X- _ O
10 -X- _ B-HyperparameterValue
on -X- _ O
both -X- _ O
datasets -X- _ O
. -X- _ O
We -X- _ O
choose -X- _ O
the -X- _ O
model -X- _ O
with -X- _ O
the -X- _ O
best -X- _ O
validation -X- _ O
performance -X- _ O
and -X- _ O
report -X- _ O
the -X- _ O
scores -X- _ O
on -X- _ O
the -X- _ O
test -X- _ O
set -X- _ O
. -X- _ O

Second -X- _ O
, -X- _ O
RelU -X- _ O
- -X- _ O
Net -X- _ O
Random -X- _ O
significantly -X- _ O
outperforms -X- _ O
other -X- _ O
randomly -X- _ O
initialized -X- _ O
models -X- _ O
on -X- _ O
the -X- _ O
NYT -X- _ B-DatasetName
and -X- _ O
WebNLG -X- _ B-DatasetName
datasets -X- _ O
. -X- _ O
Moreover -X- _ O
, -X- _ O
RelU -X- _ B-MethodName
- -X- _ I-MethodName
Net -X- _ I-MethodName
Random -X- _ O
even -X- _ O
outperforms -X- _ O
RelU -X- _ B-MethodName
- -X- _ I-MethodName
Net -X- _ I-MethodName
Raw -X- _ O
where -X- _ O
the -X- _ O
latter -X- _ O
uses -X- _ O
pre -X- _ O
- -X- _ O
trained -X- _ O
BERT -X- _ O
weights -X- _ O
while -X- _ O
the -X- _ O
former -X- _ O
does -X- _ O
not -X- _ O
. -X- _ O
It -X- _ O
indicates -X- _ O
the -X- _ O
effectiveness -X- _ O
of -X- _ O
our -X- _ O
method -X- _ O
to -X- _ O
incorporate -X- _ O
the -X- _ O
syntactic -X- _ O
structure -X- _ O
of -X- _ O
the -X- _ O
sentence -X- _ O
by -X- _ O
automatically -X- _ O
contracting -X- _ O
the -X- _ O
dependency -X- _ O
tree -X- _ O
and -X- _ O
reducing -X- _ O
noisy -X- _ O
contents -X- _ O
. -X- _ O
Finally -X- _ O
, -X- _ O
RelU -X- _ B-MethodName
- -X- _ I-MethodName
Net -X- _ I-MethodName
BERT -X- _ O
and -X- _ O
RelU -X- _ B-MethodName
- -X- _ I-MethodName
Net -X- _ I-MethodName
RoBERTa -X- _ O
further -X- _ O
outperforms -X- _ O
RelU -X- _ O
- -X- _ O
Net -X- _ O
Random -X- _ O
and -X- _ O
other -X- _ O
baseline -X- _ O
models -X- _ O
. -X- _ O

It -X- _ O
indicates -X- _ O
that -X- _ O
the -X- _ O
pre -X- _ O
- -X- _ O
trained -X- _ O
language -X- _ O
models -X- _ O
bring -X- _ O
more -X- _ O
prior -X- _ O
knowledge -X- _ O
from -X- _ O
unlabeled -X- _ O
corpus -X- _ O
and -X- _ O
enhance -X- _ O
the -X- _ O
model -X- _ O
performance -X- _ O
. -X- _ O

Following -X- _ O
previous -X- _ O
work -X- _ O
( -X- _ O
Wei -X- _ O
et -X- _ O
al -X- _ O
. -X- _ O
, -X- _ O
2020 -X- _ O
; -X- _ O
Zheng -X- _ O
et -X- _ O
al -X- _ O
. -X- _ O
, -X- _ O
2021 -X- _ O
; -X- _ O
, -X- _ O
we -X- _ O
divide -X- _ O
the -X- _ O
test -X- _ O
sets -X- _ O
of -X- _ O
two -X- _ O
datasets -X- _ O
according -X- _ O
to -X- _ O
the -X- _ O
overlapping -X- _ O
patterns -X- _ O
and -X- _ O
the -X- _ O
triple -X- _ O
counts -X- _ O
to -X- _ O
investigate -X- _ O
the -X- _ O
ability -X- _ O
of -X- _ O
our -X- _ O
model -X- _ O
in -X- _ O
handling -X- _ O
complex -X- _ O
sentences -X- _ O
. -X- _ O
The -X- _ O
results -X- _ O
are -X- _ O
shown -X- _ O
in -X- _ O
Table -X- _ O
3 -X- _ O
. -X- _ O
We -X- _ O
observe -X- _ O
that -X- _ O
our -X- _ O
RelU -X- _ B-MethodName
- -X- _ I-MethodName
Net -X- _ I-MethodName
model -X- _ O
outperforms -X- _ O
the -X- _ O
baseline -X- _ O
models -X- _ O
in -X- _ O
almost -X- _ O
all -X- _ O
the -X- _ O
subsets -X- _ O
, -X- _ O
especially -X- _ O
on -X- _ O
the -X- _ O
WebNLG -X- _ B-DatasetName
dataset -X- _ O
. -X- _ O
We -X- _ O
speculate -X- _ O
that -X- _ O
this -X- _ O
is -X- _ O
because -X- _ O
we -X- _ O
train -X- _ O
the -X- _ O
model -X- _ O
with -X- _ O
the -X- _ O
graph -X- _ O
similarity -X- _ O
loss -X- _ O
( -X- _ O
Section -X- _ O
3.3 -X- _ O
) -X- _ O
to -X- _ O
bootstrap -X- _ O
the -X- _ O
core -X- _ O
topology -X- _ O
connections -X- _ O
to -X- _ O
reflect -X- _ O
relational -X- _ O
facts -X- _ O
, -X- _ O
thus -X- _ O
the -X- _ O
complex -X- _ O
interactions -X- _ O
between -X- _ O
multiple -X- _ O
relational -X- _ O
triples -X- _ O
can -X- _ O
be -X- _ O
naturally -X- _ O
captured -X- _ O
through -X- _ O
the -X- _ O
graph -X- _ O
convolutions -X- _ O
over -X- _ O
the -X- _ O
core -X- _ O
topology -X- _ O
. -X- _ O
In -X- _ O
general -X- _ O
, -X- _ O
the -X- _ O
results -X- _ O
on -X- _ O
different -X- _ O
sentence -X- _ O
types -X- _ O
show -X- _ O
the -X- _ O
effectiveness -X- _ O
of -X- _ O
our -X- _ O
model -X- _ O
in -X- _ O
complicated -X- _ O
scenarios -X- _ O
. -X- _ O

In -X- _ O
this -X- _ O
section -X- _ O
, -X- _ O
we -X- _ O
conduct -X- _ O
an -X- _ O
ablation -X- _ O
study -X- _ O
on -X- _ O
the -X- _ O
NYT -X- _ B-DatasetName
test -X- _ O
set -X- _ O
to -X- _ O
demonstrate -X- _ O
the -X- _ O
contribution -X- _ O
of -X- _ O
each -X- _ O
component -X- _ O
of -X- _ O
our -X- _ O
model -X- _ O
. -X- _ O
The -X- _ O
result -X- _ O
is -X- _ O
shown -X- _ O
in -X- _ O
Table -X- _ O
4 -X- _ O
. -X- _ O
Note -X- _ O
that -X- _ O
when -X- _ O
removing -X- _ O
Graph -X- _ O
- -X- _ O
SAGE -X- _ O
, -X- _ O
we -X- _ O
use -X- _ O
the -X- _ O
transductive -X- _ O
convolution -X- _ O
( -X- _ O
Kipf -X- _ O
and -X- _ O
Welling -X- _ O
, -X- _ O
2016 -X- _ O
) -X- _ O
to -X- _ O
the -X- _ O
model -X- _ O
because -X- _ O
it -X- _ O
helps -X- _ O
minimize -X- _ O
the -X- _ O
approximate -X- _ O
lower -X- _ O
bound -X- _ O
of -X- _ O
the -X- _ O
node -X- _ O
matching -X- _ O
cost -X- _ O
, -X- _ O
which -X- _ O
is -X- _ O
approximately -X- _ O
equivalent -X- _ O
to -X- _ O
minimizing -X- _ O
the -X- _ O
actual -X- _ O
cost -X- _ O
with -X- _ O
a -X- _ O
relaxation -X- _ O
since -X- _ O
the -X- _ O
real -X- _ O
optimal -X- _ O
permutation -X- _ O
is -X- _ O
unknown -X- _ O
. -X- _ O
Moreover -X- _ O
, -X- _ O
removing -X- _ O
the -X- _ O
bipartite -X- _ O
matching -X- _ O
and -X- _ O
graph -X- _ O
similarity -X- _ O
loss -X- _ O
together -X- _ O
causes -X- _ O
a -X- _ O
significant -X- _ O
performance -X- _ O
drop -X- _ O
. -X- _ O
It -X- _ O
demonstrates -X- _ O
the -X- _ O
effectiveness -X- _ O
of -X- _ O
our -X- _ O
training -X- _ O
objectives -X- _ O
in -X- _ O
capturing -X- _ O
the -X- _ O
reflections -X- _ O
between -X- _ O
syntactic -X- _ O
connections -X- _ O
and -X- _ O
relational -X- _ O
facts -X- _ O
. -X- _ O
Finally -X- _ O
, -X- _ O
the -X- _ O
model -X- _ O
without -X- _ O
all -X- _ O
three -X- _ O
components -X- _ O
produces -X- _ O
the -X- _ O
worst -X- _ O
performance -X- _ O
, -X- _ O
which -X- _ O
proves -X- _ O
that -X- _ O
our -X- _ O
model -X- _ O
can -X- _ O
sufficiently -X- _ O
explore -X- _ O
syntactic -X- _ O
information -X- _ O
and -X- _ O
improve -X- _ O
RTE -X- _ B-TaskName
performance -X- _ O
. -X- _ O

To -X- _ O
investigate -X- _ O
the -X- _ O
balance -X- _ O
between -X- _ O
pruning -X- _ O
irrelevant -X- _ O
contents -X- _ O
and -X- _ O
preserving -X- _ O
informative -X- _ O
edges -X- _ O
, -X- _ O
we -X- _ O
conduct -X- _ O
experiments -X- _ O
on -X- _ O
the -X- _ O
NYT -X- _ B-DatasetName
test -X- _ O
sets -X- _ O
with -X- _ O
different -X- _ O
core -X- _ O
topology -X- _ O
sizes -X- _ O
, -X- _ O
which -X- _ O
stand -X- _ O
for -X- _ O
different -X- _ O
ratios -X- _ O
of -X- _ O
graph -X- _ O
reduction -X- _ O
. -X- _ O
The -X- _ O
results -X- _ O
are -X- _ O
illustrated -X- _ O
in -X- _ O
Figure -X- _ O
3 -X- _ O
. -X- _ O
We -X- _ O
observe -X- _ O
that -X- _ O
when -X- _ O
the -X- _ O
size -X- _ O
is -X- _ O
too -X- _ O
small -X- _ O
, -X- _ O
the -X- _ O
performance -X- _ O
drops -X- _ O
significantly -X- _ O
. -X- _ O
We -X- _ O
hypothesize -X- _ O
that -X- _ O
too -X- _ O
aggressive -X- _ O
pooling -X- _ O
causes -X- _ O
undesired -X- _ O
pruning -X- _ O
of -X- _ O
informative -X- _ O
contents -X- _ O
, -X- _ O
or -X- _ O
even -X- _ O
merging -X- _ O
of -X- _ O
multiple -X- _ O
entities -X- _ O
, -X- _ O
and -X- _ O
hurts -X- _ O
the -X- _ O
performance -X- _ O
. -X- _ O
When -X- _ O
the -X- _ O
topology -X- _ O
size -X- _ O
increases -X- _ O
up -X- _ O
to -X- _ O
the -X- _ O
most -X- _ O
extreme -X- _ O
setting -X- _ O
of -X- _ O
no -X- _ O
pooling -X- _ O
, -X- _ O
the -X- _ O
noisy -X- _ O
content -X- _ O
can -X- _ O
not -X- _ O
be -X- _ O
sufficiently -X- _ O
eliminated -X- _ O
thus -X- _ O
leads -X- _ O
to -X- _ O
performance -X- _ O
degradation -X- _ O
. -X- _ O

Figure -X- _ O
4 -X- _ O
shows -X- _ O
the -X- _ O
comparison -X- _ O
of -X- _ O
the -X- _ O
RelU -X- _ B-MethodName
- -X- _ I-MethodName
Net -X- _ I-MethodName
BERT -X- _ O
and -X- _ O
CASREL -X- _ B-MethodName
BERT -X- _ O
models -X- _ O
on -X- _ O
two -X- _ O
examples -X- _ O
. -X- _ O
In -X- _ O
the -X- _ O
first -X- _ O
example -X- _ O
, -X- _ O
the -X- _ O
dependency -X- _ O
tree -X- _ O
itself -X- _ O
contains -X- _ O
conjunct -X- _ O
patterns -X- _ O
between -X- _ O
the -X- _ O
entities -X- _ O
" -X- _ O
Ghana -X- _ O
" -X- _ O
, -X- _ O
" -X- _ O
Togo -X- _ O
" -X- _ O
and -X- _ O
" -X- _ O
Angola -X- _ O
" -X- _ O
and -X- _ O
the -X- _ O
patterns -X- _ O
are -X- _ O
successfully -X- _ O
preserved -X- _ O
in -X- _ O
the -X- _ O
core -X- _ O
topology -X- _ O
. -X- _ O
In -X- _ O
the -X- _ O
second -X- _ O
example -X- _ O
, -X- _ O
despite -X- _ O
the -X- _ O
redundancy -X- _ O
of -X- _ O
the -X- _ O
dependency -X- _ O
structure -X- _ O
between -X- _ O
the -X- _ O
entities -X- _ O
" -X- _ O
Danny -X- _ O
Glover -X- _ O
" -X- _ O
and -X- _ O
" -X- _ O
San -X- _ O
Francisco -X- _ O
" -X- _ O
, -X- _ O
the -X- _ O
graph -X- _ O
pooling -X- _ O
operations -X- _ O
eliminate -X- _ O
the -X- _ O
irrelevant -X- _ O
contents -X- _ O
and -X- _ O
the -X- _ O
corresponding -X- _ O
connection -X- _ O
in -X- _ O
the -X- _ O
core -X- _ O
topology -X- _ O
is -X- _ O
informative -X- _ O
enough -X- _ O
for -X- _ O
the -X- _ O
triple -X- _ O
to -X- _ O
be -X- _ O
extracted -X- _ O
. -X- _ O
We -X- _ O
can -X- _ O
observe -X- _ O
that -X- _ O
our -X- _ O
model -X- _ O
sufficiently -X- _ O
explores -X- _ O
the -X- _ O
syntactic -X- _ O
information -X- _ O
of -X- _ O
the -X- _ O
dependency -X- _ O
trees -X- _ O
, -X- _ O
while -X- _ O
CASREL -X- _ B-MethodName
only -X- _ O
captures -X- _ O
semantic -X- _ O
information -X- _ O
and -X- _ O
thus -X- _ O
yields -X- _ O
worse -X- _ O
predictions -X- _ O
than -X- _ O
our -X- _ O
model -X- _ O
. -X- _ O
The -X- _ O
above -X- _ O
observations -X- _ O
demonstrate -X- _ O
the -X- _ O
effectiveness -X- _ O
of -X- _ O
our -X- _ O
method -X- _ O
in -X- _ O
incorporating -X- _ O
syntactic -X- _ O
structures -X- _ O
for -X- _ O
relational -X- _ O
triple -X- _ O
extraction -X- _ O
. -X- _ O

In -X- _ O
this -X- _ O
paper -X- _ O
, -X- _ O
we -X- _ O
propose -X- _ O
a -X- _ O
unified -X- _ O
framework -X- _ O
to -X- _ O
incorporate -X- _ O
syntactic -X- _ O
structures -X- _ O
of -X- _ O
the -X- _ O
sentence -X- _ O
for -X- _ O
relation -X- _ B-TaskName
triple -X- _ I-TaskName
extraction -X- _ I-TaskName
. -X- _ O
We -X- _ O
propose -X- _ O
a -X- _ O
graph -X- _ O
pooling -X- _ O
network -X- _ O
to -X- _ O
automatically -X- _ O
prune -X- _ O
the -X- _ O
dependency -X- _ O
tree -X- _ O
to -X- _ O
a -X- _ O
core -X- _ O
topology -X- _ O
and -X- _ O
remove -X- _ O
useless -X- _ O
information -X- _ O
. -X- _ O
We -X- _ O
propose -X- _ O
a -X- _ O
symmetrical -X- _ O
graph -X- _ O
unpooling -X- _ O
network -X- _ O
to -X- _ O
integrate -X- _ O
the -X- _ O
syntactic -X- _ O
interactions -X- _ O
underlying -X- _ O
the -X- _ O
core -X- _ O
topology -X- _ O
with -X- _ O
the -X- _ O
original -X- _ O
sen -X- _ O
- -X- _ O
tence -X- _ O
context -X- _ O
. -X- _ O
We -X- _ O
also -X- _ O
propose -X- _ O
a -X- _ O
bipartite -X- _ O
graph -X- _ O
matching -X- _ O
objective -X- _ O
function -X- _ O
to -X- _ O
learn -X- _ O
the -X- _ O
reflections -X- _ O
between -X- _ O
the -X- _ O
core -X- _ O
syntactic -X- _ O
interactions -X- _ O
and -X- _ O
golden -X- _ O
relational -X- _ O
facts -X- _ O
. -X- _ O
We -X- _ O
conduct -X- _ O
experiments -X- _ O
on -X- _ O
two -X- _ O
benchmark -X- _ O
datasets -X- _ O
, -X- _ O
and -X- _ O
the -X- _ O
results -X- _ O
demonstrate -X- _ O
the -X- _ O
effectiveness -X- _ O
of -X- _ O
our -X- _ O
method -X- _ O
. -X- _ O

We -X- _ O
would -X- _ O
like -X- _ O
to -X- _ O
thank -X- _ O
the -X- _ O
anonymous -X- _ O
reviewers -X- _ O
for -X- _ O
their -X- _ O
valuable -X- _ O
comments -X- _ O
on -X- _ O
this -X- _ O
paper -X- _ O
. -X- _ O
This -X- _ O
work -X- _ O
was -X- _ O
supported -X- _ O
by -X- _ O
National -X- _ O
Key -X- _ O
Research -X- _ O
and -X- _ O
Development -X- _ O
Program -X- _ O
of -X- _ O
China -X- _ O
under -X- _ O
Grant -X- _ O
number -X- _ O
2021ZD0113902 -X- _ O
and -X- _ O
the -X- _ O
National -X- _ O
Natural -X- _ O
Science -X- _ O
Foundation -X- _ O
of -X- _ O
China -X- _ O
under -X- _ O
Grant -X- _ O
numbers -X- _ O
U1936216 -X- _ O
and -X- _ O
U1936208 -X- _ O
. -X- _ O
We -X- _ O
would -X- _ O
like -X- _ O
to -X- _ O
thank -X- _ O
the -X- _ O
VMWare -X- _ O
gift -X- _ O
funding -X- _ O
's -X- _ O
partial -X- _ O
support -X- _ O
to -X- _ O
the -X- _ O
authors -X- _ O
. -X- _ O

Three -X- _ O
of -X- _ O
Africa -X- _ O
's -X- _ O
World -X- _ O
Cup -X- _ O
representatives -X- _ O
-Ghana -X- _ O
, -X- _ O
Togo -X- _ O
and -X- _ O
Angola -X- _ O
-were -X- _ O
eliminated -X- _ O
in -X- _ O
the -X- _ O
first -X- _ O
round -X- _ O
. -X- _ O

San -X- _ O
Francisco -X- _ O
Core -X- _ O
Topology -X- _ O
Africa -X- _ O
Ghana -X- _ O
Togo -X- _ O
Angola -X- _ O
Danny -X- _ O
Glover -X- _ O
Haight -X- _ O
- -X- _ O
Ashbury -X- _ O
San -X- _ O
Francisco -X- _ O
Africa -X- _ O
Ghana -X- _ O
Togo -X- _ O
Angola -X- _ O
Danny -X- _ O
Glover -X- _ O
Haight -X- _ O
- -X- _ O
Ashbury -X- _ O
San -X- _ O
Francisco -X- _ O
live_in -X- _ O
contains -X- _ O
was -X- _ O
for -X- _ O
Glover -X- _ O
Ashbury -X- _ O
in -X- _ O
Danny -X- _ O
Francisco -X- _ O
Haight -X- _ O
San -X- _ O
eliminated -X- _ O
representatives -X- _ O
Africa -X- _ O
Ghana -X- _ O
Togo -X- _ O
Ango -X- _ O

Recent -X- _ O
entity -X- _ O
and -X- _ O
relation -X- _ O
extraction -X- _ O
works -X- _ O
focus -X- _ O
on -X- _ O
investigating -X- _ O
how -X- _ O
to -X- _ O
obtain -X- _ O
a -X- _ O
better -X- _ O
span -X- _ O
representation -X- _ O
from -X- _ O
the -X- _ O
pre -X- _ O
- -X- _ O
trained -X- _ O
encoder -X- _ O
. -X- _ O
However -X- _ O
, -X- _ O
a -X- _ O
major -X- _ O
limitation -X- _ O
of -X- _ O
existing -X- _ O
works -X- _ O
is -X- _ O
that -X- _ O
they -X- _ O
ignore -X- _ O
the -X- _ O
interrelation -X- _ O
between -X- _ O
spans -X- _ O
( -X- _ O
pairs -X- _ O
) -X- _ O
. -X- _ O
In -X- _ O
this -X- _ O
work -X- _ O
, -X- _ O
we -X- _ O
propose -X- _ O
a -X- _ O
novel -X- _ O
span -X- _ O
representation -X- _ O
approach -X- _ O
, -X- _ O
named -X- _ O
Packed -X- _ B-MethodName
Levitated -X- _ I-MethodName
Markers -X- _ I-MethodName
( -X- _ O
PL -X- _ B-MethodName
- -X- _ I-MethodName
Marker -X- _ I-MethodName
) -X- _ O
, -X- _ O
to -X- _ O
consider -X- _ O
the -X- _ O
interrelation -X- _ O
between -X- _ O
the -X- _ O
spans -X- _ O
( -X- _ O
pairs -X- _ O
) -X- _ O
by -X- _ O
strategically -X- _ O
packing -X- _ O
the -X- _ O
markers -X- _ O
in -X- _ O
the -X- _ O
encoder -X- _ O
. -X- _ O
In -X- _ O
particular -X- _ O
, -X- _ O
we -X- _ O
propose -X- _ O
a -X- _ O
neighborhood -X- _ O
- -X- _ O
oriented -X- _ O
packing -X- _ O
strategy -X- _ O
, -X- _ O
which -X- _ O
considers -X- _ O
the -X- _ O
neighbor -X- _ O
spans -X- _ O
integrally -X- _ O
to -X- _ O
better -X- _ O
model -X- _ O
the -X- _ O
entity -X- _ O
boundary -X- _ O
information -X- _ O
. -X- _ O
Furthermore -X- _ O
, -X- _ O
for -X- _ O
those -X- _ O
more -X- _ O
complicated -X- _ O
span -X- _ O
pair -X- _ O
classification -X- _ O
tasks -X- _ O
, -X- _ O
we -X- _ O
design -X- _ O
a -X- _ O
subject -X- _ O
- -X- _ O
oriented -X- _ O
packing -X- _ O
strategy -X- _ O
, -X- _ O
which -X- _ O
packs -X- _ O
each -X- _ O
subject -X- _ O
and -X- _ O
all -X- _ O
its -X- _ O
objects -X- _ O
to -X- _ O
model -X- _ O
the -X- _ O
interrelation -X- _ O
between -X- _ O
the -X- _ O
same -X- _ O
- -X- _ O
subject -X- _ O
span -X- _ O
pairs -X- _ O
. -X- _ O
The -X- _ O
experimental -X- _ O
results -X- _ O
show -X- _ O
that -X- _ O
, -X- _ O
with -X- _ O
the -X- _ O
enhanced -X- _ O
marker -X- _ O
feature -X- _ O
, -X- _ O
our -X- _ O
model -X- _ O
advances -X- _ O
baselines -X- _ O
on -X- _ O
six -X- _ O
NER -X- _ B-TaskName
benchmarks -X- _ O
, -X- _ O
and -X- _ O
obtains -X- _ O
a -X- _ O
4.1 -X- _ B-MetricValue
% -X- _ I-MetricValue
-4.3 -X- _ I-MetricValue
% -X- _ B-MetricValue
strict -X- _ O
relation -X- _ O
F1 -X- _ B-MetricName
improvement -X- _ O
with -X- _ O
higher -X- _ O
speed -X- _ O
over -X- _ O
previous -X- _ O
state -X- _ O
- -X- _ O
of -X- _ O
- -X- _ O
the -X- _ O
- -X- _ O
art -X- _ O
models -X- _ O
on -X- _ O
ACE04 -X- _ B-DatasetName
and -X- _ O
ACE05 -X- _ B-DatasetName
. -X- _ O
Our -X- _ O
code -X- _ O
and -X- _ O
models -X- _ O
are -X- _ O
publicly -X- _ O
available -X- _ O
at -X- _ O
https -X- _ O
: -X- _ O
/ -X- _ O
/ -X- _ O
github.com -X- _ O
/ -X- _ O
thunlp -X- _ O
/ -X- _ O
PL -X- _ O
- -X- _ O
Marker -X- _ O
. -X- _ O

Recently -X- _ O
, -X- _ O
pre -X- _ O
- -X- _ O
trained -X- _ O
language -X- _ O
models -X- _ O
( -X- _ O
PLMs -X- _ O
) -X- _ O
( -X- _ O
Devlin -X- _ O
et -X- _ O
al -X- _ O
. -X- _ O
, -X- _ O
2019 -X- _ O
; -X- _ O
have -X- _ O
achieved -X- _ O
significant -X- _ O
improvements -X- _ O
in -X- _ O
Named -X- _ B-TaskName
Entity -X- _ I-TaskName
Recognition -X- _ I-TaskName
( -X- _ O
NER -X- _ B-TaskName
, -X- _ O
Luo -X- _ O
et -X- _ O
al -X- _ O
. -X- _ O
( -X- _ O
2020 -X- _ O
) -X- _ O
; -X- _ O
Fu -X- _ O
et -X- _ O
al -X- _ O
. -X- _ O
( -X- _ O
2021 -X- _ O
) -X- _ O
) -X- _ O
and -X- _ O
Relation -X- _ B-TaskName
Extraction -X- _ I-TaskName
( -X- _ O
RE -X- _ B-TaskName
, -X- _ O
; -X- _ O
Zhou -X- _ O
and -X- _ O
Chen -X- _ O
( -X- _ O
2021 -X- _ O
) -X- _ O
) -X- _ O
, -X- _ O
two -X- _ O
key -X- _ O
sub -X- _ O
- -X- _ O
tasks -X- _ O
of -X- _ O
information -X- _ O
extraction -X- _ O
. -X- _ O
Recent -X- _ O
works -X- _ O
( -X- _ O
Wang -X- _ O
et -X- _ O
al -X- _ O
. -X- _ O
, -X- _ O
2021c -X- _ O
; -X- _ O
Zhong -X- _ O
and -X- _ O
Chen -X- _ O
, -X- _ O
2021 -X- _ O
) -X- _ O
regard -X- _ O
these -X- _ O
two -X- _ O
tasks -X- _ O
as -X- _ O
span -X- _ O
classification -X- _ O
or -X- _ O
span -X- _ O
pair -X- _ O
classification -X- _ O
, -X- _ O
and -X- _ O
thus -X- _ O
focus -X- _ O
on -X- _ O
extracting -X- _ O
better -X- _ O
span -X- _ O
representations -X- _ O
from -X- _ O
the -X- _ O
PLMs -X- _ O
. -X- _ O
Three -X- _ O
span -X- _ O
representation -X- _ O
extraction -X- _ O
methods -X- _ O
are -X- _ O
widely -X- _ O
used -X- _ O
: -X- _ O
( -X- _ O
1 -X- _ O
) -X- _ O
T -X- _ O
- -X- _ O
Concat -X- _ O
( -X- _ O
Lee -X- _ O
et -X- _ O
al -X- _ O
. -X- _ O
, -X- _ O
2017 -X- _ O
; -X- _ O
Jiang -X- _ O
et -X- _ O
al -X- _ O
. -X- _ O
, -X- _ O
2020 -X- _ O
) -X- _ O
concatenates -X- _ O
the -X- _ O
representation -X- _ O
of -X- _ O
the -X- _ O
span -X- _ O
's -X- _ O
boundary -X- _ O
( -X- _ O
start -X- _ O
and -X- _ O
end -X- _ O
) -X- _ O
tokens -X- _ O
to -X- _ O
obtain -X- _ O
the -X- _ O
span -X- _ O
representation -X- _ O
. -X- _ O
It -X- _ O
collects -X- _ O
information -X- _ O
at -X- _ O
the -X- _ O
token -X- _ O
level -X- _ O
but -X- _ O
ignores -X- _ O
the -X- _ O
connection -X- _ O
between -X- _ O
boundary -X- _ O
tokens -X- _ O
of -X- _ O
a -X- _ O
span -X- _ O
when -X- _ O
they -X- _ O
pass -X- _ O
through -X- _ O
the -X- _ O
network -X- _ O
; -X- _ O
( -X- _ O
2 -X- _ O
) -X- _ O
Solid -X- _ O
Marker -X- _ O
( -X- _ O
Soares -X- _ O
et -X- _ O
al -X- _ O
. -X- _ O
, -X- _ O
2019 -X- _ O
; -X- _ O
explicitly -X- _ O
insert -X- _ O
two -X- _ O
solid -X- _ O
markers -X- _ O
before -X- _ O
and -X- _ O
after -X- _ O
the -X- _ O
span -X- _ O
to -X- _ O
highlight -X- _ O
the -X- _ O
span -X- _ O
in -X- _ O
the -X- _ O
input -X- _ O
text -X- _ O
. -X- _ O
And -X- _ O
it -X- _ O
inserts -X- _ O
two -X- _ O
pair -X- _ O
of -X- _ O
markers -X- _ O
to -X- _ O
locate -X- _ O
the -X- _ O
subject -X- _ O
and -X- _ O
object -X- _ O
of -X- _ O
a -X- _ O
span -X- _ O
pair -X- _ O
. -X- _ O
However -X- _ O
, -X- _ O
the -X- _ O
method -X- _ O
can -X- _ O
not -X- _ O
handle -X- _ O
multiple -X- _ O
span -X- _ O
pairs -X- _ O
at -X- _ O
the -X- _ O
same -X- _ O
time -X- _ O
because -X- _ O
of -X- _ O
its -X- _ O
weakness -X- _ O
in -X- _ O
specifying -X- _ O
the -X- _ O
solid -X- _ O
markers -X- _ O
of -X- _ O
a -X- _ O
span -X- _ O
pair -X- _ O
from -X- _ O
more -X- _ O
than -X- _ O
two -X- _ O
pairs -X- _ O
of -X- _ O
markers -X- _ O
in -X- _ O
the -X- _ O
sequence -X- _ O
. -X- _ O
( -X- _ O
3 -X- _ O
) -X- _ O
Levitated -X- _ O
Marker -X- _ O
( -X- _ O
Zhong -X- _ O
and -X- _ O
Chen -X- _ O
, -X- _ O
2021 -X- _ O
) -X- _ O
first -X- _ O
sets -X- _ O
a -X- _ O
pair -X- _ O
of -X- _ O
levitated -X- _ O
markers -X- _ O
to -X- _ O
share -X- _ O
the -X- _ O
same -X- _ O
position -X- _ O
with -X- _ O
the -X- _ O
span -X- _ O
's -X- _ O
boundary -X- _ O
tokens -X- _ O
and -X- _ O
then -X- _ O
ties -X- _ O
a -X- _ O
pair -X- _ O
of -X- _ O
markers -X- _ O
by -X- _ O
a -X- _ O
directional -X- _ O
attention -X- _ O
. -X- _ O
To -X- _ O
be -X- _ O
specific -X- _ O
, -X- _ O
the -X- _ O
markers -X- _ O
within -X- _ O
a -X- _ O
pair -X- _ O
are -X- _ O
set -X- _ O
to -X- _ O
be -X- _ O
visible -X- _ O
to -X- _ O
each -X- _ O
other -X- _ O
in -X- _ O
the -X- _ O
attention -X- _ O
mask -X- _ O
matrix -X- _ O
, -X- _ O
but -X- _ O
not -X- _ O
to -X- _ O
the -X- _ O
text -X- _ O
token -X- _ O
and -X- _ O
other -X- _ O
pairs -X- _ O
of -X- _ O
markers -X- _ O
. -X- _ O
Existing -X- _ O
work -X- _ O
( -X- _ O
Zhong -X- _ O
and -X- _ O
Chen -X- _ O
, -X- _ O
2021 -X- _ O
) -X- _ O
simply -X- _ O
replaces -X- _ O
solid -X- _ O
markers -X- _ O
with -X- _ O
levitated -X- _ O
markers -X- _ O
for -X- _ O
an -X- _ O
efficient -X- _ O
batch -X- _ O
computation -X- _ O
, -X- _ O
but -X- _ O
sacrifices -X- _ O
the -X- _ O
model -X- _ O
performance -X- _ O
. -X- _ O

As -X- _ O
the -X- _ O
RE -X- _ B-TaskName
example -X- _ O
shown -X- _ O
in -X- _ O
Figure -X- _ O
1 -X- _ O
, -X- _ O
to -X- _ O
correctly -X- _ O
identify -X- _ O
that -X- _ O
David -X- _ O
, -X- _ O
workers -X- _ O
and -X- _ O
teammates -X- _ O
are -X- _ O
located_in -X- _ O
Copenhagen -X- _ O
, -X- _ O
it -X- _ O
is -X- _ O
important -X- _ O
to -X- _ O
separate -X- _ O
out -X- _ O
that -X- _ O
David -X- _ O
attacked -X- _ O
the -X- _ O
restaurant -X- _ O
workers -X- _ O
and -X- _ O
he -X- _ O
had -X- _ O
social -X- _ O
relation -X- _ O
with -X- _ O
his -X- _ O
teammates -X- _ O
. -X- _ O
However -X- _ O
, -X- _ O
prior -X- _ O
works -X- _ O
with -X- _ O
markers -X- _ O
( -X- _ O
Zhong -X- _ O
and -X- _ O
Chen -X- _ O
, -X- _ O
2021 -X- _ O
) -X- _ O
independently -X- _ O
processes -X- _ O
the -X- _ O
span -X- _ O
pairs -X- _ O
with -X- _ O
different -X- _ O
insertions -X- _ O
of -X- _ O
markers -X- _ O
in -X- _ O
the -X- _ O
training -X- _ O
phrase -X- _ O
, -X- _ O
and -X- _ O
thus -X- _ O
ignore -X- _ O
interrelation -X- _ O
between -X- _ O
spans -X- _ O
( -X- _ O
pairs -X- _ O
) -X- _ O
( -X- _ O
Sorokin -X- _ O
and -X- _ O
Gurevych -X- _ O
, -X- _ O
2017 -X- _ O
; -X- _ O
. -X- _ O

In -X- _ O
this -X- _ O
work -X- _ O
, -X- _ O
we -X- _ O
introduce -X- _ O
Packed -X- _ B-MethodName
Levitated -X- _ I-MethodName
Marker -X- _ I-MethodName
( -X- _ O
PL -X- _ B-MethodName
- -X- _ I-MethodName
Marker -X- _ I-MethodName
) -X- _ O
, -X- _ O
to -X- _ O
model -X- _ O
the -X- _ O
interrelation -X- _ O
between -X- _ O
spans -X- _ O
( -X- _ O
pairs -X- _ O
) -X- _ O
by -X- _ O
strategically -X- _ O
packing -X- _ O
levitated -X- _ O
markers -X- _ O
in -X- _ O
the -X- _ O
encoding -X- _ O
phase -X- _ O
. -X- _ O
A -X- _ O
key -X- _ O
challenge -X- _ O
of -X- _ O
packing -X- _ O
levitated -X- _ O
markers -X- _ O
together -X- _ O
for -X- _ O
span -X- _ O
classification -X- _ O
tasks -X- _ O
is -X- _ O
that -X- _ O
the -X- _ O
increasing -X- _ O
number -X- _ O
of -X- _ O
inserted -X- _ O
levitated -X- _ O
markers -X- _ O
would -X- _ O
exacerbate -X- _ O
the -X- _ O
complexity -X- _ O
of -X- _ O
PLMs -X- _ O
quadratically -X- _ O
( -X- _ O
Ye -X- _ O
et -X- _ O
al -X- _ O
. -X- _ O
, -X- _ O
2021 -X- _ O
) -X- _ O
. -X- _ O
Thus -X- _ O
, -X- _ O
we -X- _ O
have -X- _ O
to -X- _ O
divide -X- _ O
spans -X- _ O
into -X- _ O
several -X- _ O
groups -X- _ O
to -X- _ O
control -X- _ O
the -X- _ O
length -X- _ O
of -X- _ O
each -X- _ O
input -X- _ O
sequence -X- _ O
for -X- _ O
a -X- _ O
higher -X- _ O
speed -X- _ O
and -X- _ O
feasibility -X- _ O
. -X- _ O
In -X- _ O
this -X- _ O
case -X- _ O
, -X- _ O
it -X- _ O
is -X- _ O
necessary -X- _ O
to -X- _ O
consider -X- _ O
the -X- _ O
neighbor -X- _ O
spans -X- _ O
integrally -X- _ O
, -X- _ O
which -X- _ O
could -X- _ O
help -X- _ O
the -X- _ O
model -X- _ O
compare -X- _ O
neighbor -X- _ O
spans -X- _ O
, -X- _ O
e.g. -X- _ O
the -X- _ O
span -X- _ O
with -X- _ O
the -X- _ O
same -X- _ O
start -X- _ O
token -X- _ O
, -X- _ O
to -X- _ O
acquire -X- _ O
a -X- _ O
more -X- _ O
precise -X- _ O
entity -X- _ O
boundary -X- _ O
. -X- _ O
Hence -X- _ O
, -X- _ O
we -X- _ O
propose -X- _ O
a -X- _ O
neighborhood -X- _ O
- -X- _ O
oriented -X- _ O
packing -X- _ O
strategy -X- _ O
, -X- _ O
which -X- _ O
packs -X- _ O
the -X- _ O
spans -X- _ O
with -X- _ O
the -X- _ O
same -X- _ O
start -X- _ O
token -X- _ O
into -X- _ O
a -X- _ O
training -X- _ O
instance -X- _ O
as -X- _ O
much -X- _ O
as -X- _ O
possible -X- _ O
to -X- _ O
better -X- _ O
distinguish -X- _ O
the -X- _ O
entity -X- _ O
boundary -X- _ O
. -X- _ O

For -X- _ O
the -X- _ O
more -X- _ O
complicated -X- _ O
span -X- _ O
pair -X- _ O
classification -X- _ O
tasks -X- _ O
, -X- _ O
an -X- _ O
ideal -X- _ O
packing -X- _ O
scheme -X- _ O
is -X- _ O
to -X- _ O
pack -X- _ O
all -X- _ O
the -X- _ O
span -X- _ O
pairs -X- _ O
together -X- _ O
with -X- _ O
multiple -X- _ O
pairs -X- _ O
of -X- _ O
levitated -X- _ O
markers -X- _ O
, -X- _ O
to -X- _ O
model -X- _ O
all -X- _ O
the -X- _ O
span -X- _ O
pairs -X- _ O
integrally -X- _ O
. -X- _ O
However -X- _ O
, -X- _ O
since -X- _ O
each -X- _ O
pair -X- _ O
of -X- _ O
levitated -X- _ O
markers -X- _ O
is -X- _ O
already -X- _ O
tied -X- _ O
by -X- _ O
directional -X- _ O
attention -X- _ O
, -X- _ O
if -X- _ O
we -X- _ O
continue -X- _ O
to -X- _ O
apply -X- _ O
directional -X- _ O
attention -X- _ O
to -X- _ O
bind -X- _ O
two -X- _ O
pairs -X- _ O
of -X- _ O
markers -X- _ O
, -X- _ O
the -X- _ O
levitated -X- _ O
marker -X- _ O
will -X- _ O
not -X- _ O
be -X- _ O
able -X- _ O
to -X- _ O
identify -X- _ O
its -X- _ O
partner -X- _ O
marker -X- _ O
of -X- _ O
the -X- _ O
same -X- _ O
span -X- _ O
. -X- _ O
Hence -X- _ O
, -X- _ O
we -X- _ O
adopt -X- _ O
a -X- _ O
fusion -X- _ O
of -X- _ O
solid -X- _ O
markers -X- _ O
and -X- _ O
levitated -X- _ O
markers -X- _ O
, -X- _ O
and -X- _ O
use -X- _ O
a -X- _ O
subject -X- _ O
- -X- _ O
oriented -X- _ O
packing -X- _ O
strategy -X- _ O
to -X- _ O
model -X- _ O
the -X- _ O
subject -X- _ O
with -X- _ O
all -X- _ O
its -X- _ O
related -X- _ O
objects -X- _ O
integrally -X- _ O
. -X- _ O
To -X- _ O
be -X- _ O
specific -X- _ O
, -X- _ O
we -X- _ O
emphasize -X- _ O
the -X- _ O
subject -X- _ O
span -X- _ O
with -X- _ O
solid -X- _ O
markers -X- _ O
and -X- _ O
pack -X- _ O
all -X- _ O
its -X- _ O
candidate -X- _ O
object -X- _ O
spans -X- _ O
with -X- _ O
levitated -X- _ O
markers -X- _ O
. -X- _ O
Moreover -X- _ O
, -X- _ O
we -X- _ O
apply -X- _ O
an -X- _ O
object -X- _ O
- -X- _ O
oriented -X- _ O
packing -X- _ O
strategy -X- _ O
for -X- _ O
an -X- _ O
intact -X- _ O
bidirectional -X- _ O
modeling -X- _ O
. -X- _ O

We -X- _ O
examine -X- _ O
the -X- _ O
effect -X- _ O
of -X- _ O
PL -X- _ B-MethodName
- -X- _ I-MethodName
Marker -X- _ I-MethodName
on -X- _ O
two -X- _ O
typical -X- _ O
span -X- _ O
( -X- _ O
pair -X- _ O
) -X- _ O
classification -X- _ O
tasks -X- _ O
, -X- _ O
NER -X- _ B-TaskName
and -X- _ O
endto -X- _ O
- -X- _ O
end -X- _ O
RE -X- _ B-TaskName
. -X- _ O
The -X- _ O
experimental -X- _ O
results -X- _ O
indicate -X- _ O
that -X- _ O
PL -X- _ B-MethodName
- -X- _ I-MethodName
Marker -X- _ I-MethodName
with -X- _ O
neighborhood -X- _ O
- -X- _ O
oriented -X- _ O
packing -X- _ O
scheme -X- _ O
performs -X- _ O
much -X- _ O
better -X- _ O
than -X- _ O
the -X- _ O
model -X- _ O
with -X- _ O
random -X- _ O
packing -X- _ O
scheme -X- _ O
on -X- _ O
NER -X- _ B-TaskName
, -X- _ O
which -X- _ O
shows -X- _ O
the -X- _ O
necessity -X- _ O
of -X- _ O
considering -X- _ O
the -X- _ O
neighbor -X- _ O
spans -X- _ O
integrally -X- _ O
. -X- _ O
And -X- _ O
our -X- _ O
model -X- _ O
also -X- _ O
advances -X- _ O
the -X- _ O
T -X- _ O
- -X- _ O
Concat -X- _ O
model -X- _ O
on -X- _ O
six -X- _ O
NER -X- _ B-TaskName
benchmarks -X- _ O
, -X- _ O
which -X- _ O
demonstrates -X- _ O
the -X- _ O
effectiveness -X- _ O
of -X- _ O
the -X- _ O
feature -X- _ O
obtained -X- _ O
by -X- _ O
span -X- _ O
marker -X- _ O
. -X- _ O
Moreover -X- _ O
, -X- _ O
compared -X- _ O
with -X- _ O
the -X- _ O
previous -X- _ O
state -X- _ O
- -X- _ O
of -X- _ O
- -X- _ O
the -X- _ O
- -X- _ O
art -X- _ O
RE -X- _ B-TaskName
model -X- _ O
, -X- _ O
our -X- _ O
model -X- _ O
gains -X- _ O
a -X- _ O
4.1 -X- _ B-MetricValue
% -X- _ I-MetricValue
-4.3 -X- _ I-MetricValue
% -X- _ B-MetricValue
strict -X- _ O
relation -X- _ O
F1 -X- _ B-MetricName
improvement -X- _ O
with -X- _ O
higher -X- _ O
speed -X- _ O
on -X- _ O
ACE04 -X- _ B-DatasetName
and -X- _ O
ACE05 -X- _ B-DatasetName
and -X- _ O
also -X- _ O
achieves -X- _ O
better -X- _ O
performance -X- _ O
on -X- _ O
SciERC -X- _ B-DatasetName
, -X- _ O
which -X- _ O
shows -X- _ O
the -X- _ O
importance -X- _ O
of -X- _ O
considering -X- _ O
the -X- _ O
interrelation -X- _ O
between -X- _ O
the -X- _ O
subject -X- _ O
- -X- _ O
oriented -X- _ O
span -X- _ O
pairs -X- _ O
. -X- _ O

The -X- _ O
structural -X- _ O
extension -X- _ O
methods -X- _ O
add -X- _ O
reasoning -X- _ O
modules -X- _ O
to -X- _ O
the -X- _ O
existing -X- _ O
models -X- _ O
, -X- _ O
such -X- _ O
as -X- _ O
biaffine -X- _ O
attention -X- _ O
( -X- _ O
Wang -X- _ O
et -X- _ O
al -X- _ O
. -X- _ O
, -X- _ O
2021d -X- _ O
) -X- _ O
, -X- _ O
graph -X- _ O
propagation -X- _ O
and -X- _ O
memory -X- _ O
flow -X- _ O
( -X- _ O
Shen -X- _ O
et -X- _ O
al -X- _ O
. -X- _ O
, -X- _ O
2021 -X- _ O
) -X- _ O
. -X- _ O
With -X- _ O
the -X- _ O
support -X- _ O
of -X- _ O
modern -X- _ O
pre -X- _ O
- -X- _ O
training -X- _ O
encoders -X- _ O
( -X- _ O
e.g. -X- _ O
BERT -X- _ O
) -X- _ O
, -X- _ O
the -X- _ O
simple -X- _ O
model -X- _ O
with -X- _ O
solid -X- _ O
markers -X- _ O
could -X- _ O
achieve -X- _ O
state -X- _ O
- -X- _ O
of -X- _ O
- -X- _ O
art -X- _ O
results -X- _ O
in -X- _ O
RE -X- _ B-TaskName
( -X- _ O
Zhou -X- _ O
and -X- _ O
Chen -X- _ O
, -X- _ O
2021 -X- _ O
; -X- _ O
Zhong -X- _ O
and -X- _ O
Chen -X- _ O
, -X- _ O
2021 -X- _ O
) -X- _ O
. -X- _ O
However -X- _ O
, -X- _ O
it -X- _ O
is -X- _ O
hard -X- _ O
to -X- _ O
specify -X- _ O
the -X- _ O
solid -X- _ O
markers -X- _ O
of -X- _ O
a -X- _ O
span -X- _ O
pair -X- _ O
from -X- _ O
more -X- _ O
than -X- _ O
two -X- _ O
pairs -X- _ O
of -X- _ O
markers -X- _ O
in -X- _ O
the -X- _ O
sequence -X- _ O
. -X- _ O
Hence -X- _ O
, -X- _ O
previous -X- _ O
work -X- _ O
( -X- _ O
Zhong -X- _ O
and -X- _ O
Chen -X- _ O
, -X- _ O
2021 -X- _ O
) -X- _ O
has -X- _ O
to -X- _ O
process -X- _ O
span -X- _ O
pairs -X- _ O
independently -X- _ O
, -X- _ O
which -X- _ O
is -X- _ O
time -X- _ O
- -X- _ O
consuming -X- _ O
and -X- _ O
ignores -X- _ O
the -X- _ O
interrelation -X- _ O
between -X- _ O
the -X- _ O
span -X- _ O
pairs -X- _ O
. -X- _ O
In -X- _ O
this -X- _ O
work -X- _ O
, -X- _ O
we -X- _ O
introduce -X- _ O
the -X- _ O
neighborhoodoriented -X- _ O
and -X- _ O
the -X- _ O
subject -X- _ O
- -X- _ O
oriented -X- _ O
packing -X- _ O
strategies -X- _ O
to -X- _ O
take -X- _ O
advantage -X- _ O
of -X- _ O
the -X- _ O
levitated -X- _ O
markers -X- _ O
to -X- _ O
provide -X- _ O
an -X- _ O
integral -X- _ O
modeling -X- _ O
on -X- _ O
spans -X- _ O
( -X- _ O
pairs -X- _ O
) -X- _ O
. -X- _ O

To -X- _ O
our -X- _ O
best -X- _ O
knowledge -X- _ O
, -X- _ O
we -X- _ O
are -X- _ O
the -X- _ O
first -X- _ O
to -X- _ O
apply -X- _ O
the -X- _ O
levitated -X- _ O
markers -X- _ O
on -X- _ O
the -X- _ O
NER -X- _ B-TaskName
. -X- _ O
On -X- _ O
the -X- _ O
RE -X- _ B-TaskName
, -X- _ O
the -X- _ O
closest -X- _ O
work -X- _ O
to -X- _ O
ours -X- _ O
is -X- _ O
the -X- _ O
PURE -X- _ B-MethodName
( -X- _ O
Approx -X- _ O
. -X- _ O
) -X- _ O
( -X- _ O
Zhong -X- _ O
and -X- _ O
Chen -X- _ O
, -X- _ O
2021 -X- _ O
) -X- _ O
, -X- _ O
which -X- _ O
independently -X- _ O
encodes -X- _ O
each -X- _ O
span -X- _ O
pair -X- _ O
with -X- _ O
two -X- _ O
pairs -X- _ O
of -X- _ O
levitated -X- _ O
markers -X- _ O
in -X- _ O
the -X- _ O
training -X- _ O
phase -X- _ O
and -X- _ O
batches -X- _ O
multiple -X- _ O
pairs -X- _ O
of -X- _ O
markers -X- _ O
to -X- _ O
accelerate -X- _ O
the -X- _ O
inference -X- _ O
process -X- _ O
. -X- _ O
Compared -X- _ O
to -X- _ O
their -X- _ O
work -X- _ O
, -X- _ O
our -X- _ O
model -X- _ O
adopts -X- _ O
a -X- _ O
fusion -X- _ O
subject -X- _ O
- -X- _ O
oriented -X- _ O
packing -X- _ O
scheme -X- _ O
and -X- _ O
thus -X- _ O
handle -X- _ O
multiple -X- _ O
span -X- _ O
pairs -X- _ O
well -X- _ O
in -X- _ O
both -X- _ O
the -X- _ O
training -X- _ O
and -X- _ O
inference -X- _ O
process -X- _ O
. -X- _ O
We -X- _ O
detail -X- _ O
the -X- _ O
differences -X- _ O
between -X- _ O
our -X- _ O
work -X- _ O
and -X- _ O
PURE -X- _ B-MethodName
in -X- _ O
Section -X- _ O
4.4.2 -X- _ O
and -X- _ O
explain -X- _ O
why -X- _ O
our -X- _ O
model -X- _ O
performs -X- _ O
better -X- _ O
. -X- _ O

Levitated -X- _ O
marker -X- _ O
is -X- _ O
used -X- _ O
as -X- _ O
an -X- _ O
approximation -X- _ O
of -X- _ O
solid -X- _ O
markers -X- _ O
, -X- _ O
which -X- _ O
allows -X- _ O
models -X- _ O
to -X- _ O
classify -X- _ O
multiple -X- _ O
pairs -X- _ O
of -X- _ O
entities -X- _ O
simultaneously -X- _ O
to -X- _ O
accelerate -X- _ O
the -X- _ O
inference -X- _ O
process -X- _ O
( -X- _ O
Zhong -X- _ O
and -X- _ O
Chen -X- _ O
, -X- _ O
2021 -X- _ O
) -X- _ O
. -X- _ O
A -X- _ O
pair -X- _ O
of -X- _ O
levitated -X- _ O
markers -X- _ O
, -X- _ O
associated -X- _ O
with -X- _ O
a -X- _ O
span -X- _ O
, -X- _ O
consists -X- _ O
of -X- _ O
a -X- _ O
start -X- _ O
token -X- _ O
marker -X- _ O
and -X- _ O
an -X- _ O
end -X- _ O
token -X- _ O
marker -X- _ O
. -X- _ O
These -X- _ O
two -X- _ O
markers -X- _ O
share -X- _ O
the -X- _ O
same -X- _ O
position -X- _ O
embedding -X- _ O
with -X- _ O
the -X- _ O
start -X- _ O
and -X- _ O
end -X- _ O
tokens -X- _ O
of -X- _ O
the -X- _ O
corresponding -X- _ O
span -X- _ O
, -X- _ O
while -X- _ O
keeping -X- _ O
the -X- _ O
position -X- _ O
i -X- _ O
d -X- _ O
of -X- _ O
original -X- _ O
text -X- _ O
tokens -X- _ O
unchanged -X- _ O
. -X- _ O
In -X- _ O
order -X- _ O
to -X- _ O
specify -X- _ O
multiple -X- _ O
pairs -X- _ O
of -X- _ O
levitated -X- _ O
markers -X- _ O
in -X- _ O
parallel -X- _ O
, -X- _ O
a -X- _ O
directional -X- _ O
attention -X- _ O
mask -X- _ O
matrix -X- _ O
is -X- _ O
applied -X- _ O
. -X- _ O
Specifically -X- _ O
, -X- _ O
each -X- _ O
levitated -X- _ O
marker -X- _ O
is -X- _ O
visible -X- _ O
to -X- _ O
its -X- _ O
partner -X- _ O
marker -X- _ O
within -X- _ O
pair -X- _ O
in -X- _ O
the -X- _ O
attention -X- _ O
mask -X- _ O
matrix -X- _ O
, -X- _ O
but -X- _ O
not -X- _ O
to -X- _ O
the -X- _ O
text -X- _ O
tokens -X- _ O
and -X- _ O
other -X- _ O
levitated -X- _ O
markers -X- _ O
. -X- _ O
In -X- _ O
the -X- _ O
meantime -X- _ O
, -X- _ O
the -X- _ O
levitated -X- _ O
markers -X- _ O
are -X- _ O
able -X- _ O
to -X- _ O
attend -X- _ O
to -X- _ O
the -X- _ O
text -X- _ O
tokens -X- _ O
to -X- _ O
aggregate -X- _ O
information -X- _ O
for -X- _ O
their -X- _ O
associated -X- _ O
spans -X- _ O
. -X- _ O

Benefiting -X- _ O
from -X- _ O
the -X- _ O
parallelism -X- _ O
of -X- _ O
levitated -X- _ O
markers -X- _ O
, -X- _ O
we -X- _ O
can -X- _ O
flexibly -X- _ O
pack -X- _ O
a -X- _ O
series -X- _ O
of -X- _ O
related -X- _ O
spans -X- _ O
into -X- _ O
a -X- _ O
training -X- _ O
instance -X- _ O
. -X- _ O
In -X- _ O
practice -X- _ O
, -X- _ O
we -X- _ O
append -X- _ O
multiple -X- _ O
associated -X- _ O
levitated -X- _ O
markers -X- _ O
to -X- _ O
an -X- _ O
input -X- _ O
sequence -X- _ O
to -X- _ O
conduct -X- _ O
a -X- _ O
comprehensive -X- _ O
modeling -X- _ O
on -X- _ O
each -X- _ O
span -X- _ O
. -X- _ O

However -X- _ O
, -X- _ O
even -X- _ O
though -X- _ O
the -X- _ O
entity -X- _ O
length -X- _ O
is -X- _ O
restricted -X- _ O
, -X- _ O
some -X- _ O
of -X- _ O
the -X- _ O
span -X- _ O
classification -X- _ O
tasks -X- _ O
still -X- _ O
contain -X- _ O
a -X- _ O
large -X- _ O
number -X- _ O
of -X- _ O
candidate -X- _ O
spans -X- _ O
. -X- _ O
Hence -X- _ O
, -X- _ O
we -X- _ O
have -X- _ O
to -X- _ O
group -X- _ O
the -X- _ O
markers -X- _ O
into -X- _ O
several -X- _ O
batches -X- _ O
to -X- _ O
equip -X- _ O
the -X- _ O
model -X- _ O
with -X- _ O
higher -X- _ O
speed -X- _ O
and -X- _ O
feasibility -X- _ O
in -X- _ O
practice -X- _ O
. -X- _ O
To -X- _ O
better -X- _ O
model -X- _ O
the -X- _ O
connection -X- _ O
between -X- _ O
spans -X- _ O
with -X- _ O
the -X- _ O
same -X- _ O
start -X- _ O
tokens -X- _ O
, -X- _ O
we -X- _ O
adopt -X- _ O
a -X- _ O
neighborhood -X- _ O
- -X- _ O
oriented -X- _ O
packing -X- _ O
scheme -X- _ O
. -X- _ O
As -X- _ O
shown -X- _ O
in -X- _ O
Figure -X- _ O
2 -X- _ O
, -X- _ O
we -X- _ O
first -X- _ O
sort -X- _ O
the -X- _ O
pairs -X- _ O
of -X- _ O
levitated -X- _ O
markers -X- _ O
by -X- _ O
taking -X- _ O
the -X- _ O
position -X- _ O
of -X- _ O
start -X- _ O
marker -X- _ O
as -X- _ O
the -X- _ O
first -X- _ O
keyword -X- _ O
and -X- _ O
the -X- _ O
position -X- _ O
of -X- _ O
end -X- _ O
marker -X- _ O
as -X- _ O
the -X- _ O
second -X- _ O
keyword -X- _ O
. -X- _ O
After -X- _ O
that -X- _ O
, -X- _ O
we -X- _ O
split -X- _ O
them -X- _ O
into -X- _ O
groups -X- _ O
of -X- _ O
size -X- _ O
up -X- _ O
to -X- _ O
K -X- _ O
and -X- _ O
thus -X- _ O
gather -X- _ O
adjacent -X- _ O
spans -X- _ O
into -X- _ O
the -X- _ O
same -X- _ O
group -X- _ O
. -X- _ O
We -X- _ O
packs -X- _ O
each -X- _ O
groups -X- _ O
of -X- _ O
markers -X- _ O
and -X- _ O
dispersedly -X- _ O
process -X- _ O
them -X- _ O
in -X- _ O
multiple -X- _ O
runs -X- _ O
. -X- _ O

Formally -X- _ O
, -X- _ O
given -X- _ O
a -X- _ O
sequence -X- _ O
of -X- _ O
N -X- _ O
text -X- _ O
tokens -X- _ O
, -X- _ O
X -X- _ O
= -X- _ O
{ -X- _ O
x -X- _ O
1 -X- _ O
, -X- _ O
. -X- _ O
. -X- _ O
. -X- _ O
, -X- _ O
x -X- _ O
N -X- _ O
} -X- _ O
and -X- _ O
a -X- _ O
maximum -X- _ O
span -X- _ O
length -X- _ O
L -X- _ O
, -X- _ O
we -X- _ O
define -X- _ O
the -X- _ O
candidate -X- _ O
spans -X- _ O
set -X- _ O
as -X- _ O
S -X- _ O
( -X- _ O
X -X- _ O
) -X- _ O
= -X- _ O
{ -X- _ O
( -X- _ O
1 -X- _ O
, -X- _ O
1 -X- _ O
) -X- _ O
, -X- _ O
.. -X- _ O
, -X- _ O
( -X- _ O
1 -X- _ O
, -X- _ O
L -X- _ O
) -X- _ O
, -X- _ O
... -X- _ O
, -X- _ O
( -X- _ O
N -X- _ O
, -X- _ O
N -X- _ O
−L -X- _ O
) -X- _ O
, -X- _ O
.. -X- _ O
, -X- _ O
( -X- _ O
N -X- _ O
, -X- _ O
N -X- _ O
) -X- _ O
) -X- _ O
} -X- _ O
. -X- _ O
We -X- _ O
first -X- _ O
divide -X- _ O
S -X- _ O
( -X- _ O
X -X- _ O
) -X- _ O
into -X- _ O
multiple -X- _ O
groups -X- _ O
up -X- _ O
to -X- _ O
the -X- _ O
size -X- _ O
of -X- _ O
K -X- _ O
in -X- _ O
order -X- _ O
. -X- _ O
For -X- _ O
example -X- _ O
, -X- _ O
we -X- _ O
cluster -X- _ O
K -X- _ O
spans -X- _ O
, -X- _ O

{ -X- _ O
( -X- _ O
1 -X- _ O
, -X- _ O
1 -X- _ O
) -X- _ O
, -X- _ O
( -X- _ O
1 -X- _ O
, -X- _ O
2 -X- _ O
) -X- _ O
, -X- _ O
... -X- _ O
, -X- _ O
( -X- _ O
K -X- _ O
L -X- _ O
, -X- _ O
K -X- _ O
− -X- _ O
K−1 -X- _ O
L -X- _ O
* -X- _ O
L -X- _ O
) -X- _ O
} -X- _ O
, -X- _ O
into -X- _ O
a -X- _ O
group -X- _ O
S -X- _ O
1 -X- _ O
. -X- _ O

We -X- _ O
associate -X- _ O
a -X- _ O
pair -X- _ O
of -X- _ O
levitated -X- _ O
markers -X- _ O
to -X- _ O
each -X- _ O
span -X- _ O
in -X- _ O
S -X- _ O
1 -X- _ O
. -X- _ O
Then -X- _ O
, -X- _ O
we -X- _ O
provide -X- _ O
the -X- _ O
combined -X- _ O
sequence -X- _ O
of -X- _ O
the -X- _ O
text -X- _ O
token -X- _ O
and -X- _ O
the -X- _ O
inserted -X- _ O
levitated -X- _ O
markers -X- _ O
to -X- _ O
the -X- _ O
PLM -X- _ O
( -X- _ O
e.g. -X- _ O
BERT -X- _ O
) -X- _ O
to -X- _ O
obtain -X- _ O
the -X- _ O
contextualized -X- _ O
representations -X- _ O
of -X- _ O
the -X- _ O
start -X- _ O
token -X- _ O
marker -X- _ O
H -X- _ O
( -X- _ O
s -X- _ O
) -X- _ O
= -X- _ O
{ -X- _ O
h -X- _ O
1,2 -X- _ O
) -X- _ O
, -X- _ O
... -X- _ O
, -X- _ O
( -X- _ O
1,5 -X- _ O
) -X- _ O
} -X- _ O
, -X- _ O
in -X- _ O
the -X- _ O
same -X- _ O
group -X- _ O
. -X- _ O
The -X- _ O
subject -X- _ O
- -X- _ O
oriented -X- _ O
packing -X- _ O
strategy -X- _ O
encloses -X- _ O
the -X- _ O
subject -X- _ O
span -X- _ O
, -X- _ O
David -X- _ O
Green -X- _ O
, -X- _ O
with -X- _ O
solid -X- _ O
markers -X- _ O
, -X- _ O
applies -X- _ O
levitated -X- _ O
markers -X- _ O
on -X- _ O
its -X- _ O
candidate -X- _ O
object -X- _ O
spans -X- _ O
, -X- _ O
his -X- _ O
, -X- _ O
wife -X- _ O
and -X- _ O
Dallas -X- _ O
, -X- _ O
and -X- _ O
packs -X- _ O
them -X- _ O
into -X- _ O
an -X- _ O
instance -X- _ O
. -X- _ O

For -X- _ O
instance -X- _ O
, -X- _ O
we -X- _ O
apply -X- _ O
the -X- _ O
levitated -X- _ O
marker -X- _ O
to -X- _ O
a -X- _ O
typical -X- _ O
overlapping -X- _ O
span -X- _ O
classification -X- _ O
task -X- _ O
, -X- _ O
NER -X- _ B-TaskName
, -X- _ O
which -X- _ O
aims -X- _ O
to -X- _ O
assign -X- _ O
an -X- _ O
entity -X- _ O
type -X- _ O
or -X- _ O
a -X- _ O
non -X- _ O
- -X- _ O
entity -X- _ O
type -X- _ O
to -X- _ O
each -X- _ O
possible -X- _ O
span -X- _ O
in -X- _ O
a -X- _ O
sentence -X- _ O
. -X- _ O
We -X- _ O
obtain -X- _ O
the -X- _ O
span -X- _ O
representation -X- _ O
from -X- _ O
the -X- _ O
PLM -X- _ O
via -X- _ O
the -X- _ O
packed -X- _ O
levitated -X- _ O
markers -X- _ O
and -X- _ O
then -X- _ O
combine -X- _ O
the -X- _ O
features -X- _ O
of -X- _ O
PL -X- _ B-MethodName
- -X- _ I-MethodName
Marker -X- _ I-MethodName
and -X- _ O
T -X- _ O
- -X- _ O
Concat -X- _ O
to -X- _ O
better -X- _ O
predict -X- _ O
the -X- _ O
entity -X- _ O
type -X- _ O
of -X- _ O
the -X- _ O
cadidate -X- _ O
span -X- _ O
. -X- _ O

To -X- _ O
obtain -X- _ O
a -X- _ O
span -X- _ O
pair -X- _ O
representation -X- _ O
, -X- _ O
a -X- _ O
feasible -X- _ O
method -X- _ O
is -X- _ O
to -X- _ O
adopt -X- _ O
levitated -X- _ O
markers -X- _ O
to -X- _ O
emphasize -X- _ O
a -X- _ O
series -X- _ O
of -X- _ O
the -X- _ O
subject -X- _ O
and -X- _ O
object -X- _ O
spans -X- _ O
simultaneously -X- _ O
. -X- _ O
Commonly -X- _ O
, -X- _ O
each -X- _ O
pair -X- _ O
of -X- _ O
levitated -X- _ O
markers -X- _ O
is -X- _ O
tied -X- _ O
by -X- _ O
the -X- _ O
directional -X- _ O
attention -X- _ O
. -X- _ O
But -X- _ O
if -X- _ O
we -X- _ O
continue -X- _ O
to -X- _ O
apply -X- _ O
directional -X- _ O
attention -X- _ O
to -X- _ O
bind -X- _ O
two -X- _ O
pairs -X- _ O
of -X- _ O
markers -X- _ O
, -X- _ O
the -X- _ O
levitated -X- _ O
marker -X- _ O
will -X- _ O
not -X- _ O
be -X- _ O
able -X- _ O
to -X- _ O
identify -X- _ O
its -X- _ O
partner -X- _ O
marker -X- _ O
of -X- _ O
the -X- _ O
same -X- _ O
span -X- _ O
. -X- _ O
Hence -X- _ O
, -X- _ O
as -X- _ O
shown -X- _ O
in -X- _ O
Figure -X- _ O
2 -X- _ O
, -X- _ O
our -X- _ O
span -X- _ O
pair -X- _ O
model -X- _ O
adopts -X- _ O
a -X- _ O
fusion -X- _ O
subject -X- _ O
- -X- _ O
oriented -X- _ O
packing -X- _ O
scheme -X- _ O
to -X- _ O
offer -X- _ O
an -X- _ O
integral -X- _ O
modeling -X- _ O
for -X- _ O
the -X- _ O
same -X- _ O
- -X- _ O
subject -X- _ O
spans -X- _ O
. -X- _ O

For -X- _ O
instance -X- _ O
, -X- _ O
we -X- _ O
evaluate -X- _ O
our -X- _ O
model -X- _ O
on -X- _ O
a -X- _ O
typical -X- _ O
span -X- _ O
pair -X- _ O
classification -X- _ O
task -X- _ O
, -X- _ O
end -X- _ O
- -X- _ O
to -X- _ O
- -X- _ O
end -X- _ O
RE -X- _ B-TaskName
, -X- _ O
which -X- _ O
concentrates -X- _ O
on -X- _ O
identifying -X- _ O
whether -X- _ O
all -X- _ O
span -X- _ O
pairs -X- _ O
are -X- _ O
related -X- _ O
and -X- _ O
their -X- _ O
relation -X- _ O
types -X- _ O
. -X- _ O
Following -X- _ O
Zhong -X- _ O
and -X- _ O
Chen -X- _ O
( -X- _ O
2021 -X- _ O
) -X- _ O
, -X- _ O
we -X- _ O
first -X- _ O
use -X- _ O
a -X- _ O
NER -X- _ B-TaskName
model -X- _ O
to -X- _ O
filter -X- _ O
candidate -X- _ O
entity -X- _ O
spans -X- _ O
, -X- _ O
and -X- _ O
then -X- _ O
acquire -X- _ O
the -X- _ O
span -X- _ O
pair -X- _ O
representation -X- _ O
of -X- _ O
the -X- _ O
filtered -X- _ O
entity -X- _ O
span -X- _ O
pairs -X- _ O
to -X- _ O
predict -X- _ O
the -X- _ O
relation -X- _ O
between -X- _ O
them -X- _ O
. -X- _ O
Moreover -X- _ O
, -X- _ O
to -X- _ O
build -X- _ O
the -X- _ O
connection -X- _ O
between -X- _ O
entity -X- _ O
type -X- _ O
and -X- _ O
relation -X- _ O
type -X- _ O
, -X- _ O
we -X- _ O
add -X- _ O
an -X- _ O
auxiliary -X- _ O
loss -X- _ O
for -X- _ O
predicting -X- _ O
the -X- _ O
type -X- _ O
of -X- _ O
object -X- _ O
entity -X- _ O
( -X- _ O
Zhou -X- _ O
and -X- _ O
Chen -X- _ O
, -X- _ O
2021 -X- _ O
; -X- _ O
. -X- _ O

Dominated -X- _ O
by -X- _ O
the -X- _ O
large -X- _ O
feed -X- _ O
- -X- _ O
forward -X- _ O
network -X- _ O
, -X- _ O
the -X- _ O
computation -X- _ O
of -X- _ O
PLM -X- _ O
rises -X- _ O
almost -X- _ O
linearly -X- _ O
with -X- _ O
the -X- _ O
increase -X- _ O
in -X- _ O
small -X- _ O
sequence -X- _ O
length -X- _ O
( -X- _ O
Dai -X- _ O
et -X- _ O
al -X- _ O
. -X- _ O
, -X- _ O
2020 -X- _ O
; -X- _ O
Ye -X- _ O
et -X- _ O
al -X- _ O
. -X- _ O
, -X- _ O
2021 -X- _ O
) -X- _ O
. -X- _ O
Gradually -X- _ O
, -X- _ O
as -X- _ O
the -X- _ O
sequence -X- _ O
length -X- _ O
continues -X- _ O
to -X- _ O
grow -X- _ O
, -X- _ O
the -X- _ O
computation -X- _ O
dilates -X- _ O
quadratically -X- _ O
due -X- _ O
to -X- _ O
the -X- _ O
Self -X- _ O
- -X- _ O
Attention -X- _ O
module -X- _ O
( -X- _ O
Vaswani -X- _ O
et -X- _ O
al -X- _ O
. -X- _ O
, -X- _ O
2017 -X- _ O
) -X- _ O
. -X- _ O
Obviously -X- _ O
, -X- _ O
the -X- _ O
insertion -X- _ O
of -X- _ O
levitated -X- _ O
markers -X- _ O
extends -X- _ O
the -X- _ O
length -X- _ O
of -X- _ O
input -X- _ O
sequence -X- _ O
. -X- _ O
For -X- _ O
the -X- _ O
span -X- _ O
pair -X- _ O
classification -X- _ O
tasks -X- _ O
, -X- _ O
the -X- _ O
number -X- _ O
of -X- _ O
candidate -X- _ O
spans -X- _ O
is -X- _ O
relatively -X- _ O
small -X- _ O
, -X- _ O
thus -X- _ O
the -X- _ O
increased -X- _ O
computation -X- _ O
is -X- _ O
limited -X- _ O
. -X- _ O
For -X- _ O
the -X- _ O
span -X- _ O
classification -X- _ O
tasks -X- _ O
, -X- _ O
we -X- _ O
group -X- _ O
the -X- _ O
markers -X- _ O
into -X- _ O
several -X- _ O
batches -X- _ O
, -X- _ O
which -X- _ O
can -X- _ O
control -X- _ O
the -X- _ O
sequence -X- _ O
length -X- _ O
within -X- _ O
the -X- _ O
interval -X- _ O
in -X- _ O
which -X- _ O
the -X- _ O
complexity -X- _ O
increases -X- _ O
nearly -X- _ O
linearly -X- _ O
. -X- _ O
For -X- _ O
the -X- _ O
NER -X- _ B-TaskName
, -X- _ O
we -X- _ O
enumerate -X- _ O
candidate -X- _ O
spans -X- _ O
in -X- _ O
a -X- _ O
small -X- _ O
- -X- _ O
length -X- _ O
sentence -X- _ O
and -X- _ O
then -X- _ O
use -X- _ O
its -X- _ O
context -X- _ O
words -X- _ O
to -X- _ O
expand -X- _ O
the -X- _ O
sentence -X- _ O
to -X- _ O
512 -X- _ O
tokens -X- _ O
, -X- _ O
for -X- _ O
which -X- _ O
the -X- _ O
number -X- _ O
of -X- _ O
candidate -X- _ O
spans -X- _ O
in -X- _ O
a -X- _ O
sentence -X- _ O
is -X- _ O
usually -X- _ O
less -X- _ O
than -X- _ O
the -X- _ O
context -X- _ O
length -X- _ O
in -X- _ O
practice -X- _ O
. -X- _ O
Hence -X- _ O
, -X- _ O
with -X- _ O
a -X- _ O
small -X- _ O
number -X- _ O
of -X- _ O
packing -X- _ O
groups -X- _ O
, -X- _ O
the -X- _ O
complexity -X- _ O
of -X- _ O
PL -X- _ B-MethodName
- -X- _ I-MethodName
Marker -X- _ I-MethodName
is -X- _ O
still -X- _ O
near -X- _ O
- -X- _ O
linearly -X- _ O
to -X- _ O
the -X- _ O
complexity -X- _ O
of -X- _ O
previous -X- _ O
models -X- _ O
. -X- _ O

Moreover -X- _ O
, -X- _ O
to -X- _ O
further -X- _ O
alleviate -X- _ O
the -X- _ O
inference -X- _ O
cost -X- _ O
, -X- _ O
we -X- _ O
adopt -X- _ O
PL -X- _ B-MethodName
- -X- _ I-MethodName
Marker -X- _ I-MethodName
as -X- _ O
a -X- _ O
post -X- _ O
- -X- _ O
processing -X- _ O
module -X- _ O
of -X- _ O
a -X- _ O
two -X- _ O
- -X- _ O
stage -X- _ O
model -X- _ O
, -X- _ O
in -X- _ O
which -X- _ O
it -X- _ O
is -X- _ O
used -X- _ O
to -X- _ O
identify -X- _ O
entities -X- _ O
from -X- _ O
a -X- _ O
small -X- _ O
number -X- _ O
of -X- _ O
candidate -X- _ O
entities -X- _ O
proposed -X- _ O
by -X- _ O
a -X- _ O
simpler -X- _ O
and -X- _ O
faster -X- _ O
model -X- _ O
. -X- _ O
. -X- _ O
Then -X- _ O
, -X- _ O
on -X- _ O
the -X- _ O
nested -X- _ O
NER -X- _ B-TaskName
, -X- _ O
we -X- _ O
use -X- _ O
ACE04 -X- _ B-DatasetName
( -X- _ O
Doddington -X- _ O
et -X- _ O
al -X- _ O
. -X- _ O
, -X- _ O
2004 -X- _ O
) -X- _ O
, -X- _ O
ACE05 -X- _ B-DatasetName
( -X- _ O
Walker -X- _ O
et -X- _ O
al -X- _ O
. -X- _ O
, -X- _ O
2006 -X- _ O
) -X- _ O
and -X- _ O
SciERC -X- _ B-DatasetName
( -X- _ O
Luan -X- _ O
et -X- _ O
al -X- _ O
. -X- _ O
, -X- _ O
2018 -X- _ O
) -X- _ O
. -X- _ O
The -X- _ O
three -X- _ O
nested -X- _ O
NER -X- _ B-TaskName
datasets -X- _ O
are -X- _ O
also -X- _ O
used -X- _ O
to -X- _ O
evaluate -X- _ O
the -X- _ O
end -X- _ O
- -X- _ O
to -X- _ O
- -X- _ O
end -X- _ O
RE -X- _ B-TaskName
. -X- _ I-TaskName
We -X- _ O
follow -X- _ O
sets -X- _ O
. -X- _ O
For -X- _ O
other -X- _ O
datasets -X- _ O
, -X- _ O
we -X- _ O
adopt -X- _ O
the -X- _ O
official -X- _ O
split -X- _ O
. -X- _ O

For -X- _ O
NER -X- _ B-TaskName
task -X- _ O
, -X- _ O
we -X- _ O
follow -X- _ O
a -X- _ O
span -X- _ O
- -X- _ O
level -X- _ O
evaluation -X- _ O
setting -X- _ O
, -X- _ O
where -X- _ O
the -X- _ O
entity -X- _ B-MetricName
boundary -X- _ I-MetricName
and -X- _ O
entity -X- _ B-MetricName
type -X- _ I-MetricName
are -X- _ O
required -X- _ O
to -X- _ O
correctly -X- _ O
predicted -X- _ O
. -X- _ O
For -X- _ O
the -X- _ O
endto -X- _ O
- -X- _ O
end -X- _ O
RE -X- _ B-TaskName
, -X- _ O
we -X- _ O
report -X- _ O
two -X- _ O
evaluation -X- _ O
metrics -X- _ O
: -X- _ O
( -X- _ O
1 -X- _ O
) -X- _ O
Boundaries -X- _ B-MetricName
evaluation -X- _ I-MetricName
( -X- _ O
Rel -X- _ B-MetricName
) -X- _ O
requires -X- _ O
the -X- _ O
model -X- _ O
to -X- _ O
correctly -X- _ O
predict -X- _ O
the -X- _ O
boundaries -X- _ O
of -X- _ O
the -X- _ O
subject -X- _ O
entity -X- _ O
and -X- _ O
the -X- _ O
object -X- _ O
entity -X- _ O
, -X- _ O
and -X- _ O
the -X- _ O
entity -X- _ B-MetricName
relation -X- _ I-MetricName
; -X- _ O

( -X- _ O
2 -X- _ O
) -X- _ O
Strict -X- _ O
evaluation -X- _ O
( -X- _ O
Rel+ -X- _ B-MetricName
) -X- _ O
further -X- _ O
requires -X- _ O
the -X- _ O
model -X- _ O
to -X- _ O
predict -X- _ O
the -X- _ O
entity -X- _ O
types -X- _ O
on -X- _ O
the -X- _ O
basis -X- _ O
of -X- _ O
the -X- _ O
requirement -X- _ O
of -X- _ O
the -X- _ O
boundary -X- _ O
prediction -X- _ O
. -X- _ O
Moreover -X- _ O
, -X- _ O
following -X- _ O
Wang -X- _ O
et -X- _ O
al -X- _ O
. -X- _ O
( -X- _ O
2021d -X- _ O
) -X- _ O
, -X- _ O
we -X- _ O
regard -X- _ O
each -X- _ O
symmetric -X- _ O
relational -X- _ O
instance -X- _ O
as -X- _ O
two -X- _ O
directed -X- _ O
relational -X- _ O
instances -X- _ O
. -X- _ O

We -X- _ O
adopt -X- _ O
bert -X- _ O
- -X- _ O
base -X- _ O
- -X- _ O
uncased -X- _ O
( -X- _ O
Devlin -X- _ O
et -X- _ O
al -X- _ O
. -X- _ O
, -X- _ O
2019 -X- _ O
) -X- _ O
and -X- _ O
albert -X- _ O
- -X- _ O
xxlarge -X- _ O
- -X- _ O
v1 -X- _ O
( -X- _ O
Lan -X- _ O
et -X- _ O
al -X- _ O
. -X- _ O
, -X- _ O
2020 -X- _ O
) -X- _ O
encoders -X- _ O
for -X- _ O
ACE04 -X- _ B-DatasetName
and -X- _ O
ACE05 -X- _ B-DatasetName
. -X- _ O
For -X- _ O
SciERC -X- _ B-DatasetName
, -X- _ O
we -X- _ O
use -X- _ O
the -X- _ O
indomain -X- _ O
scibert -X- _ O
- -X- _ O
scivocab -X- _ O
- -X- _ O
uncased -X- _ O
( -X- _ O
Beltagy -X- _ O
et -X- _ O
al -X- _ O
. -X- _ O
, -X- _ O
2019 -X- _ O
) -X- _ O
encoder -X- _ O
. -X- _ O
For -X- _ O
flat -X- _ O
NER -X- _ B-TaskName
, -X- _ O
we -X- _ O
adopt -X- _ O
robertalarge -X- _ O
encoder -X- _ O
. -X- _ O
We -X- _ O
also -X- _ O
leverage -X- _ O
the -X- _ O
cross -X- _ O
- -X- _ O
sentence -X- _ O
information -X- _ O
Luoma -X- _ O
and -X- _ O
Pyysalo -X- _ O
, -X- _ O
2020 -X- _ O
) -X- _ O
, -X- _ O
which -X- _ O
extends -X- _ O
each -X- _ O
sentence -X- _ O
by -X- _ O
its -X- _ O
context -X- _ O
and -X- _ O
ensures -X- _ O
that -X- _ O
the -X- _ O
original -X- _ O
sentence -X- _ O
is -X- _ O
located -X- _ O
in -X- _ O
the -X- _ O
middle -X- _ O
of -X- _ O
the -X- _ O
expanded -X- _ O
sentence -X- _ O
as -X- _ O
much -X- _ O
as -X- _ O
possible -X- _ O
. -X- _ O
As -X- _ O
discussed -X- _ O
in -X- _ O
Section -X- _ O
4.4.1 -X- _ O
, -X- _ O
for -X- _ O
the -X- _ O
packing -X- _ O
scheme -X- _ O
on -X- _ O
NER -X- _ B-TaskName
, -X- _ O
we -X- _ O
set -X- _ O
the -X- _ O
group -X- _ O
size -X- _ O
to -X- _ O
256 -X- _ O
to -X- _ O
improve -X- _ O
efficiency -X- _ O
. -X- _ O
We -X- _ O
run -X- _ O
all -X- _ O
experiments -X- _ O
with -X- _ O
5 -X- _ O
different -X- _ O
seeds -X- _ O
and -X- _ O
report -X- _ O
the -X- _ O
average -X- _ O
score -X- _ O
. -X- _ O
See -X- _ O
the -X- _ O
appendix -X- _ O
for -X- _ O
the -X- _ O
standard -X- _ O
deviations -X- _ O
and -X- _ O
the -X- _ O
detailed -X- _ O
training -X- _ O
configuration -X- _ O
. -X- _ O

Our -X- _ O
packing -X- _ O
scheme -X- _ O
allows -X- _ O
the -X- _ O
model -X- _ O
to -X- _ O
apply -X- _ O
the -X- _ O
levitated -X- _ O
markers -X- _ O
to -X- _ O
process -X- _ O
massive -X- _ O
span -X- _ O
pairs -X- _ O
and -X- _ O
to -X- _ O
our -X- _ O
best -X- _ O
knowledge -X- _ O
, -X- _ O
we -X- _ O
are -X- _ O
the -X- _ O
first -X- _ O
to -X- _ O
apply -X- _ O
the -X- _ O
levitated -X- _ O
markers -X- _ O
on -X- _ O
the -X- _ O
NER -X- _ B-TaskName
task -X- _ O
. -X- _ O
We -X- _ O
compare -X- _ O
our -X- _ O
neighborhood -X- _ O
- -X- _ O
oriented -X- _ O
packing -X- _ O
scheme -X- _ O
with -X- _ O

For -X- _ O
the -X- _ O
end -X- _ O
- -X- _ O
to -X- _ O
- -X- _ O
end -X- _ O
RE -X- _ B-TaskName
, -X- _ O
we -X- _ O
compare -X- _ O
our -X- _ O
model -X- _ O
, -X- _ O
PL -X- _ B-MethodName
- -X- _ I-MethodName
Marker -X- _ I-MethodName
, -X- _ O
with -X- _ O
a -X- _ O
series -X- _ O
of -X- _ O
state -X- _ O
- -X- _ O
of -X- _ O
- -X- _ O
the -X- _ O
- -X- _ O
art -X- _ O
models -X- _ O
. -X- _ O

In -X- _ O
this -X- _ O
section -X- _ O
, -X- _ O
we -X- _ O
compare -X- _ O
the -X- _ O
models -X- _ O
' -X- _ O
inference -X- _ O
speed -X- _ O
on -X- _ O
an -X- _ O
A100 -X- _ O
GPU -X- _ O
with -X- _ O
a -X- _ O
batch -X- _ B-HyperparameterName
size -X- _ I-HyperparameterName
of -X- _ O
32 -X- _ B-HyperparameterValue
. -X- _ O
We -X- _ O
use -X- _ O
the -X- _ O
BASE -X- _ O
size -X- _ O
encoder -X- _ O
for -X- _ O
ACE05 -X- _ B-DatasetName
and -X- _ O
SciERC -X- _ B-DatasetName
in -X- _ O
the -X- _ O
experiments -X- _ O
and -X- _ O
the -X- _ O
LARGE -X- _ O
size -X- _ O
encoder -X- _ O
for -X- _ O
flat -X- _ O
NER -X- _ O
models -X- _ O
. -X- _ O

We -X- _ O
apply -X- _ O
the -X- _ O
subject -X- _ O
- -X- _ O
oriented -X- _ O
and -X- _ O
the -X- _ O
objectoriented -X- _ O
packing -X- _ O
strategies -X- _ O
on -X- _ O
levitated -X- _ O
markers -X- _ O
for -X- _ O
RE -X- _ B-TaskName
. -X- _ O
Here -X- _ O
, -X- _ O
we -X- _ O
compare -X- _ O
our -X- _ O
model -X- _ O
with -X- _ O
the -X- _ O
other -X- _ O
two -X- _ O
marker -X- _ O
- -X- _ O
based -X- _ O
models -X- _ O
. -X- _ O
Firstly -X- _ O
, -X- _ O
PURE -X- _ B-MethodName
( -X- _ O
Full -X- _ O
) -X- _ O
( -X- _ O
Zhong -X- _ O
and -X- _ O
Chen -X- _ O
, -X- _ O
2021 -X- _ O
) -X- _ O
applies -X- _ O
solid -X- _ O
markers -X- _ O
to -X- _ O
process -X- _ O
each -X- _ O
entity -X- _ O
pair -X- _ O
independently -X- _ O
. -X- _ O
Secondly -X- _ O
, -X- _ O
PURE -X- _ B-MethodName
( -X- _ O
Approx -X- _ O
. -X- _ O
) -X- _ O
packs -X- _ O
the -X- _ O
levitated -X- _ O
markers -X- _ O
of -X- _ O
all -X- _ O
entity -X- _ O
pairs -X- _ O
into -X- _ O
an -X- _ O
instance -X- _ O
for -X- _ O
batch -X- _ O
computation -X- _ O
. -X- _ O
Since -X- _ O
the -X- _ O
performance -X- _ O
and -X- _ O
the -X- _ O
running -X- _ O
time -X- _ O
of -X- _ O
the -X- _ O
above -X- _ O
methods -X- _ O
rely -X- _ O
on -X- _ O
the -X- _ O
quality -X- _ O
and -X- _ O
the -X- _ O
number -X- _ O
of -X- _ O
predicted -X- _ O
entities -X- _ O
, -X- _ O
for -X- _ O
a -X- _ O
fair -X- _ O
comparison -X- _ O
, -X- _ O
we -X- _ O
adopt -X- _ O
the -X- _ O
same -X- _ O
entity -X- _ O
input -X- _ O
from -X- _ O
the -X- _ O
entity -X- _ O
model -X- _ O
of -X- _ O
PURE -X- _ B-MethodName
on -X- _ O
all -X- _ O
the -X- _ O
RE -X- _ B-TaskName
models -X- _ O
. -X- _ O
Table -X- _ O
5 -X- _ O
shows -X- _ O
the -X- _ O
relation -X- _ O
F1 -X- _ B-MetricName
scores -X- _ O
and -X- _ O
the -X- _ O
inference -X- _ O
speed -X- _ O
of -X- _ O
the -X- _ O
above -X- _ O
three -X- _ O
methods -X- _ O
. -X- _ O
On -X- _ O
both -X- _ O
datasets -X- _ O
, -X- _ O
our -X- _ O
RE -X- _ B-TaskName
model -X- _ O
, -X- _ O
PL -X- _ B-MethodName
- -X- _ I-MethodName
Marker -X- _ I-MethodName
, -X- _ O
achieves -X- _ O
the -X- _ O
best -X- _ O
performance -X- _ O
and -X- _ O
PURE -X- _ B-TaskName
( -X- _ O
Approx -X- _ O
. -X- _ O
) -X- _ O
has -X- _ O
highest -X- _ O
efficiency -X- _ O
in -X- _ O
the -X- _ O
inference -X- _ O
process -X- _ O
. -X- _ O
Compared -X- _ O
to -X- _ O
the -X- _ O
PURE -X- _ B-TaskName
( -X- _ O
Full -X- _ O
) -X- _ O
, -X- _ O
our -X- _ O
model -X- _ O
obtains -X- _ O
a -X- _ O
2.2x-2.8x -X- _ B-MetricValue
speedup -X- _ B-MetricName
and -X- _ O
better -X- _ O
performance -X- _ O
on -X- _ O
ACE05 -X- _ B-DatasetName
and -X- _ O
SciERC -X- _ B-DatasetName
. -X- _ O
Compared -X- _ O
to -X- _ O
PURE -X- _ B-MethodName
( -X- _ O
Approx -X- _ O
. -X- _ O
) -X- _ O
, -X- _ O
our -X- _ O
model -X- _ O
achieves -X- _ O
a -X- _ O
2.8 -X- _ B-MetricValue
% -X- _ I-MetricValue
-4.0 -X- _ I-MetricValue
% -X- _ B-MetricValue
relation -X- _ O
F1 -X- _ B-MetricName
( -X- _ O
boundaries -X- _ O
) -X- _ O
improvement -X- _ O
on -X- _ O
ACE05 -X- _ B-DatasetName
and -X- _ O
SciERC -X- _ B-DatasetName
, -X- _ O
which -X- _ O
again -X- _ O
demonstrates -X- _ O
the -X- _ O
effectiveness -X- _ O
of -X- _ O
our -X- _ O
fusion -X- _ O
markers -X- _ O
and -X- _ O
packing -X- _ O
strategy -X- _ O
. -X- _ O
Overall -X- _ O
, -X- _ O
our -X- _ O
model -X- _ O
, -X- _ O
with -X- _ O
a -X- _ O
novel -X- _ O
subjectoriented -X- _ O
packing -X- _ O
strategy -X- _ O
for -X- _ O
markers -X- _ O
, -X- _ O
has -X- _ O
been -X- _ O
proven -X- _ O
effective -X- _ O
in -X- _ O
practice -X- _ O
, -X- _ O
with -X- _ O
satisfactory -X- _ O
accuracy -X- _ O
and -X- _ O
affordable -X- _ O
cost -X- _ O
. -X- _ O

We -X- _ O
show -X- _ O
several -X- _ O
cases -X- _ O
to -X- _ O
compare -X- _ O
our -X- _ O
span -X- _ O
model -X- _ O
with -X- _ O
T -X- _ O
- -X- _ O
Concat -X- _ O
and -X- _ O
to -X- _ O
compare -X- _ O
our -X- _ O
span -X- _ O
pair -X- _ O
model -X- _ O
with -X- _ O
PURE -X- _ B-MethodName
( -X- _ O
Full -X- _ O
) -X- _ O
. -X- _ O
As -X- _ O
shown -X- _ O
in -X- _ O
Table -X- _ O
6 -X- _ O
, -X- _ O
our -X- _ O
span -X- _ O
model -X- _ O
could -X- _ O
collect -X- _ O
contextual -X- _ O
information -X- _ O
, -X- _ O
such -X- _ O
as -X- _ O
Taiwan -X- _ O
and -X- _ O
mainland -X- _ O
, -X- _ O
for -X- _ O
underlined -X- _ O
span -X- _ O
, -X- _ O
Cross -X- _ O
Strait -X- _ O
, -X- _ O
assisting -X- _ O
in -X- _ O
predicting -X- _ O
its -X- _ O
type -X- _ O
as -X- _ O
organization -X- _ O
rather -X- _ O
than -X- _ O
work -X- _ O
of -X- _ O
art -X- _ O
. -X- _ O
Our -X- _ O
span -X- _ O
model -X- _ O
learns -X- _ O
to -X- _ O
integrally -X- _ O
consider -X- _ O
the -X- _ O
interrelation -X- _ O
between -X- _ O
the -X- _ O
same -X- _ O
- -X- _ O
object -X- _ O
relational -X- _ O
facts -X- _ O
in -X- _ O
training -X- _ O
phase -X- _ O
, -X- _ O
so -X- _ O
as -X- _ O
to -X- _ O
successfully -X- _ O
obtain -X- _ O
the -X- _ O
fact -X- _ O
that -X- _ O
both -X- _ O
Liana -X- _ O
and -X- _ O
her -X- _ O
parents -X- _ O
are -X- _ O
located -X- _ O
in -X- _ O
Manhattan -X- _ O
. -X- _ O

In -X- _ O
this -X- _ O
section -X- _ O
, -X- _ O
we -X- _ O
conduct -X- _ O
ablation -X- _ O
studies -X- _ O
to -X- _ O
investigate -X- _ O
the -X- _ O
contribution -X- _ O
of -X- _ O
different -X- _ O
components -X- _ O
to -X- _ O
our -X- _ O
RE -X- _ B-TaskName
model -X- _ O
, -X- _ O
where -X- _ O
we -X- _ O
apply -X- _ O
BASE -X- _ O
size -X- _ O
encoder -X- _ O
in -X- _ O
the -X- _ O
experiments -X- _ O
. -X- _ O

We -X- _ O
evaluate -X- _ O
the -X- _ O
w -X- _ O
/ -X- _ O
o -X- _ O
solid -X- _ O
marker -X- _ O
baseline -X- _ O
, -X- _ O
which -X- _ O
applies -X- _ O
two -X- _ O
pairs -X- _ O
of -X- _ O
levitated -X- _ O
markers -X- _ O
on -X- _ O
the -X- _ O
subject -X- _ O
and -X- _ O
object -X- _ O
respectively -X- _ O
and -X- _ O
packs -X- _ O
all -X- _ O
the -X- _ O
span -X- _ O
pairs -X- _ O
into -X- _ O
an -X- _ O
instance -X- _ O
. -X- _ O
As -X- _ O
shown -X- _ O
in -X- _ O
Marker -X- _ O
, -X- _ O
the -X- _ O
model -X- _ O
without -X- _ O
solid -X- _ O
markers -X- _ O
drops -X- _ O
a -X- _ O
huge -X- _ O
2.0 -X- _ B-MetricValue
% -X- _ I-MetricValue
-3.8 -X- _ I-MetricValue
% -X- _ B-MetricValue
F1 -X- _ B-MetricName
on -X- _ O
ACE05 -X- _ B-DatasetName
and -X- _ O
SciERC -X- _ B-DatasetName
when -X- _ O
the -X- _ O
golden -X- _ O
entities -X- _ O
are -X- _ O
given -X- _ O
. -X- _ O
The -X- _ O
result -X- _ O
demonstrates -X- _ O
that -X- _ O
it -X- _ O
is -X- _ O
sub -X- _ O
- -X- _ O
optimal -X- _ O
to -X- _ O
continue -X- _ O
to -X- _ O
apply -X- _ O
directional -X- _ O
attention -X- _ O
to -X- _ O
bind -X- _ O
two -X- _ O
pairs -X- _ O
of -X- _ O
levitated -X- _ O
markers -X- _ O
, -X- _ O
since -X- _ O
a -X- _ O
pair -X- _ O
of -X- _ O
levitated -X- _ O
marker -X- _ O
is -X- _ O
already -X- _ O
tied -X- _ O
by -X- _ O
the -X- _ O
directional -X- _ O
attention -X- _ O
. -X- _ O

We -X- _ O
establish -X- _ O
an -X- _ O
inverse -X- _ O
relation -X- _ O
for -X- _ O
each -X- _ O
asymmetric -X- _ O
relation -X- _ O
for -X- _ O
a -X- _ O
bidirectional -X- _ O
prediction -X- _ O
. -X- _ O
We -X- _ O
evaluate -X- _ O
the -X- _ O
model -X- _ O
without -X- _ O
inverse -X- _ O
relation -X- _ O
, -X- _ O
which -X- _ O
replaces -X- _ O
the -X- _ O
constructed -X- _ O
inverse -X- _ O
relation -X- _ O
with -X- _ O
a -X- _ O
non -X- _ O
- -X- _ O
relation -X- _ O
type -X- _ O
and -X- _ O
adopts -X- _ O
a -X- _ O
unidirectional -X- _ O
prediction -X- _ O
. -X- _ O
As -X- _ O
shown -X- _ O
in -X- _ O
Table -X- _ O
7 -X- _ O
, -X- _ O
the -X- _ O
model -X- _ O
without -X- _ O
inverse -X- _ O
relation -X- _ O
drops -X- _ O
0.9 -X- _ B-MetricValue
% -X- _ I-MetricValue
-1.1 -X- _ I-MetricValue
% -X- _ B-MetricValue
F1 -X- _ B-MetricName
on -X- _ O
both -X- _ O
datasets -X- _ O
with -X- _ O
the -X- _ O
gold -X- _ O
entities -X- _ O
given -X- _ O
, -X- _ O
indicating -X- _ O
the -X- _ O
significance -X- _ O
of -X- _ O
modeling -X- _ O
the -X- _ O
information -X- _ O
from -X- _ O
the -X- _ O
object -X- _ O
entity -X- _ O
to -X- _ O
the -X- _ O
subject -X- _ O
entity -X- _ O
in -X- _ O
our -X- _ O
asymmetric -X- _ O
framework -X- _ O
. -X- _ O

We -X- _ O
add -X- _ O
an -X- _ O
auxiliary -X- _ O
entity -X- _ O
type -X- _ O
loss -X- _ O
to -X- _ O
RE -X- _ B-TaskName
model -X- _ O
to -X- _ O
introduce -X- _ O
the -X- _ O
entity -X- _ O
type -X- _ O
information -X- _ O
. -X- _ O
As -X- _ O
shown -X- _ O
in -X- _ O
Table -X- _ O
7 -X- _ O
, -X- _ O
when -X- _ O
the -X- _ O
gold -X- _ O
entities -X- _ O
are -X- _ O
given -X- _ O
, -X- _ O
the -X- _ O
model -X- _ O
without -X- _ O
entity -X- _ O
type -X- _ O
loss -X- _ O
drops -X- _ O
0.4 -X- _ B-MetricValue
% -X- _ I-MetricValue
-0.7 -X- _ I-MetricValue
% -X- _ B-MetricValue
F1 -X- _ B-MetricName
on -X- _ O
both -X- _ O
datasets -X- _ O
, -X- _ O
which -X- _ O
shows -X- _ O
the -X- _ O
importance -X- _ O
of -X- _ O
entity -X- _ O
type -X- _ O
information -X- _ O
in -X- _ O
RE -X- _ B-TaskName
. -X- _ O
Moreover -X- _ O
, -X- _ O
we -X- _ O
try -X- _ O
to -X- _ O
apply -X- _ O
the -X- _ O
type -X- _ O
markers -X- _ O
( -X- _ O
Zhong -X- _ O
and -X- _ O
Chen -X- _ O
, -X- _ O
2021 -X- _ O
) -X- _ O
, -X- _ O
such -X- _ O
as -X- _ O
[ -X- _ O
Subject -X- _ O
: -X- _ O
PER -X- _ O
] -X- _ O
and -X- _ O
[ -X- _ O
Object -X- _ O
: -X- _ O
GPE -X- _ O
] -X- _ O
, -X- _ O
to -X- _ O
inject -X- _ O
entity -X- _ O
type -X- _ O
information -X- _ O
predicted -X- _ O
by -X- _ O
the -X- _ O
NER -X- _ B-TaskName
model -X- _ O
into -X- _ O
the -X- _ O
RE -X- _ B-TaskName
model -X- _ O
. -X- _ O
We -X- _ O
find -X- _ O
the -X- _ O
RE -X- _ B-TaskName
model -X- _ O
with -X- _ O
type -X- _ O
marker -X- _ O
performs -X- _ O
slightly -X- _ O
worse -X- _ O
than -X- _ O
the -X- _ O
model -X- _ O
with -X- _ O
entity -X- _ O
type -X- _ O
loss -X- _ O
in -X- _ O
the -X- _ O
end -X- _ O
- -X- _ O
to -X- _ O
- -X- _ O
end -X- _ O
setting -X- _ O
. -X- _ O
It -X- _ O
shows -X- _ O
that -X- _ O
the -X- _ O
entity -X- _ O
type -X- _ O
prediction -X- _ O
error -X- _ O
from -X- _ O
the -X- _ O
NER -X- _ B-TaskName
model -X- _ O
may -X- _ O
be -X- _ O
propagated -X- _ O
to -X- _ O
the -X- _ O
RE -X- _ B-TaskName
model -X- _ O
if -X- _ O
we -X- _ O
adopt -X- _ O
the -X- _ O
type -X- _ O
markers -X- _ O
as -X- _ O
input -X- _ O
features -X- _ O
. -X- _ O
Finally -X- _ O
, -X- _ O
we -X- _ O
discuss -X- _ O
when -X- _ O
to -X- _ O
use -X- _ O
the -X- _ O
entity -X- _ O
type -X- _ O
prediction -X- _ O
from -X- _ O
the -X- _ O
RE -X- _ B-TaskName
model -X- _ O
to -X- _ O
refine -X- _ O
the -X- _ O
NER -X- _ B-TaskName
prediction -X- _ O
in -X- _ O
the -X- _ O
Appendix -X- _ O
and -X- _ O
we -X- _ O
finally -X- _ O
refine -X- _ O
entity -X- _ O
type -X- _ O
for -X- _ O
ACE04 -X- _ B-DatasetName
and -X- _ O
ACE05 -X- _ B-DatasetName
except -X- _ O
SciERC -X- _ B-DatasetName
according -X- _ O
to -X- _ O
their -X- _ O
dataset -X- _ O
statistic -X- _ O
. -X- _ O

In -X- _ O
this -X- _ O
work -X- _ O
, -X- _ O
we -X- _ O
present -X- _ O
a -X- _ O
novel -X- _ O
packed -X- _ O
levitated -X- _ O
markers -X- _ O
, -X- _ O
with -X- _ O
a -X- _ O
neighborhood -X- _ O
- -X- _ O
oriented -X- _ O
packing -X- _ O
strategy -X- _ O
and -X- _ O
a -X- _ O
subject -X- _ O
- -X- _ O
oriented -X- _ O
packing -X- _ O
strategy -X- _ O
, -X- _ O
to -X- _ O
obtain -X- _ O
the -X- _ O
span -X- _ O
( -X- _ O
pair -X- _ O
) -X- _ O
representation -X- _ O
. -X- _ O
Considering -X- _ O
the -X- _ O
interrelation -X- _ O
between -X- _ O
spans -X- _ O
and -X- _ O
span -X- _ O
pairs -X- _ O
, -X- _ O
our -X- _ O
model -X- _ O
achieves -X- _ O
the -X- _ O
state -X- _ O
- -X- _ O
of -X- _ O
- -X- _ O
the -X- _ O
- -X- _ O
art -X- _ O
F1 -X- _ B-MetricName
scores -X- _ O
and -X- _ O
a -X- _ O
promising -X- _ O
efficiency -X- _ O
on -X- _ O
both -X- _ O
NER -X- _ B-TaskName
and -X- _ O
RE -X- _ B-TaskName
tasks -X- _ O
across -X- _ O
six -X- _ O
standard -X- _ O
benchmarks -X- _ O
. -X- _ O
In -X- _ O
future -X- _ O
, -X- _ O
we -X- _ O
will -X- _ O
further -X- _ O
investigate -X- _ O
how -X- _ O
to -X- _ O
generalize -X- _ O
the -X- _ O
markerbased -X- _ O
span -X- _ O
representation -X- _ O
to -X- _ O
more -X- _ O
NLP -X- _ O
tasks -X- _ O
. -X- _ O

We -X- _ O
train -X- _ O
all -X- _ O
the -X- _ O
models -X- _ O
with -X- _ O
Adam -X- _ B-HyperparameterValue
optimizer -X- _ B-HyperparameterName
( -X- _ O
Kingma -X- _ O
and -X- _ O
Ba -X- _ O
, -X- _ O
2015 -X- _ O
) -X- _ O
and -X- _ O
10 -X- _ B-HyperparameterValue
% -X- _ I-HyperparameterValue
warmingup -X- _ B-HyperparameterName
steps -X- _ I-HyperparameterName
. -X- _ O
And -X- _ O
we -X- _ O
adopt -X- _ O
a -X- _ O
learning -X- _ B-HyperparameterName
rate -X- _ I-HyperparameterName
of -X- _ O
2e-5 -X- _ B-HyperparameterValue
for -X- _ O
models -X- _ O
with -X- _ O
BASE -X- _ O
size -X- _ O
and -X- _ O
a -X- _ O
learning -X- _ B-HyperparameterName
rate -X- _ I-HyperparameterName
of -X- _ O
1e-5 -X- _ B-HyperparameterValue
for -X- _ O
models -X- _ O
with -X- _ O
LARGE -X- _ O
or -X- _ O
XXLARGE -X- _ O
size -X- _ O
. -X- _ O
We -X- _ O
run -X- _ O
all -X- _ O
experiments -X- _ O
with -X- _ O
5 -X- _ O
different -X- _ O
seeds -X- _ O
( -X- _ O
42,43,44,45,46 -X- _ O
) -X- _ O
. -X- _ O
For -X- _ O
the -X- _ O
bidirectional -X- _ O
prediction -X- _ O
on -X- _ O
RE -X- _ B-TaskName
, -X- _ O
we -X- _ O
set -X- _ O
the -X- _ O
forward -X- _ O
and -X- _ O
inverse -X- _ O
relation -X- _ O
of -X- _ O
symmetric -X- _ O
labels -X- _ O
to -X- _ O
be -X- _ O
consistent -X- _ O
. -X- _ O
The -X- _ O
symmetric -X- _ O
labels -X- _ O
include -X- _ O
the -X- _ O
PER -X- _ O
- -X- _ O
SOC -X- _ O
in -X- _ O
the -X- _ O
ACE04 -X- _ B-DatasetName
/ -X- _ O
ACE05 -X- _ B-DatasetName
and -X- _ O
the -X- _ O
Compare -X- _ O
and -X- _ O
Conjunction -X- _ O
in -X- _ O
the -X- _ O
SciERC -X- _ B-DatasetName
. -X- _ O

For -X- _ O
NER -X- _ B-TaskName
model -X- _ O
, -X- _ O
we -X- _ O
set -X- _ O
the -X- _ O
maximum -X- _ B-HyperparameterName
length -X- _ I-HyperparameterName
of -X- _ I-HyperparameterName
expanded -X- _ I-HyperparameterName
sentence -X- _ I-HyperparameterName
C -X- _ B-HyperparameterName
as -X- _ O
512 -X- _ B-HyperparameterValue
. -X- _ O
For -X- _ O
RE -X- _ B-TaskName
model -X- _ O
, -X- _ O
we -X- _ O
set -X- _ O
C -X- _ B-HyperparameterName
as -X- _ O
256 -X- _ B-HyperparameterValue
for -X- _ O
ACE05 -X- _ B-DatasetName
and -X- _ O
SciERC -X- _ B-DatasetName
and -X- _ O
set -X- _ O
C -X- _ B-HyperparameterName
as -X- _ O
384 -X- _ B-HyperparameterValue
for -X- _ O
ACE04 -X- _ B-DatasetName
. -X- _ O
To -X- _ O
enumerate -X- _ O
possible -X- _ O
spans -X- _ O
, -X- _ O
we -X- _ O
set -X- _ O
the -X- _ O
maximum -X- _ B-HyperparameterName
span -X- _ I-HyperparameterName
length -X- _ I-HyperparameterName
L -X- _ B-HyperparameterName
as -X- _ O
16 -X- _ B-HyperparameterValue
for -X- _ O
OntoNote -X- _ B-DatasetName
5.0 -X- _ I-DatasetName
and -X- _ O
Few -X- _ B-DatasetName
- -X- _ I-DatasetName
NERD -X- _ I-DatasetName
and -X- _ O
set -X- _ O
8 -X- _ B-HyperparameterValue
for -X- _ O
the -X- _ O
other -X- _ O
datasets -X- _ O
. -X- _ O
For -X- _ O
the -X- _ O
NER -X- _ B-TaskName
on -X- _ O
CoNLL03 -X- _ B-DatasetName
and -X- _ O
the -X- _ O
RE -X- _ B-TaskName
on -X- _ O
ACE05 -X- _ B-DatasetName
, -X- _ O
we -X- _ O
search -X- _ O
the -X- _ O
batch -X- _ B-HyperparameterName
size -X- _ I-HyperparameterName
in -X- _ O
[ -X- _ O
4,8,16,32 -X- _ B-HyperparameterValue
] -X- _ O
and -X- _ O
observe -X- _ O
the -X- _ O
model -X- _ O
with -X- _ O
a -X- _ O
batch -X- _ B-HyperparameterName
size -X- _ I-HyperparameterName
of -X- _ O
8 -X- _ B-HyperparameterValue
achieves -X- _ O
a -X- _ O
sightly -X- _ O
better -X- _ O
performance -X- _ O
. -X- _ O
Hence -X- _ O
, -X- _ O
we -X- _ O
choose -X- _ O
a -X- _ O
batch -X- _ B-HyperparameterName
size -X- _ I-HyperparameterName
of -X- _ O
8 -X- _ B-HyperparameterValue
for -X- _ O
all -X- _ O
the -X- _ O
datasets -X- _ O
. -X- _ O
We -X- _ O
search -X- _ O
the -X- _ O
number -X- _ B-HyperparameterName
of -X- _ I-HyperparameterName
epochs -X- _ I-HyperparameterName
in -X- _ O
[ -X- _ O
3,5,8,10,15,50 -X- _ B-HyperparameterValue
] -X- _ O
for -X- _ O
all -X- _ O
the -X- _ O
datasets -X- _ O
and -X- _ O
finally -X- _ O
choose -X- _ O
8 -X- _ B-HyperparameterValue
for -X- _ O
CoNLL03 -X- _ B-DatasetName
, -X- _ O
4 -X- _ B-HyperparameterValue
for -X- _ O
OntoNote -X- _ B-DatasetName
5.0 -X- _ I-DatasetName
, -X- _ O
3 -X- _ B-HyperparameterValue
for -X- _ O
Few -X- _ B-DatasetName
- -X- _ I-DatasetName
NERD -X- _ I-DatasetName
, -X- _ O
10 -X- _ B-HyperparameterValue
for -X- _ O
ACE05 -X- _ B-DatasetName
- -X- _ O
NER -X- _ B-TaskName
, -X- _ O
15 -X- _ B-HyperparameterValue
for -X- _ O
ACE04 -X- _ B-DatasetName
- -X- _ O
NER -X- _ B-TaskName
, -X- _ O
50 -X- _ B-HyperparameterValue
for -X- _ O
SciERC -X- _ B-DatasetName
- -X- _ I-DatasetName
NER -X- _ I-DatasetName
and -X- _ O
10 -X- _ B-HyperparameterValue
for -X- _ O
all -X- _ O
the -X- _ O
RE -X- _ B-TaskName
models -X- _ O
. -X- _ O

Inspired -X- _ O
by -X- _ O
the -X- _ O
success -X- _ O
of -X- _ O
prompt -X- _ O
tuning -X- _ O
( -X- _ O
Brown -X- _ O
et -X- _ O
al -X- _ O
. -X- _ O
, -X- _ O
2020 -X- _ O
; -X- _ O
Schick -X- _ O
and -X- _ O
Schütze -X- _ O
, -X- _ O
2021 -X- _ O
) -X- _ O
, -X- _ O
we -X- _ O
use -X- _ O
the -X- _ O
embedding -X- _ O
of -X- _ O
meaningful -X- _ O
words -X- _ O
instead -X- _ O
of -X- _ O
randomness -X- _ O
to -X- _ O
initialize -X- _ O
the -X- _ O
embedding -X- _ O
of -X- _ O
markers -X- _ O
for -X- _ O
the -X- _ O
NER -X- _ B-TaskName
models -X- _ O
. -X- _ O
To -X- _ O
be -X- _ O
specific -X- _ O
, -X- _ O
we -X- _ O
initialize -X- _ O
a -X- _ O
pair -X- _ O
of -X- _ O
markers -X- _ O
for -X- _ O
the -X- _ O
span -X- _ O
with -X- _ O
the -X- _ O
words -X- _ O
[ -X- _ O
MASK -X- _ O
] -X- _ O
and -X- _ O
entity -X- _ O
. -X- _ O
As -X- _ O
shown -X- _ O
in -X- _ O
Table -X- _ O
8 -X- _ O
, -X- _ O
using -X- _ O
meaningful -X- _ O
words -X- _ O
as -X- _ O
prompt -X- _ O
to -X- _ O
initialize -X- _ O
the -X- _ O
markers -X- _ O
can -X- _ O
bring -X- _ O
a -X- _ O
slight -X- _ O
improvement -X- _ O
to -X- _ O
all -X- _ O
six -X- _ O
NER -X- _ B-TaskName
benchmarks -X- _ O
. -X- _ O

We -X- _ O
attempt -X- _ O
to -X- _ O
apply -X- _ O
the -X- _ O
entity -X- _ O
type -X- _ O
prediction -X- _ O
from -X- _ O
the -X- _ O
RE -X- _ B-TaskName
model -X- _ O
to -X- _ O
refine -X- _ O
the -X- _ O
entity -X- _ O
type -X- _ O
prediction -X- _ O
from -X- _ O
the -X- _ O
NER -X- _ B-TaskName
model -X- _ O
. -X- _ O
As -X- _ O
shown -X- _ O
in -X- _ O
Table -X- _ O
9 -X- _ O
, -X- _ O
using -X- _ O
the -X- _ O
entity -X- _ O
type -X- _ O
predicted -X- _ O
by -X- _ O
the -X- _ O
RE -X- _ B-TaskName
model -X- _ O
brings -X- _ O
+0.5 -X- _ B-MetricValue
% -X- _ I-MetricValue
and -X- _ O
-0.9 -X- _ B-MetricValue
% -X- _ I-MetricValue
strict -X- _ O
relation -X- _ O
F1 -X- _ B-MetricName
on -X- _ O
ACE05 -X- _ B-DatasetName
and -X- _ O
SciERC -X- _ B-DatasetName
respectively -X- _ O
. -X- _ O
We -X- _ O
observe -X- _ O
that -X- _ O
the -X- _ O
most -X- _ B-MetricName
frequent -X- _ I-MetricName
entity -X- _ I-MetricName
type -X- _ I-MetricName
pair -X- _ I-MetricName
for -X- _ O
each -X- _ O
relation -X- _ O
occupies -X- _ O
48.5 -X- _ B-HyperparameterValue
% -X- _ I-HyperparameterValue
for -X- _ O
ACE05 -X- _ B-DatasetName
, -X- _ O
52.0 -X- _ B-HyperparameterValue
% -X- _ I-HyperparameterValue
for -X- _ O
ACE04 -X- _ B-DatasetName
and -X- _ O
19.1 -X- _ B-HyperparameterValue
% -X- _ I-HyperparameterValue
for -X- _ O
SciERC -X- _ B-DatasetName
, -X- _ O
which -X- _ O
shows -X- _ O
that -X- _ O
the -X- _ O
relation -X- _ O
is -X- _ O
more -X- _ O

We -X- _ O
illustrate -X- _ O
the -X- _ O
span -X- _ O
representation -X- _ O
adopted -X- _ O
by -X- _ O
the -X- _ O
NER -X- _ B-TaskName
models -X- _ O
in -X- _ O
Figure -X- _ O
3 -X- _ O
. -X- _ O
And -X- _ O
we -X- _ O
show -X- _ O
the -X- _ O
average -X- _ O
scores -X- _ O
of -X- _ O
the -X- _ O
baselines -X- _ O
and -X- _ O
PL -X- _ B-MethodName
- -X- _ I-MethodName
Marker -X- _ I-MethodName
on -X- _ O
flat -X- _ O
NER -X- _ B-TaskName
with -X- _ O
standard -X- _ O
deviations -X- _ O
in -X- _ O
Table -X- _ O
11 -X- _ O
. -X- _ O

Single -X- _ O
Sequence -X- _ O
Prediction -X- _ O
over -X- _ O
Reasoning -X- _ O
Graphs -X- _ O
for -X- _ O
Multi -X- _ B-TaskName
- -X- _ I-TaskName
hop -X- _ I-TaskName
QA -X- _ I-TaskName

Recent -X- _ O
generative -X- _ O
approaches -X- _ O
for -X- _ O
multi -X- _ B-TaskName
- -X- _ I-TaskName
hop -X- _ I-TaskName
question -X- _ I-TaskName
answering -X- _ I-TaskName
( -X- _ O
QA -X- _ O
) -X- _ O
utilize -X- _ O
the -X- _ O
fusion -X- _ O
- -X- _ O
indecoder -X- _ O
method -X- _ O
( -X- _ O
Izacard -X- _ O
and -X- _ O
Grave -X- _ O
, -X- _ O
2021 -X- _ O
) -X- _ O
to -X- _ O
generate -X- _ O
a -X- _ O
single -X- _ O
sequence -X- _ O
output -X- _ O
which -X- _ O
includes -X- _ O
both -X- _ O
a -X- _ O
final -X- _ O
answer -X- _ O
and -X- _ O
a -X- _ O
reasoning -X- _ O
path -X- _ O
taken -X- _ O
to -X- _ O
arrive -X- _ O
at -X- _ O
that -X- _ O
answer -X- _ O
, -X- _ O
such -X- _ O
as -X- _ O
passage -X- _ O
titles -X- _ O
and -X- _ O
key -X- _ O
facts -X- _ O
from -X- _ O
those -X- _ O
passages -X- _ O
. -X- _ O
While -X- _ O
such -X- _ O
models -X- _ O
can -X- _ O
lead -X- _ O
to -X- _ O
better -X- _ O
interpretability -X- _ O
and -X- _ O
high -X- _ O
quantitative -X- _ O
scores -X- _ O
, -X- _ O
they -X- _ O
often -X- _ O
have -X- _ O
difficulty -X- _ O
accurately -X- _ O
identifying -X- _ O
the -X- _ O
passages -X- _ O
corresponding -X- _ O
to -X- _ O
key -X- _ O
entities -X- _ O
in -X- _ O
the -X- _ O
context -X- _ O
, -X- _ O
resulting -X- _ O
in -X- _ O
incorrect -X- _ O
passage -X- _ O
hops -X- _ O
and -X- _ O
a -X- _ O
lack -X- _ O
of -X- _ O
faithfulness -X- _ O
in -X- _ O
the -X- _ O
reasoning -X- _ O
path -X- _ O
. -X- _ O
To -X- _ O
address -X- _ O
this -X- _ O
, -X- _ O
we -X- _ O
propose -X- _ O
a -X- _ O
single -X- _ O
- -X- _ O
sequence -X- _ O
prediction -X- _ O
method -X- _ O
over -X- _ O
a -X- _ O
local -X- _ O
reasoning -X- _ O
graph -X- _ O
( -X- _ O
SEQGRAPH -X- _ B-MethodName
) -X- _ O
1 -X- _ O
that -X- _ O
integrates -X- _ O
a -X- _ O
graph -X- _ O
structure -X- _ O
connecting -X- _ O
key -X- _ O
entities -X- _ O
in -X- _ O
each -X- _ O
context -X- _ O
passage -X- _ O
to -X- _ O
relevant -X- _ O
subsequent -X- _ O
passages -X- _ O
for -X- _ O
each -X- _ O
question -X- _ O
. -X- _ O
We -X- _ O
use -X- _ O
a -X- _ O
graph -X- _ O
neural -X- _ O
network -X- _ O
to -X- _ O
encode -X- _ O
this -X- _ O
graph -X- _ O
structure -X- _ O
and -X- _ O
fuse -X- _ O
the -X- _ O
resulting -X- _ O
representations -X- _ O
into -X- _ O
the -X- _ O
entity -X- _ O
representations -X- _ O
of -X- _ O
the -X- _ O
model -X- _ O
. -X- _ O
Our -X- _ O
experiments -X- _ O
show -X- _ O
significant -X- _ O
improvements -X- _ O
in -X- _ O
answer -X- _ B-MetricName
exact -X- _ I-MetricName
- -X- _ I-MetricName
match -X- _ I-MetricName
/ -X- _ O
F1 -X- _ B-MetricName
scores -X- _ O
and -X- _ O
faithfulness -X- _ O
of -X- _ O
grounding -X- _ O
in -X- _ O
the -X- _ O
reasoning -X- _ O
path -X- _ O
on -X- _ O
the -X- _ O
HotpotQA -X- _ B-DatasetName
dataset -X- _ O
and -X- _ O
achieve -X- _ O
stateof -X- _ O
- -X- _ O
the -X- _ O
- -X- _ O
art -X- _ O
numbers -X- _ O
on -X- _ O
the -X- _ O
Musique -X- _ B-DatasetName
dataset -X- _ O
with -X- _ O
only -X- _ O
up -X- _ O
to -X- _ O
a -X- _ O
4 -X- _ O
% -X- _ O
increase -X- _ O
in -X- _ O
model -X- _ O
parameters -X- _ O
. -X- _ O

Multi -X- _ B-TaskName
- -X- _ I-TaskName
hop -X- _ I-TaskName
Question -X- _ I-TaskName
Answering -X- _ I-TaskName
( -X- _ O
QA -X- _ O
) -X- _ O
involves -X- _ O
reasoning -X- _ O
over -X- _ O
multiple -X- _ O
passages -X- _ O
and -X- _ O
understanding -X- _ O
the -X- _ O
relationships -X- _ O
between -X- _ O
those -X- _ O
pieces -X- _ O
of -X- _ O
information -X- _ O
to -X- _ O
answer -X- _ O
a -X- _ O
question -X- _ O
. -X- _ O
Compared -X- _ O
with -X- _ O
singlehop -X- _ O
QA -X- _ O
, -X- _ O
which -X- _ O
often -X- _ O
extracts -X- _ O
answers -X- _ O
from -X- _ O
a -X- _ O
single -X- _ O
passage -X- _ O
, -X- _ O
multi -X- _ B-TaskName
- -X- _ I-TaskName
hop -X- _ I-TaskName
QA -X- _ I-TaskName
is -X- _ O
more -X- _ O
challenging -X- _ O
as -X- _ O
it -X- _ O
requires -X- _ O
a -X- _ O
model -X- _ O
to -X- _ O
determine -X- _ O
the -X- _ O
relevant -X- _ O
facts -X- _ O
from -X- _ O
multiple -X- _ O
passages -X- _ O
and -X- _ O
connect -X- _ O
those -X- _ O
facts -X- _ O
for -X- _ O
reasoning -X- _ O
to -X- _ O
infer -X- _ O
the -X- _ O
final -X- _ O
answer -X- _ O
. -X- _ O

To -X- _ O
tackle -X- _ O
multi -X- _ B-TaskName
- -X- _ I-TaskName
hop -X- _ I-TaskName
QA -X- _ I-TaskName
, -X- _ O
recent -X- _ O
works -X- _ O
have -X- _ O
investigated -X- _ O
large -X- _ O
pretrained -X- _ O
generative -X- _ O
models -X- _ O
( -X- _ O
Lewis -X- _ O
Figure -X- _ O
1 -X- _ O
: -X- _ O
Localized -X- _ O
graph -X- _ O
construction -X- _ O
connecting -X- _ O
entity -X- _ O
spans -X- _ O
to -X- _ O
corresponding -X- _ O
passages -X- _ O
in -X- _ O
the -X- _ O
context -X- _ O
. -X- _ O
If -X- _ O
there -X- _ O
are -X- _ O
multiple -X- _ O
passages -X- _ O
with -X- _ O
the -X- _ O
same -X- _ O
title -X- _ O
, -X- _ O
we -X- _ O
connect -X- _ O
the -X- _ O
entity -X- _ O
span -X- _ O
to -X- _ O
all -X- _ O
such -X- _ O
passages -X- _ O
. -X- _ O
et -X- _ O
al -X- _ O
. -X- _ O
, -X- _ O
2020b -X- _ O
; -X- _ O
Brown -X- _ O
et -X- _ O
al -X- _ O
. -X- _ O
, -X- _ O
2020 -X- _ O
) -X- _ O
and -X- _ O
demonstrated -X- _ O
their -X- _ O
effectiveness -X- _ O
over -X- _ O
traditional -X- _ O
extractive -X- _ O
models -X- _ O
( -X- _ O
Chen -X- _ O
et -X- _ O
al -X- _ O
. -X- _ O
, -X- _ O
2017 -X- _ O
) -X- _ O
. -X- _ O
Compared -X- _ O
with -X- _ O
extractive -X- _ O
models -X- _ O
, -X- _ O
the -X- _ O
ability -X- _ O
of -X- _ O
generative -X- _ O
models -X- _ O
to -X- _ O
effectively -X- _ O
aggregate -X- _ O
and -X- _ O
combine -X- _ O
evidence -X- _ O
from -X- _ O
multiple -X- _ O
passages -X- _ O
proves -X- _ O
advantageous -X- _ O
for -X- _ O
multi -X- _ B-TaskName
- -X- _ I-TaskName
hop -X- _ I-TaskName
QA -X- _ I-TaskName
. -X- _ O
In -X- _ O
particular -X- _ O
, -X- _ O
Izacard -X- _ O
and -X- _ O
Grave -X- _ O
( -X- _ O
2021 -X- _ O
) -X- _ O
propose -X- _ O
a -X- _ O
method -X- _ O
called -X- _ O
FID -X- _ O
( -X- _ O
Fusion -X- _ O
- -X- _ O
in -X- _ O
- -X- _ O
Decoder -X- _ O
) -X- _ O
, -X- _ O
which -X- _ O
leverages -X- _ O
passage -X- _ O
retrieval -X- _ O
with -X- _ O
a -X- _ O
generative -X- _ O
model -X- _ O
, -X- _ O
such -X- _ O
as -X- _ O
T5 -X- _ O
or -X- _ O
BART -X- _ O
( -X- _ O
Lewis -X- _ O
et -X- _ O
al -X- _ O
. -X- _ O
, -X- _ O
2020a -X- _ O
) -X- _ O
, -X- _ O
to -X- _ O
achieve -X- _ O
state -X- _ O
- -X- _ O
of -X- _ O
- -X- _ O
the -X- _ O
- -X- _ O
art -X- _ O
performance -X- _ O
on -X- _ O
various -X- _ O
single -X- _ O
- -X- _ O
hop -X- _ O
QA -X- _ O
tasks -X- _ O
. -X- _ O
However -X- _ O
, -X- _ O
this -X- _ O
approach -X- _ O
does -X- _ O
not -X- _ O
extend -X- _ O
well -X- _ O
to -X- _ O
multi -X- _ B-TaskName
- -X- _ I-TaskName
hop -X- _ I-TaskName
QA -X- _ I-TaskName
tasks -X- _ O
( -X- _ O
Yavuz -X- _ O
et -X- _ O
al -X- _ O
. -X- _ O
, -X- _ O
2022 -X- _ O
) -X- _ O
, -X- _ O
as -X- _ O
it -X- _ O
sorely -X- _ O
relies -X- _ O
on -X- _ O
a -X- _ O
black -X- _ O
- -X- _ O
box -X- _ O
generative -X- _ O
model -X- _ O
to -X- _ O
generate -X- _ O
answers -X- _ O
directly -X- _ O
without -X- _ O
explicitly -X- _ O
modeling -X- _ O
the -X- _ O
multi -X- _ O
- -X- _ O
hop -X- _ O
reasoning -X- _ O
process -X- _ O
. -X- _ O
Additionally -X- _ O
, -X- _ O
FID -X- _ O
encodes -X- _ O
multiple -X- _ O
context -X- _ O
passages -X- _ O
independently -X- _ O
for -X- _ O
multi -X- _ B-TaskName
- -X- _ I-TaskName
hop -X- _ I-TaskName
QA -X- _ I-TaskName
, -X- _ O
ignoring -X- _ O
the -X- _ O
structural -X- _ O
and -X- _ O
semantic -X- _ O
relationship -X- _ O
between -X- _ O
these -X- _ O
passages -X- _ O
. -X- _ O
Building -X- _ O
on -X- _ O
FID -X- _ O
, -X- _ O
PATH -X- _ O
- -X- _ O
FID -X- _ O
( -X- _ O
Yavuz -X- _ O
et -X- _ O
al -X- _ O
. -X- _ O
, -X- _ O
2022 -X- _ O
) -X- _ O
addresses -X- _ O
the -X- _ O
interpretability -X- _ O
issue -X- _ O
by -X- _ O
training -X- _ O
a -X- _ O
model -X- _ O
to -X- _ O
generate -X- _ O
a -X- _ O
reasoning -X- _ O
path -X- _ O
that -X- _ O
contains -X- _ O
supporting -X- _ O
pas -X- _ O
- -X- _ O
sage -X- _ O
titles -X- _ O
, -X- _ O
facts -X- _ O
, -X- _ O
and -X- _ O
the -X- _ O
final -X- _ O
answer -X- _ O
. -X- _ O
However -X- _ O
, -X- _ O
our -X- _ O
analysis -X- _ O
of -X- _ O
PATH -X- _ O
- -X- _ O
FID -X- _ O
outputs -X- _ O
shows -X- _ O
disconnected -X- _ O
reasoning -X- _ O
with -X- _ O
incorrect -X- _ O
passage -X- _ O
hops -X- _ O
in -X- _ O
the -X- _ O
model -X- _ O
's -X- _ O
reasoning -X- _ O
path -X- _ O
which -X- _ O
affects -X- _ O
final -X- _ O
answer -X- _ O
generation -X- _ O
. -X- _ O
Recently -X- _ O
, -X- _ O
there -X- _ O
have -X- _ O
been -X- _ O
multiple -X- _ O
techniques -X- _ O
( -X- _ O
Jiang -X- _ O
and -X- _ O
Bansal -X- _ O
, -X- _ O
2019 -X- _ O
; -X- _ O
Lee -X- _ O
et -X- _ O
al -X- _ O
. -X- _ O
, -X- _ O
2021 -X- _ O
; -X- _ O
Ye -X- _ O
et -X- _ O
al -X- _ O
. -X- _ O
, -X- _ O
2021 -X- _ O
) -X- _ O
to -X- _ O
counter -X- _ O
disconnected -X- _ O
reasoning -X- _ O
which -X- _ O
operate -X- _ O
at -X- _ O
the -X- _ O
dataset -X- _ O
level -X- _ O
, -X- _ O
using -X- _ O
adversarial -X- _ O
training -X- _ O
, -X- _ O
adding -X- _ O
extra -X- _ O
annotations -X- _ O
or -X- _ O
using -X- _ O
dataset -X- _ O
rebalancing -X- _ O
for -X- _ O
training -X- _ O
. -X- _ O
While -X- _ O
these -X- _ O
approaches -X- _ O
optimize -X- _ O
models -X- _ O
to -X- _ O
mitigate -X- _ O
disconnected -X- _ O
reasoning -X- _ O
( -X- _ O
Trivedi -X- _ O
et -X- _ O
al -X- _ O
. -X- _ O
, -X- _ O
2020 -X- _ O
) -X- _ O
, -X- _ O
the -X- _ O
performance -X- _ O
on -X- _ O
the -X- _ O
original -X- _ O
test -X- _ O
set -X- _ O
often -X- _ O
suffers -X- _ O
from -X- _ O
a -X- _ O
significant -X- _ O
decrease -X- _ O
. -X- _ O

In -X- _ O
this -X- _ O
paper -X- _ O
, -X- _ O
we -X- _ O
propose -X- _ O
a -X- _ O
single -X- _ B-MethodName
- -X- _ I-MethodName
sequence -X- _ I-MethodName
prediction -X- _ I-MethodName
method -X- _ I-MethodName
over -X- _ I-MethodName
a -X- _ I-MethodName
local -X- _ I-MethodName
reasoning -X- _ I-MethodName
graph -X- _ I-MethodName
( -X- _ O
SEQGRAPH -X- _ B-MethodName
) -X- _ O
that -X- _ O
integrates -X- _ O
a -X- _ O
graph -X- _ O
structure -X- _ O
connecting -X- _ O
key -X- _ O
entities -X- _ O
in -X- _ O
each -X- _ O
context -X- _ O
passage -X- _ O
to -X- _ O
relevant -X- _ O
subsequent -X- _ O
passages -X- _ O
for -X- _ O
each -X- _ O
question -X- _ O
. -X- _ O
Different -X- _ O
from -X- _ O
the -X- _ O
prior -X- _ O
works -X- _ O
, -X- _ O
our -X- _ O
method -X- _ O
not -X- _ O
only -X- _ O
mitigates -X- _ O
the -X- _ O
disconnected -X- _ O
reasoning -X- _ O
issue -X- _ O
but -X- _ O
also -X- _ O
maintains -X- _ O
robust -X- _ O
performance -X- _ O
on -X- _ O
the -X- _ O
original -X- _ O
dataset -X- _ O
. -X- _ O
Intuitively -X- _ O
, -X- _ O
for -X- _ O
each -X- _ O
multi -X- _ O
- -X- _ O
hop -X- _ O
question -X- _ O
, -X- _ O
our -X- _ O
method -X- _ O
leverages -X- _ O
the -X- _ O
structural -X- _ O
relationship -X- _ O
between -X- _ O
different -X- _ O
passages -X- _ O
to -X- _ O
learn -X- _ O
structured -X- _ O
representations -X- _ O
through -X- _ O
a -X- _ O
graph -X- _ O
neural -X- _ O
network -X- _ O
( -X- _ O
GNN -X- _ O
) -X- _ O
( -X- _ O
Hamilton -X- _ O
et -X- _ O
al -X- _ O
. -X- _ O
, -X- _ O
2017 -X- _ O
; -X- _ O
Kipf -X- _ O
and -X- _ O
Welling -X- _ O
, -X- _ O
2017 -X- _ O
) -X- _ O
. -X- _ O
The -X- _ O
structured -X- _ O
representations -X- _ O
are -X- _ O
fused -X- _ O
to -X- _ O
bias -X- _ O
the -X- _ O
generative -X- _ O
model -X- _ O
toward -X- _ O
predicting -X- _ O
a -X- _ O
faithful -X- _ O
, -X- _ O
connected -X- _ O
reasoning -X- _ O
path -X- _ O
which -X- _ O
improves -X- _ O
answer -X- _ O
predictions -X- _ O
. -X- _ O
Our -X- _ O
experiments -X- _ O
on -X- _ O
the -X- _ O
HOTPOT -X- _ B-DatasetName
- -X- _ I-DatasetName
QA -X- _ I-DatasetName
dataset -X- _ O
( -X- _ O
Yang -X- _ O
et -X- _ O
al -X- _ O
. -X- _ O
, -X- _ O
2018 -X- _ O
) -X- _ O
show -X- _ O
clear -X- _ O
improvements -X- _ O
in -X- _ O
exact -X- _ B-MetricName
- -X- _ I-MetricName
match -X- _ I-MetricName
( -X- _ I-MetricName
EM -X- _ B-MetricName
) -X- _ I-MetricName
/ -X- _ I-MetricName
F1 -X- _ B-MetricName
scores -X- _ O
compared -X- _ O
to -X- _ O
generative -X- _ O
baselines -X- _ O
in -X- _ O
the -X- _ O
distractor -X- _ O
setting -X- _ O
while -X- _ O
minimizing -X- _ O
disconnected -X- _ O
reasoning -X- _ O
quantified -X- _ O
by -X- _ O
the -X- _ O
DIRE -X- _ B-MetricName
score -X- _ O
( -X- _ O
Trivedi -X- _ O
et -X- _ O
al -X- _ O
. -X- _ O
, -X- _ O
2020 -X- _ O
) -X- _ O
. -X- _ O
We -X- _ O
also -X- _ O
achieve -X- _ O
the -X- _ O
state -X- _ O
- -X- _ O
of -X- _ O
- -X- _ O
the -X- _ O
- -X- _ O
art -X- _ O
performance -X- _ O
on -X- _ O
the -X- _ O
MUSIQUE -X- _ B-DatasetName
- -X- _ O
Answerable -X- _ O
test -X- _ O
dataset -X- _ O
( -X- _ O
Trivedi -X- _ O
et -X- _ O
al -X- _ O
. -X- _ O
, -X- _ O
2022a -X- _ O
) -X- _ O
with -X- _ O
a -X- _ O
17 -X- _ B-MetricValue
- -X- _ O
point -X- _ O
improvement -X- _ O
in -X- _ O
answer -X- _ O
F1 -X- _ B-MetricName
over -X- _ O
the -X- _ O
current -X- _ O
best -X- _ O
- -X- _ O
performing -X- _ O
model -X- _ O
in -X- _ O
the -X- _ O
end -X- _ O
- -X- _ O
to -X- _ O
- -X- _ O
end -X- _ O
( -X- _ O
E2E -X- _ O
) -X- _ O
category -X- _ O
. -X- _ O

• -X- _ O
We -X- _ O
propose -X- _ O
an -X- _ O
interpretable -X- _ O
single -X- _ O
- -X- _ O
sequence -X- _ O
prediction -X- _ O
approach -X- _ O
over -X- _ O
local -X- _ O
reasoning -X- _ O
graphs -X- _ O
, -X- _ O
SEQGRAPH -X- _ B-MethodName
, -X- _ O
to -X- _ O
bias -X- _ O
the -X- _ O
model -X- _ O
representations -X- _ O
• -X- _ O
SEQGRAPH -X- _ B-MethodName
achieves -X- _ O
notable -X- _ O
performance -X- _ O
improvements -X- _ O
on -X- _ O
two -X- _ O
multi -X- _ B-TaskName
- -X- _ I-TaskName
hop -X- _ I-TaskName
QA -X- _ I-TaskName
benchmarks -X- _ O
, -X- _ O
HOTPOT -X- _ B-DatasetName
- -X- _ I-DatasetName
QA -X- _ I-DatasetName
and -X- _ O
MUSIQUE -X- _ B-DatasetName
( -X- _ O
SOTA -X- _ O
) -X- _ O
, -X- _ O
with -X- _ O
only -X- _ O
a -X- _ O
minimal -X- _ O
increase -X- _ O
in -X- _ O
the -X- _ O
model -X- _ O
size -X- _ O
. -X- _ O
• -X- _ O
SEQGRAPH -X- _ B-MethodName
reduces -X- _ O
disconnected -X- _ O
reasoning -X- _ O
as -X- _ O
measured -X- _ O
by -X- _ O
DIRE -X- _ B-MetricName
score -X- _ O
while -X- _ O
maintaining -X- _ O
strong -X- _ O
performance -X- _ O
gains -X- _ O
on -X- _ O
the -X- _ O
original -X- _ O
dataset -X- _ O
. -X- _ O

Problem -X- _ O
Setup -X- _ O
: -X- _ O
In -X- _ O
a -X- _ O
multi -X- _ B-TaskName
- -X- _ I-TaskName
hop -X- _ I-TaskName
QA -X- _ I-TaskName
task -X- _ O
, -X- _ O
each -X- _ O
QA -X- _ O
pair -X- _ O
in -X- _ O
a -X- _ O
labeled -X- _ O
dataset -X- _ O
D -X- _ O
is -X- _ O
given -X- _ O
along -X- _ O
with -X- _ O
a -X- _ O
set -X- _ O
of -X- _ O
N -X- _ O
passages -X- _ O
, -X- _ O
P -X- _ O
q -X- _ O
= -X- _ O
{ -X- _ O
p -X- _ O
1 -X- _ O
, -X- _ O
p -X- _ O
2 -X- _ O
, -X- _ O
... -X- _ O
, -X- _ O
p -X- _ O
N -X- _ O
} -X- _ O
, -X- _ O
i.e. -X- _ O
, -X- _ O
( -X- _ O
q -X- _ O
, -X- _ O
a -X- _ O
, -X- _ O
P -X- _ O
q -X- _ O
) -X- _ O
∈ -X- _ O
D -X- _ O
, -X- _ O
where -X- _ O
a -X- _ O
passage -X- _ O
has -X- _ O
its -X- _ O
title -X- _ O
and -X- _ O
content -X- _ O
p -X- _ O
i -X- _ O
= -X- _ O
( -X- _ O
t -X- _ O
i -X- _ O
, -X- _ O
c -X- _ O
i -X- _ O
) -X- _ O
. -X- _ O
The -X- _ O
task -X- _ O
is -X- _ O
to -X- _ O
learn -X- _ O
a -X- _ O
model -X- _ O
parameterized -X- _ O
θ -X- _ O
to -X- _ O
generate -X- _ O
an -X- _ O
answer -X- _ O
string -X- _ O
a -X- _ O
for -X- _ O
the -X- _ O
given -X- _ O
question -X- _ O
q -X- _ O
and -X- _ O
P -X- _ O
q -X- _ O
. -X- _ O
In -X- _ O
this -X- _ O
paper -X- _ O
, -X- _ O
we -X- _ O
focus -X- _ O
on -X- _ O
the -X- _ O
distractor -X- _ O
setting -X- _ O
, -X- _ O
where -X- _ O
P -X- _ O
q -X- _ O
is -X- _ O
given -X- _ O
for -X- _ O
each -X- _ O
question -X- _ O
and -X- _ O
contains -X- _ O
m -X- _ O
distractors -X- _ O
that -X- _ O
are -X- _ O
not -X- _ O
useful -X- _ O
to -X- _ O
the -X- _ O
answer -X- _ O
prediction -X- _ O
. -X- _ O
Thus -X- _ O
, -X- _ O
this -X- _ O
task -X- _ O
requires -X- _ O
a -X- _ O
model -X- _ O
to -X- _ O
reason -X- _ O
over -X- _ O
multiple -X- _ O
hops -X- _ O
of -X- _ O
the -X- _ O
remaining -X- _ O
N -X- _ O
− -X- _ O
m -X- _ O
relevant -X- _ O
passages -X- _ O
. -X- _ O
In -X- _ O
addition -X- _ O
to -X- _ O
predicting -X- _ O
the -X- _ O
final -X- _ O
answer -X- _ O
a -X- _ O
, -X- _ O
we -X- _ O
also -X- _ O
aim -X- _ O
to -X- _ O
train -X- _ O
a -X- _ O
model -X- _ O
to -X- _ O
predict -X- _ O
a -X- _ O
reasoning -X- _ O
path -X- _ O
R -X- _ O
of -X- _ O
important -X- _ O
elements -X- _ O
( -X- _ O
e.g. -X- _ O
, -X- _ O
relevant -X- _ O
passage -X- _ O
titles -X- _ O
, -X- _ O
supporting -X- _ O
facts -X- _ O
in -X- _ O
a -X- _ O
passage -X- _ O
) -X- _ O
that -X- _ O
lead -X- _ O
to -X- _ O
the -X- _ O
final -X- _ O
answer -X- _ O
. -X- _ O

Multi -X- _ B-TaskName
- -X- _ I-TaskName
hop -X- _ I-TaskName
QA -X- _ I-TaskName
as -X- _ O
Single -X- _ O
Sequence -X- _ O
Generation -X- _ O
: -X- _ O
Recent -X- _ O
generative -X- _ O
question -X- _ O
answering -X- _ O
( -X- _ O
QA -X- _ O
) -X- _ O
approaches -X- _ O
( -X- _ O
e.g. -X- _ O
, -X- _ O
FID -X- _ O
( -X- _ O
Izacard -X- _ O
and -X- _ O
Grave -X- _ O
, -X- _ O
2021 -X- _ O
) -X- _ O
, -X- _ O
PATH -X- _ O
- -X- _ O
FID -X- _ O
( -X- _ O
Yavuz -X- _ O
et -X- _ O
al -X- _ O
. -X- _ O
, -X- _ O
2022 -X- _ O
) -X- _ O
) -X- _ O
utilize -X- _ O
an -X- _ O
encoderdecoder -X- _ O
model -X- _ O
as -X- _ O
the -X- _ O
backbone -X- _ O
to -X- _ O
generate -X- _ O
answers -X- _ O
in -X- _ O
a -X- _ O
single -X- _ O
text -X- _ O
sequence -X- _ O
. -X- _ O
In -X- _ O
particular -X- _ O
, -X- _ O
FID -X- _ O
is -X- _ O
one -X- _ O
of -X- _ O
the -X- _ O
popular -X- _ O
formulations -X- _ O
. -X- _ O
Specifically -X- _ O
, -X- _ O
for -X- _ O
each -X- _ O
passage -X- _ O
p -X- _ O
i -X- _ O
= -X- _ O
( -X- _ O
t -X- _ O
i -X- _ O
, -X- _ O
c -X- _ O
i -X- _ O
) -X- _ O
∈ -X- _ O
P -X- _ O
q -X- _ O
of -X- _ O
a -X- _ O
question -X- _ O
q -X- _ O
, -X- _ O
FID -X- _ O
encodes -X- _ O
a -X- _ O
combined -X- _ O
sequence -X- _ O
of -X- _ O
the -X- _ O
question -X- _ O
, -X- _ O
the -X- _ O
passage -X- _ O
title -X- _ O
and -X- _ O
contents -X- _ O
into -X- _ O
an -X- _ O
embedding -X- _ O
. -X- _ O
These -X- _ O
embeddings -X- _ O
for -X- _ O
all -X- _ O
passages -X- _ O
are -X- _ O
concatenated -X- _ O
as -X- _ O
inputs -X- _ O
to -X- _ O
the -X- _ O
decoder -X- _ O
for -X- _ O
generating -X- _ O
the -X- _ O
final -X- _ O
answer -X- _ O
. -X- _ O
PATH -X- _ O
- -X- _ O
FID -X- _ O
builds -X- _ O
upon -X- _ O
this -X- _ O
by -X- _ O
explicitly -X- _ O
modeling -X- _ O
a -X- _ O
reasoning -X- _ O
path -X- _ O
as -X- _ O
part -X- _ O
of -X- _ O
the -X- _ O
generation -X- _ O
output -X- _ O
in -X- _ O
addition -X- _ O
to -X- _ O
the -X- _ O
answer -X- _ O
. -X- _ O
Specifically -X- _ O
, -X- _ O
special -X- _ O
index -X- _ O
tokens -X- _ O
[ -X- _ O
f -X- _ O
i -X- _ O
] -X- _ O
are -X- _ O
added -X- _ O
to -X- _ O
demarcate -X- _ O
all -X- _ O
sentences -X- _ O
in -X- _ O
each -X- _ O
passage -X- _ O
context -X- _ O
. -X- _ O
The -X- _ O
sentences -X- _ O
supporting -X- _ O
the -X- _ O
prediction -X- _ O
of -X- _ O
a -X- _ O
final -X- _ O
answer -X- _ O
are -X- _ O
considered -X- _ O
facts -X- _ O
. -X- _ O
The -X- _ O
decoder -X- _ O
is -X- _ O
then -X- _ O
trained -X- _ O
to -X- _ O
generate -X- _ O
the -X- _ O
reasoning -X- _ O
path -X- _ O
R -X- _ O
as -X- _ O
a -X- _ O
linearized -X- _ O
sequence -X- _ O
consisting -X- _ O
of -X- _ O
the -X- _ O
passage -X- _ O
titles -X- _ O
and -X- _ O
the -X- _ O
index -X- _ O
tokens -X- _ O
of -X- _ O
facts -X- _ O
used -X- _ O
within -X- _ O
those -X- _ O
passages -X- _ O
to -X- _ O
obtain -X- _ O
the -X- _ O
final -X- _ O
answer -X- _ O
. -X- _ O
Figure -X- _ O
1 -X- _ O
shows -X- _ O
an -X- _ O
example -X- _ O
of -X- _ O
a -X- _ O
reasoning -X- _ O
path -X- _ O
. -X- _ O

Disconnected -X- _ O
Reasoning -X- _ O
in -X- _ O
PATH -X- _ O
- -X- _ O
FID -X- _ O
: -X- _ O
Since -X- _ O
the -X- _ O
model -X- _ O
predictions -X- _ O
now -X- _ O
include -X- _ O
the -X- _ O
reasoning -X- _ O
path -X- _ O
, -X- _ O
we -X- _ O
can -X- _ O
analyze -X- _ O
which -X- _ O
facts -X- _ O
in -X- _ O
the -X- _ O
passage -X- _ O
are -X- _ O
utilized -X- _ O
by -X- _ O
the -X- _ O
model -X- _ O
to -X- _ O
determine -X- _ O
the -X- _ O
next -X- _ O
passage -X- _ O
to -X- _ O
hop -X- _ O
to -X- _ O
and -X- _ O
arrive -X- _ O
at -X- _ O
the -X- _ O
final -X- _ O
answer -X- _ O
. -X- _ O
For -X- _ O
a -X- _ O
perfectly -X- _ O
faithful -X- _ O
model -X- _ O
, -X- _ O
all -X- _ O
predictions -X- _ O
with -X- _ O
correct -X- _ O
answers -X- _ O
should -X- _ O
have -X- _ O
correctly -X- _ O
identified -X- _ O
passages -X- _ O
and -X- _ O
facts -X- _ O
. -X- _ O
However -X- _ O
, -X- _ O
due -X- _ O
to -X- _ O
the -X- _ O
presence -X- _ O
of -X- _ O
shortcuts -X- _ O
in -X- _ O
the -X- _ O
datasets -X- _ O
as -X- _ O
well -X- _ O
as -X- _ O
the -X- _ O
model -X- _ O
's -X- _ O
predicted -X- _ O
reasoning -X- _ O
path -X- _ O
not -X- _ O
being -X- _ O
faithful -X- _ O
, -X- _ O
we -X- _ O
observe -X- _ O
model -X- _ O
predictions -X- _ O
containing -X- _ O
correct -X- _ O
final -X- _ O
answers -X- _ O
but -X- _ O
incorrect -X- _ O
identification -X- _ O
of -X- _ O
passage -X- _ O
titles -X- _ O
or -X- _ O
facts -X- _ O
. -X- _ O
This -X- _ O
unfaithful -X- _ O
prediction -X- _ O
issue -X- _ O
is -X- _ O
referred -X- _ O
to -X- _ O
as -X- _ O
disconnected -X- _ O
reasoning -X- _ O
( -X- _ O
Trivedi -X- _ O
et -X- _ O
al -X- _ O
. -X- _ O
, -X- _ O
2020 -X- _ O
) -X- _ O
. -X- _ O
Different -X- _ O
from -X- _ O
PATH -X- _ O
- -X- _ O
FID -X- _ O
, -X- _ O
we -X- _ O
use -X- _ O
the -X- _ O
presence -X- _ O
of -X- _ O
a -X- _ O
local -X- _ O
graph -X- _ O
structure -X- _ O
between -X- _ O
different -X- _ O
passages -X- _ O
in -X- _ O
the -X- _ O
context -X- _ O
to -X- _ O
bias -X- _ O
the -X- _ O
representations -X- _ O
of -X- _ O
the -X- _ O
model -X- _ O
and -X- _ O
help -X- _ O
alleviate -X- _ O
this -X- _ O
problem -X- _ O
. -X- _ O

In -X- _ O
this -X- _ O
section -X- _ O
, -X- _ O
we -X- _ O
describe -X- _ O
our -X- _ O
proposed -X- _ O
method -X- _ O
for -X- _ O
solving -X- _ O
disconnected -X- _ O
reasoning -X- _ O
for -X- _ O
multi -X- _ B-TaskName
- -X- _ I-TaskName
hop -X- _ I-TaskName
QA -X- _ I-TaskName
in -X- _ O
the -X- _ O
distractor -X- _ O
setting -X- _ O
. -X- _ O

Overview -X- _ O
: -X- _ O
Our -X- _ O
method -X- _ O
first -X- _ O
constructs -X- _ O
a -X- _ O
local -X- _ O
graph -X- _ O
over -X- _ O
passage -X- _ O
contexts -X- _ O
for -X- _ O
each -X- _ O
question -X- _ O
( -X- _ O
§ -X- _ O
3.1 -X- _ O
) -X- _ O
, -X- _ O
and -X- _ O
integrates -X- _ O
the -X- _ O
graph -X- _ O
information -X- _ O
with -X- _ O
the -X- _ O
key -X- _ O
entities -X- _ O
to -X- _ O
improve -X- _ O
the -X- _ O
generation -X- _ O
of -X- _ O
reasoning -X- _ O
paths -X- _ O
( -X- _ O
§ -X- _ O
3.2 -X- _ O
) -X- _ O
. -X- _ O
Different -X- _ O
from -X- _ O
prior -X- _ O
works -X- _ O
that -X- _ O
encode -X- _ O
all -X- _ O
the -X- _ O
passages -X- _ O
independently -X- _ O
, -X- _ O
we -X- _ O
connect -X- _ O
the -X- _ O
passages -X- _ O
through -X- _ O
the -X- _ O
key -X- _ O
pivot -X- _ O
entities -X- _ O
into -X- _ O
a -X- _ O
local -X- _ O
graph -X- _ O
for -X- _ O
a -X- _ O
question -X- _ O
, -X- _ O
which -X- _ O
allows -X- _ O
us -X- _ O
to -X- _ O
encode -X- _ O
structural -X- _ O
representations -X- _ O
across -X- _ O
passages -X- _ O
by -X- _ O
a -X- _ O
graph -X- _ O
neural -X- _ O
network -X- _ O
. -X- _ O
These -X- _ O
graph -X- _ O
structured -X- _ O
representations -X- _ O
are -X- _ O
then -X- _ O
fused -X- _ O
with -X- _ O
the -X- _ O
contextualized -X- _ O
text -X- _ O
representations -X- _ O
from -X- _ O
a -X- _ O
text -X- _ O
encoder -X- _ O
, -X- _ O
guiding -X- _ O
the -X- _ O
model -X- _ O
to -X- _ O
leverage -X- _ O
structural -X- _ O
information -X- _ O
to -X- _ O
alleviate -X- _ O
disconnected -X- _ O
reasoning -X- _ O
over -X- _ O
passages -X- _ O
. -X- _ O

In -X- _ O
contrast -X- _ O
to -X- _ O
the -X- _ O
full -X- _ O
- -X- _ O
wiki -X- _ O
setting -X- _ O
where -X- _ O
a -X- _ O
model -X- _ O
must -X- _ O
retrieve -X- _ O
relevant -X- _ O
passages -X- _ O
from -X- _ O
Wikipedia -X- _ O
or -X- _ O
a -X- _ O
large -X- _ O
corpus -X- _ O
, -X- _ O
the -X- _ O
distractor -X- _ O
setting -X- _ O
provides -X- _ O
the -X- _ O
model -X- _ O
with -X- _ O
a -X- _ O
list -X- _ O
of -X- _ O
N -X- _ O
passages -X- _ O
P -X- _ O
q -X- _ O
consisting -X- _ O
of -X- _ O
N -X- _ O
− -X- _ O
m -X- _ O
relevant -X- _ O
passages -X- _ O
and -X- _ O
m -X- _ O
distractors -X- _ O
for -X- _ O
each -X- _ O
question -X- _ O
q. -X- _ O
Conventionally -X- _ O
, -X- _ O
these -X- _ O
passages -X- _ O
are -X- _ O
collected -X- _ O
from -X- _ O
Wikipedia -X- _ O
, -X- _ O
as -X- _ O
Wikipedia -X- _ O
remains -X- _ O
one -X- _ O
of -X- _ O
the -X- _ O
largest -X- _ O
faithful -X- _ O
knowledge -X- _ O
sources -X- _ O
available -X- _ O
for -X- _ O
public -X- _ O
usage -X- _ O
. -X- _ O
Even -X- _ O
for -X- _ O
text -X- _ O
passages -X- _ O
out -X- _ O
of -X- _ O
Wikipedia -X- _ O
, -X- _ O
there -X- _ O
are -X- _ O
existing -X- _ O
out -X- _ O
- -X- _ O
of -X- _ O
- -X- _ O
box -X- _ O
entity -X- _ O
linkers -X- _ O
( -X- _ O
e.g. -X- _ O
, -X- _ O
SLING -X- _ O
( -X- _ O
Ringgaard -X- _ O
et -X- _ O
al -X- _ O
. -X- _ O
, -X- _ O
2017 -X- _ O
) -X- _ O
, -X- _ O
BLINK -X- _ O
) -X- _ O
that -X- _ O
can -X- _ O
identify -X- _ O
key -X- _ O
entities -X- _ O
from -X- _ O
texts -X- _ O
and -X- _ O
link -X- _ O
them -X- _ O
to -X- _ O
their -X- _ O
Wikipedia -X- _ O
pages -X- _ O
. -X- _ O
As -X- _ O
a -X- _ O
result -X- _ O
, -X- _ O
each -X- _ O
provided -X- _ O
passage -X- _ O
may -X- _ O
contain -X- _ O
pivot -X- _ O
entities -X- _ O
with -X- _ O
hyperlinks -X- _ O
connecting -X- _ O
to -X- _ O
their -X- _ O
corresponding -X- _ O
Wikipedia -X- _ O
pages -X- _ O
. -X- _ O
We -X- _ O
exploit -X- _ O
such -X- _ O
entity -X- _ O
hyperlinks -X- _ O
to -X- _ O
construct -X- _ O
a -X- _ O
local -X- _ O
directed -X- _ O
graph -X- _ O
G -X- _ O
= -X- _ O
( -X- _ O
N -X- _ O
, -X- _ O
L -X- _ O
) -X- _ O
containing -X- _ O
two -X- _ O
types -X- _ O
of -X- _ O
nodes -X- _ O
( -X- _ O
i.e. -X- _ O
, -X- _ O
entities -X- _ O
and -X- _ O
passage -X- _ O
titles -X- _ O
) -X- _ O
and -X- _ O
links -X- _ O
between -X- _ O
these -X- _ O
nodes -X- _ O
. -X- _ O
Specifically -X- _ O
, -X- _ O
for -X- _ O
each -X- _ O
pivot -X- _ O
entity -X- _ O
e -X- _ O
in -X- _ O
a -X- _ O
passage -X- _ O
p -X- _ O
i -X- _ O
, -X- _ O
we -X- _ O
create -X- _ O
a -X- _ O
link -X- _ O
from -X- _ O
e -X- _ O
to -X- _ O
the -X- _ O
title -X- _ O
t -X- _ O
j -X- _ O
of -X- _ O
another -X- _ O
passage -X- _ O
p -X- _ O
j -X- _ O
( -X- _ O
denoted -X- _ O
as -X- _ O
l -X- _ O
e→t -X- _ O
j -X- _ O
) -X- _ O
whenever -X- _ O
the -X- _ O
entity -X- _ O
span -X- _ O
e -X- _ O
points -X- _ O
to -X- _ O
a -X- _ O
Wikipedia -X- _ O
article -X- _ O
that -X- _ O
contains -X- _ O
the -X- _ O
passage -X- _ O
p -X- _ O
j -X- _ O
. -X- _ O

For -X- _ O
example -X- _ O
, -X- _ O
an -X- _ O
entity -X- _ O
span -X- _ O
" -X- _ O
David -X- _ O
Noughton -X- _ O
" -X- _ O
appears -X- _ O
in -X- _ O
the -X- _ O
passage -X- _ O
context -X- _ O
: -X- _ O
" -X- _ O
An -X- _ O
American -X- _ O
Werewolf -X- _ O
in -X- _ O
London -X- _ O
is -X- _ O
a -X- _ O
1981 -X- _ O
horror -X- _ O
comedy -X- _ O
film -X- _ O
starring -X- _ O
David -X- _ O
Noughton -X- _ O
, -X- _ O
Jenny -X- _ O
Agutter -X- _ O
. -X- _ O
... -X- _ O
" -X- _ O
This -X- _ O
entity -X- _ O
would -X- _ O
be -X- _ O
connected -X- _ O
to -X- _ O
a -X- _ O
passage -X- _ O
with -X- _ O
the -X- _ O
title -X- _ O
of -X- _ O
" -X- _ O
David -X- _ O
Walsh -X- _ O
Noughton -X- _ O
" -X- _ O
, -X- _ O
forming -X- _ O
the -X- _ O
link -X- _ O
( -X- _ O
David -X- _ O
Noughton -X- _ O
[ -X- _ O
Entity -X- _ O
] -X- _ O
→ -X- _ O
David -X- _ O
Walsh -X- _ O
Noughton -X- _ O
[ -X- _ O
Passage -X- _ O
] -X- _ O
) -X- _ O
. -X- _ O
If -X- _ O
there -X- _ O
are -X- _ O
multiple -X- _ O
passages -X- _ O
with -X- _ O
the -X- _ O
title -X- _ O
" -X- _ O
David -X- _ O
Walsh -X- _ O
Noughton -X- _ O
" -X- _ O
among -X- _ O
the -X- _ O
N -X- _ O
passages -X- _ O
, -X- _ O
the -X- _ O
entity -X- _ O
span -X- _ O
would -X- _ O
be -X- _ O
connected -X- _ O
to -X- _ O
all -X- _ O
of -X- _ O
them -X- _ O
with -X- _ O
distinct -X- _ O
links -X- _ O
. -X- _ O
Figure -X- _ O
1 -X- _ O
shows -X- _ O
an -X- _ O
example -X- _ O
of -X- _ O
an -X- _ O
entity -X- _ O
- -X- _ O
passage -X- _ O
graph -X- _ O
. -X- _ O

We -X- _ O
utilize -X- _ O
the -X- _ O
same -X- _ O
model -X- _ O
as -X- _ O
PATH -X- _ O
- -X- _ O
FID -X- _ O
with -X- _ O
a -X- _ O
pre -X- _ O
- -X- _ O
trained -X- _ O
T5 -X- _ O
model -X- _ O
as -X- _ O
our -X- _ O
backbone -X- _ O
architecture -X- _ O
. -X- _ O
The -X- _ O
input -X- _ O
for -X- _ O
this -X- _ O
method -X- _ O
consists -X- _ O
of -X- _ O
the -X- _ O
N -X- _ O
sequences -X- _ O
, -X- _ O
where -X- _ O
each -X- _ O
sequence -X- _ O
is -X- _ O
a -X- _ O
concatenation -X- _ O
of -X- _ O
the -X- _ O
question -X- _ O
q -X- _ O
, -X- _ O
the -X- _ O
title -X- _ O
and -X- _ O
contents -X- _ O
of -X- _ O
a -X- _ O
passage -X- _ O
p -X- _ O
i -X- _ O
from -X- _ O
the -X- _ O
collection -X- _ O
p -X- _ O
i -X- _ O
∈ -X- _ O
P -X- _ O
q -X- _ O
together -X- _ O
with -X- _ O
their -X- _ O
indicator -X- _ O
tokens -X- _ O
, -X- _ O
denoted -X- _ O
as -X- _ O
S -X- _ O
i -X- _ O
below -X- _ O
: -X- _ O

We -X- _ O
utilize -X- _ O
these -X- _ O
shallow -X- _ O
representations -X- _ O
to -X- _ O
initialize -X- _ O
the -X- _ O
node -X- _ O
embeddings -X- _ O
for -X- _ O
a -X- _ O
graph -X- _ O
neural -X- _ O
network -X- _ O
. -X- _ O
Specifically -X- _ O
, -X- _ O
we -X- _ O
extract -X- _ O
the -X- _ O
representations -X- _ O
of -X- _ O
the -X- _ O
entity -X- _ O
spans -X- _ O
or -X- _ O
passage -X- _ O
title -X- _ O
spans -X- _ O
( -X- _ O
i.e. -X- _ O
, -X- _ O
nodes -X- _ O
in -X- _ O
the -X- _ O
graph -X- _ O
G -X- _ O
) -X- _ O
from -X- _ O
Z -X- _ O
L -X- _ O
i -X- _ O
according -X- _ O
to -X- _ O
their -X- _ O
span -X- _ O
positions -X- _ O
[ -X- _ O
a -X- _ O
, -X- _ O
b -X- _ O
] -X- _ O
in -X- _ O
S -X- _ O
i -X- _ O
. -X- _ O
Next -X- _ O
, -X- _ O
for -X- _ O
a -X- _ O
text -X- _ O
span -X- _ O
S -X- _ O
i -X- _ O
, -X- _ O
a -X- _ O
: -X- _ O
b -X- _ O
representing -X- _ O
either -X- _ O
an -X- _ O
entity -X- _ O
or -X- _ O
a -X- _ O
title -X- _ O
in -X- _ O
S -X- _ O
i -X- _ O
, -X- _ O
we -X- _ O
average -X- _ O
the -X- _ O
extracted -X- _ O
representations -X- _ O
of -X- _ O
the -X- _ O
text -X- _ O
span -X- _ O
to -X- _ O
obtain -X- _ O
an -X- _ O
initial -X- _ O
node -X- _ O
embedding -X- _ O
, -X- _ O
i.e. -X- _ O
, -X- _ O
n -X- _ O
= -X- _ O
avg -X- _ O
( -X- _ O
Z -X- _ O
L -X- _ O
i -X- _ O
, -X- _ O
a -X- _ O
: -X- _ O
b -X- _ O
) -X- _ O
. -X- _ O
Finally -X- _ O
, -X- _ O
we -X- _ O
stack -X- _ O
the -X- _ O
initial -X- _ O
embeddings -X- _ O
for -X- _ O
all -X- _ O
nodes -X- _ O
denoted -X- _ O
as -X- _ O
N -X- _ O
and -X- _ O
apply -X- _ O
a -X- _ O
graph -X- _ O
neural -X- _ O
network -X- _ O
( -X- _ O
GNN -X- _ O
) -X- _ O
to -X- _ O
further -X- _ O
encode -X- _ O
the -X- _ O
structural -X- _ O
embeddings -X- _ O
on -X- _ O
the -X- _ O
graph -X- _ O
G -X- _ O
: -X- _ O

Finally -X- _ O
, -X- _ O
we -X- _ O
fuse -X- _ O
the -X- _ O
contextualized -X- _ O
text -X- _ O
representations -X- _ O
Z -X- _ O
L -X- _ O
i -X- _ O
from -X- _ O
the -X- _ O
text -X- _ O
encoder -X- _ O
and -X- _ O
the -X- _ O
structured -X- _ O
node -X- _ O
representations -X- _ O
Z -X- _ O
G -X- _ O
i -X- _ O
by -X- _ O
an -X- _ O
aggregation -X- _ O
operator -X- _ O
⊕ -X- _ O
, -X- _ O
and -X- _ O
pass -X- _ O
them -X- _ O
to -X- _ O
the -X- _ O
remaining -X- _ O
layers -X- _ O
of -X- _ O
the -X- _ O
text -X- _ O
encoder -X- _ O
to -X- _ O
obtained -X- _ O
the -X- _ O
fused -X- _ O
representations -X- _ O
S -X- _ O
i -X- _ O
for -X- _ O
each -X- _ O
input -X- _ O
sequence -X- _ O
S -X- _ O
i -X- _ O
: -X- _ O

Subsequently -X- _ O
, -X- _ O
S -X- _ O
is -X- _ O
passed -X- _ O
as -X- _ O
inputs -X- _ O
to -X- _ O
the -X- _ O
T5 -X- _ O
decoder -X- _ O
that -X- _ O
estimates -X- _ O
the -X- _ O
conditional -X- _ O
probability -X- _ O
P -X- _ O
θ -X- _ O
( -X- _ O
R|S -X- _ O
) -X- _ O
of -X- _ O
predicting -X- _ O
a -X- _ O
reasoning -X- _ O
path -X- _ O
R. -X- _ O
Depending -X- _ O
on -X- _ O
the -X- _ O
annotations -X- _ O
in -X- _ O
different -X- _ O
datasets -X- _ O
, -X- _ O
a -X- _ O
reasoning -X- _ O
path -X- _ O
R -X- _ O
can -X- _ O
take -X- _ O
various -X- _ O
formats -X- _ O
. -X- _ O
For -X- _ O
example -X- _ O
, -X- _ O
the -X- _ O
reasoning -X- _ O
path -X- _ O
takes -X- _ O
the -X- _ O
form -X- _ O
" -X- _ O
R -X- _ O
: -X- _ O
= -X- _ O
[ -X- _ O
title -X- _ O
] -X- _ O
t -X- _ O
i -X- _ O
[ -X- _ O
facts -X- _ O
] -X- _ O
f -X- _ O
i -X- _ O
[ -X- _ O
answer -X- _ O
] -X- _ O
a -X- _ O
" -X- _ O
for -X- _ O
HOTPOT -X- _ O
- -X- _ O
QA -X- _ O
and -X- _ O
" -X- _ O
R -X- _ O
: -X- _ O
= -X- _ O
[ -X- _ O
title -X- _ O
] -X- _ O
t -X- _ O
i -X- _ O
[ -X- _ O
intermediate_answer -X- _ O
] -X- _ O
ans -X- _ O
i -X- _ O
[ -X- _ O
answer -X- _ O
] -X- _ O
a -X- _ O
" -X- _ O
for -X- _ O
MUSIQUE -X- _ B-DatasetName
. -X- _ O
We -X- _ O
also -X- _ O
investigate -X- _ O
variants -X- _ O
of -X- _ O
reasoning -X- _ O
paths -X- _ O
for -X- _ O
MUSIQUE -X- _ B-DatasetName
in -X- _ O
our -X- _ O
experiments -X- _ O
. -X- _ O
As -X- _ O
we -X- _ O
can -X- _ O
construct -X- _ O
ground -X- _ O
- -X- _ O
truth -X- _ O
reasoning -X- _ O
paths -X- _ O
R -X- _ O
* -X- _ O
during -X- _ O
training -X- _ O
, -X- _ O
the -X- _ O
model -X- _ O
is -X- _ O
optimized -X- _ O
using -X- _ O
a -X- _ O
cross -X- _ O
- -X- _ O
entropy -X- _ O
loss -X- _ O
between -X- _ O
the -X- _ O
conditional -X- _ O
probability -X- _ O
P -X- _ O
θ -X- _ O
( -X- _ O
R|S -X- _ O
) -X- _ O
and -X- _ O
R -X- _ O
* -X- _ O
. -X- _ O

In -X- _ O
this -X- _ O
section -X- _ O
, -X- _ O
we -X- _ O
elaborate -X- _ O
on -X- _ O
the -X- _ O
datasets -X- _ O
, -X- _ O
the -X- _ O
baseline -X- _ O
models -X- _ O
and -X- _ O
the -X- _ O
variants -X- _ O
of -X- _ O
SEQGRAPH -X- _ B-MethodName
we -X- _ O
consider -X- _ O
for -X- _ O
our -X- _ O
experiment -X- _ O
settings -X- _ O
. -X- _ O
We -X- _ O
consider -X- _ O
two -X- _ O
multi -X- _ B-TaskName
- -X- _ I-TaskName
hop -X- _ I-TaskName
QA -X- _ I-TaskName
datasets -X- _ O
, -X- _ O
HOTPOT -X- _ B-DatasetName
- -X- _ I-DatasetName
QA -X- _ I-DatasetName
and -X- _ O
MUSIQUE -X- _ B-DatasetName
. -X- _ O
Since -X- _ O
SEQGRAPH -X- _ B-MethodName
is -X- _ O
primarily -X- _ O
focused -X- _ O
only -X- _ O
on -X- _ O
improving -X- _ O
the -X- _ O
efficacy -X- _ O
of -X- _ O
encoding -X- _ O
, -X- _ O
we -X- _ O
consider -X- _ O
only -X- _ O
the -X- _ O
distractor -X- _ O
setting -X- _ O
for -X- _ O
both -X- _ O
datasets -X- _ O
. -X- _ O
Table -X- _ O
4 -X- _ O
shows -X- _ O
the -X- _ O
standard -X- _ O
train -X- _ O
/ -X- _ O
dev -X- _ O
/ -X- _ O
test -X- _ O
statistics -X- _ O
. -X- _ O

HOTPOT -X- _ B-DatasetName
- -X- _ I-DatasetName
QA -X- _ I-DatasetName
: -X- _ O
The -X- _ O
final -X- _ O
answer -X- _ O
to -X- _ O
each -X- _ O
question -X- _ O
in -X- _ O
the -X- _ O
distractor -X- _ O
setting -X- _ O
is -X- _ O
extracted -X- _ O
from -X- _ O
10 -X- _ O
passages -X- _ O
. -X- _ O
The -X- _ O
dataset -X- _ O
includes -X- _ O
two -X- _ O
main -X- _ O
types -X- _ O
of -X- _ O
questions -X- _ O
: -X- _ O
bridge -X- _ O
( -X- _ O
80 -X- _ O
% -X- _ O
) -X- _ O
and -X- _ O
comparison -X- _ O
( -X- _ O
20 -X- _ O
% -X- _ O
) -X- _ O
. -X- _ O
Bridge -X- _ O
questions -X- _ O
often -X- _ O
require -X- _ O
identifying -X- _ O
a -X- _ O
bridge -X- _ O
entity -X- _ O
in -X- _ O
the -X- _ O
first -X- _ O
passage -X- _ O
to -X- _ O
correctly -X- _ O
hop -X- _ O
to -X- _ O
the -X- _ O
second -X- _ O
passage -X- _ O
that -X- _ O
contains -X- _ O
the -X- _ O
answer -X- _ O
, -X- _ O
while -X- _ O
comparison -X- _ O
questions -X- _ O
do -X- _ O
not -X- _ O
have -X- _ O
this -X- _ O
requirement -X- _ O
. -X- _ O
Each -X- _ O
question -X- _ O
is -X- _ O
also -X- _ O
provided -X- _ O
with -X- _ O
annotations -X- _ O
of -X- _ O
2 -X- _ O
supporting -X- _ O
passages -X- _ O
( -X- _ O
2 -X- _ O
- -X- _ O
hop -X- _ O
) -X- _ O
and -X- _ O
up -X- _ O
to -X- _ O
5 -X- _ O
corresponding -X- _ O
relevant -X- _ O
sentences -X- _ O
as -X- _ O
their -X- _ O
supporting -X- _ O
facts -X- _ O
. -X- _ O

MUSIQUE -X- _ B-DatasetName
: -X- _ O
MUSIQUE -X- _ B-DatasetName
has -X- _ O
questions -X- _ O
that -X- _ O
range -X- _ O
in -X- _ O
difficulty -X- _ O
from -X- _ O
2 -X- _ O
to -X- _ O
4 -X- _ O
- -X- _ O
hops -X- _ O
and -X- _ O
six -X- _ O
types -X- _ O
of -X- _ O
reasoning -X- _ O
chains -X- _ O
. -X- _ O
MUSIQUE -X- _ B-DatasetName
uses -X- _ O
a -X- _ O
stringent -X- _ O
filtering -X- _ O
process -X- _ O
as -X- _ O
well -X- _ O
as -X- _ O
a -X- _ O
bottom -X- _ O
- -X- _ O
up -X- _ O
technique -X- _ O
to -X- _ O
iteratively -X- _ O
combine -X- _ O
single -X- _ O
- -X- _ O
hop -X- _ O
questions -X- _ O
from -X- _ O
several -X- _ O
datasets -X- _ O
into -X- _ O
a -X- _ O
k -X- _ O
- -X- _ O
hop -X- _ O
benchmark -X- _ O
that -X- _ O
is -X- _ O
more -X- _ O
difficult -X- _ O
than -X- _ O
each -X- _ O
individual -X- _ O
dataset -X- _ O
and -X- _ O
significantly -X- _ O
less -X- _ O
susceptible -X- _ O
to -X- _ O
the -X- _ O
disconnected -X- _ O
- -X- _ O
reasoning -X- _ O
problem -X- _ O
. -X- _ O
Unlike -X- _ O
HOTPOT -X- _ B-DatasetName
- -X- _ I-DatasetName
QA -X- _ I-DatasetName
, -X- _ O
MUSIQUE -X- _ B-DatasetName
does -X- _ O
not -X- _ O
provide -X- _ O
annotations -X- _ O
of -X- _ O
relevant -X- _ O
sentences -X- _ O
but -X- _ O
provides -X- _ O
supporting -X- _ O
passage -X- _ O
titles -X- _ O
, -X- _ O
question -X- _ O
decomposition -X- _ O
( -X- _ O
decomposition -X- _ O
of -X- _ O
a -X- _ O
multi -X- _ O
- -X- _ O
hop -X- _ O
question -X- _ O
into -X- _ O
simpler -X- _ O
1 -X- _ O
- -X- _ O
hop -X- _ O
sub -X- _ O
- -X- _ O
questions -X- _ O
) -X- _ O
and -X- _ O
also -X- _ O
intermediate -X- _ O
answers -X- _ O
to -X- _ O
the -X- _ O
decomposed -X- _ O
questions -X- _ O
. -X- _ O
Given -X- _ O
this -X- _ O
variety -X- _ O
, -X- _ O
we -X- _ O
use -X- _ O
the -X- _ O
following -X- _ O
reasoning -X- _ O
path -X- _ O
variants -X- _ O
to -X- _ O
train -X- _ O
the -X- _ O
model -X- _ O
to -X- _ O
generate -X- _ O
: -X- _ O
6 -X- _ O
shows -X- _ O
an -X- _ O
example -X- _ O
of -X- _ O
different -X- _ O
reasoning -X- _ O
paths -X- _ O
. -X- _ O
While -X- _ O
the -X- _ O
last -X- _ O
variant -X- _ O
( -X- _ O
predicting -X- _ O
every -X- _ O
decomposition -X- _ O
/ -X- _ O
intermediate -X- _ O
answer -X- _ O
or -X- _ O
support -X- _ O
title -X- _ O
) -X- _ O
is -X- _ O
more -X- _ O
interpretable -X- _ O
, -X- _ O
it -X- _ O
encounters -X- _ O
the -X- _ O
challenge -X- _ O
of -X- _ O
producing -X- _ O
a -X- _ O
long -X- _ O
sequence -X- _ O
. -X- _ O
SIA -X- _ O
is -X- _ O
our -X- _ O
bestperforming -X- _ O
reasoning -X- _ O
path -X- _ O
variant -X- _ O
which -X- _ O
is -X- _ O
used -X- _ O
for -X- _ O
all -X- _ O
of -X- _ O
our -X- _ O
results -X- _ O
and -X- _ O
analysis -X- _ O
. -X- _ O

Our -X- _ O
main -X- _ O
baselines -X- _ O
are -X- _ O
generative -X- _ O
approaches -X- _ O
to -X- _ O
multi -X- _ B-TaskName
- -X- _ I-TaskName
hop -X- _ I-TaskName
QA -X- _ I-TaskName
that -X- _ O
include -X- _ O
and -X- _ O
build -X- _ O
upon -X- _ O
the -X- _ O
FID -X- _ O
approach -X- _ O
. -X- _ O
For -X- _ O
all -X- _ O
of -X- _ O
the -X- _ O
models -X- _ O
, -X- _ O
we -X- _ O
use -X- _ O
the -X- _ O
pretrained -X- _ O
T5 -X- _ O
encoder -X- _ O
- -X- _ O
decoder -X- _ O
as -X- _ O
the -X- _ O
backbone -X- _ O
and -X- _ O
consider -X- _ O
two -X- _ O
sizes -X- _ O
- -X- _ O
base -X- _ O
and -X- _ O
large -X- _ O
variants -X- _ O
. -X- _ O

• -X- _ O
FID -X- _ B-MethodName
: -X- _ O
Model -X- _ O
generation -X- _ O
includes -X- _ O
only -X- _ O
the -X- _ O
final -X- _ O
answer -X- _ O
. -X- _ O

• -X- _ O
PATH -X- _ B-MethodName
- -X- _ I-MethodName
FID -X- _ I-MethodName
: -X- _ O
Model -X- _ O
generation -X- _ O
includes -X- _ O
the -X- _ O
reasoning -X- _ O
path -X- _ O
as -X- _ O
well -X- _ O
as -X- _ O
the -X- _ O
final -X- _ O
answer -X- _ O
. -X- _ O

• -X- _ O
SEQGRAPH -X- _ B-MethodName
: -X- _ O
Model -X- _ O
that -X- _ O
utilizes -X- _ O
a -X- _ O
fusion -X- _ O
of -X- _ O
representations -X- _ O
from -X- _ O
the -X- _ O
language -X- _ O
model -X- _ O
and -X- _ O
the -X- _ O
Graph -X- _ O
Neural -X- _ O
Network -X- _ O
. -X- _ O
Similar -X- _ O
to -X- _ O
PATH -X- _ B-MethodName
- -X- _ I-MethodName
FID -X- _ I-MethodName
, -X- _ O
we -X- _ O
train -X- _ O
the -X- _ O
model -X- _ O
to -X- _ O
generate -X- _ O
the -X- _ O
reasoning -X- _ O
path -X- _ O
in -X- _ O
addition -X- _ O
to -X- _ O
the -X- _ O
final -X- _ O
answer -X- _ O
. -X- _ O

For -X- _ O
both -X- _ O
HOTPOT -X- _ B-DatasetName
- -X- _ I-DatasetName
QA -X- _ I-DatasetName
and -X- _ O
MUSIQUE -X- _ B-DatasetName
, -X- _ O
we -X- _ O
use -X- _ O
the -X- _ O
standard -X- _ O
quantitative -X- _ O
metrics -X- _ O
of -X- _ O
exact -X- _ B-MetricName
- -X- _ I-MetricName
match -X- _ I-MetricName
and -X- _ O
F1 -X- _ B-MetricName
scores -X- _ O
to -X- _ O
evaluate -X- _ O
the -X- _ O
quality -X- _ O
of -X- _ O
predicted -X- _ O
answers -X- _ O
. -X- _ O
For -X- _ O
models -X- _ O
that -X- _ O
predict -X- _ O
the -X- _ O
reasoning -X- _ O
path -X- _ O
in -X- _ O
addition -X- _ O
to -X- _ O
the -X- _ O
final -X- _ O
answer -X- _ O
, -X- _ O
we -X- _ O
can -X- _ O
quantify -X- _ O
how -X- _ O
accurately -X- _ O
they -X- _ O
can -X- _ O
identify -X- _ O
the -X- _ O
supporting -X- _ O
facts -X- _ O
( -X- _ O
or -X- _ O
supporting -X- _ O
titles -X- _ O
for -X- _ O
MUSIQUE -X- _ B-DatasetName
) -X- _ O
using -X- _ O
the -X- _ O
Support -X- _ B-MetricName
- -X- _ I-MetricName
EM -X- _ I-MetricName
and -X- _ O
Support -X- _ B-MetricName
- -X- _ I-MetricName
F1 -X- _ I-MetricName
scores -X- _ O
Yang -X- _ O
et -X- _ O
al -X- _ O
. -X- _ O
( -X- _ O
2018 -X- _ O
) -X- _ O
. -X- _ O

To -X- _ O
quantify -X- _ O
the -X- _ O
level -X- _ O
of -X- _ O
disconnected -X- _ O
reasoning -X- _ O
, -X- _ O
we -X- _ O
compute -X- _ O
dire -X- _ O
F1 -X- _ B-MetricName
scores -X- _ O
on -X- _ O
the -X- _ O
answer -X- _ O
spans -X- _ O
( -X- _ O
Answer -X- _ O
) -X- _ O
, -X- _ O
supporting -X- _ O
paragraphs -X- _ O
( -X- _ O
Supp -X- _ O
p -X- _ O
) -X- _ O
, -X- _ O
supporting -X- _ O
sentences -X- _ O
( -X- _ O
Supp -X- _ O
s -X- _ O
) -X- _ O
, -X- _ O
joint -X- _ O
metrics -X- _ O
( -X- _ O
Ans+Supp -X- _ O
p -X- _ O
, -X- _ O
Ans+Supp -X- _ O
s -X- _ O
) -X- _ O
of -X- _ O
the -X- _ O
Dire -X- _ O
HOTPOT -X- _ B-DatasetName
- -X- _ I-DatasetName
QA -X- _ I-DatasetName
subset -X- _ O
. -X- _ O

We -X- _ O
train -X- _ O
all -X- _ O
models -X- _ O
using -X- _ O
an -X- _ O
effective -X- _ O
batch -X- _ B-HyperparameterName
size -X- _ I-HyperparameterName
of -X- _ O
64 -X- _ B-HyperparameterValue
. -X- _ O
We -X- _ O
use -X- _ O
an -X- _ O
initial -X- _ O
learning -X- _ B-HyperparameterName
rate -X- _ I-HyperparameterName
of -X- _ O
1e-4 -X- _ B-HyperparameterValue
, -X- _ O
a -X- _ O
linear -X- _ B-HyperparameterValue
rate -X- _ I-HyperparameterValue
scheduler -X- _ B-HyperparameterName
, -X- _ O
a -X- _ O
warmup -X- _ B-HyperparameterName
of -X- _ O
2,000 -X- _ B-HyperparameterValue
steps -X- _ O
( -X- _ O
1,000 -X- _ B-HyperparameterValue
steps -X- _ O
for -X- _ O
MUSIQUE -X- _ B-DatasetName
) -X- _ O
, -X- _ O
and -X- _ O
finetune -X- _ O
the -X- _ O
models -X- _ O
for -X- _ O
10 -X- _ B-HyperparameterValue
epochs -X- _ B-HyperparameterName
. -X- _ O
For -X- _ O
SEQGRAPH -X- _ B-MethodName
, -X- _ O
we -X- _ O
use -X- _ O
GAT -X- _ O
( -X- _ O
Veličković -X- _ O
et -X- _ O
al -X- _ O
. -X- _ O
, -X- _ O
2017 -X- _ O
) -X- _ O
for -X- _ O
our -X- _ O
GNN -X- _ O
layers -X- _ O
. -X- _ O
A -X- _ O
maximum -X- _ B-HyperparameterName
sequence -X- _ I-HyperparameterName
length -X- _ I-HyperparameterName
of -X- _ O
256 -X- _ B-HyperparameterValue
tokens -X- _ O
is -X- _ O
used -X- _ O
for -X- _ O
constructing -X- _ O
the -X- _ O
input -X- _ O
. -X- _ O
All -X- _ O
experiments -X- _ O
have -X- _ O
been -X- _ O
conducted -X- _ O
on -X- _ O
a -X- _ O
machine -X- _ O
with -X- _ O
either -X- _ O
4×40 -X- _ O
G -X- _ O
A100 -X- _ O
GPUs -X- _ O
or -X- _ O
4×80 -X- _ O
G -X- _ O
A100 -X- _ O
GPUs -X- _ O
. -X- _ O
A -X- _ O
detailed -X- _ O
list -X- _ O
of -X- _ O
hyperparameters -X- _ O
can -X- _ O
be -X- _ O
found -X- _ O
in -X- _ O
Appendix -X- _ O
E -X- _ O
. -X- _ O

In -X- _ O
this -X- _ O
section -X- _ O
, -X- _ O
we -X- _ O
present -X- _ O
the -X- _ O
main -X- _ O
results -X- _ O
of -X- _ O
the -X- _ O
baselines -X- _ O
and -X- _ O
our -X- _ O
proposed -X- _ O
approach -X- _ O
on -X- _ O
HOTPOT -X- _ B-DatasetName
- -X- _ I-DatasetName
QA -X- _ I-DatasetName
and -X- _ O
MUSIQUE -X- _ B-DatasetName
( -X- _ O
§ -X- _ O
5.1 -X- _ O
) -X- _ O
, -X- _ O
and -X- _ O
then -X- _ O
perform -X- _ O
finegrained -X- _ O
analysis -X- _ O
thereafter -X- _ O
. -X- _ O

The -X- _ O
quantitative -X- _ O
performance -X- _ O
of -X- _ O
the -X- _ O
models -X- _ O
in -X- _ O
terms -X- _ O
of -X- _ O
exact -X- _ B-MetricName
- -X- _ I-MetricName
match -X- _ I-MetricName
and -X- _ O
F1 -X- _ B-MetricName
scores -X- _ O
for -X- _ O
both -X- _ O
the -X- _ O
final -X- _ O
answer -X- _ O
and -X- _ O
the -X- _ O
predicted -X- _ O
supports -X- _ O
are -X- _ O
shown -X- _ O
in -X- _ O
Table -X- _ O
1 -X- _ O
. -X- _ O
We -X- _ O
find -X- _ O
that -X- _ O
across -X- _ O
both -X- _ O
model -X- _ O
sizes -X- _ O
( -X- _ O
BASE -X- _ O
and -X- _ O
LARGE -X- _ O
) -X- _ O
, -X- _ O
explicitly -X- _ O
predicting -X- _ O
the -X- _ O
reasoning -X- _ O
path -X- _ O
helps -X- _ O
PATH -X- _ B-MethodName
- -X- _ I-MethodName
FID -X- _ I-MethodName
in -X- _ O
improving -X- _ O
the -X- _ O
answer -X- _ O
EM -X- _ B-MetricName
and -X- _ O
F1 -X- _ B-MetricName
scores -X- _ O
over -X- _ O
the -X- _ O
vanilla -X- _ O
FID -X- _ B-MethodName
approach -X- _ O
. -X- _ O
By -X- _ O
biasing -X- _ O
the -X- _ O
model -X- _ O
with -X- _ O
graph -X- _ O
representations -X- _ O
, -X- _ O
SEQGRAPH -X- _ B-MethodName
outperforms -X- _ O
the -X- _ O
baselines -X- _ O
on -X- _ O
both -X- _ O
the -X- _ O
HOTPOT -X- _ B-DatasetName
- -X- _ I-DatasetName
QA -X- _ I-DatasetName
and -X- _ O
the -X- _ O
MUSIQUE -X- _ B-DatasetName
datasets -X- _ O
. -X- _ O
SEQGRAPH -X- _ B-MethodName
achieves -X- _ O
a -X- _ O
2 -X- _ B-MetricValue
- -X- _ O
point -X- _ O
improvement -X- _ O
in -X- _ O
both -X- _ O
answer -X- _ O
and -X- _ O
support -X- _ O
EM -X- _ B-MetricName
when -X- _ O
considering -X- _ O
the -X- _ O
base -X- _ O
variant -X- _ O
and -X- _ O
1.5 -X- _ B-MetricValue
point -X- _ O
improvement -X- _ O
for -X- _ O
the -X- _ O
large -X- _ O
variant -X- _ O
on -X- _ O
the -X- _ O
dev -X- _ O
set -X- _ O
of -X- _ O
HOTPOT -X- _ B-DatasetName
- -X- _ I-DatasetName
QA -X- _ I-DatasetName
. -X- _ O

On -X- _ O
the -X- _ O
more -X- _ O
challenging -X- _ O
MUSIQUE -X- _ B-DatasetName
dataset -X- _ O
, -X- _ O
we -X- _ O
observe -X- _ O
stronger -X- _ O
results -X- _ O
from -X- _ O
SEQGRAPH -X- _ B-MethodName
where -X- _ O
it -X- _ O
records -X- _ O
up -X- _ O
to -X- _ O
a -X- _ O
4 -X- _ B-MetricValue
- -X- _ O
point -X- _ O
improvement -X- _ O
in -X- _ O
both -X- _ O
answer -X- _ O
and -X- _ O
support -X- _ O
scores -X- _ O
across -X- _ O
both -X- _ O
model -X- _ O
sizes -X- _ O
on -X- _ O
the -X- _ O
dev -X- _ O
set -X- _ O
. -X- _ O
On -X- _ O
the -X- _ O
test -X- _ O
set -X- _ O
( -X- _ O
in -X- _ O
Table -X- _ O
8 -X- _ O
of -X- _ O
the -X- _ O
appendix -X- _ O
) -X- _ O
, -X- _ O
the -X- _ O
current -X- _ O
best -X- _ O
performing -X- _ O
approach -X- _ O
is -X- _ O
a -X- _ O
two -X- _ O
stage -X- _ O
ROBERTA -X- _ O
/ -X- _ O
LONGFORMER -X- _ O
- -X- _ O
Large -X- _ O
model -X- _ O
, -X- _ O
Select -X- _ O
- -X- _ O
Answer -X- _ O
, -X- _ O
where -X- _ O
the -X- _ O
passage -X- _ O
selection -X- _ O
/ -X- _ O
ranking -X- _ O
and -X- _ O
answer -X- _ O
generation -X- _ O
stage -X- _ O
is -X- _ O
optimized -X- _ O
separately -X- _ O
using -X- _ O
different -X- _ O
models -X- _ O
. -X- _ O
SEQ -X- _ B-MethodName
- -X- _ I-MethodName
GRAPH -X- _ I-MethodName
- -X- _ O
Large -X- _ O
achieves -X- _ O
state -X- _ O
- -X- _ O
of -X- _ O
- -X- _ O
the -X- _ O
- -X- _ O
art -X- _ O
numbers -X- _ O
on -X- _ O
Answer -X- _ O
- -X- _ O
F1 -X- _ B-MetricName
with -X- _ O
a -X- _ O
5 -X- _ B-MetricValue
- -X- _ O
point -X- _ O
improvement -X- _ O
over -X- _ O
the -X- _ O
Select -X- _ O
- -X- _ O
Answer -X- _ O
model -X- _ O
2 -X- _ O
even -X- _ O
though -X- _ O
it -X- _ O
is -X- _ O
a -X- _ O
single -X- _ O
stage -X- _ O
approach -X- _ O
. -X- _ O
When -X- _ O
comparing -X- _ O
with -X- _ O
the -X- _ O
top -X- _ O
score -X- _ O
in -X- _ O
the -X- _ O
end -X- _ O
- -X- _ O
to -X- _ O
- -X- _ O
end -X- _ O
( -X- _ O
E2E -X- _ O
) -X- _ O
category -X- _ O
which -X- _ O
all -X- _ O
of -X- _ O
our -X- _ O
models -X- _ O
belong -X- _ O
to -X- _ O
, -X- _ O
SEQGRAPH -X- _ B-MethodName
gets -X- _ O
a -X- _ O
massive -X- _ O
17 -X- _ B-MetricValue
- -X- _ O
point -X- _ O
improvement -X- _ O
in -X- _ O
answer -X- _ O
F1 -X- _ B-MetricName
and -X- _ O
a -X- _ O
9 -X- _ B-MetricValue
- -X- _ O
point -X- _ O
improvement -X- _ O
in -X- _ O
support -X- _ O
F1 -X- _ B-MetricName
establishing -X- _ O
the -X- _ O
efficacy -X- _ O
of -X- _ O
our -X- _ O
approach -X- _ O
. -X- _ O
It -X- _ O
should -X- _ O
also -X- _ O
be -X- _ O
noted -X- _ O
that -X- _ O
all -X- _ O
of -X- _ O
the -X- _ O
current -X- _ O
models -X- _ O
on -X- _ O
the -X- _ O
leaderboard -X- _ O
are -X- _ O
discriminative -X- _ O
approaches -X- _ O
with -X- _ O
an -X- _ O
encoder -X- _ O
- -X- _ O
only -X- _ O
model -X- _ O
2 -X- _ O
https -X- _ O
: -X- _ O
/ -X- _ O
/ -X- _ O
leaderboard.allenai.org -X- _ O
/ -X- _ O
musique_ans -X- _ O
/ -X- _ O
( -X- _ O
LONGFORMER -X- _ O
- -X- _ O
Large -X- _ O
) -X- _ O
encoding -X- _ O
a -X- _ O
very -X- _ O
long -X- _ O
context -X- _ B-HyperparameterName
length -X- _ I-HyperparameterName
of -X- _ O
4,096 -X- _ B-HyperparameterValue
, -X- _ O
while -X- _ O
all -X- _ O
of -X- _ O
our -X- _ O
models -X- _ O
are -X- _ O
generative -X- _ O
in -X- _ O
nature -X- _ O
with -X- _ O
a -X- _ O
much -X- _ O
smaller -X- _ O
context -X- _ B-HyperparameterName
length -X- _ I-HyperparameterName
of -X- _ O
256 -X- _ B-HyperparameterValue
. -X- _ O
MUSIQUE -X- _ B-DatasetName
is -X- _ O
also -X- _ O
designed -X- _ O
to -X- _ O
be -X- _ O
more -X- _ O
challenging -X- _ O
than -X- _ O
HOTPOT -X- _ B-DatasetName
- -X- _ I-DatasetName
QA -X- _ I-DatasetName
and -X- _ O
explicitly -X- _ O
tackles -X- _ O
the -X- _ O
issue -X- _ O
of -X- _ O
disconnected -X- _ O
reasoning -X- _ O
during -X- _ O
dataset -X- _ O
curation -X- _ O
, -X- _ O
making -X- _ O
it -X- _ O
harder -X- _ O
for -X- _ O
the -X- _ O
model -X- _ O
to -X- _ O
take -X- _ O
shortcuts -X- _ O
and -X- _ O
cheat -X- _ O
. -X- _ O
The -X- _ O
larger -X- _ O
performance -X- _ O
improvements -X- _ O
of -X- _ O
SEQGRAPH -X- _ B-MethodName
on -X- _ O
MUSIQUE -X- _ B-DatasetName
compared -X- _ O
to -X- _ O
HOTPOT -X- _ B-DatasetName
- -X- _ I-DatasetName
QA -X- _ I-DatasetName
showcases -X- _ O
the -X- _ O
advantage -X- _ O
of -X- _ O
our -X- _ O
proposed -X- _ O
approach -X- _ O
, -X- _ O
providing -X- _ O
promising -X- _ O
results -X- _ O
for -X- _ O
further -X- _ O
research -X- _ O
in -X- _ O
this -X- _ O
direction -X- _ O
to -X- _ O
mitigate -X- _ O
disconnected -X- _ O
reasoning -X- _ O
. -X- _ O

Predicted -X- _ O
Answer -X- _ O
in -X- _ O
Predicted -X- _ O
Titles -X- _ O
/ -X- _ O
Support -X- _ O
: -X- _ O
how -X- _ O
often -X- _ O
are -X- _ O
the -X- _ O
predicted -X- _ O
answers -X- _ O
found -X- _ O
in -X- _ O
one -X- _ O
of -X- _ O
the -X- _ O
predicted -X- _ O
passages -X- _ O
or -X- _ O
in -X- _ O
the -X- _ O
predicted -X- _ O
supporting -X- _ O
facts -X- _ O
3 -X- _ O
. -X- _ O

Gold -X- _ O
Answer -X- _ O
in -X- _ O
Predicted -X- _ O
Titles -X- _ O
/ -X- _ O
Support -X- _ O
: -X- _ O
how -X- _ O
often -X- _ O
are -X- _ O
the -X- _ O
gold -X- _ O
answers -X- _ O
found -X- _ O
in -X- _ O
one -X- _ O
of -X- _ O
the -X- _ O
predicted -X- _ O
passages -X- _ O
or -X- _ O
in -X- _ O
the -X- _ O
predicted -X- _ O
supporting -X- _ O
facts -X- _ O
. -X- _ O

Predicted -X- _ O
Answer -X- _ O
in -X- _ O
Gold -X- _ O
Titles -X- _ O
/ -X- _ O
Support -X- _ O
: -X- _ O
how -X- _ O
often -X- _ O
are -X- _ O
the -X- _ O
predicted -X- _ O
answers -X- _ O
found -X- _ O
in -X- _ O
one -X- _ O
of -X- _ O
the -X- _ O
gold -X- _ O
passages -X- _ O
or -X- _ O
in -X- _ O
the -X- _ O
gold -X- _ O
supporting -X- _ O
facts -X- _ O
. -X- _ O

Figure -X- _ O
3 -X- _ O
shows -X- _ O
the -X- _ O
described -X- _ O
faithfulness -X- _ O
metric -X- _ O
scores -X- _ O
on -X- _ O
HOTPOT -X- _ B-DatasetName
- -X- _ I-DatasetName
QA -X- _ I-DatasetName
. -X- _ O
We -X- _ O
find -X- _ O
that -X- _ O
SEQGRAPH -X- _ B-MethodName
is -X- _ O
more -X- _ O
faithful -X- _ O
with -X- _ O
a -X- _ O
0.5 -X- _ B-MetricValue
- -X- _ O
1.5 -X- _ B-MetricValue
% -X- _ I-MetricValue
improvement -X- _ O
over -X- _ O
PATH -X- _ B-MethodName
- -X- _ I-MethodName
FID -X- _ I-MethodName
across -X- _ O
all -X- _ O
considered -X- _ O
categories -X- _ O
. -X- _ O

We -X- _ O
break -X- _ O
down -X- _ O
the -X- _ O
final -X- _ O
answer -X- _ O
exact -X- _ B-MetricName
- -X- _ I-MetricName
match -X- _ I-MetricName
and -X- _ O
F1 -X- _ B-MetricName
scores -X- _ O
based -X- _ O
on -X- _ O
how -X- _ O
many -X- _ O
supporting -X- _ O
facts -X- _ O
( -X- _ O
or -X- _ O
titles -X- _ O
for -X- _ O
Musique -X- _ B-DatasetName
) -X- _ O
are -X- _ O
required -X- _ O
to -X- _ O
answer -X- _ O
the -X- _ O
question -X- _ O
. -X- _ O
Figure -X- _ O
5 -X- _ O
shows -X- _ O
this -X- _ O
performance -X- _ O
breakdown -X- _ O
for -X- _ O
HOTPOT -X- _ B-DatasetName
- -X- _ I-DatasetName
QA -X- _ I-DatasetName
and -X- _ O
Figure -X- _ O
6 -X- _ O
shows -X- _ O
it -X- _ O
for -X- _ O
MUSIQUE -X- _ B-DatasetName
. -X- _ O
We -X- _ O
observe -X- _ O
that -X- _ O
SEQGRAPH -X- _ B-MethodName
improves -X- _ O
over -X- _ O
PATH -X- _ B-MethodName
- -X- _ I-MethodName
FID -X- _ I-MethodName
in -X- _ O
the -X- _ O
cases -X- _ O
where -X- _ O
the -X- _ O
support -X- _ O
includes -X- _ O
two -X- _ O
or -X- _ O
three -X- _ O
supporting -X- _ O
facts -X- _ O
( -X- _ O
or -X- _ O
titles -X- _ O
) -X- _ O
, -X- _ O
but -X- _ O
the -X- _ O
answer -X- _ O
EM -X- _ B-MetricName
takes -X- _ O
a -X- _ O
hit -X- _ O
when -X- _ O
the -X- _ O
number -X- _ O
of -X- _ O
supporting -X- _ O
facts -X- _ O
( -X- _ O
titles -X- _ O
) -X- _ O
≥ -X- _ O
4 -X- _ O
. -X- _ O
We -X- _ O
notice -X- _ O
that -X- _ O
SEQGRAPH -X- _ B-MethodName
has -X- _ O
a -X- _ O
higher -X- _ O
support -X- _ O
EM -X- _ B-MetricName
over -X- _ O
PATH -X- _ B-MethodName
- -X- _ I-MethodName
FID -X- _ I-MethodName
in -X- _ O
such -X- _ O
cases -X- _ O
where -X- _ O
shortcuts -X- _ O
may -X- _ O
exist -X- _ O
in -X- _ O
the -X- _ O
dataset -X- _ O
and -X- _ O
PATH -X- _ B-MethodName
- -X- _ I-MethodName
FID -X- _ I-MethodName
relies -X- _ O
on -X- _ O
those -X- _ O
shortcuts -X- _ O
to -X- _ O
get -X- _ O
a -X- _ O
higher -X- _ O
answer -X- _ O
EM -X- _ B-MetricName
but -X- _ O
a -X- _ O
lower -X- _ O
support -X- _ O
EM -X- _ B-MetricName
. -X- _ O
Section -X- _ O
§ -X- _ O
5.4 -X- _ O
quantifies -X- _ O
the -X- _ O
extent -X- _ O
to -X- _ O
which -X- _ O
PATH -X- _ B-MethodName
- -X- _ I-MethodName
FID -X- _ I-MethodName
suffers -X- _ O
from -X- _ O
disconnected -X- _ O
reasoning -X- _ O
as -X- _ O
compared -X- _ O
to -X- _ O
SEQGRAPH -X- _ B-MethodName
. -X- _ O

HOTPOT -X- _ B-DatasetName
- -X- _ I-DatasetName
QA -X- _ I-DatasetName
suffers -X- _ O
from -X- _ O
information -X- _ O
leakage -X- _ O
in -X- _ O
the -X- _ O
form -X- _ O
of -X- _ O
reasoning -X- _ O
shortcuts -X- _ O
leading -X- _ O
to -X- _ O
disconnected -X- _ O
reasoning -X- _ O
. -X- _ O
This -X- _ O
affects -X- _ O
the -X- _ O
generalization -X- _ O
capability -X- _ O
of -X- _ O
such -X- _ O
models -X- _ O
and -X- _ O
inflates -X- _ O
the -X- _ O
performance -X- _ O
on -X- _ O
the -X- _ O
evaluation -X- _ O
sets -X- _ O
. -X- _ O
Table -X- _ O
4 -X- _ O
shows -X- _ O
some -X- _ O
qualitative -X- _ O
examples -X- _ O
of -X- _ O
disconnected -X- _ O
reasoning -X- _ O
in -X- _ O
PATH -X- _ B-MethodName
- -X- _ I-MethodName
FID -X- _ I-MethodName
that -X- _ O
are -X- _ O
avoided -X- _ O
by -X- _ O
SEQGRAPH -X- _ B-MethodName
Trivedi -X- _ O
et -X- _ O
al -X- _ O
. -X- _ O
( -X- _ O
2020 -X- _ O
) -X- _ O
construct -X- _ O
a -X- _ O
probe -X- _ O
of -X- _ O
HOTPOT -X- _ B-DatasetName
- -X- _ I-DatasetName
QA -X- _ I-DatasetName
by -X- _ O
splitting -X- _ O
the -X- _ O
two -X- _ O
supporting -X- _ O
paragraphs -X- _ O
for -X- _ O
the -X- _ O
original -X- _ O
question -X- _ O
across -X- _ O
two -X- _ O
questions -X- _ O
. -X- _ O
If -X- _ O
the -X- _ O
model -X- _ O
can -X- _ O
answer -X- _ O
modified -X- _ O
questions -X- _ O
correctly -X- _ O
without -X- _ O
the -X- _ O
complete -X- _ O
context -X- _ O
, -X- _ O
it -X- _ O
suggests -X- _ O
that -X- _ O
the -X- _ O
model -X- _ O
uses -X- _ O
disconnected -X- _ O
reasoning -X- _ O
for -X- _ O
the -X- _ O
original -X- _ O
question -X- _ O
. -X- _ O
By -X- _ O
measuring -X- _ O
the -X- _ O
performance -X- _ O
of -X- _ O
a -X- _ O
model -X- _ O
on -X- _ O
such -X- _ O
a -X- _ O
dataset -X- _ O
, -X- _ O
we -X- _ O
arrive -X- _ O
at -X- _ O
the -X- _ O
DIRE -X- _ B-MetricName
score -X- _ O
with -X- _ O
a -X- _ O
higher -X- _ O
value -X- _ O
implying -X- _ O
more -X- _ O
disconnected -X- _ O
reasoning -X- _ O
. -X- _ O
Table -X- _ O
2 -X- _ O
shows -X- _ O
the -X- _ O
DIRE -X- _ B-MetricName
scores -X- _ O
for -X- _ O
the -X- _ O
various -X- _ O
models -X- _ O
. -X- _ O
We -X- _ O
see -X- _ O
that -X- _ O
SEQGRAPH -X- _ B-MethodName
resorts -X- _ O
to -X- _ O
lower -X- _ O
disconnected -X- _ O
reasoning -X- _ O
compared -X- _ O
to -X- _ O
PATH -X- _ B-MethodName
- -X- _ I-MethodName
FID -X- _ I-MethodName
while -X- _ O
maintaining -X- _ O
strong -X- _ O
performance -X- _ O
gains -X- _ O
on -X- _ O
the -X- _ O
original -X- _ O
evaluation -X- _ O
set -X- _ O
. -X- _ O

Yavuz -X- _ O
et -X- _ O
al -X- _ O
. -X- _ O
( -X- _ O
2022 -X- _ O
) -X- _ O
extend -X- _ O
PATH -X- _ B-MethodName
- -X- _ I-MethodName
FID -X- _ I-MethodName
and -X- _ O
introduce -X- _ O
PATH -X- _ B-MethodName
- -X- _ I-MethodName
FID -X- _ I-MethodName
+ -X- _ I-MethodName
to -X- _ O
improve -X- _ O
the -X- _ O
cross -X- _ O
- -X- _ O
passage -X- _ O
interactions -X- _ O
before -X- _ O
feeding -X- _ O
to -X- _ O
the -X- _ O
FiD -X- _ O
decoder -X- _ O
and -X- _ O
show -X- _ O
an -X- _ O
improvement -X- _ O
of -X- _ O
7 -X- _ B-MetricValue
EM -X- _ B-MetricName
points -X- _ O
and -X- _ O
achieve -X- _ O
state -X- _ O
- -X- _ O
of -X- _ O
- -X- _ O
the -X- _ O
- -X- _ O
art -X- _ O
results -X- _ O
on -X- _ O
HOTPOT -X- _ B-DatasetName
- -X- _ I-DatasetName
QA -X- _ I-DatasetName
distractor -X- _ O
dataset -X- _ O
. -X- _ O
However -X- _ O
, -X- _ O
we -X- _ O
find -X- _ O
the -X- _ O
following -X- _ O
limitations -X- _ O
of -X- _ O
the -X- _ O
approach -X- _ O
: -X- _ O

Hop -X- _ O
- -X- _ O
assumption -X- _ O
: -X- _ O
PATH -X- _ B-MethodName
- -X- _ I-MethodName
FID -X- _ I-MethodName
+ -X- _ I-MethodName
adds -X- _ O
pairs -X- _ O
of -X- _ O
contexts -X- _ O
as -X- _ O
input -X- _ O
to -X- _ O
the -X- _ O
FID -X- _ O
encoder -X- _ O
, -X- _ O
which -X- _ O
assumes -X- _ O
a -X- _ O
fixed -X- _ O
number -X- _ O
of -X- _ O
hops -X- _ O
( -X- _ O
in -X- _ O
case -X- _ O
of -X- _ O
HOTPOT -X- _ B-DatasetName
- -X- _ I-DatasetName
QA -X- _ I-DatasetName
, -X- _ O
two -X- _ O
) -X- _ O
and -X- _ O
doubles -X- _ O
the -X- _ O
input -X- _ O
sequence -X- _ O
length -X- _ O
, -X- _ O
leading -X- _ O
to -X- _ O
increased -X- _ O
training -X- _ O
time -X- _ O
. -X- _ O

To -X- _ O
efficiently -X- _ O
encode -X- _ O
pairs -X- _ O
of -X- _ O
passages -X- _ O
( -X- _ O
instead -X- _ O
of -X- _ O
inefficient -X- _ O
N -X- _ O
2 -X- _ O
passages -X- _ O
, -X- _ O
where -X- _ O
N -X- _ O
is -X- _ O
the -X- _ O
total -X- _ O
number -X- _ O
of -X- _ O
passages -X- _ O
) -X- _ O
, -X- _ O
PATH -X- _ B-MethodName
- -X- _ I-MethodName
FID -X- _ I-MethodName
+ -X- _ I-MethodName
also -X- _ O
needs -X- _ O
to -X- _ O
run -X- _ O
the -X- _ O
vanilla -X- _ O
PATH -X- _ B-MethodName
- -X- _ I-MethodName
FID -X- _ I-MethodName
or -X- _ O
train -X- _ O
another -X- _ O
model -X- _ O
to -X- _ O
choose -X- _ O
the -X- _ O
first -X- _ O
relevant -X- _ O
context -X- _ O
P -X- _ O
* -X- _ O
to -X- _ O
jump -X- _ O
to -X- _ O
and -X- _ O
then -X- _ O
construct -X- _ O
pairs -X- _ O
( -X- _ O
P -X- _ O
* -X- _ O
, -X- _ O
P -X- _ O
n -X- _ O
) -X- _ O
. -X- _ O
This -X- _ O
makes -X- _ O
it -X- _ O
inefficient -X- _ O
and -X- _ O
not -X- _ O
scalable -X- _ O
to -X- _ O
questions -X- _ O
with -X- _ O
higher -X- _ O
hops -X- _ O
or -X- _ O
complex -X- _ O
datasets -X- _ O
like -X- _ O
MUSIQUE -X- _ B-DatasetName
In -X- _ O
contrast -X- _ O
, -X- _ O
our -X- _ O
approach -X- _ O
does -X- _ O
not -X- _ O
make -X- _ O
any -X- _ O
assumptions -X- _ O
about -X- _ O
the -X- _ O
number -X- _ O
of -X- _ O
hops -X- _ O
and -X- _ O
is -X- _ O
scalable -X- _ O
. -X- _ O
It -X- _ O
produces -X- _ O
output -X- _ O
in -X- _ O
a -X- _ O
single -X- _ O
shot -X- _ O
without -X- _ O
requiring -X- _ O
multiple -X- _ O
steps -X- _ O
or -X- _ O
increased -X- _ O
sequence -X- _ O
length -X- _ O
. -X- _ O
While -X- _ O
PATH -X- _ B-MethodName
- -X- _ I-MethodName
FID -X- _ I-MethodName
+ -X- _ I-MethodName
may -X- _ O
achieve -X- _ O
stronger -X- _ O
performance -X- _ O
in -X- _ O
2 -X- _ O
- -X- _ O
hop -X- _ O
HOTPOT -X- _ B-DatasetName
- -X- _ I-DatasetName
QA -X- _ I-DatasetName
, -X- _ O
our -X- _ O
proposed -X- _ O
method -X- _ O
is -X- _ O
more -X- _ O
general -X- _ O
, -X- _ O
efficient -X- _ O
and -X- _ O
scalable -X- _ O
, -X- _ O
making -X- _ O
it -X- _ O
a -X- _ O
more -X- _ O
practical -X- _ O
solution -X- _ O
for -X- _ O
real -X- _ O
- -X- _ O
world -X- _ O
applications -X- _ O
and -X- _ O
also -X- _ O
easily -X- _ O
extendable -X- _ O
to -X- _ O
open -X- _ O
- -X- _ O
domain -X- _ O
setting -X- _ O
. -X- _ O

Multihop -X- _ B-TaskName
question -X- _ I-TaskName
answering -X- _ I-TaskName
requires -X- _ O
a -X- _ O
model -X- _ O
to -X- _ O
perform -X- _ O
reasoning -X- _ O
over -X- _ O
multiple -X- _ O
pieces -X- _ O
of -X- _ O
information -X- _ O
, -X- _ O
utilizing -X- _ O
multiple -X- _ O
sources -X- _ O
and -X- _ O
inferring -X- _ O
relationships -X- _ O
between -X- _ O
them -X- _ O
to -X- _ O
provide -X- _ O
a -X- _ O
correct -X- _ O
answer -X- _ O
to -X- _ O
a -X- _ O
given -X- _ O
question -X- _ O
. -X- _ O
There -X- _ O
have -X- _ O
been -X- _ O
various -X- _ O
approaches -X- _ O
and -X- _ O
datasets -X- _ O
proposed -X- _ O
for -X- _ O
training -X- _ O
QA -X- _ O
systems -X- _ O
, -X- _ O
such -X- _ O
as -X- _ O
HotpotQA -X- _ B-DatasetName
( -X- _ O
Yang -X- _ O
et -X- _ O
al -X- _ O
. -X- _ O
, -X- _ O
2018 -X- _ O
) -X- _ O
, -X- _ O
IIRC -X- _ O
( -X- _ O
Ferguson -X- _ O
et -X- _ O
al -X- _ O
. -X- _ O
, -X- _ O
2020 -X- _ O
) -X- _ O
and -X- _ O
Musique -X- _ B-DatasetName
( -X- _ O
Trivedi -X- _ O
et -X- _ O
al -X- _ O
. -X- _ O
, -X- _ O
2022b -X- _ O
) -X- _ O
. -X- _ O

In -X- _ O
the -X- _ O
HOTPOT -X- _ B-DatasetName
- -X- _ I-DatasetName
QA -X- _ I-DatasetName
full -X- _ O
- -X- _ O
wiki -X- _ O
setting -X- _ O
, -X- _ O
the -X- _ O
task -X- _ O
is -X- _ O
to -X- _ O
find -X- _ O
relevant -X- _ O
facts -X- _ O
from -X- _ O
all -X- _ O
Wikipedia -X- _ O
articles -X- _ O
and -X- _ O
then -X- _ O
use -X- _ O
them -X- _ O
to -X- _ O
complete -X- _ O
the -X- _ O
multi -X- _ B-TaskName
- -X- _ I-TaskName
hop -X- _ I-TaskName
QA -X- _ I-TaskName
task -X- _ O
. -X- _ O
Retrieval -X- _ O
models -X- _ O
play -X- _ O
an -X- _ O
important -X- _ O
role -X- _ O
in -X- _ O
this -X- _ O
setting -X- _ O
, -X- _ O
such -X- _ O
as -X- _ O
DPR -X- _ O
, -X- _ O
which -X- _ O
focuses -X- _ O
on -X- _ O
retrieving -X- _ O
relevant -X- _ O
information -X- _ O
in -X- _ O
the -X- _ O
semantic -X- _ O
space -X- _ O
. -X- _ O
Other -X- _ O
methods -X- _ O
, -X- _ O
such -X- _ O
as -X- _ O
Entitiescentric -X- _ O
( -X- _ O
Das -X- _ O
et -X- _ O
al -X- _ O
. -X- _ O
, -X- _ O
2019 -X- _ O
) -X- _ O
, -X- _ O
and -X- _ O
Golden -X- _ O
Retriever -X- _ O
( -X- _ O
Qi -X- _ O
et -X- _ O
al -X- _ O
. -X- _ O
, -X- _ O
2019 -X- _ O
) -X- _ O
, -X- _ O
use -X- _ O
entities -X- _ O
mentioned -X- _ O
or -X- _ O
reformulated -X- _ O
in -X- _ O
query -X- _ O
keywords -X- _ O
to -X- _ O
retrieve -X- _ O
the -X- _ O
next -X- _ O
hop -X- _ O
document -X- _ O
. -X- _ O
Additionally -X- _ O
, -X- _ O
PathRetriever -X- _ O
( -X- _ O
Asai -X- _ O
et -X- _ O
al -X- _ O
. -X- _ O
, -X- _ O
2020 -X- _ O
) -X- _ O
and -X- _ O
HopRetriever -X- _ O
use -X- _ O
RNN -X- _ O
to -X- _ O
select -X- _ O
documents -X- _ O
to -X- _ O
form -X- _ O
a -X- _ O
paragraph -X- _ O
- -X- _ O
level -X- _ O
reasoning -X- _ O
path -X- _ O
iteratively -X- _ O
. -X- _ O
The -X- _ O
above -X- _ O
methods -X- _ O
mainly -X- _ O
focus -X- _ O
on -X- _ O
the -X- _ O
open -X- _ O
- -X- _ O
domain -X- _ O
setting -X- _ O
( -X- _ O
full -X- _ O
- -X- _ O
wiki -X- _ O
) -X- _ O
and -X- _ O
improve -X- _ O
the -X- _ O
retriever -X- _ O
's -X- _ O
performance -X- _ O
and -X- _ O
do -X- _ O
not -X- _ O
address -X- _ O
the -X- _ O
disconnected -X- _ O
reasoning -X- _ O
problem -X- _ O
. -X- _ O

Multiple -X- _ O
techniques -X- _ O
( -X- _ O
Jiang -X- _ O
and -X- _ O
Bansal -X- _ O
, -X- _ O
2019 -X- _ O
; -X- _ O
Lee -X- _ O
et -X- _ O
al -X- _ O
. -X- _ O
, -X- _ O
2021 -X- _ O
; -X- _ O
Ye -X- _ O
et -X- _ O
al -X- _ O
. -X- _ O
, -X- _ O
2021 -X- _ O
) -X- _ O
to -X- _ O
counter -X- _ O
disconnected -X- _ O
reasoning -X- _ O
operate -X- _ O
at -X- _ O
the -X- _ O
dataset -X- _ O
level -X- _ O
, -X- _ O
using -X- _ O
adversarial -X- _ O
training -X- _ O
, -X- _ O
adding -X- _ O
extra -X- _ O
annotations -X- _ O
or -X- _ O
using -X- _ O
dataset -X- _ O
augmentations -X- _ O
to -X- _ O
get -X- _ O
a -X- _ O
balanced -X- _ O
train -X- _ O
set -X- _ O
and -X- _ O
prevent -X- _ O
the -X- _ O
model -X- _ O
from -X- _ O
cheating -X- _ O
. -X- _ O
We -X- _ O
highlight -X- _ O
differences -X- _ O
between -X- _ O
our -X- _ O
approach -X- _ O
and -X- _ O
other -X- _ O
related -X- _ O
works -X- _ O
on -X- _ O
HOTPOT -X- _ B-DatasetName
- -X- _ I-DatasetName
QA -X- _ I-DatasetName
- -X- _ O
distractor -X- _ O
and -X- _ O
other -X- _ O
works -X- _ O
that -X- _ O
combine -X- _ O
language -X- _ O
models -X- _ O
with -X- _ O
graphs -X- _ O
below -X- _ O
: -X- _ O

Generative -X- _ O
approaches -X- _ O
: -X- _ O
Our -X- _ O
generative -X- _ O
- -X- _ O
FiD -X- _ O
approach -X- _ O
differs -X- _ O
from -X- _ O
others -X- _ O
using -X- _ O
KG -X- _ O
/ -X- _ O
GNN -X- _ O
( -X- _ O
Ju -X- _ O
et -X- _ O
al -X- _ O
. -X- _ O
, -X- _ O
2022 -X- _ O
; -X- _ O
as -X- _ O
we -X- _ O
use -X- _ O
an -X- _ O
entity -X- _ O
- -X- _ O
passage -X- _ O
graph -X- _ O
with -X- _ O
Wikipedia -X- _ O
hyperlinks -X- _ O
. -X- _ O
Also -X- _ O
, -X- _ O
our -X- _ O
focus -X- _ O
is -X- _ O
primarily -X- _ O
on -X- _ O
the -X- _ O
distractor -X- _ O
setting -X- _ O
of -X- _ O
multi -X- _ B-MethodName
- -X- _ I-MethodName
hop -X- _ I-MethodName
QA -X- _ I-MethodName
, -X- _ O
while -X- _ O
other -X- _ O
baselines -X- _ O
( -X- _ O
Ju -X- _ O
et -X- _ O
al -X- _ O
. -X- _ O
, -X- _ O
2022 -X- _ O
; -X- _ O
are -X- _ O
either -X- _ O
single -X- _ O
- -X- _ O
hop -X- _ O
or -X- _ O
improving -X- _ O
retrieval -X- _ O
in -X- _ O
open -X- _ O
- -X- _ O
domain -X- _ O
setting -X- _ O
Pipeline -X- _ O
vs -X- _ O
single -X- _ O
- -X- _ O
stage -X- _ O
: -X- _ O
Other -X- _ O
baselines -X- _ O
( -X- _ O
Tu -X- _ O
et -X- _ O
al -X- _ O
. -X- _ O
, -X- _ O
2019 -X- _ O
; -X- _ O
Qiu -X- _ O
et -X- _ O
al -X- _ O
. -X- _ O
, -X- _ O
2019 -X- _ O
; -X- _ O
Wang -X- _ O
et -X- _ O
al -X- _ O
. -X- _ O
, -X- _ O
2021 -X- _ O
; -X- _ O
Li -X- _ O
et -X- _ O
al -X- _ O
. -X- _ O
, -X- _ O
2023 -X- _ O
) -X- _ O
use -X- _ O
a -X- _ O
pipeline -X- _ O
approach -X- _ O
with -X- _ O
distinct -X- _ O
encoder -X- _ O
models -X- _ O
in -X- _ O
the -X- _ O
reasoning -X- _ O
process -X- _ O
, -X- _ O
while -X- _ O
we -X- _ O
use -X- _ O
a -X- _ O
single -X- _ O
- -X- _ O
stage -X- _ O
, -X- _ O
oneshot -X- _ O
prediction -X- _ O
process -X- _ O
without -X- _ O
assumptions -X- _ O
on -X- _ O
the -X- _ O
number -X- _ O
of -X- _ O
hops -X- _ O
. -X- _ O

Graph -X- _ O
construction -X- _ O
: -X- _ O
Other -X- _ O
methods -X- _ O
( -X- _ O
Tu -X- _ O
et -X- _ O
al -X- _ O
. -X- _ O
, -X- _ O
2019 -X- _ O
; -X- _ O
Qiu -X- _ O
et -X- _ O
al -X- _ O
. -X- _ O
, -X- _ O
2019 -X- _ O
) -X- _ O
select -X- _ O
relevant -X- _ O
passages -X- _ O
heuristically -X- _ O
from -X- _ O
among -X- _ O
distractors -X- _ O
to -X- _ O
construct -X- _ O
graphs -X- _ O
. -X- _ O
However -X- _ O
, -X- _ O
we -X- _ O
construct -X- _ O
our -X- _ O
entity -X- _ O
- -X- _ O
passage -X- _ O
graph -X- _ O
on -X- _ O
all -X- _ O
passages -X- _ O
( -X- _ O
including -X- _ O
distractors -X- _ O
) -X- _ O
and -X- _ O
fuse -X- _ O
the -X- _ O
representations -X- _ O
in -X- _ O
the -X- _ O
encoder -X- _ O
. -X- _ O

In -X- _ O
this -X- _ O
paper -X- _ O
, -X- _ O
we -X- _ O
propose -X- _ O
SEQGRAPH -X- _ B-MethodName
, -X- _ O
an -X- _ O
approach -X- _ O
that -X- _ O
utilizes -X- _ O
the -X- _ O
structured -X- _ O
relationship -X- _ O
between -X- _ O
passages -X- _ O
in -X- _ O
the -X- _ O
context -X- _ O
of -X- _ O
multi -X- _ O
- -X- _ O
hop -X- _ O
questions -X- _ O
to -X- _ O
reduce -X- _ O
disconnected -X- _ O
reasoning -X- _ O
. -X- _ O
We -X- _ O
construct -X- _ O
a -X- _ O
localized -X- _ O
entity -X- _ O
- -X- _ O
passage -X- _ O
graph -X- _ O
using -X- _ O
Wikipedia -X- _ O
hyperlinks -X- _ O
, -X- _ O
encode -X- _ O
it -X- _ O
using -X- _ O
a -X- _ O
GNN -X- _ O
, -X- _ O
and -X- _ O
fuse -X- _ O
the -X- _ O
structured -X- _ O
representations -X- _ O
with -X- _ O
the -X- _ O
text -X- _ O
encoder -X- _ O
for -X- _ O
predicting -X- _ O
a -X- _ O
reasoning -X- _ O
path -X- _ O
. -X- _ O
Our -X- _ O
approach -X- _ O
results -X- _ O
in -X- _ O
strong -X- _ O
performance -X- _ O
gains -X- _ O
in -X- _ O
terms -X- _ O
of -X- _ O
both -X- _ O
answer -X- _ O
and -X- _ O
support -X- _ O
EM -X- _ B-MetricName
/ -X- _ O
F1 -X- _ B-MetricName
on -X- _ O
HOTPOT -X- _ B-DatasetName
- -X- _ I-DatasetName
QA -X- _ I-DatasetName
and -X- _ O
reduces -X- _ O
disconnected -X- _ O
reasoning -X- _ O
measured -X- _ O
using -X- _ O
DIRE -X- _ B-MetricName
score -X- _ O
. -X- _ O
We -X- _ O
also -X- _ O
obtain -X- _ O
state -X- _ O
- -X- _ O
of -X- _ O
- -X- _ O
the -X- _ O
- -X- _ O
art -X- _ O
performance -X- _ O
on -X- _ O
the -X- _ O
more -X- _ O
challenging -X- _ O
MUSIQUE -X- _ B-DatasetName
benchmark -X- _ O
with -X- _ O
a -X- _ O
17 -X- _ B-MetricValue
- -X- _ O
point -X- _ O
improvement -X- _ O
in -X- _ O
answer -X- _ O
F1 -X- _ B-MetricName
over -X- _ O
the -X- _ O
current -X- _ O
best -X- _ O
end -X- _ O
- -X- _ O
to -X- _ O
- -X- _ O
end -X- _ O
( -X- _ O
E2E -X- _ O
) -X- _ O
model -X- _ O
. -X- _ O
Experimenting -X- _ O
with -X- _ O
sophisticated -X- _ O
methods -X- _ O
of -X- _ O
encoding -X- _ O
the -X- _ O
graph -X- _ O
structure -X- _ O
and -X- _ O
fusing -X- _ O
the -X- _ O
text -X- _ O
and -X- _ O
graph -X- _ O
representations -X- _ O
can -X- _ O
be -X- _ O
explored -X- _ O
in -X- _ O
future -X- _ O
work -X- _ O
. -X- _ O

Longer -X- _ O
Output -X- _ O
Sequences -X- _ O
While -X- _ O
outputting -X- _ O
the -X- _ O
reasoning -X- _ O
path -X- _ O
as -X- _ O
a -X- _ O
single -X- _ O
short -X- _ O
sequence -X- _ O
makes -X- _ O
the -X- _ O
model -X- _ O
more -X- _ O
interpretable -X- _ O
, -X- _ O
it -X- _ O
increases -X- _ O
the -X- _ O
challenge -X- _ O
of -X- _ O
producing -X- _ O
a -X- _ O
long -X- _ O
/ -X- _ O
coherent -X- _ O
sequence -X- _ O
when -X- _ O
the -X- _ O
question -X- _ O
is -X- _ O
complex -X- _ O
( -X- _ O
more -X- _ O
than -X- _ O
3 -X- _ O
hops -X- _ O
) -X- _ O
. -X- _ O
Producing -X- _ O
a -X- _ O
longer -X- _ O
sequence -X- _ O
also -X- _ O
increases -X- _ O
the -X- _ O
inference -X- _ O
time -X- _ O
. -X- _ O
Simplifying -X- _ O
this -X- _ O
output -X- _ O
while -X- _ O
not -X- _ O
sacrificing -X- _ O
interpretability -X- _ O
is -X- _ O
a -X- _ O
good -X- _ O
future -X- _ O
direction -X- _ O
Entity -X- _ O
Identification -X- _ O
Our -X- _ O
method -X- _ O
needs -X- _ O
wikipedia -X- _ O
outlinks -X- _ O
or -X- _ O
a -X- _ O
entity -X- _ O
linker -X- _ O
to -X- _ O
construct -X- _ O
a -X- _ O
localized -X- _ O
graph -X- _ O
for -X- _ O
every -X- _ O
question -X- _ O
. -X- _ O
Generalizing -X- _ O
this -X- _ O
step -X- _ O
by -X- _ O
pretraining -X- _ O
the -X- _ O
model -X- _ O
to -X- _ O
do -X- _ O
entity -X- _ O
linking -X- _ O
( -X- _ O
Févry -X- _ O
et -X- _ O
al -X- _ O
. -X- _ O
, -X- _ O
2020 -X- _ O
; -X- _ O
Sun -X- _ O
et -X- _ O
al -X- _ O
. -X- _ O
, -X- _ O
2021 -X- _ O
; -X- _ O
Verga -X- _ O
et -X- _ O
al -X- _ O
. -X- _ O
, -X- _ O
2020 -X- _ O
) -X- _ O

We -X- _ O
hypothesize -X- _ O
that -X- _ O
the -X- _ O
answer -X- _ O
F1 -X- _ B-MetricName
of -X- _ O
SEQGRAPH -X- _ B-MethodName
on -X- _ O
questions -X- _ O
with -X- _ O
≥ -X- _ O
4 -X- _ O
hops -X- _ O
gets -X- _ O
impacted -X- _ O
due -X- _ O
to -X- _ O
presence -X- _ O
of -X- _ O
shortcuts -X- _ O
since -X- _ O
the -X- _ O
support -X- _ O
F1 -X- _ B-MetricName
score -X- _ O
is -X- _ O
higher -X- _ O
than -X- _ O
PATH -X- _ B-MethodName
- -X- _ I-MethodName
FID -X- _ I-MethodName
. -X- _ O

Table -X- _ O
8 -X- _ O
shows -X- _ O
the -X- _ O
comparison -X- _ O
of -X- _ O
our -X- _ O
models -X- _ O
with -X- _ O
the -X- _ O
current -X- _ O
best -X- _ O
performing -X- _ O
ones -X- _ O
on -X- _ O
the -X- _ O
MUSIQUE -X- _ B-DatasetName
- -X- _ O
Answerable -X- _ O
test -X- _ O
set -X- _ O
leaderboard -X- _ O
. -X- _ O
Our -X- _ O
End -X- _ O
- -X- _ O
to -X- _ O
- -X- _ O
End -X- _ O
single -X- _ O
stage -X- _ O
model -X- _ O
SEQGRAPH -X- _ B-MethodName
- -X- _ O
large -X- _ O
trained -X- _ O
to -X- _ O
output -X- _ O
title -X- _ O
+ -X- _ O
intermediate -X- _ O
answers -X- _ O
( -X- _ O
SIA -X- _ O
) -X- _ O
outperforms -X- _ O
the -X- _ O
Longformer -X- _ O
- -X- _ O
Large -X- _ O
( -X- _ O
Beltagy -X- _ O
et -X- _ O
al -X- _ O
. -X- _ O
, -X- _ O
2020 -X- _ O
) -X- _ O
End -X- _ O
- -X- _ O
to -X- _ O
- -X- _ O
End -X- _ O
model -X- _ O
by -X- _ O
17 -X- _ B-MetricValue
points -X- _ O
in -X- _ O
answer -X- _ O
F1 -X- _ B-MetricName
and -X- _ O
by -X- _ O
9 -X- _ B-MetricValue
- -X- _ O
points -X- _ O
in -X- _ O
support -X- _ O
F1 -X- _ B-MetricName
. -X- _ O
Furthermore -X- _ O
, -X- _ O
we -X- _ O
also -X- _ O
outperform -X- _ O
the -X- _ O
current -X- _ O
state -X- _ O
- -X- _ O
of -X- _ O
- -X- _ O
the -X- _ O
- -X- _ O
art -X- _ O
SA -X- _ O
model -X- _ O
which -X- _ O
is -X- _ O
a -X- _ O
two -X- _ O
stage -X- _ O
model -X- _ O
( -X- _ O
Roberta -X- _ O
Large -X- _ O
( -X- _ O
Liu -X- _ O
et -X- _ O
al -X- _ O
. -X- _ O
, -X- _ O
2019 -X- _ O
) -X- _ O
+ -X- _ O
Longformer -X- _ O
Large -X- _ O
) -X- _ O
by -X- _ O
5 -X- _ B-MetricValue
points -X- _ O
on -X- _ O
Answer -X- _ O
F1 -X- _ B-MetricName
and -X- _ O
3 -X- _ B-MetricValue
points -X- _ O
on -X- _ O
Support -X- _ O
F1 -X- _ B-MetricName
. -X- _ O

Tables -X- _ O
9 -X- _ O
, -X- _ O
10 -X- _ O
, -X- _ O
11 -X- _ O
detail -X- _ O
the -X- _ O
hyperparameters -X- _ O
we -X- _ O
use -X- _ O
for -X- _ O
FID -X- _ B-MethodName
, -X- _ O
PATH -X- _ B-MethodName
- -X- _ I-MethodName
FID -X- _ I-MethodName
and -X- _ O
SEQGRAPH -X- _ B-MethodName
for -X- _ O
HOTPOT -X- _ B-DatasetName
- -X- _ I-DatasetName
QA -X- _ I-DatasetName
and -X- _ O
MUSIQUE -X- _ B-DatasetName
. -X- _ O
The -X- _ O
2 -X- _ O
- -X- _ O
layer -X- _ O
GNN -X- _ O
module -X- _ O
is -X- _ O
17 -X- _ O
M -X- _ O
parameters -X- _ O
for -X- _ O
the -X- _ O
large -X- _ O
model -X- _ O
and -X- _ O
9.5 -X- _ O
M -X- _ O
for -X- _ O
the -X- _ O
base -X- _ O
, -X- _ O
accounting -X- _ O
for -X- _ O
only -X- _ O
upto -X- _ O
4 -X- _ O
% -X- _ O
increase -X- _ O
in -X- _ O
model -X- _ O
parameters -X- _ O
. -X- _ O

A -X- _ O
Neural -X- _ O
Divide -X- _ O
- -X- _ O
and -X- _ O
- -X- _ O
Conquer -X- _ O
Reasoning -X- _ O
Framework -X- _ O
for -X- _ O
Image -X- _ B-TaskName
Retrieval -X- _ I-TaskName
from -X- _ O
Linguistically -X- _ O
Complex -X- _ O
Text -X- _ O

Pretrained -X- _ O
Vision -X- _ O
- -X- _ O
Language -X- _ O
Models -X- _ O
( -X- _ O
VLMs -X- _ O
) -X- _ O
have -X- _ O
achieved -X- _ O
remarkable -X- _ O
performance -X- _ O
in -X- _ O
image -X- _ B-TaskName
retrieval -X- _ I-TaskName
from -X- _ O
text -X- _ O
. -X- _ O
However -X- _ O
, -X- _ O
their -X- _ O
performance -X- _ O
drops -X- _ O
drastically -X- _ O
when -X- _ O
confronted -X- _ O
with -X- _ O
linguistically -X- _ O
complex -X- _ O
texts -X- _ O
that -X- _ O
they -X- _ O
struggle -X- _ O
to -X- _ O
comprehend -X- _ O
. -X- _ O
Inspired -X- _ O
by -X- _ O
the -X- _ O
Divide -X- _ O
- -X- _ O
and -X- _ O
- -X- _ O
Conquer -X- _ O
( -X- _ O
Smith -X- _ O
, -X- _ O
1985 -X- _ O
) -X- _ O
algorithm -X- _ O
and -X- _ O
dualprocess -X- _ O
theory -X- _ O
( -X- _ O
Groves -X- _ O
and -X- _ O
Thompson -X- _ O
, -X- _ O
1970 -X- _ O
) -X- _ O
, -X- _ O
in -X- _ O
this -X- _ O
paper -X- _ O
, -X- _ O
we -X- _ O
regard -X- _ O
linguistically -X- _ O
complex -X- _ O
texts -X- _ O
as -X- _ O
compound -X- _ O
proposition -X- _ O
texts -X- _ O
composed -X- _ O
of -X- _ O
multiple -X- _ O
simple -X- _ O
proposition -X- _ O
sentences -X- _ O
and -X- _ O
propose -X- _ O
an -X- _ O
end -X- _ O
- -X- _ O
to -X- _ O
- -X- _ O
end -X- _ O
Neural -X- _ B-MethodName
Divide -X- _ I-MethodName
- -X- _ I-MethodName
and -X- _ I-MethodName
- -X- _ I-MethodName
Conquer -X- _ I-MethodName
Reasoning -X- _ I-MethodName
framework -X- _ O
, -X- _ O
dubbed -X- _ O
NDCR -X- _ B-MethodName
. -X- _ O
It -X- _ O
contains -X- _ O
three -X- _ O
main -X- _ O
components -X- _ O
: -X- _ O
1 -X- _ O
) -X- _ O
Divide -X- _ O
: -X- _ O
a -X- _ O
proposition -X- _ O
generator -X- _ O
divides -X- _ O
the -X- _ O
compound -X- _ O
proposition -X- _ O
text -X- _ O
into -X- _ O
simple -X- _ O
proposition -X- _ O
sentences -X- _ O
and -X- _ O
produces -X- _ O
their -X- _ O
corresponding -X- _ O
representations -X- _ O
, -X- _ O
2 -X- _ O
) -X- _ O
Conquer -X- _ O
: -X- _ O
a -X- _ O
pretrained -X- _ O
VLMsbased -X- _ O
visual -X- _ O
- -X- _ O
linguistic -X- _ O
interactor -X- _ O
achieves -X- _ O
the -X- _ O
interaction -X- _ O
between -X- _ O
decomposed -X- _ O
proposition -X- _ O
sentences -X- _ O
and -X- _ O
images -X- _ O
, -X- _ O
3 -X- _ O
) -X- _ O
Combine -X- _ O
: -X- _ O
a -X- _ O
neuralsymbolic -X- _ O
reasoner -X- _ O
combines -X- _ O
the -X- _ O
above -X- _ O
reasoning -X- _ O
states -X- _ O
to -X- _ O
obtain -X- _ O
the -X- _ O
final -X- _ O
solution -X- _ O
via -X- _ O
a -X- _ O
neural -X- _ O
logic -X- _ O
reasoning -X- _ O
approach -X- _ O
. -X- _ O
According -X- _ O
to -X- _ O
the -X- _ O
dual -X- _ O
- -X- _ O
process -X- _ O
theory -X- _ O
, -X- _ O
the -X- _ O
visual -X- _ O
- -X- _ O
linguistic -X- _ O
interactor -X- _ O
and -X- _ O
neural -X- _ O
- -X- _ O
symbolic -X- _ O
reasoner -X- _ O
could -X- _ O
be -X- _ O
regarded -X- _ O
as -X- _ O
analogical -X- _ O
reasoning -X- _ O
System -X- _ O
1 -X- _ O
and -X- _ O
logical -X- _ O
reasoning -X- _ O
System -X- _ O
2 -X- _ O
. -X- _ O
We -X- _ O
conduct -X- _ O
extensive -X- _ O
experiments -X- _ O
on -X- _ O
a -X- _ O
challenging -X- _ O
image -X- _ B-TaskName
retrieval -X- _ I-TaskName
from -X- _ O
contextual -X- _ O
descriptions -X- _ O
data -X- _ O
set -X- _ O
. -X- _ O
Experimental -X- _ O
results -X- _ O
and -X- _ O
analyses -X- _ O
indicate -X- _ O
NDCR -X- _ B-MethodName
significantly -X- _ O
improves -X- _ O
performance -X- _ O
in -X- _ O
the -X- _ O
complex -X- _ O
image -X- _ O
- -X- _ O
text -X- _ O
reasoning -X- _ O
problem -X- _ O
. -X- _ O
Code -X- _ O
link -X- _ O
: -X- _ O
https -X- _ O
: -X- _ O
/ -X- _ O
/ -X- _ O
github.com -X- _ O
/ -X- _ O
YunxinLi -X- _ O
/ -X- _ O
NDCR -X- _ O
. -X- _ O

Image -X- _ O
- -X- _ O
text -X- _ O
retrieval -X- _ O
tasks -X- _ O
have -X- _ O
made -X- _ O
remarkable -X- _ O
progress -X- _ O
owing -X- _ O
to -X- _ O
pretrained -X- _ O
Vision -X- _ O
- -X- _ O
Language -X- _ O
Models -X- _ O
( -X- _ O
VLMs -X- _ O
) -X- _ O
such -X- _ O
as -X- _ O
LXMERT -X- _ O
( -X- _ O
Tan -X- _ O
and -X- _ O
Bansal -X- _ O
, -X- _ O
2019 -X- _ O
) -X- _ O
, -X- _ O
UNITER -X- _ O
, -X- _ O
OS -X- _ O
- -X- _ O
CAR -X- _ O
( -X- _ O
Li -X- _ O
et -X- _ O
al -X- _ O
. -X- _ O
, -X- _ O
2020b -X- _ O
; -X- _ O
, -X- _ O
ViL -X- _ O
- -X- _ O
BERT -X- _ O
( -X- _ O
Lu -X- _ O
et -X- _ O
al -X- _ O
. -X- _ O
, -X- _ O
2019 -X- _ O
) -X- _ O
, -X- _ O
CLIP -X- _ O
( -X- _ O
Radford -X- _ O
et -X- _ O
al -X- _ O
. -X- _ O
, -X- _ O
2021 -X- _ O
) -X- _ O
, -X- _ O
* -X- _ O
Corresponding -X- _ O
author -X- _ O
. -X- _ O
Figure -X- _ O
1 -X- _ O
: -X- _ O
An -X- _ O
example -X- _ O
from -X- _ O
the -X- _ O
IMAGECODE -X- _ O
( -X- _ O
Krojer -X- _ O
et -X- _ O
al -X- _ O
. -X- _ O
, -X- _ O
2022 -X- _ O
) -X- _ O
data -X- _ O
set -X- _ O
, -X- _ O
where -X- _ O
the -X- _ O
description -X- _ O
is -X- _ O
linguistically -X- _ O
complex -X- _ O
and -X- _ O
images -X- _ O
are -X- _ O
minimally -X- _ O
contrastive -X- _ O
. -X- _ O
The -X- _ O
target -X- _ O
image -X- _ O
is -X- _ O
in -X- _ O
red -X- _ O
and -X- _ O
others -X- _ O
are -X- _ O
incorrect -X- _ O
frames -X- _ O
. -X- _ O
The -X- _ O
bottom -X- _ O
part -X- _ O
depicts -X- _ O
the -X- _ O
conventional -X- _ O
method -X- _ O
and -X- _ O
the -X- _ O
neural -X- _ B-MethodName
divide -X- _ I-MethodName
- -X- _ I-MethodName
and -X- _ I-MethodName
- -X- _ I-MethodName
conquer -X- _ I-MethodName
reasoning -X- _ I-MethodName
framework -X- _ O
. -X- _ O
and -X- _ O
many -X- _ O
others -X- _ O
. -X- _ O
These -X- _ O
VLMs -X- _ O
are -X- _ O
usually -X- _ O
trained -X- _ O
on -X- _ O
the -X- _ O
large -X- _ O
- -X- _ O
scale -X- _ O
short -X- _ O
text -X- _ O
- -X- _ O
image -X- _ O
corpus -X- _ O
by -X- _ O
crossmodal -X- _ O
semantic -X- _ O
alignment -X- _ O
methods -X- _ O
. -X- _ O
They -X- _ O
are -X- _ O
capable -X- _ O
of -X- _ O
essential -X- _ O
perceptual -X- _ O
computing -X- _ O
capability -X- _ O
and -X- _ O
excel -X- _ O
at -X- _ O
retrieving -X- _ O
images -X- _ O
from -X- _ O
sentences -X- _ O
with -X- _ O
few -X- _ O
objects -X- _ O
and -X- _ O
simple -X- _ O
linguistic -X- _ O
, -X- _ O
e.g. -X- _ O
, -X- _ O
" -X- _ O
There -X- _ O
is -X- _ O
a -X- _ O
duck -X- _ O
swimming -X- _ O
in -X- _ O
the -X- _ O
pond -X- _ O
" -X- _ O
. -X- _ O
However -X- _ O
, -X- _ O
when -X- _ O
pretrained -X- _ O
VLMs -X- _ O
meet -X- _ O
the -X- _ O
case -X- _ O
of -X- _ O
retrieving -X- _ O
the -X- _ O
accurate -X- _ O
image -X- _ O
from -X- _ O
similar -X- _ O
candidates -X- _ O
based -X- _ O
on -X- _ O
a -X- _ O
linguistically -X- _ O
complex -X- _ O
text -X- _ O
, -X- _ O
as -X- _ O
the -X- _ O
example -X- _ O
shown -X- _ O
in -X- _ O
Figure -X- _ O
1 -X- _ O
, -X- _ O
previous -X- _ O
works -X- _ O
( -X- _ O
Krojer -X- _ O
et -X- _ O
al -X- _ O
. -X- _ O
, -X- _ O
2022 -X- _ O
; -X- _ O
Talmor -X- _ O
et -X- _ O
al -X- _ O
. -X- _ O
, -X- _ O
2021a -X- _ O
; -X- _ O
Thrush -X- _ O
et -X- _ O
al -X- _ O
. -X- _ O
, -X- _ O
2022 -X- _ O
) -X- _ O
show -X- _ O
that -X- _ O
they -X- _ O
struggle -X- _ O
to -X- _ O
understand -X- _ O
the -X- _ O
elaborate -X- _ O
description -X- _ O
and -X- _ O
perform -X- _ O
complex -X- _ O
cross -X- _ O
- -X- _ O
modal -X- _ O
reasoning -X- _ O
. -X- _ O

According -X- _ O
to -X- _ O
the -X- _ O
dual -X- _ O
- -X- _ O
process -X- _ O
theory -X- _ O
for -X- _ O
human -X- _ O
thinking -X- _ O
( -X- _ O
Groves -X- _ O
and -X- _ O
Thompson -X- _ O
, -X- _ O
1970 -X- _ O
; -X- _ O
Evans -X- _ O
, -X- _ O
2003 -X- _ O
; -X- _ O
Pelaccia -X- _ O
et -X- _ O
al -X- _ O
. -X- _ O
, -X- _ O
2011 -X- _ O
) -X- _ O
, -X- _ O
human -X- _ O
brains -X- _ O
contain -X- _ O
two -X- _ O
thinking -X- _ O
systems -X- _ O
: -X- _ O
System -X- _ O
1 -X- _ O
performs -X- _ O
analogical -X- _ O
reasoning -X- _ O
well -X- _ O
, -X- _ O
which -X- _ O
is -X- _ O
fast -X- _ O
yet -X- _ O
unconscious -X- _ O
; -X- _ O
System -X- _ O
2 -X- _ O
is -X- _ O
capable -X- _ O
of -X- _ O
abstract -X- _ O
logical -X- _ O
reasoning -X- _ O
, -X- _ O
which -X- _ O
is -X- _ O
slow -X- _ O
yet -X- _ O
conscious -X- _ O
and -X- _ O
well -X- _ O
- -X- _ O
suitable -X- _ O
for -X- _ O
complex -X- _ O
reasoning -X- _ O
problems -X- _ O
. -X- _ O
The -X- _ O
theory -X- _ O
could -X- _ O
also -X- _ O
hold -X- _ O
for -X- _ O
the -X- _ O
image -X- _ O
- -X- _ O
text -X- _ O
retrieval -X- _ O
tasks -X- _ O
, -X- _ O
and -X- _ O
the -X- _ O
widely -X- _ O
adopted -X- _ O
models -X- _ O
( -X- _ O
e.g. -X- _ O
, -X- _ O
VLMs -X- _ O
) -X- _ O
focus -X- _ O
on -X- _ O
analogical -X- _ O
reasoning -X- _ O
as -X- _ O
System -X- _ O
1 -X- _ O
based -X- _ O
on -X- _ O
the -X- _ O
analysis -X- _ O
of -X- _ O
deep -X- _ O
learning -X- _ O
networks -X- _ O
( -X- _ O
Bengio -X- _ O
, -X- _ O
2017 -X- _ O
( -X- _ O
Bengio -X- _ O
, -X- _ O
, -X- _ O
2019Bengio -X- _ O
et -X- _ O
al -X- _ O
. -X- _ O
, -X- _ O
2021 -X- _ O
) -X- _ O
. -X- _ O
For -X- _ O
the -X- _ O
linguistically -X- _ O
complex -X- _ O
description -X- _ O
that -X- _ O
contains -X- _ O
multiple -X- _ O
conditions -X- _ O
, -X- _ O
they -X- _ O
have -X- _ O
inferior -X- _ O
performance -X- _ O
, -X- _ O
and -X- _ O
we -X- _ O
need -X- _ O
to -X- _ O
introduce -X- _ O
logical -X- _ O
reasoning -X- _ O
System -X- _ O
2 -X- _ O
more -X- _ O
to -X- _ O
cover -X- _ O
and -X- _ O
logically -X- _ O
incorporate -X- _ O
the -X- _ O
scattered -X- _ O
information -X- _ O
in -X- _ O
the -X- _ O
description -X- _ O
based -X- _ O
on -X- _ O
System -X- _ O
1 -X- _ O
. -X- _ O
Inspired -X- _ O
by -X- _ O
the -X- _ O
above -X- _ O
investigations -X- _ O
and -X- _ O
classical -X- _ O
Divide -X- _ O
- -X- _ O
and -X- _ O
- -X- _ O
Conquer -X- _ O
( -X- _ O
Smith -X- _ O
, -X- _ O
1985 -X- _ O
) -X- _ O
algorithm -X- _ O
, -X- _ O
we -X- _ O
design -X- _ O
an -X- _ O
end -X- _ O
- -X- _ O
to -X- _ O
- -X- _ O
end -X- _ O
Neural -X- _ B-MethodName
Divide -X- _ I-MethodName
- -X- _ I-MethodName
and -X- _ I-MethodName
- -X- _ I-MethodName
Conquer -X- _ I-MethodName
Reasoning -X- _ I-MethodName
framework -X- _ O
named -X- _ O
NDCR -X- _ B-MethodName
. -X- _ O
As -X- _ O
shown -X- _ O
in -X- _ O
Figure -X- _ O
1 -X- _ O
, -X- _ O
our -X- _ O
key -X- _ O
idea -X- _ O
is -X- _ O
to -X- _ O
regard -X- _ O
the -X- _ O
complex -X- _ O
description -X- _ O
as -X- _ O
compound -X- _ O
proposition -X- _ O
text -X- _ O
and -X- _ O
solve -X- _ O
the -X- _ O
challenging -X- _ O
retrieval -X- _ O
problem -X- _ O
in -X- _ O
three -X- _ O
steps -X- _ O
: -X- _ O
divide -X- _ O
, -X- _ O
conquer -X- _ O
, -X- _ O
and -X- _ O
combine -X- _ O
. -X- _ O
Specifically -X- _ O
, -X- _ O
Divide -X- _ O
: -X- _ O
NDCR -X- _ B-MethodName
first -X- _ O
utilizes -X- _ O
a -X- _ O
proposition -X- _ O
generator -X- _ O
to -X- _ O
divide -X- _ O
the -X- _ O
complex -X- _ O
compound -X- _ O
text -X- _ O
and -X- _ O
produce -X- _ O
the -X- _ O
global -X- _ O
representation -X- _ O
of -X- _ O
simple -X- _ O
proposition -X- _ O
sentences -X- _ O
with -X- _ O
visually -X- _ O
printing -X- _ O
them -X- _ O
. -X- _ O
Conquer -X- _ O
: -X- _ O
we -X- _ O
devise -X- _ O
a -X- _ O
visuallinguistic -X- _ O
interactor -X- _ O
to -X- _ O
achieve -X- _ O
the -X- _ O
interaction -X- _ O
between -X- _ O
decomposed -X- _ O
proposition -X- _ O
sentences -X- _ O
and -X- _ O
images -X- _ O
, -X- _ O
which -X- _ O
resembles -X- _ O
System -X- _ O
1 -X- _ O
. -X- _ O
It -X- _ O
uses -X- _ O
the -X- _ O
Transformer -X- _ O
( -X- _ O
Vaswani -X- _ O
et -X- _ O
al -X- _ O
. -X- _ O
, -X- _ O
2017 -X- _ O
) -X- _ O
-based -X- _ O
contextual -X- _ O
interactor -X- _ O
to -X- _ O
achieve -X- _ O
the -X- _ O
inter -X- _ O
- -X- _ O
learning -X- _ O
of -X- _ O
different -X- _ O
proposition -X- _ O
- -X- _ O
image -X- _ O
pairs -X- _ O
. -X- _ O
Considering -X- _ O
the -X- _ O
incorrectness -X- _ O
or -X- _ O
information -X- _ O
loss -X- _ O
of -X- _ O
simple -X- _ O
proposition -X- _ O
representation -X- _ O
, -X- _ O
we -X- _ O
also -X- _ O
present -X- _ O
a -X- _ O
modifier -X- _ O
to -X- _ O
incorporate -X- _ O
the -X- _ O
context -X- _ O
reasoning -X- _ O
information -X- _ O
to -X- _ O
improve -X- _ O
their -X- _ O
cross -X- _ O
- -X- _ O
modal -X- _ O
reasoning -X- _ O
states -X- _ O
. -X- _ O
Combine -X- _ O
: -X- _ O
we -X- _ O
design -X- _ O
a -X- _ O
learnable -X- _ O
neural -X- _ O
- -X- _ O
symbolic -X- _ O
reasoner -X- _ O
to -X- _ O
integrate -X- _ O
reasoning -X- _ O
information -X- _ O
of -X- _ O
simple -X- _ O
propositions -X- _ O
logically -X- _ O
. -X- _ O
It -X- _ O
first -X- _ O
employs -X- _ O
a -X- _ O
negation -X- _ O
executor -X- _ O
to -X- _ O
obtain -X- _ O
a -X- _ O
simple -X- _ O
proposition -X- _ O
sentence -X- _ O
's -X- _ O
negational -X- _ O
reasoning -X- _ O
hidden -X- _ O
state -X- _ O
and -X- _ O
corresponding -X- _ O
confidence -X- _ O
score -X- _ O
. -X- _ O
Then -X- _ O
, -X- _ O
we -X- _ O
use -X- _ O
the -X- _ O
global -X- _ O
reasoning -X- _ O
information -X- _ O
of -X- _ O
compound -X- _ O
proposition -X- _ O
text -X- _ O
as -X- _ O
the -X- _ O
query -X- _ O
signal -X- _ O
to -X- _ O
perform -X- _ O
the -X- _ O
conjunction -X- _ O
operation -X- _ O
across -X- _ O
simple -X- _ O
propositions -X- _ O
and -X- _ O
their -X- _ O
negational -X- _ O
information -X- _ O
. -X- _ O
Finally -X- _ O
, -X- _ O
as -X- _ O
shown -X- _ O
in -X- _ O
Figure -X- _ O
1 -X- _ O
, -X- _ O
we -X- _ O
also -X- _ O
combine -X- _ O
the -X- _ O
inferred -X- _ O
results -X- _ O
of -X- _ O
the -X- _ O
neural -X- _ O
- -X- _ O
symbolic -X- _ O
reasoner -X- _ O
( -X- _ O
resembles -X- _ O
System -X- _ O
2 -X- _ O
) -X- _ O
and -X- _ O
visual -X- _ O
- -X- _ O
linguistic -X- _ O
interactor -X- _ O
( -X- _ O
resembles -X- _ O
System -X- _ O
1 -X- _ O
) -X- _ O
to -X- _ O
obtain -X- _ O
the -X- _ O
final -X- _ O
solution -X- _ O
. -X- _ O
In -X- _ O
this -X- _ O
way -X- _ O
, -X- _ O
the -X- _ O
whole -X- _ O
framework -X- _ O
integrate -X- _ O
the -X- _ O
capabilities -X- _ O
of -X- _ O
Systems -X- _ O
1 -X- _ O
and -X- _ O
2 -X- _ O
to -X- _ O
obtain -X- _ O
better -X- _ O
performance -X- _ O
. -X- _ O

We -X- _ O
conduct -X- _ O
extensive -X- _ O
experiments -X- _ O
on -X- _ O
a -X- _ O
largescale -X- _ O
image -X- _ B-TaskName
retrieval -X- _ I-TaskName
from -X- _ O
contextual -X- _ O
descriptions -X- _ O
data -X- _ O
set -X- _ O
, -X- _ O
IMAGECODE -X- _ B-DatasetName
( -X- _ O
Krojer -X- _ O
et -X- _ O
al -X- _ O
. -X- _ O
, -X- _ O
2022 -X- _ O
) -X- _ O
. -X- _ O
The -X- _ O
experimental -X- _ O
results -X- _ O
indicate -X- _ O
that -X- _ O
NDCR -X- _ B-MethodName
achieves -X- _ O
the -X- _ O
state -X- _ O
- -X- _ O
of -X- _ O
- -X- _ O
the -X- _ O
- -X- _ O
art -X- _ O
performance -X- _ O
and -X- _ O
the -X- _ O
ablation -X- _ O
and -X- _ O
case -X- _ O
studies -X- _ O
verify -X- _ O
the -X- _ O
effectiveness -X- _ O
of -X- _ O
different -X- _ O
modules -X- _ O
. -X- _ O

• -X- _ O
We -X- _ O
propose -X- _ O
a -X- _ O
divide -X- _ O
- -X- _ O
and -X- _ O
- -X- _ O
conquer -X- _ O
reasoning -X- _ O
framework -X- _ O
for -X- _ O
image -X- _ B-TaskName
retrievals -X- _ I-TaskName
from -X- _ O
linguistically -X- _ O
complex -X- _ O
text -X- _ O
, -X- _ O
where -X- _ O
we -X- _ O
first -X- _ O
attempt -X- _ O
to -X- _ O
combine -X- _ O
the -X- _ O
perceptually -X- _ O
analogical -X- _ O
reasoning -X- _ O
System -X- _ O
1 -X- _ O
and -X- _ O
neural -X- _ O
- -X- _ O
symbolic -X- _ O
logic -X- _ O
reasoning -X- _ O
System -X- _ O
2 -X- _ O
to -X- _ O
solve -X- _ O
the -X- _ O
complex -X- _ O
multimodal -X- _ O
reasoning -X- _ O
problem -X- _ O
. -X- _ O

• -X- _ O
Experimental -X- _ O
results -X- _ O
indicate -X- _ O
our -X- _ O
approach -X- _ O
remarkably -X- _ O
improves -X- _ O
the -X- _ O
performance -X- _ O
, -X- _ O
and -X- _ O
we -X- _ O
obtain -X- _ O
the -X- _ O
first -X- _ O
place -X- _ O
on -X- _ O
the -X- _ O
leaderboard -X- _ O
1 -X- _ O
. -X- _ O
Ablation -X- _ O
and -X- _ O
case -X- _ O
studies -X- _ O
confirm -X- _ O
the -X- _ O
effectiveness -X- _ O
of -X- _ O
introducing -X- _ O
and -X- _ O
combining -X- _ O
logical -X- _ O
reasoning -X- _ O
System -X- _ O
2 -X- _ O
based -X- _ O
on -X- _ O
System -X- _ O
1 -X- _ O
. -X- _ O

Pretrained -X- _ O
Vision -X- _ O
- -X- _ O
Language -X- _ O
Models -X- _ O
for -X- _ O
Cross -X- _ O
Modal -X- _ O
Matching -X- _ O
. -X- _ O
Owing -X- _ O
to -X- _ O
the -X- _ O
success -X- _ O
of -X- _ O
Transformer -X- _ O
( -X- _ O
Vaswani -X- _ O
et -X- _ O
al -X- _ O
. -X- _ O
, -X- _ O
2017 -X- _ O
) -X- _ O
architecture -X- _ O
equipped -X- _ O
with -X- _ O
pretrain -X- _ O
- -X- _ O
finetuning -X- _ O
( -X- _ O
Erhan -X- _ O
et -X- _ O
al -X- _ O
. -X- _ O
, -X- _ O
2010 -X- _ O
) -X- _ O
learning -X- _ O
method -X- _ O
, -X- _ O
pretrained -X- _ O
VLMs -X- _ O
have -X- _ O
made -X- _ O
a -X- _ O
remarkable -X- _ O
performance -X- _ O
in -X- _ O
cross -X- _ O
- -X- _ O
modal -X- _ O
matching -X- _ O
or -X- _ O
reasoning -X- _ O
tasks -X- _ O
( -X- _ O
Talmor -X- _ O
et -X- _ O
al -X- _ O
. -X- _ O
, -X- _ O
2021b -X- _ O
) -X- _ O
, -X- _ O
especially -X- _ O
image -X- _ O
- -X- _ O
text -X- _ O
retrieval -X- _ O
. -X- _ O
Early -X- _ O
pretrained -X- _ O
VLMs -X- _ O
utilize -X- _ O
BERT -X- _ O
( -X- _ O
Devlin -X- _ O
et -X- _ O
al -X- _ O
. -X- _ O
, -X- _ O
2019 -X- _ O
) -X- _ O
-like -X- _ O
single -X- _ O
encoder -X- _ O
architecture -X- _ O
to -X- _ O
encode -X- _ O
and -X- _ O
fuse -X- _ O
the -X- _ O
image -X- _ O
- -X- _ O
text -X- _ O
information -X- _ O
, -X- _ O
then -X- _ O
perform -X- _ O
image -X- _ O
- -X- _ O
text -X- _ O
reasoning -X- _ O
such -X- _ O
as -X- _ O
ViLBERT -X- _ O
( -X- _ O
Lu -X- _ O
et -X- _ O
al -X- _ O
. -X- _ O
, -X- _ O
2019 -X- _ O
) -X- _ O
, -X- _ O
VisualBERT -X- _ O
( -X- _ O
Li -X- _ O
et -X- _ O
al -X- _ O
. -X- _ O
, -X- _ O
2019 -X- _ O
) -X- _ O
, -X- _ O
and -X- _ O
Oscar -X- _ O
( -X- _ O
Li -X- _ O
et -X- _ O
al -X- _ O
. -X- _ O
, -X- _ O
2020b -X- _ O
) -X- _ O
. -X- _ O
In -X- _ O
addition -X- _ O
, -X- _ O
dual -X- _ O
- -X- _ O
encoder -X- _ O
architecture -X- _ O
such -X- _ O
as -X- _ O
CLIP -X- _ O
( -X- _ O
Radford -X- _ O
et -X- _ O
al -X- _ O
. -X- _ O
, -X- _ O
2021 -X- _ O
) -X- _ O
, -X- _ O
and -X- _ O
ALBERT -X- _ O
, -X- _ O
performs -X- _ O
better -X- _ O
than -X- _ O
single -X- _ O
- -X- _ O
encoder -X- _ O
architecture -X- _ O
on -X- _ O
image -X- _ O
- -X- _ O
text -X- _ O
matching -X- _ O
tasks -X- _ O
and -X- _ O
is -X- _ O
widely -X- _ O
used -X- _ O
in -X- _ O
industry -X- _ O
because -X- _ O
of -X- _ O
its -X- _ O
efficiency -X- _ O
. -X- _ O
Divide -X- _ O
- -X- _ O
and -X- _ O
- -X- _ O
Conquer -X- _ O
for -X- _ O
Question -X- _ O
Answering -X- _ O
. -X- _ O

Image -X- _ B-TaskName
retrieval -X- _ I-TaskName
from -X- _ O
contextual -X- _ O
descriptions -X- _ O
( -X- _ O
Krojer -X- _ O
et -X- _ O
al -X- _ O
. -X- _ O
, -X- _ O
2022 -X- _ O
) -X- _ O
aims -X- _ O
to -X- _ O
infer -X- _ O
the -X- _ O
correct -X- _ O
image -X- _ O
given -X- _ O
a -X- _ O
linguistically -X- _ O
complex -X- _ O
text -X- _ O
Y -X- _ O
= -X- _ O
( -X- _ O
y -X- _ O
1 -X- _ O
, -X- _ O
... -X- _ O
, -X- _ O
y -X- _ O
N -X- _ O
) -X- _ O
and -X- _ O
similar -X- _ O
images -X- _ O
I -X- _ O
= -X- _ O
( -X- _ O
I -X- _ O
1 -X- _ O
, -X- _ O
... -X- _ O
, -X- _ O
I -X- _ O
L -X- _ O
) -X- _ O
, -X- _ O
where -X- _ O
y -X- _ O
i -X- _ O
, -X- _ O
N -X- _ O
, -X- _ O
I -X- _ O
i -X- _ O
, -X- _ O
and -X- _ O
L -X- _ O
represent -X- _ O
the -X- _ O
i -X- _ O
th -X- _ O
token -X- _ O
, -X- _ O
the -X- _ O
total -X- _ O
length -X- _ O
of -X- _ O
text -X- _ O
, -X- _ O
i -X- _ O
th -X- _ O
image -X- _ O
, -X- _ O
and -X- _ O
the -X- _ O
number -X- _ O
of -X- _ O
images -X- _ O
, -X- _ O
respectively -X- _ O
. -X- _ O
We -X- _ O
propose -X- _ O
a -X- _ O
novel -X- _ O
divideand -X- _ O
- -X- _ O
conquer -X- _ O
reasoning -X- _ O
framework -X- _ O
to -X- _ O
tackle -X- _ O
such -X- _ O
a -X- _ O
task -X- _ O
. -X- _ O
It -X- _ O
consists -X- _ O
of -X- _ O
three -X- _ O
components -X- _ O
, -X- _ O
namely -X- _ O
, -X- _ O
Proposition -X- _ O
Generator -X- _ O
, -X- _ O
Visual -X- _ O
- -X- _ O
Linguistic -X- _ O
Interactor -X- _ O
, -X- _ O
and -X- _ O
Neural -X- _ O
- -X- _ O
Symbolic -X- _ O
Reasoner -X- _ O
, -X- _ O
which -X- _ O
are -X- _ O
coupled -X- _ O
and -X- _ O
trained -X- _ O
in -X- _ O
an -X- _ O
end -X- _ O
- -X- _ O
to -X- _ O
- -X- _ O
end -X- _ O
manner -X- _ O
. -X- _ O
Specifically -X- _ O
, -X- _ O
the -X- _ O
proposition -X- _ O
generator -X- _ O
divides -X- _ O
the -X- _ O
complex -X- _ O
description -X- _ O
into -X- _ O
multiple -X- _ O
proposition -X- _ O
sentences -X- _ O
, -X- _ O
allowing -X- _ O
it -X- _ O
to -X- _ O
convert -X- _ O
the -X- _ O
complex -X- _ O
matching -X- _ O
problem -X- _ O
to -X- _ O
simple -X- _ O
ones -X- _ O
. -X- _ O
Afterwards -X- _ O
, -X- _ O
the -X- _ O
visual -X- _ O
- -X- _ O
linguistic -X- _ O
interactor -X- _ O
achieves -X- _ O
the -X- _ O
interaction -X- _ O
between -X- _ O
decomposed -X- _ O
proposition -X- _ O
sentences -X- _ O
and -X- _ O
images -X- _ O
, -X- _ O
resembling -X- _ O
System -X- _ O
1 -X- _ O
, -X- _ O
to -X- _ O
perform -X- _ O
the -X- _ O
essential -X- _ O
analogical -X- _ O
reasoning -X- _ O
. -X- _ O
Subsequently -X- _ O
, -X- _ O
the -X- _ O
neural -X- _ O
- -X- _ O
symbolic -X- _ O
reasoner -X- _ O
that -X- _ O
relies -X- _ O
on -X- _ O
the -X- _ O
reasoning -X- _ O
state -X- _ O
output -X- _ O
by -X- _ O
the -X- _ O
visual -X- _ O
- -X- _ O
linguistic -X- _ O
interactor -X- _ O
resembles -X- _ O
System -X- _ O
2 -X- _ O
to -X- _ O
perform -X- _ O
logical -X- _ O
reasoning -X- _ O
. -X- _ O
Finally -X- _ O
, -X- _ O
we -X- _ O
also -X- _ O
combine -X- _ O
the -X- _ O
output -X- _ O
results -X- _ O
of -X- _ O
System -X- _ O
1 -X- _ O
and -X- _ O
System -X- _ O
2 -X- _ O
to -X- _ O
obtain -X- _ O
the -X- _ O
final -X- _ O
solution -X- _ O
. -X- _ O

where -X- _ O
h -X- _ O
I -X- _ O
is -X- _ O
the -X- _ O
randomly -X- _ O
initial -X- _ O
proposition -X- _ O
representations -X- _ O
. -X- _ O
Attention -X- _ O
and -X- _ O
FNN -X- _ O
calculation -X- _ O
subnetworks -X- _ O
are -X- _ O
identical -X- _ O
to -X- _ O
the -X- _ O
transformer -X- _ O
( -X- _ O
Vaswani -X- _ O
et -X- _ O
al -X- _ O
. -X- _ O
, -X- _ O
2017 -X- _ O
) -X- _ O
architecture -X- _ O
. -X- _ O
Different -X- _ O
from -X- _ O
the -X- _ O
transformer -X- _ O
, -X- _ O
we -X- _ O
let -X- _ O
the -X- _ O
output -X- _ O
of -X- _ O
Cross -X- _ O
- -X- _ O
Attention -X- _ O
layer -X- _ O
subtract -X- _ O
the -X- _ O
output -X- _ O
of -X- _ O
Self -X- _ O
- -X- _ O
Attention -X- _ O
layer -X- _ O
, -X- _ O
aiming -X- _ O
to -X- _ O
achieve -X- _ O
information -X- _ O
differences -X- _ O
across -X- _ O
propositions -X- _ O
. -X- _ O

By -X- _ O
doing -X- _ O
the -X- _ O
same -X- _ O
two -X- _ O
- -X- _ O
layer -X- _ O
calculation -X- _ O
, -X- _ O
we -X- _ O
obtain -X- _ O
ten -X- _ O
global -X- _ O
hidden -X- _ O
states -X- _ O
of -X- _ O
simple -X- _ O
propositions -X- _ O
. -X- _ O
Due -X- _ O
to -X- _ O
context -X- _ O
containing -X- _ O
different -X- _ O
numbers -X- _ O
of -X- _ O
simple -X- _ O
proposition -X- _ O
, -X- _ O
we -X- _ O
use -X- _ O
a -X- _ O
MLP -X- _ O
to -X- _ O
predict -X- _ O
the -X- _ O
target -X- _ O
number -X- _ O
of -X- _ O
simple -X- _ O
proposition -X- _ O
sentences -X- _ O
. -X- _ O
It -X- _ O
only -X- _ O
attends -X- _ O
to -X- _ O
the -X- _ O
global -X- _ O
hidden -X- _ O
state -X- _ O
h -X- _ O
cls -X- _ O
of -X- _ O
compound -X- _ O
proposition -X- _ O
text -X- _ O
. -X- _ O
Suppose -X- _ O
that -X- _ O
the -X- _ O
predicted -X- _ O
number -X- _ O
M -X- _ O
of -X- _ O
simple -X- _ O
propositions -X- _ O
is -X- _ O
3 -X- _ O
( -X- _ O
same -X- _ O
as -X- _ O
Figure -X- _ O
2 -X- _ O
) -X- _ O
, -X- _ O
we -X- _ O
adopt -X- _ O
the -X- _ O
first -X- _ O
- -X- _ O
three -X- _ O
hidden -X- _ O
states -X- _ O
of -X- _ O
the -X- _ O
semantic -X- _ O
parsing -X- _ O
module -X- _ O
as -X- _ O
the -X- _ O
global -X- _ O
representation -X- _ O
of -X- _ O
the -X- _ O
targeted -X- _ O
simple -X- _ O
proposition -X- _ O
. -X- _ O
As -X- _ O
shown -X- _ O
in -X- _ O
Figure -X- _ O
2 -X- _ O
, -X- _ O
for -X- _ O
explaining -X- _ O
what -X- _ O
simple -X- _ O
propositions -X- _ O
represent -X- _ O
, -X- _ O
we -X- _ O
also -X- _ O
use -X- _ O
the -X- _ O
decoder -X- _ O
of -X- _ O
BART -X- _ O
to -X- _ O
generate -X- _ O
the -X- _ O
simple -X- _ O
proposition -X- _ O
sentence -X- _ O
with -X- _ O
only -X- _ O
attending -X- _ O
to -X- _ O
their -X- _ O
global -X- _ O
representations -X- _ O
. -X- _ O

After -X- _ O
obtaining -X- _ O
the -X- _ O
global -X- _ O
representations -X- _ O
of -X- _ O
simple -X- _ O
proposition -X- _ O
sentences -X- _ O
, -X- _ O
we -X- _ O
introduce -X- _ O
the -X- _ O
visuallinguistic -X- _ O
interactor -X- _ O
to -X- _ O
mine -X- _ O
the -X- _ O
interaction -X- _ O
of -X- _ O
image -X- _ O
- -X- _ O
proposition -X- _ O
pairs -X- _ O
. -X- _ O
Specifically -X- _ O
, -X- _ O
we -X- _ O
use -X- _ O
a -X- _ O
pretrained -X- _ O
visual -X- _ O
encoder -X- _ O
to -X- _ O
obtain -X- _ O
the -X- _ O
image -X- _ O
encoding -X- _ O
representations -X- _ O
H -X- _ O
I -X- _ O
= -X- _ O
( -X- _ O
h -X- _ O
I -X- _ O
1 -X- _ O
, -X- _ O
... -X- _ O
, -X- _ O
h -X- _ O
I -X- _ O
L -X- _ O
) -X- _ O
and -X- _ O
fuse -X- _ O
them -X- _ O
with -X- _ O
the -X- _ O
simple -X- _ O
proposition -X- _ O
representation -X- _ O
via -X- _ O
the -X- _ O
dot -X- _ O
- -X- _ O
product -X- _ O
way -X- _ O
( -X- _ O
as -X- _ O
the -X- _ O
" -X- _ O
F -X- _ O
" -X- _ O
shown -X- _ O
in -X- _ O
Figure -X- _ O
2 -X- _ O
) -X- _ O
. -X- _ O
The -X- _ O
two -X- _ O
- -X- _ O
modal -X- _ O
fusion -X- _ O
process -X- _ O
is -X- _ O
H -X- _ O
( -X- _ O
p -X- _ O
) -X- _ O
= -X- _ O
λ -X- _ O
• -X- _ O
Norm -X- _ O
( -X- _ O
P -X- _ O
) -X- _ O
• -X- _ O
Norm -X- _ O
( -X- _ O
H -X- _ O
I -X- _ O
) -X- _ O
, -X- _ O
where -X- _ O
λ -X- _ B-HyperparameterName
is -X- _ O
the -X- _ O
hyperparameter -X- _ O
set -X- _ O
to -X- _ O
enlarge -X- _ O
the -X- _ O
scale -X- _ O
of -X- _ O
fused -X- _ O
vectors -X- _ O
. -X- _ O
We -X- _ O
denote -X- _ O
the -X- _ O
fused -X- _ O
sequence -X- _ O
representation -X- _ O
of -X- _ O
proposition -X- _ O
- -X- _ O
image -X- _ O
pairs -X- _ O
to -X- _ O
H -X- _ O
( -X- _ O
p -X- _ O
) -X- _ O
= -X- _ O
( -X- _ O
H -X- _ O
( -X- _ O
p -X- _ O
1 -X- _ O
) -X- _ O
, -X- _ O
... -X- _ O
, -X- _ O
H -X- _ O
( -X- _ O
p -X- _ O
M -X- _ O
) -X- _ O
) -X- _ O
where -X- _ O
H -X- _ O
( -X- _ O
p -X- _ O
1 -X- _ O
) -X- _ O
indicates -X- _ O
the -X- _ O
sequential -X- _ O
representation -X- _ O
of -X- _ O
first -X- _ O
proposition -X- _ O
combined -X- _ O
with -X- _ O
images -X- _ O
. -X- _ O

Then -X- _ O
, -X- _ O
we -X- _ O
employ -X- _ O
a -X- _ O
two -X- _ O
- -X- _ O
layer -X- _ O
transformer -X- _ O
to -X- _ O
perform -X- _ O
the -X- _ O
contextual -X- _ O
information -X- _ O
interaction -X- _ O
for -X- _ O
fused -X- _ O
sequential -X- _ O
representations -X- _ O
H -X- _ O
( -X- _ O
p -X- _ O
) -X- _ O
and -X- _ O
obtain -X- _ O
the -X- _ O
initial -X- _ O
reasoning -X- _ O
states -X- _ O
of -X- _ O
simple -X- _ O
proposition -X- _ O
on -X- _ O
images -X- _ O
. -X- _ O
Considering -X- _ O
the -X- _ O
incorrectness -X- _ O
or -X- _ O
information -X- _ O
loss -X- _ O
of -X- _ O
simple -X- _ O
proposition -X- _ O
representation -X- _ O
obtained -X- _ O
by -X- _ O
the -X- _ O
proposition -X- _ O
generator -X- _ O
, -X- _ O
we -X- _ O
introduce -X- _ O
a -X- _ O
MLP -X- _ O
- -X- _ O
based -X- _ O
modifier -X- _ O
to -X- _ O
incorporate -X- _ O
the -X- _ O
reasoning -X- _ O
state -X- _ O
of -X- _ O
compound -X- _ O
proposition -X- _ O
text -X- _ O
to -X- _ O
enhance -X- _ O
previous -X- _ O
initial -X- _ O
reasoning -X- _ O
states -X- _ O
of -X- _ O
simple -X- _ O
propositions -X- _ O
. -X- _ O
The -X- _ O
whole -X- _ O
process -X- _ O
is -X- _ O
performed -X- _ O
as -X- _ O
Eq -X- _ O
. -X- _ O
2 -X- _ O
, -X- _ O

where -X- _ O
H -X- _ O
C -X- _ O
indicates -X- _ O
the -X- _ O
fusion -X- _ O
information -X- _ O
of -X- _ O
the -X- _ O
compound -X- _ O
proposition -X- _ O
text -X- _ O
and -X- _ O
images -X- _ O
, -X- _ O
gained -X- _ O
by -X- _ O
the -X- _ O
cross -X- _ O
- -X- _ O
modal -X- _ O
encoder -X- _ O
( -X- _ O
arr -X- _ O
. -X- _ O
cross -X- _ O
encoder -X- _ O
as -X- _ O
shown -X- _ O
in -X- _ O
Figure -X- _ O
2 -X- _ O
) -X- _ O
. -X- _ O
W -X- _ O
M -X- _ O
1 -X- _ O
∈ -X- _ O
R -X- _ O
2d×d -X- _ O
and -X- _ O
W -X- _ O
M -X- _ O
2 -X- _ O
∈ -X- _ O
R -X- _ O
2d×2d -X- _ O
are -X- _ O
learnable -X- _ O
parameters -X- _ O
. -X- _ O
Before -X- _ O
feeding -X- _ O
H -X- _ O
( -X- _ O
p -X- _ O
) -X- _ O
into -X- _ O
the -X- _ O
transformer -X- _ O
, -X- _ O
we -X- _ O
introduce -X- _ O
the -X- _ O
learnable -X- _ O
position -X- _ O
embeddings -X- _ O
P -X- _ O
E -X- _ O
to -X- _ O
facilitate -X- _ O
it -X- _ O
pay -X- _ O
attention -X- _ O
to -X- _ O
the -X- _ O
contextual -X- _ O
information -X- _ O
across -X- _ O
images -X- _ O
. -X- _ O
After -X- _ O
obtaining -X- _ O
the -X- _ O
final -X- _ O
reasoning -X- _ O
state -X- _ O
in -X- _ O
System -X- _ O
1 -X- _ O
, -X- _ O
we -X- _ O
adopt -X- _ O
a -X- _ O
linear -X- _ O
prediction -X- _ O
head -X- _ O
to -X- _ O
produce -X- _ O
the -X- _ O
confidence -X- _ O
score -X- _ O
of -X- _ O
each -X- _ O
proposition -X- _ O
to -X- _ O
images -X- _ O
, -X- _ O
which -X- _ O
are -X- _ O
defined -X- _ O
as -X- _ O

For -X- _ O
complex -X- _ O
reasoning -X- _ O
problems -X- _ O
, -X- _ O
the -X- _ O
logical -X- _ O
reasoning -X- _ O
process -X- _ O
usually -X- _ O
plays -X- _ O
a -X- _ O
more -X- _ O
significant -X- _ O
role -X- _ O
for -X- _ O
intelligent -X- _ O
machines -X- _ O
and -X- _ O
human -X- _ O
reasoning -X- _ O
( -X- _ O
Bengio -X- _ O
, -X- _ O
2019 -X- _ O
) -X- _ O
, -X- _ O
which -X- _ O
the -X- _ O
visual -X- _ O
- -X- _ O
linguistic -X- _ O
interactor -X- _ O
is -X- _ O
not -X- _ O
capable -X- _ O
of -X- _ O
. -X- _ O
Instead -X- _ O
of -X- _ O
combining -X- _ O
the -X- _ O
inferring -X- _ O
results -X- _ O
in -X- _ O
System -X- _ O
1 -X- _ O
via -X- _ O
rule -X- _ O
- -X- _ O
based -X- _ O
methods -X- _ O
such -X- _ O
as -X- _ O
mean -X- _ O
pooling -X- _ O
, -X- _ O
inspired -X- _ O
by -X- _ O
Shi -X- _ O
et -X- _ O
al -X- _ O
. -X- _ O
( -X- _ O
2020 -X- _ O
) -X- _ O
; -X- _ O
, -X- _ O
we -X- _ O
devise -X- _ O
a -X- _ O
learnable -X- _ O
Neural -X- _ O
- -X- _ O
Symbolic -X- _ O
Reasoner -X- _ O
( -X- _ O
NSR -X- _ O
) -X- _ O
to -X- _ O
perform -X- _ O
logical -X- _ O
reasoning -X- _ O
based -X- _ O
on -X- _ O
System -X- _ O
1 -X- _ O
as -X- _ O
shown -X- _ O
in -X- _ O
Figure -X- _ O
2 -X- _ O
. -X- _ O
As -X- _ O
depicted -X- _ O
in -X- _ O
Figure -X- _ O
3 -X- _ O
, -X- _ O
it -X- _ O
contains -X- _ O
a -X- _ O
negation -X- _ O
executor -X- _ O
to -X- _ O
obtain -X- _ O
the -X- _ O
negational -X- _ O
reasoning -X- _ O
states -X- _ O
and -X- _ O
a -X- _ O
conjunction -X- _ O
operation -X- _ O
to -X- _ O
acquire -X- _ O
the -X- _ O
result -X- _ O
of -X- _ O
logical -X- _ O
reasoning -X- _ O
with -X- _ O
attention -X- _ O
to -X- _ O
the -X- _ O
positive -X- _ O
and -X- _ O
negational -X- _ O
reasoning -X- _ O
information -X- _ O
. -X- _ O

Negation -X- _ O
Executor -X- _ O
. -X- _ O
The -X- _ O
negation -X- _ O
executor -X- _ O
is -X- _ O
a -X- _ O
module -X- _ O
that -X- _ O
takes -X- _ O
the -X- _ O
reasoning -X- _ O
state -X- _ O
of -X- _ O
a -X- _ O
simple -X- _ O
proposition -X- _ O
as -X- _ O
input -X- _ O
and -X- _ O
produces -X- _ O
the -X- _ O
corresponding -X- _ O
reasoning -X- _ O
state -X- _ O
of -X- _ O
its -X- _ O
negation -X- _ O
as -X- _ O
output -X- _ O
. -X- _ O
Its -X- _ O
aim -X- _ O
is -X- _ O
to -X- _ O
obtain -X- _ O
useful -X- _ O
cross -X- _ O
- -X- _ O
modal -X- _ O
reasoning -X- _ O
states -X- _ O
for -X- _ O
the -X- _ O
negation -X- _ O
of -X- _ O
a -X- _ O
proposition -X- _ O
. -X- _ O
We -X- _ O
regard -X- _ O
H -X- _ O
S -X- _ O
1 -X- _ O
as -X- _ O
the -X- _ O
positive -X- _ O
reasoning -X- _ O
state -X- _ O
and -X- _ O
use -X- _ O
a -X- _ O
two -X- _ O
- -X- _ O
layer -X- _ O
MLP -X- _ O
with -X- _ O
the -X- _ O
ReLU -X- _ O
activation -X- _ O
function -X- _ O
to -X- _ O
obtain -X- _ O
the -X- _ O
negational -X- _ O
reasoning -X- _ O
state -X- _ O
. -X- _ O
The -X- _ O
calculation -X- _ O
process -X- _ O
is -X- _ O
given -X- _ O
in -X- _ O
Eq -X- _ O
. -X- _ O
3 -X- _ O
, -X- _ O

are -X- _ O
learnable -X- _ O
parameters -X- _ O
. -X- _ O
We -X- _ O
define -X- _ O
the -X- _ O
output -X- _ O
of -X- _ O
negation -X- _ O
executor -X- _ O
to -X- _ O
H -X- _ O
N -X- _ O
= -X- _ O
( -X- _ O
h -X- _ O
− -X- _ O
1 -X- _ O
, -X- _ O
... -X- _ O
, -X- _ O
h -X- _ O
− -X- _ O
M -X- _ O
) -X- _ O
, -X- _ O
contrast -X- _ O
to -X- _ O
H -X- _ O
S -X- _ O
1 -X- _ O
.The -X- _ O
negational -X- _ O
proposition -X- _ O
has -X- _ O
a -X- _ O
different -X- _ O
cross -X- _ O
- -X- _ O
modal -X- _ O
reasoning -X- _ O
state -X- _ O
H -X- _ O
N -X- _ O
than -X- _ O
the -X- _ O
corresponding -X- _ O
positive -X- _ O
proposition -X- _ O
H -X- _ O
S -X- _ O
1 -X- _ O
. -X- _ O
We -X- _ O
use -X- _ O
the -X- _ O
same -X- _ O
linear -X- _ O
prediction -X- _ O
head -X- _ O
as -X- _ O
System -X- _ O
1 -X- _ O
to -X- _ O
produce -X- _ O
the -X- _ O
corresponding -X- _ O
confidence -X- _ O
score -X- _ O
on -X- _ O
images -X- _ O
, -X- _ O
which -X- _ O
are -X- _ O
presented -X- _ O
to -X- _ O
P -X- _ O
N -X- _ O
= -X- _ O
( -X- _ O
p -X- _ O
− -X- _ O
1 -X- _ O
, -X- _ O
... -X- _ O
, -X- _ O
p -X- _ O
− -X- _ O
M -X- _ O
) -X- _ O
. -X- _ O
To -X- _ O
make -X- _ O
the -X- _ O
negation -X- _ O
executor -X- _ O
effective -X- _ O
, -X- _ O
we -X- _ O
will -X- _ O
define -X- _ O
a -X- _ O
negational -X- _ O
feedback -X- _ O
loss -X- _ O
to -X- _ O
locally -X- _ O
optimize -X- _ O
it -X- _ O
. -X- _ O

To -X- _ O
make -X- _ O
the -X- _ O
proposition -X- _ O
generator -X- _ O
perform -X- _ O
proposition -X- _ O
decomposition -X- _ O
and -X- _ O
generation -X- _ O
effectively -X- _ O
, -X- _ O
we -X- _ O
train -X- _ O
it -X- _ O
on -X- _ O
a -X- _ O
large -X- _ O
- -X- _ O
scale -X- _ O
corpus -X- _ O
solely -X- _ O
and -X- _ O
then -X- _ O
train -X- _ O
the -X- _ O
whole -X- _ O
NDCR -X- _ B-MethodName
framework -X- _ O
on -X- _ O
the -X- _ O
specific -X- _ O
training -X- _ O
data -X- _ O
. -X- _ O
The -X- _ O
two -X- _ O
training -X- _ O
phases -X- _ O
are -X- _ O
as -X- _ O
follows -X- _ O
: -X- _ O
Phase -X- _ O
1 -X- _ O
. -X- _ O
We -X- _ O
first -X- _ O
pretrain -X- _ O
the -X- _ O
proposition -X- _ O
generator -X- _ O
on -X- _ O
the -X- _ O
released -X- _ O
large -X- _ O
- -X- _ O
scale -X- _ O
complex -X- _ O
text -X- _ O
simplification -X- _ O
data -X- _ O
set -X- _ O
MinWikiSplit -X- _ O
( -X- _ O
Niklaus -X- _ O
et -X- _ O
al -X- _ O
. -X- _ O
, -X- _ O
2019 -X- _ O
) -X- _ O
, -X- _ O
which -X- _ O
is -X- _ O
composed -X- _ O
of -X- _ O
203 -X- _ O
K -X- _ O
pairs -X- _ O
of -X- _ O
aligned -X- _ O
complex -X- _ O
source -X- _ O
and -X- _ O
simplified -X- _ O
target -X- _ O
sentences -X- _ O
. -X- _ O
We -X- _ O
adopt -X- _ O
the -X- _ O
cross -X- _ O
entropy -X- _ O
generation -X- _ O
loss -X- _ O
L -X- _ O
g -X- _ O
for -X- _ O
the -X- _ O
decoder -X- _ O
output -X- _ O
. -X- _ O
Similar -X- _ O
to -X- _ O
SimCSE -X- _ O
, -X- _ O
we -X- _ O
employ -X- _ O
the -X- _ O
contrastive -X- _ O
learning -X- _ O
loss -X- _ O
L -X- _ O
c -X- _ O
to -X- _ O
make -X- _ O
the -X- _ O
global -X- _ O
representation -X- _ O
of -X- _ O
simple -X- _ O
proposition -X- _ O
sentence -X- _ O
different -X- _ O
. -X- _ O
In -X- _ O
addition -X- _ O
, -X- _ O
we -X- _ O
use -X- _ O
a -X- _ O
crossentropy -X- _ O
multi -X- _ O
- -X- _ O
label -X- _ O
classification -X- _ O
loss -X- _ O
L -X- _ O
p -X- _ O
to -X- _ O
train -X- _ O
the -X- _ O
prediction -X- _ O
head -X- _ O
of -X- _ O
numbers -X- _ O
of -X- _ O
propositions -X- _ O
, -X- _ O
where -X- _ O
the -X- _ O
label -X- _ O
is -X- _ O
the -X- _ O
number -X- _ O
of -X- _ O
simple -X- _ O
sentences -X- _ O
in -X- _ O
the -X- _ O
pretraining -X- _ O
corpus -X- _ O
. -X- _ O
The -X- _ O
whole -X- _ O
training -X- _ O
loss -X- _ O
: -X- _ O

Phase -X- _ O
2 -X- _ O
. -X- _ O
While -X- _ O
training -X- _ O
NDCR -X- _ B-MethodName
, -X- _ O
we -X- _ O
employ -X- _ O
the -X- _ O
proposition -X- _ O
sentence -X- _ O
- -X- _ O
image -X- _ O
confidence -X- _ O
score -X- _ O
to -X- _ O
calculate -X- _ O
the -X- _ O
classification -X- _ O
loss -X- _ O
. -X- _ O
The -X- _ O
loss -X- _ O
will -X- _ O
cover -X- _ O
the -X- _ O
output -X- _ O
of -X- _ O
System -X- _ O
1 -X- _ O
, -X- _ O
System -X- _ O
2 -X- _ O
and -X- _ O
final -X- _ O
solution -X- _ O
, -X- _ O
which -X- _ O
is -X- _ O
defined -X- _ O
as -X- _ O
follows -X- _ O
: -X- _ O

where -X- _ O
KL -X- _ O
indicates -X- _ O
the -X- _ O
K -X- _ O
- -X- _ O
L -X- _ O
Divergence -X- _ O
( -X- _ O
Kullback -X- _ O
and -X- _ O
Leibler -X- _ O
, -X- _ O
1951 -X- _ O
) -X- _ O
. -X- _ O
θ -X- _ B-HyperparameterName
is -X- _ O
a -X- _ O
super -X- _ O
- -X- _ O
parameter -X- _ O
used -X- _ O
to -X- _ O
expand -X- _ O
the -X- _ O
positive -X- _ O
and -X- _ O
negational -X- _ O
interval -X- _ O
, -X- _ O
which -X- _ O
is -X- _ O
set -X- _ O
to -X- _ O
0.2 -X- _ B-HyperparameterValue
. -X- _ O
Hence -X- _ O
, -X- _ O
the -X- _ O
whole -X- _ O
optimization -X- _ O
target -X- _ O
is -X- _ O
L -X- _ O
match -X- _ O
+ -X- _ O
L -X- _ O
neg -X- _ O
. -X- _ O

We -X- _ O
conduct -X- _ O
extensive -X- _ O
experiments -X- _ O
on -X- _ O
a -X- _ O
challenging -X- _ O
data -X- _ O
set -X- _ O
IMAGECODE -X- _ B-DatasetName
( -X- _ O
Krojer -X- _ O
et -X- _ O
al -X- _ O
. -X- _ O
, -X- _ O
2022 -X- _ O
) -X- _ O
, -X- _ O
which -X- _ O
contains -X- _ O
94,020 -X- _ O
images -X- _ O
, -X- _ O
and -X- _ O
they -X- _ O
are -X- _ O
divided -X- _ O
into -X- _ O
9,402 -X- _ O
sets -X- _ O
. -X- _ O
The -X- _ O
overall -X- _ O
images -X- _ O
are -X- _ O
collected -X- _ O
from -X- _ O
four -X- _ O
released -X- _ O
data -X- _ O
sets -X- _ O
: -X- _ O
MSR -X- _ O
- -X- _ O
VTT -X- _ O
( -X- _ O
Xu -X- _ O
et -X- _ O
al -X- _ O
. -X- _ O
, -X- _ O
2016 -X- _ O
) -X- _ O
, -X- _ O
Video -X- _ O
- -X- _ O
Storytelling -X- _ O
( -X- _ O
Li -X- _ O
et -X- _ O
al -X- _ O
. -X- _ O
, -X- _ O
2020a -X- _ O
) -X- _ O
, -X- _ O
YouCook -X- _ O
( -X- _ O
Das -X- _ O
et -X- _ O
al -X- _ O
. -X- _ O
, -X- _ O
2013 -X- _ O
) -X- _ O
, -X- _ O
and -X- _ O
Open -X- _ O
Images -X- _ O
V6 -X- _ O
( -X- _ O
Kuznetsova -X- _ O
et -X- _ O
al -X- _ O
. -X- _ O
, -X- _ O
2020 -X- _ O
) -X- _ O
. -X- _ O
It -X- _ O
consists -X- _ O
of -X- _ O
21,202 -X- _ O
human -X- _ O
- -X- _ O
writing -X- _ O
complex -X- _ O
descriptions -X- _ O
and -X- _ O
manually -X- _ O
labelling -X- _ O
corresponding -X- _ O
golden -X- _ O
images -X- _ O
, -X- _ O
which -X- _ O
are -X- _ O
divided -X- _ O
into -X- _ O
16,594 -X- _ O
, -X- _ O
2,302 -X- _ O
, -X- _ O
and -X- _ O
2,306 -X- _ O
for -X- _ O
training -X- _ O
, -X- _ O
validating -X- _ O
, -X- _ O
and -X- _ O
testing -X- _ O
, -X- _ O
respectively -X- _ O
. -X- _ O
The -X- _ O
image -X- _ O
sources -X- _ O
in -X- _ O
the -X- _ O
overall -X- _ O
data -X- _ O
set -X- _ O
include -X- _ O
video -X- _ O
frames -X- _ O
and -X- _ O
static -X- _ O
images -X- _ O
. -X- _ O

We -X- _ O
compare -X- _ O
NDCR -X- _ B-MethodName
with -X- _ O
various -X- _ O
types -X- _ O
of -X- _ O
pretrained -X- _ O
VLMs -X- _ O
and -X- _ O
other -X- _ O
designed -X- _ O
models -X- _ O
based -X- _ O
on -X- _ O
the -X- _ O
specific -X- _ O
condition -X- _ O
of -X- _ O
this -X- _ O
task -X- _ O
. -X- _ O
Specifically -X- _ O
, -X- _ O
ViLBERT -X- _ B-MethodName
( -X- _ O
Lu -X- _ O
et -X- _ O
al -X- _ O
. -X- _ O
, -X- _ O
2019 -X- _ O
) -X- _ O
is -X- _ O
a -X- _ O
cross -X- _ O
encoder -X- _ O
where -X- _ O
language -X- _ O
and -X- _ O
vision -X- _ O
interact -X- _ O
in -X- _ O
the -X- _ O
transitional -X- _ O
layer -X- _ O
via -X- _ O
cross -X- _ O
attention -X- _ O
calculation -X- _ O
. -X- _ O
CLIP -X- _ B-MethodName
( -X- _ O
Radford -X- _ O
et -X- _ O
al -X- _ O
. -X- _ O
, -X- _ O
2021 -X- _ O
) -X- _ O
is -X- _ O
a -X- _ O
two -X- _ O
- -X- _ O
stream -X- _ O
vision -X- _ O
- -X- _ O
language -X- _ O
encoder -X- _ O
with -X- _ O
two -X- _ O
independent -X- _ O
visual -X- _ O
and -X- _ O
textual -X- _ O
encoders -X- _ O
. -X- _ O
UNITER -X- _ B-MethodName
) -X- _ O
is -X- _ O
a -X- _ O
singlestream -X- _ O
encoder -X- _ O
where -X- _ O
visual -X- _ O
representations -X- _ O
and -X- _ O
text -X- _ O
tokens -X- _ O
are -X- _ O
concatenated -X- _ O
and -X- _ O
interact -X- _ O
via -X- _ O
the -X- _ O
same -X- _ O
transformer -X- _ O
. -X- _ O
OFA -X- _ O
) -X- _ O
is -X- _ O
a -X- _ O
unified -X- _ O
cross -X- _ O
- -X- _ O
modal -X- _ O
and -X- _ O
unimodal -X- _ O
encoder -X- _ O
and -X- _ O
has -X- _ O
achieved -X- _ O
impressive -X- _ O
performance -X- _ O
on -X- _ O
multiple -X- _ O
cross -X- _ O
modal -X- _ O
reasoning -X- _ O
tasks -X- _ O
. -X- _ O
Krojer -X- _ O
et -X- _ O
al -X- _ O
. -X- _ O
( -X- _ O
2022 -X- _ O
) -X- _ O
also -X- _ O
designed -X- _ O
a -X- _ O
contextual -X- _ O
module -X- _ O
to -X- _ O
improve -X- _ O
the -X- _ O
interaction -X- _ O
across -X- _ O
different -X- _ O
text -X- _ O
- -X- _ O
image -X- _ O
fusion -X- _ O
representations -X- _ O
, -X- _ O
achieving -X- _ O
state -X- _ O
- -X- _ O
of -X- _ O
- -X- _ O
the -X- _ O
- -X- _ O
art -X- _ O
performance -X- _ O
. -X- _ O

The -X- _ O
L -X- _ B-HyperparameterName
, -X- _ O
λ -X- _ B-HyperparameterName
, -X- _ O
and -X- _ O
d -X- _ B-HyperparameterName
equal -X- _ O
10 -X- _ B-HyperparameterValue
, -X- _ O
1000 -X- _ B-HyperparameterValue
, -X- _ O
and -X- _ O
512 -X- _ B-HyperparameterValue
, -X- _ O
respectively -X- _ O
. -X- _ O
For -X- _ O
the -X- _ O
proposition -X- _ O
generator -X- _ O
, -X- _ O
we -X- _ O
adopt -X- _ O
a -X- _ O
two -X- _ O
- -X- _ O
layer -X- _ O
semantic -X- _ O
parsing -X- _ O
module -X- _ O
and -X- _ O
the -X- _ O
pretrained -X- _ O
parameters -X- _ O
of -X- _ O
BART -X- _ O
- -X- _ O
base -X- _ O
version -X- _ O
. -X- _ O
We -X- _ O
set -X- _ O
the -X- _ O
maximum -X- _ B-HyperparameterName
number -X- _ I-HyperparameterName
of -X- _ I-HyperparameterName
propositions -X- _ I-HyperparameterName
to -X- _ O
10 -X- _ B-HyperparameterValue
and -X- _ O
trained -X- _ O
the -X- _ O
proposition -X- _ O
generator -X- _ O
for -X- _ O
15 -X- _ B-HyperparameterValue
epochs -X- _ B-HyperparameterName
on -X- _ O
the -X- _ O
MinWikiSplit -X- _ O
data -X- _ O
set -X- _ O
. -X- _ O
In -X- _ O
addition -X- _ O
, -X- _ O
we -X- _ O
set -X- _ O
the -X- _ O
depth -X- _ B-HyperparameterName
of -X- _ I-HyperparameterName
transformer -X- _ I-HyperparameterName
block -X- _ I-HyperparameterName
to -X- _ O
2 -X- _ B-HyperparameterValue
in -X- _ O
the -X- _ O
visuallinguistic -X- _ O
interactor -X- _ O
and -X- _ O
utilized -X- _ O
the -X- _ O
finetuned -X- _ O
visual -X- _ O
encoder -X- _ O
of -X- _ O
CLIP -X- _ O
( -X- _ O
ViT -X- _ O
- -X- _ O
B -X- _ O
/ -X- _ O
16 -X- _ O
) -X- _ O
to -X- _ O
encode -X- _ O
images -X- _ O
. -X- _ O
For -X- _ O
the -X- _ O
cross -X- _ O
encoder -X- _ O
, -X- _ O
we -X- _ O
adopt -X- _ O
the -X- _ O
OFA -X- _ O
- -X- _ O
large -X- _ O
architecture -X- _ O
and -X- _ O
first -X- _ O
finetune -X- _ O
it -X- _ O
for -X- _ O
two -X- _ B-HyperparameterValue
epochs -X- _ B-HyperparameterName
before -X- _ O
training -X- _ O
the -X- _ O
overall -X- _ O
structure -X- _ O
of -X- _ O
NDCR -X- _ B-MethodName
. -X- _ O
We -X- _ O
froze -X- _ O
the -X- _ O
cross -X- _ O
encoder -X- _ O
, -X- _ O
proposition -X- _ O
generator -X- _ O
, -X- _ O
and -X- _ O
visual -X- _ O
encoder -X- _ O
to -X- _ O
prevent -X- _ O
overfitting -X- _ O
while -X- _ O
training -X- _ O
NDCR -X- _ B-MethodName
. -X- _ O
While -X- _ O
training -X- _ O
all -X- _ O
models -X- _ O
, -X- _ O
we -X- _ O
set -X- _ O
the -X- _ O
batch -X- _ B-HyperparameterName
size -X- _ I-HyperparameterName
, -X- _ O
initial -X- _ O
learning -X- _ B-HyperparameterName
rate -X- _ I-HyperparameterName
, -X- _ O
and -X- _ O
dropout -X- _ O
rate -X- _ O
to -X- _ O
36 -X- _ B-HyperparameterValue
, -X- _ O
6 -X- _ B-HyperparameterValue
× -X- _ I-HyperparameterValue
1e -X- _ I-HyperparameterValue
−5 -X- _ I-HyperparameterValue
, -X- _ O
and -X- _ O
0.1 -X- _ B-HyperparameterValue
, -X- _ O
respectively -X- _ O
. -X- _ O
The -X- _ O
maximum -X- _ O
training -X- _ O
epoch -X- _ B-HyperparameterName
is -X- _ O
set -X- _ O
to -X- _ O
30 -X- _ B-HyperparameterValue
, -X- _ O
and -X- _ O
we -X- _ O
employ -X- _ O
the -X- _ O
Adam -X- _ B-HyperparameterValue
Optimizer -X- _ B-HyperparameterName
( -X- _ O
Kingma -X- _ O
and -X- _ O
Ba -X- _ O
, -X- _ O
2014 -X- _ O
) -X- _ O
with -X- _ O
the -X- _ O
initial -X- _ O
learning -X- _ O
rate -X- _ O
declining -X- _ O
linearly -X- _ B-HyperparameterValue
to -X- _ O
train -X- _ O
all -X- _ O
models -X- _ O
. -X- _ O
We -X- _ O
use -X- _ O
the -X- _ O
validation -X- _ O
set -X- _ O
to -X- _ O
select -X- _ O
the -X- _ O
best -X- _ O
- -X- _ O
performing -X- _ O
model -X- _ O
. -X- _ O

Overall -X- _ O
Performance -X- _ O
. -X- _ O
We -X- _ O
present -X- _ O
the -X- _ O
performance -X- _ O
of -X- _ O
NDCR -X- _ B-MethodName
and -X- _ O
comparative -X- _ O
models -X- _ O
on -X- _ O
the -X- _ O
test -X- _ O
set -X- _ O
in -X- _ O
Table -X- _ O
1 -X- _ O
. -X- _ O
' -X- _ O
† -X- _ O
' -X- _ O
indicates -X- _ O
that -X- _ O
the -X- _ O
pretrained -X- _ O
VLMs -X- _ O
are -X- _ O
equipped -X- _ O
with -X- _ O
the -X- _ O
contextual -X- _ O
module -X- _ O
and -X- _ O
temporal -X- _ O
embedding -X- _ O
to -X- _ O
enhance -X- _ O
the -X- _ O
contextual -X- _ O
semantic -X- _ O
interaction -X- _ O
across -X- _ O
similar -X- _ O
images -X- _ O
. -X- _ O
This -X- _ O
variant -X- _ O
shows -X- _ O
its -X- _ O
effectiveness -X- _ O
on -X- _ O
the -X- _ O
case -X- _ O
of -X- _ O
video -X- _ O
frame -X- _ O
according -X- _ O
to -X- _ O
the -X- _ O
comparative -X- _ O
performances -X- _ O
such -X- _ O
as -X- _ O
CLIP -X- _ B-MethodName
vs. -X- _ O
CLIP -X- _ O
† -X- _ O
. -X- _ O
video -X- _ O
clips -X- _ O
, -X- _ O
which -X- _ O
may -X- _ O
be -X- _ O
attributed -X- _ O
to -X- _ O
the -X- _ O
high -X- _ O
similarity -X- _ O
across -X- _ O
video -X- _ O
frames -X- _ O
. -X- _ O
Hence -X- _ O
, -X- _ O
there -X- _ O
is -X- _ O
a -X- _ O
big -X- _ O
room -X- _ O
to -X- _ O
improve -X- _ O
the -X- _ O
whole -X- _ O
performance -X- _ O
on -X- _ O
the -X- _ O
challenging -X- _ O
multi -X- _ O
- -X- _ O
modal -X- _ O
reasoning -X- _ O
task -X- _ O
. -X- _ O

Effectiveness -X- _ O
of -X- _ O
Modules -X- _ O
. -X- _ O
mances -X- _ O
. -X- _ O
For -X- _ O
the -X- _ O
fairness -X- _ O
of -X- _ O
model -X- _ O
comparison -X- _ O
, -X- _ O
the -X- _ O
random -X- _ O
seeds -X- _ O
of -X- _ O
all -X- _ O
ablation -X- _ O
experiments -X- _ O
are -X- _ O
set -X- _ O
to -X- _ O
the -X- _ O
same -X- _ O
value -X- _ O
10 -X- _ O
. -X- _ O
Firstly -X- _ O
, -X- _ O
NDCR -X- _ B-MethodName
achieves -X- _ O
the -X- _ O
best -X- _ O
performance -X- _ O
and -X- _ O
significantly -X- _ O
surpasses -X- _ O
other -X- _ O
models -X- _ O
on -X- _ O
two -X- _ O
test -X- _ O
sets -X- _ O
. -X- _ O
When -X- _ O
we -X- _ O
add -X- _ O
System -X- _ O
2 -X- _ O
based -X- _ O
on -X- _ O
System -X- _ O
1 -X- _ O
, -X- _ O
the -X- _ O
overall -X- _ O
performance -X- _ O
improves -X- _ O
by -X- _ O
about -X- _ O
1.0 -X- _ B-MetricValue
, -X- _ O
suggesting -X- _ O
the -X- _ O
neural -X- _ O
- -X- _ O
symbolic -X- _ O
reasoner -X- _ O
's -X- _ O
effectiveness -X- _ O
. -X- _ O
Comparing -X- _ O
System -X- _ O
2 -X- _ O
and -X- _ O
System -X- _ O
2 -X- _ O
w -X- _ O
/ -X- _ O
o -X- _ O
negation -X- _ O
, -X- _ O
we -X- _ O
observe -X- _ O
that -X- _ O
the -X- _ O
negation -X- _ O
executor -X- _ O
improves -X- _ O
the -X- _ O
performance -X- _ O
of -X- _ O
the -X- _ O
neural -X- _ O
- -X- _ O
symbolic -X- _ O
reasoner -X- _ O
, -X- _ O
mainly -X- _ O
in -X- _ O
the -X- _ O
case -X- _ O
of -X- _ O
static -X- _ O
images -X- _ O
. -X- _ O
In -X- _ O
addition -X- _ O
, -X- _ O
comparing -X- _ O
System -X- _ O
1 -X- _ O
and -X- _ O
System -X- _ O
1 -X- _ O
w -X- _ O
/ -X- _ O
o -X- _ O
modifier -X- _ O
, -X- _ O
we -X- _ O
observe -X- _ O
that -X- _ O
introducing -X- _ O
the -X- _ O
context -X- _ O
reasoning -X- _ O
information -X- _ O
is -X- _ O
a -X- _ O
very -X- _ O
useful -X- _ O
way -X- _ O
to -X- _ O
enhance -X- _ O
the -X- _ O
reasoning -X- _ O
state -X- _ O
representation -X- _ O
of -X- _ O
decomposed -X- _ O
simple -X- _ O
proposition -X- _ O
sentences -X- _ O
. -X- _ O
Compared -X- _ O
to -X- _ O
the -X- _ O
best -X- _ O
baseline -X- _ O
OFA -X- _ O
- -X- _ O
large -X- _ O
( -X- _ O
470 -X- _ O
M -X- _ O
) -X- _ O
, -X- _ O
the -X- _ O
total -X- _ O
parameter -X- _ O
size -X- _ O
of -X- _ O
NDCR -X- _ B-MethodName
is -X- _ O
about -X- _ O
440M. -X- _ O
NDCR -X- _ B-MethodName
has -X- _ O
fewer -X- _ O
parameters -X- _ O
yet -X- _ O
significantly -X- _ O
outperforms -X- _ O
it -X- _ O
( -X- _ O
as -X- _ O
shown -X- _ O
in -X- _ O
Table -X- _ O
2 -X- _ O
) -X- _ O
. -X- _ O
This -X- _ O
suggests -X- _ O
that -X- _ O
the -X- _ O
overall -X- _ O
performance -X- _ O
improvement -X- _ O
of -X- _ O
NDCR -X- _ B-MethodName
is -X- _ O
not -X- _ O
due -X- _ O
to -X- _ O
having -X- _ O
larger -X- _ O
parameters -X- _ O
. -X- _ O

System -X- _ O
1 -X- _ O
vs. -X- _ O
System -X- _ O
2 -X- _ O
. -X- _ O
We -X- _ O
count -X- _ O
the -X- _ O
experimental -X- _ O
results -X- _ O
on -X- _ O
the -X- _ O
test -X- _ O
set -X- _ O
according -X- _ O
to -X- _ O
the -X- _ O
number -X- _ O
of -X- _ O
simple -X- _ O
proposition -X- _ O
sentences -X- _ O
into -X- _ O
which -X- _ O
compound -X- _ O
proposition -X- _ O
texts -X- _ O
are -X- _ O
divided -X- _ O
. -X- _ O
The -X- _ O
results -X- _ O
are -X- _ O
shown -X- _ O
in -X- _ O
Table -X- _ O
3 -X- _ O
. -X- _ O
The -X- _ O
statistical -X- _ O
results -X- _ O
show -X- _ O
that -X- _ O
NDCR -X- _ B-MethodName
excels -X- _ O
at -X- _ O
image -X- _ O
retrieval -X- _ O
from -X- _ O
complex -X- _ O
text -X- _ O
with -X- _ O
medium -X- _ O
length -X- _ O
, -X- _ O
especially -X- _ O
for -X- _ O
those -X- _ O
containing -X- _ O
three -X- _ O
simple -X- _ O
proposition -X- _ O
sentences -X- _ O
. -X- _ O
It -X- _ O
verifies -X- _ O
the -X- _ O
proposed -X- _ O
method -X- _ O
's -X- _ O
effectiveness -X- _ O
in -X- _ O
handling -X- _ O
the -X- _ O
complex -X- _ O
image -X- _ O
- -X- _ O
text -X- _ O
reasoning -X- _ O
problem -X- _ O
. -X- _ O
Compared -X- _ O
to -X- _ O
System -X- _ O
1 -X- _ O
, -X- _ O
System -X- _ O
2 -X- _ O
performs -X- _ O
better -X- _ O
on -X- _ O
test -X- _ O
samples -X- _ O
containing -X- _ O
2 -X- _ O
or -X- _ O
3 -X- _ O
simple -X- _ O
proposition -X- _ O
sentences -X- _ O
, -X- _ O
which -X- _ O
suggests -X- _ O
that -X- _ O
the -X- _ O
neural -X- _ O
- -X- _ O
symbolic -X- _ O
reasoner -X- _ O
can -X- _ O
improve -X- _ O
the -X- _ O
conjunction -X- _ O
operation -X- _ O
of -X- _ O
predic- -X- _ O
tion -X- _ O
results -X- _ O
of -X- _ O
decomposed -X- _ O
propositions -X- _ O
compared -X- _ O
to -X- _ O
rule -X- _ O
- -X- _ O
based -X- _ O
methods -X- _ O
such -X- _ O
as -X- _ O
mean -X- _ O
pooling -X- _ O
. -X- _ O

We -X- _ O
present -X- _ O
two -X- _ O
cases -X- _ O
in -X- _ O
Figure -X- _ O
4 -X- _ O
and -X- _ O
5 -X- _ O
. -X- _ O
For -X- _ O
the -X- _ O
first -X- _ O
case -X- _ O
( -X- _ O
Figure -X- _ O
4 -X- _ O
) -X- _ O
, -X- _ O
the -X- _ O
proposition -X- _ O
generator -X- _ O
divides -X- _ O
the -X- _ O
complex -X- _ O
text -X- _ O
into -X- _ O
three -X- _ O
proposition -X- _ O
sentences -X- _ O
, -X- _ O
and -X- _ O
System -X- _ O
1 -X- _ O
inferred -X- _ O
the -X- _ O
confidence -X- _ O
scores -X- _ O
( -X- _ O
P -X- _ O
+ -X- _ O
1,2,3 -X- _ O
) -X- _ O
of -X- _ O
them -X- _ O
to -X- _ O
ten -X- _ O
images -X- _ O
. -X- _ O
Although -X- _ O
these -X- _ O
results -X- _ O
of -X- _ O
simple -X- _ O
proposition -X- _ O
sentences -X- _ O
contain -X- _ O
some -X- _ O
errors -X- _ O
due -X- _ O
to -X- _ O
having -X- _ O
no -X- _ O
explicit -X- _ O
supervision -X- _ O
signal -X- _ O
to -X- _ O
train -X- _ O
, -X- _ O
System -X- _ O
2 -X- _ O
( -X- _ O
neural -X- _ O
- -X- _ O
symbolic -X- _ O
reasoner -X- _ O
) -X- _ O
could -X- _ O
obtain -X- _ O
the -X- _ O
correct -X- _ O
result -X- _ O
with -X- _ O
logical -X- _ O
reasoning -X- _ O
operation -X- _ O
compared -X- _ O
to -X- _ O
the -X- _ O
rule -X- _ O
- -X- _ O
based -X- _ O
aggregation -X- _ O
method -X- _ O
in -X- _ O
System -X- _ O
1 -X- _ O
. -X- _ O
It -X- _ O
indicates -X- _ O
the -X- _ O
robustness -X- _ O
of -X- _ O
System -X- _ O
2 -X- _ O
. -X- _ O
In -X- _ O
addition -X- _ O
, -X- _ O
we -X- _ O
observe -X- _ O
that -X- _ O
the -X- _ O
pretrained -X- _ O
VLMs -X- _ O
and -X- _ O
System -X- _ O
1 -X- _ O
, -X- _ O
which -X- _ O
are -X- _ O
capable -X- _ O
of -X- _ O
perceptual -X- _ O
computing -X- _ O
, -X- _ O
often -X- _ O
fail -X- _ O
to -X- _ O
cover -X- _ O
all -X- _ O
text -X- _ O
semantics -X- _ O
. -X- _ O
It -X- _ O
is -X- _ O
easy -X- _ O
for -X- _ O
them -X- _ O
to -X- _ O
ignore -X- _ O
pivotal -X- _ O
text -X- _ O
information -X- _ O
( -X- _ O
such -X- _ O
as -X- _ O
" -X- _ O
there -X- _ O
is -X- _ O
no -X- _ O
text -X- _ O
" -X- _ O
shown -X- _ O
in -X- _ O
Figure -X- _ O
5 -X- _ O
) -X- _ O
, -X- _ O
which -X- _ O
leads -X- _ O
to -X- _ O
inference -X- _ O
errors -X- _ O
. -X- _ O
In -X- _ O
conclusion -X- _ O
, -X- _ O
combining -X- _ O
logical -X- _ O
reasoning -X- _ O
System -X- _ O
2 -X- _ O
and -X- _ O
powerful -X- _ O
analogical -X- _ O
reasoning -X- _ O
System -X- _ O
1 -X- _ O
( -X- _ O
e.g. -X- _ O
, -X- _ O
pretrained -X- _ O
VLMs -X- _ O
) -X- _ O
has -X- _ O
significant -X- _ O
potential -X- _ O
to -X- _ O
take -X- _ O
their -X- _ O
advantages -X- _ O
to -X- _ O
address -X- _ O
complex -X- _ O
reasoning -X- _ O
problems -X- _ O
. -X- _ O

In -X- _ O
this -X- _ O
paper -X- _ O
, -X- _ O
inspired -X- _ O
by -X- _ O
the -X- _ O
divide -X- _ O
- -X- _ O
and -X- _ O
- -X- _ O
conquer -X- _ O
algorithm -X- _ O
and -X- _ O
dual -X- _ O
- -X- _ O
process -X- _ O
theory -X- _ O
, -X- _ O
we -X- _ O
introduced -X- _ O
an -X- _ O
end -X- _ O
- -X- _ O
to -X- _ O
- -X- _ O
end -X- _ O
neural -X- _ B-MethodName
divide -X- _ I-MethodName
- -X- _ I-MethodName
and -X- _ I-MethodName
- -X- _ I-MethodName
conquer -X- _ I-MethodName
reasoning -X- _ I-MethodName
framework -X- _ O
named -X- _ O
NDCR -X- _ B-MethodName
to -X- _ O
handle -X- _ O
the -X- _ O
challenging -X- _ O
case -X- _ O
of -X- _ O
image -X- _ O
retrievals -X- _ O
from -X- _ O
linguistically -X- _ O
complex -X- _ O
text -X- _ O
. -X- _ O
NDCR -X- _ B-MethodName
contains -X- _ O
a -X- _ O
proposition -X- _ O
generator -X- _ O
to -X- _ O
divide -X- _ O
the -X- _ O
compound -X- _ O
proposition -X- _ O
text -X- _ O
into -X- _ O
multiple -X- _ O
simple -X- _ O
proposition -X- _ O
sentences -X- _ O
, -X- _ O
then -X- _ O
uses -X- _ O
a -X- _ O
visuallinguistic -X- _ O
interactor -X- _ O
to -X- _ O
achieve -X- _ O
the -X- _ O
interaction -X- _ O
of -X- _ O
simple -X- _ O
propositions -X- _ O
and -X- _ O
images -X- _ O
. -X- _ O
To -X- _ O
improve -X- _ O
the -X- _ O
logical -X- _ O
reasoning -X- _ O
capability -X- _ O
, -X- _ O
we -X- _ O
devise -X- _ O
a -X- _ O
neuralsymbolic -X- _ O
reasoner -X- _ O
to -X- _ O
gain -X- _ O
the -X- _ O
logical -X- _ O
inferring -X- _ O
result -X- _ O
based -X- _ O
on -X- _ O
the -X- _ O
output -X- _ O
of -X- _ O
the -X- _ O
visual -X- _ O
- -X- _ O
linguistic -X- _ O
interactor -X- _ O
. -X- _ O
This -X- _ O
way -X- _ O
, -X- _ O
NDCR -X- _ B-MethodName
performs -X- _ O
the -X- _ O
lowlevel -X- _ O
analogically -X- _ O
perceptual -X- _ O
computing -X- _ O
in -X- _ O
System -X- _ O
1 -X- _ O
( -X- _ O
visual -X- _ O
- -X- _ O
linguistic -X- _ O
interactor -X- _ O
) -X- _ O
and -X- _ O
high -X- _ O
- -X- _ O
level -X- _ O
logical -X- _ O
reasoning -X- _ O
in -X- _ O
System -X- _ O
2 -X- _ O
( -X- _ O
neural -X- _ O
- -X- _ O
symbolic -X- _ O
reasoner -X- _ O
) -X- _ O
. -X- _ O
Finally -X- _ O
, -X- _ O
we -X- _ O
combine -X- _ O
the -X- _ O
output -X- _ O
result -X- _ O
in -X- _ O
Systems -X- _ O
1 -X- _ O
and -X- _ O
2 -X- _ O
to -X- _ O
obtain -X- _ O
the -X- _ O
final -X- _ O
solution -X- _ O
. -X- _ O

The -X- _ O
proposed -X- _ O
method -X- _ O
NDCR -X- _ B-MethodName
has -X- _ O
some -X- _ O
limitations -X- _ O
as -X- _ O
follows -X- _ O
: -X- _ O
1 -X- _ O
) -X- _ O
The -X- _ O
produced -X- _ O
representation -X- _ O
of -X- _ O
simple -X- _ O
proposition -X- _ O
sentences -X- _ O
in -X- _ O
the -X- _ O
proposition -X- _ O
generator -X- _ O
lies -X- _ O
in -X- _ O
a -X- _ O
different -X- _ O
space -X- _ O
distribution -X- _ O
with -X- _ O
the -X- _ O
image -X- _ O
encoding -X- _ O
, -X- _ O
which -X- _ O
affects -X- _ O
the -X- _ O
performance -X- _ O
of -X- _ O
their -X- _ O
fused -X- _ O
representation -X- _ O
. -X- _ O
Although -X- _ O
we -X- _ O
introduce -X- _ O
the -X- _ O
reasoning -X- _ O
information -X- _ O
of -X- _ O
compound -X- _ O
proposition -X- _ O
text -X- _ O
to -X- _ O
alleviate -X- _ O
this -X- _ O
issue -X- _ O
, -X- _ O
we -X- _ O
hope -X- _ O
to -X- _ O
solve -X- _ O
it -X- _ O
by -X- _ O
improving -X- _ O
the -X- _ O
text -X- _ O
understanding -X- _ O
capability -X- _ O
of -X- _ O
pretrained -X- _ O
VLMs -X- _ O
. -X- _ O
In -X- _ O
addition -X- _ O
, -X- _ O
adopting -X- _ O
the -X- _ O
pretrained -X- _ O
textual -X- _ O
encoder -X- _ O
of -X- _ O
VLMs -X- _ O
to -X- _ O
perform -X- _ O
proposition -X- _ O
decomposition -X- _ O
is -X- _ O
inadequate -X- _ O
due -X- _ O
to -X- _ O
that -X- _ O
they -X- _ O
present -X- _ O
an -X- _ O
inferior -X- _ O
understanding -X- _ O
for -X- _ O
the -X- _ O
discourse -X- _ O
structure -X- _ O
of -X- _ O
long -X- _ O
texts -X- _ O
. -X- _ O
2 -X- _ O
) -X- _ O
The -X- _ O
performance -X- _ O
of -X- _ O
samples -X- _ O
with -X- _ O
highly -X- _ O
similar -X- _ O
images -X- _ O
from -X- _ O
video -X- _ O
frames -X- _ O
is -X- _ O
quite -X- _ O
different -X- _ O
from -X- _ O
that -X- _ O
of -X- _ O
humans -X- _ O
. -X- _ O
We -X- _ O
may -X- _ O
improve -X- _ O
it -X- _ O
from -X- _ O
the -X- _ O
perspective -X- _ O
of -X- _ O
image -X- _ O
difference -X- _ O
modelling -X- _ O
. -X- _ O
3 -X- _ O
) -X- _ O
The -X- _ O
experimental -X- _ O
results -X- _ O
indicate -X- _ O
that -X- _ O
our -X- _ O
method -X- _ O
is -X- _ O
effective -X- _ O
at -X- _ O
logical -X- _ O
inference -X- _ O
on -X- _ O
examples -X- _ O
with -X- _ O
medium -X- _ O
- -X- _ O
length -X- _ O
descriptions -X- _ O
, -X- _ O
but -X- _ O
there -X- _ O
is -X- _ O
still -X- _ O
room -X- _ O
for -X- _ O
improvement -X- _ O
for -X- _ O
longer -X- _ O
descriptions -X- _ O
. -X- _ O

IMAGECODE -X- _ B-DatasetName
( -X- _ O
Krojer -X- _ O
et -X- _ O
al -X- _ O
. -X- _ O
, -X- _ O
2022 -X- _ O
) -X- _ O
is -X- _ O
an -X- _ O
open -X- _ O
data -X- _ O
set -X- _ O
used -X- _ O
for -X- _ O
scientific -X- _ O
research -X- _ O
. -X- _ O
For -X- _ O
ablation -X- _ O
studies -X- _ O
in -X- _ O
the -X- _ O
test -X- _ O
set -X- _ O
, -X- _ O
we -X- _ O
hired -X- _ O
masters -X- _ O
and -X- _ O
undergraduate -X- _ O
students -X- _ O
from -X- _ O
the -X- _ O
research -X- _ O
group -X- _ O
to -X- _ O
re -X- _ O
- -X- _ O
annotate -X- _ O
the -X- _ O
label -X- _ O
of -X- _ O
the -X- _ O
test -X- _ O
set -X- _ O
. -X- _ O
We -X- _ O
have -X- _ O
informed -X- _ O
the -X- _ O
creators -X- _ O
of -X- _ O
the -X- _ O
data -X- _ O
set -X- _ O
and -X- _ O
only -X- _ O
conducted -X- _ O
scientific -X- _ O
research -X- _ O
. -X- _ O
B3 -X- _ O
. -X- _ O
Did -X- _ O
you -X- _ O
discuss -X- _ O
if -X- _ O
your -X- _ O
use -X- _ O
of -X- _ O
existing -X- _ O
artifact -X- _ O
( -X- _ O
s -X- _ O
) -X- _ O
was -X- _ O
consistent -X- _ O
with -X- _ O
their -X- _ O
intended -X- _ O
use -X- _ O
, -X- _ O
provided -X- _ O
that -X- _ O
it -X- _ O
was -X- _ O
specified -X- _ O
? -X- _ O
For -X- _ O
the -X- _ O
artifacts -X- _ O
you -X- _ O
create -X- _ O
, -X- _ O
do -X- _ O
you -X- _ O
specify -X- _ O
intended -X- _ O
use -X- _ O
and -X- _ O
whether -X- _ O
that -X- _ O
is -X- _ O
compatible -X- _ O
with -X- _ O
the -X- _ O
original -X- _ O
access -X- _ O
conditions -X- _ O
( -X- _ O
in -X- _ O
particular -X- _ O
, -X- _ O
derivatives -X- _ O
of -X- _ O
data -X- _ O
accessed -X- _ O
for -X- _ O
research -X- _ O
purposes -X- _ O
should -X- _ O
not -X- _ O
be -X- _ O
used -X- _ O
outside -X- _ O
of -X- _ O
research -X- _ O
contexts -X- _ O
) -X- _ O
? -X- _ O
experiments -X- _ O
B4 -X- _ O
. -X- _ O
Did -X- _ O
you -X- _ O
discuss -X- _ O
the -X- _ O
steps -X- _ O
taken -X- _ O
to -X- _ O
check -X- _ O
whether -X- _ O
the -X- _ O
data -X- _ O
that -X- _ O
was -X- _ O
collected -X- _ O
/ -X- _ O
used -X- _ O
contains -X- _ O
any -X- _ O
information -X- _ O
that -X- _ O
names -X- _ O
or -X- _ O
uniquely -X- _ O
identifies -X- _ O
individual -X- _ O
people -X- _ O
or -X- _ O
offensive -X- _ O
content -X- _ O
, -X- _ O
and -X- _ O
the -X- _ O
steps -X- _ O
taken -X- _ O
to -X- _ O
protect -X- _ O
/ -X- _ O
anonymize -X- _ O
it -X- _ O
? -X- _ O
we -X- _ O
do -X- _ O
not -X- _ O
create -X- _ O
any -X- _ O
data -X- _ O
set -X- _ O
and -X- _ O
conduct -X- _ O
experiments -X- _ O
on -X- _ O
released -X- _ O
public -X- _ O
data -X- _ O
set -X- _ O
. -X- _ O

Character -X- _ O
- -X- _ O
Centric -X- _ O
Story -X- _ B-TaskName
Visualization -X- _ I-TaskName
via -X- _ O
Visual -X- _ O
Planning -X- _ O
and -X- _ O
Token -X- _ O
Alignment -X- _ O

Story -X- _ B-TaskName
visualization -X- _ I-TaskName
advances -X- _ O
the -X- _ O
traditional -X- _ O
text -X- _ O
- -X- _ O
to -X- _ O
- -X- _ O
image -X- _ O
generation -X- _ O
by -X- _ O
enabling -X- _ O
multiple -X- _ O
image -X- _ O
generation -X- _ O
based -X- _ O
on -X- _ O
a -X- _ O
complete -X- _ O
story -X- _ O
. -X- _ O
This -X- _ O
task -X- _ O
requires -X- _ O
machines -X- _ O
to -X- _ O
1 -X- _ O
) -X- _ O
understand -X- _ O
long -X- _ O
text -X- _ O
inputs -X- _ O
and -X- _ O
2 -X- _ O
) -X- _ O
produce -X- _ O
a -X- _ O
globally -X- _ O
consistent -X- _ O
image -X- _ O
sequence -X- _ O
that -X- _ O
illustrates -X- _ O
the -X- _ O
contents -X- _ O
of -X- _ O
the -X- _ O
story -X- _ O
. -X- _ O
A -X- _ O
key -X- _ O
challenge -X- _ O
of -X- _ O
consistent -X- _ O
story -X- _ O
visualization -X- _ O
is -X- _ O
to -X- _ O
preserve -X- _ O
characters -X- _ O
that -X- _ O
are -X- _ O
essential -X- _ O
in -X- _ O
stories -X- _ O
. -X- _ O
To -X- _ O
tackle -X- _ O
the -X- _ O
challenge -X- _ O
, -X- _ O
we -X- _ O
propose -X- _ O
to -X- _ O
adapt -X- _ O
a -X- _ O
recent -X- _ O
work -X- _ O
that -X- _ O
augments -X- _ O
Vector -X- _ O
- -X- _ O
Quantized -X- _ O
Variational -X- _ O
Autoencoders -X- _ O
( -X- _ O
VQ -X- _ O
- -X- _ O
VAE -X- _ O
) -X- _ O
with -X- _ O
a -X- _ O
text -X- _ O
- -X- _ O
tovisual -X- _ O
- -X- _ O
token -X- _ O
( -X- _ O
transformer -X- _ O
) -X- _ O
architecture -X- _ O
. -X- _ O
Specifically -X- _ O
, -X- _ O
we -X- _ O
modify -X- _ O
the -X- _ O
text -X- _ O
- -X- _ O
to -X- _ O
- -X- _ O
visual -X- _ O
- -X- _ O
token -X- _ O
module -X- _ O
with -X- _ O
a -X- _ O
two -X- _ O
- -X- _ O
stage -X- _ O
framework -X- _ O
: -X- _ O
1 -X- _ O
) -X- _ O
character -X- _ O
token -X- _ O
planning -X- _ O
model -X- _ O
that -X- _ O
predicts -X- _ O
the -X- _ O
visual -X- _ O
tokens -X- _ O
for -X- _ O
characters -X- _ O
only -X- _ O
; -X- _ O
2 -X- _ O
) -X- _ O
visual -X- _ O
token -X- _ O
completion -X- _ O
model -X- _ O
that -X- _ O
generates -X- _ O
the -X- _ O
remaining -X- _ O
visual -X- _ O
token -X- _ O
sequence -X- _ O
, -X- _ O
which -X- _ O
is -X- _ O
sent -X- _ O
to -X- _ O
VQ -X- _ O
- -X- _ O
VAE -X- _ O
for -X- _ O
finalizing -X- _ O
image -X- _ O
generations -X- _ O
. -X- _ O
To -X- _ O
encourage -X- _ O
characters -X- _ O
to -X- _ O
appear -X- _ O
in -X- _ O
the -X- _ O
images -X- _ O
, -X- _ O
we -X- _ O
further -X- _ O
train -X- _ O
the -X- _ O
two -X- _ O
- -X- _ O
stage -X- _ O
framework -X- _ O
with -X- _ O
a -X- _ O
character -X- _ O
- -X- _ O
token -X- _ O
alignment -X- _ O
objective -X- _ O
. -X- _ O
Extensive -X- _ O
experiments -X- _ O
and -X- _ O
evaluations -X- _ O
demonstrate -X- _ O
that -X- _ O
the -X- _ O
proposed -X- _ O
method -X- _ O
excels -X- _ O
at -X- _ O
preserving -X- _ O
characters -X- _ O
and -X- _ O
can -X- _ O
produce -X- _ O
higher -X- _ O
quality -X- _ O
image -X- _ O
sequences -X- _ O
compared -X- _ O
with -X- _ O
the -X- _ O
strong -X- _ O
baselines -X- _ O
. -X- _ O
Code -X- _ O
can -X- _ O
be -X- _ O
found -X- _ O
in -X- _ O
https -X- _ O
: -X- _ O
/ -X- _ O
/ -X- _ O
github.com -X- _ O
/ -X- _ O
PlusLabNLP -X- _ O
/ -X- _ O
VP -X- _ O
- -X- _ O
CSV -X- _ O
* -X- _ O
Work -X- _ O
done -X- _ O
when -X- _ O
the -X- _ O
author -X- _ O
was -X- _ O
visiting -X- _ O
UCLA -X- _ O
. -X- _ O

Text -X- _ O
- -X- _ O
to -X- _ O
- -X- _ O
image -X- _ O
generation -X- _ O
( -X- _ O
Ramesh -X- _ O
et -X- _ O
al -X- _ O
. -X- _ O
, -X- _ O
2021 -X- _ O
; -X- _ O
Ding -X- _ O
et -X- _ O
al -X- _ O
. -X- _ O
, -X- _ O
2021 -X- _ O
; -X- _ O
Qiao -X- _ O
et -X- _ O
al -X- _ O
. -X- _ O
, -X- _ O
2019 -X- _ O
) -X- _ O
, -X- _ O
as -X- _ O
a -X- _ O
benchmark -X- _ O
task -X- _ O
to -X- _ O
test -X- _ O
AI -X- _ O
systems -X- _ O
' -X- _ O
multi -X- _ O
- -X- _ O
modal -X- _ O
capability -X- _ O
, -X- _ O
has -X- _ O
been -X- _ O
widely -X- _ O
studied -X- _ O
over -X- _ O
the -X- _ O
past -X- _ O
decade -X- _ O
. -X- _ O
The -X- _ O
task -X- _ O
takes -X- _ O
a -X- _ O
short -X- _ O
sentence -X- _ O
or -X- _ O
phrase -X- _ O
as -X- _ O
input -X- _ O
and -X- _ O
outputs -X- _ O
a -X- _ O
single -X- _ O
image -X- _ O
illustrating -X- _ O
the -X- _ O
content -X- _ O
of -X- _ O
the -X- _ O
input -X- _ O
text -X- _ O
. -X- _ O
One -X- _ O
of -X- _ O
the -X- _ O
latest -X- _ O
successful -X- _ O
works -X- _ O
is -X- _ O
DALL -X- _ O
- -X- _ O
E -X- _ O
( -X- _ O
Ramesh -X- _ O
et -X- _ O
al -X- _ O
. -X- _ O
, -X- _ O
2021 -X- _ O
) -X- _ O
, -X- _ O
which -X- _ O
efficiently -X- _ O
encodes -X- _ O
and -X- _ O
decodes -X- _ O
images -X- _ O
with -X- _ O
discrete -X- _ O
visual -X- _ O
tokens -X- _ O
and -X- _ O
achieves -X- _ O
remarkable -X- _ O
text -X- _ O
- -X- _ O
to -X- _ O
- -X- _ O
image -X- _ O
gen -X- _ O
- -X- _ O
Figure -X- _ O
1 -X- _ O
: -X- _ O
Example -X- _ O
of -X- _ O
generated -X- _ O
images -X- _ O
from -X- _ O
previous -X- _ O
models -X- _ O
( -X- _ O
CP -X- _ B-MethodName
- -X- _ I-MethodName
CSV -X- _ I-MethodName
and -X- _ O
VLC -X- _ O
) -X- _ O
, -X- _ O
the -X- _ O
VQ -X- _ O
- -X- _ O
VAE -X- _ O
with -X- _ O
transformers -X- _ O
( -X- _ O
VQ -X- _ B-MethodName
- -X- _ I-MethodName
VAE -X- _ I-MethodName
- -X- _ I-MethodName
LM -X- _ I-MethodName
) -X- _ O
baseline -X- _ O
, -X- _ O
and -X- _ O
our -X- _ O
proposed -X- _ O
model -X- _ O
( -X- _ O
VP -X- _ B-MethodName
- -X- _ I-MethodName
CSV -X- _ I-MethodName
) -X- _ O
. -X- _ O
We -X- _ O
highlight -X- _ O
the -X- _ O
characters -X- _ O
in -X- _ O
each -X- _ O
sentence -X- _ O
in -X- _ O
red -X- _ O
. -X- _ O
We -X- _ O
can -X- _ O
see -X- _ O
that -X- _ O
the -X- _ O
generated -X- _ O
image -X- _ O
sequence -X- _ O
by -X- _ O
VP -X- _ B-MethodName
- -X- _ I-MethodName
CSV -X- _ I-MethodName
achieves -X- _ O
the -X- _ O
best -X- _ O
image -X- _ O
quality -X- _ O
and -X- _ O
character -X- _ O
preservation -X- _ O
. -X- _ O
eration -X- _ O
performance -X- _ O
by -X- _ O
prefixing -X- _ O
visual -X- _ O
tokens -X- _ O
with -X- _ O
natural -X- _ O
language -X- _ O
inputs -X- _ O
. -X- _ O

Recently -X- _ O
, -X- _ O
the -X- _ O
story -X- _ B-TaskName
visualization -X- _ I-TaskName
task -X- _ O
has -X- _ O
attracted -X- _ O
increasing -X- _ O
research -X- _ O
interests -X- _ O
with -X- _ O
a -X- _ O
variety -X- _ O
of -X- _ O
potential -X- _ O
and -X- _ O
promising -X- _ O
applications -X- _ O
such -X- _ O
as -X- _ O
automatic -X- _ O
production -X- _ O
of -X- _ O
movie -X- _ O
clips -X- _ O
and -X- _ O
animations -X- _ O
from -X- _ O
written -X- _ O
scripts -X- _ O
. -X- _ O
Story -X- _ O
visualization -X- _ O
is -X- _ O
more -X- _ O
challenging -X- _ O
than -X- _ O
the -X- _ O
original -X- _ O
text -X- _ O
- -X- _ O
to -X- _ O
- -X- _ O
image -X- _ O
generation -X- _ O
as -X- _ O
it -X- _ O
requires -X- _ O
models -X- _ O
to -X- _ O
generate -X- _ O
a -X- _ O
sequence -X- _ O
of -X- _ O
images -X- _ O
that -X- _ O
visually -X- _ O
illustrate -X- _ O
a -X- _ O
story -X- _ O
composed -X- _ O
of -X- _ O
at -X- _ O
least -X- _ O
several -X- _ O
sentences -X- _ O
. -X- _ O
Machines -X- _ O
need -X- _ O
to -X- _ O
understand -X- _ O
long -X- _ O
story -X- _ O
texts -X- _ O
and -X- _ O
simultaneously -X- _ O
generate -X- _ O
images -X- _ O
with -X- _ O
consistent -X- _ O
scenes -X- _ O
and -X- _ O
characters -X- _ O
described -X- _ O
in -X- _ O
the -X- _ O
story -X- _ O
coherently -X- _ O
. -X- _ O

Character -X- _ O
is -X- _ O
one -X- _ O
of -X- _ O
the -X- _ O
essential -X- _ O
elements -X- _ O
of -X- _ O
a -X- _ O
story -X- _ O
since -X- _ O
they -X- _ O
lead -X- _ O
and -X- _ O
develop -X- _ O
the -X- _ O
story -X- _ O
( -X- _ O
Montgomery -X- _ O
, -X- _ O
2004 -X- _ O
) -X- _ O
. -X- _ O
Further -X- _ O
, -X- _ O
since -X- _ O
characters -X- _ O
usually -X- _ O
occupy -X- _ O
a -X- _ O
large -X- _ O
region -X- _ O
in -X- _ O
an -X- _ O
image -X- _ O
, -X- _ O
incorrect -X- _ O
or -X- _ O
vague -X- _ O
characters -X- _ O
would -X- _ O
result -X- _ O
in -X- _ O
low -X- _ O
- -X- _ O
quality -X- _ O
image -X- _ O
generation -X- _ O
. -X- _ O
Therefore -X- _ O
, -X- _ O
ensuring -X- _ O
character -X- _ O
preservation -X- _ O
is -X- _ O
a -X- _ O
key -X- _ O
cornerstone -X- _ O
for -X- _ O
consistent -X- _ O
story -X- _ B-TaskName
visualization -X- _ I-TaskName
, -X- _ O
which -X- _ O
motivates -X- _ O
the -X- _ O
character -X- _ O
- -X- _ O
centric -X- _ O
approach -X- _ O
in -X- _ O
this -X- _ O
work -X- _ O
. -X- _ O
Our -X- _ O
character -X- _ O
- -X- _ O
centric -X- _ O
method -X- _ O
is -X- _ O
based -X- _ O
on -X- _ O
a -X- _ O
recent -X- _ O
state -X- _ O
- -X- _ O
of -X- _ O
- -X- _ O
the -X- _ O
- -X- _ O
art -X- _ O
text -X- _ O
- -X- _ O
to -X- _ O
- -X- _ O
image -X- _ O
generation -X- _ O
model -X- _ O
, -X- _ O
VQ -X- _ B-MethodName
- -X- _ I-MethodName
VAE -X- _ I-MethodName
- -X- _ I-MethodName
LM -X- _ I-MethodName
that -X- _ O
combines -X- _ O
VQ -X- _ O
- -X- _ O
VAE -X- _ O
( -X- _ O
Van -X- _ O
Den -X- _ O
Oord -X- _ O
et -X- _ O
al -X- _ O
. -X- _ O
, -X- _ O
2017 -X- _ O
) -X- _ O
with -X- _ O
a -X- _ O
textto -X- _ O
- -X- _ O
visual -X- _ O
- -X- _ O
token -X- _ O
transformer -X- _ O
( -X- _ O
Ramesh -X- _ O
et -X- _ O
al -X- _ O
. -X- _ O
, -X- _ O
2021 -X- _ O
; -X- _ O
Yan -X- _ O
et -X- _ O
al -X- _ O
. -X- _ O
, -X- _ O
2021 -X- _ O
) -X- _ O
. -X- _ O
In -X- _ O
order -X- _ O
to -X- _ O
boost -X- _ O
character -X- _ O
consistency -X- _ O
in -X- _ O
story -X- _ O
visualization -X- _ O
, -X- _ O
we -X- _ O
propose -X- _ O
to -X- _ O
enhance -X- _ O
VQ -X- _ B-MethodName
- -X- _ I-MethodName
VAE -X- _ I-MethodName
- -X- _ I-MethodName
LM -X- _ I-MethodName
with -X- _ O
a -X- _ O
two -X- _ O
- -X- _ O
stage -X- _ O
module -X- _ O
inspired -X- _ O
by -X- _ O
Plan -X- _ O
- -X- _ O
and -X- _ O
- -X- _ O
Write -X- _ O
story -X- _ O
generation -X- _ O
framework -X- _ O
( -X- _ O
Peng -X- _ O
et -X- _ O
al -X- _ O
. -X- _ O
, -X- _ O
2018 -X- _ O
; -X- _ O
Yao -X- _ O
et -X- _ O
al -X- _ O
. -X- _ O
, -X- _ O
2019 -X- _ O
; -X- _ O
Goldfarb -X- _ O
- -X- _ O
Tarrant -X- _ O
et -X- _ O
al -X- _ O
. -X- _ O
, -X- _ O
2019 -X- _ O
, -X- _ O
2020Han -X- _ O
et -X- _ O
al -X- _ O
. -X- _ O
, -X- _ O
2022 -X- _ O
) -X- _ O
. -X- _ O
We -X- _ O
briefly -X- _ O
summarize -X- _ O
the -X- _ O
approach -X- _ O
below -X- _ O
. -X- _ O

The -X- _ O
two -X- _ O
- -X- _ O
stage -X- _ O
model -X- _ O
freezes -X- _ O
VQ -X- _ O
- -X- _ O
VAE -X- _ O
and -X- _ O
adapts -X- _ O
the -X- _ O
text -X- _ O
- -X- _ O
to -X- _ O
- -X- _ O
visual -X- _ O
- -X- _ O
token -X- _ O
transformer -X- _ O
by -X- _ O
dividing -X- _ O
it -X- _ O
into -X- _ O
two -X- _ O
separate -X- _ O
modules -X- _ O
: -X- _ O
1 -X- _ O
) -X- _ O
the -X- _ O
plan -X- _ O
module -X- _ O
generates -X- _ O
a -X- _ O
token -X- _ O
plan -X- _ O
consisting -X- _ O
of -X- _ O
character -X- _ O
and -X- _ O
non -X- _ O
- -X- _ O
character -X- _ O
( -X- _ O
background -X- _ O
) -X- _ O
tokens -X- _ O
, -X- _ O
which -X- _ O
reinforces -X- _ O
our -X- _ O
system -X- _ O
's -X- _ O
attention -X- _ O
to -X- _ O
characters -X- _ O
; -X- _ O
2 -X- _ O
) -X- _ O
based -X- _ O
on -X- _ O
the -X- _ O
character -X- _ O
token -X- _ O
plan -X- _ O
, -X- _ O
the -X- _ O
completion -X- _ O
module -X- _ O
produces -X- _ O
the -X- _ O
entire -X- _ O
sequence -X- _ O
of -X- _ O
visual -X- _ O
tokens -X- _ O
, -X- _ O
which -X- _ O
are -X- _ O
used -X- _ O
in -X- _ O
VQ -X- _ O
- -X- _ O
VAE -X- _ O
decoder -X- _ O
to -X- _ O
produce -X- _ O
final -X- _ O
images -X- _ O
. -X- _ O
The -X- _ O
two -X- _ O
modules -X- _ O
are -X- _ O
separately -X- _ O
trained -X- _ O
to -X- _ O
avoid -X- _ O
the -X- _ O
expensive -X- _ O
decoding -X- _ O
in -X- _ O
training -X- _ O
. -X- _ O
Crucially -X- _ O
, -X- _ O
we -X- _ O
train -X- _ O
the -X- _ O
completion -X- _ O
module -X- _ O
with -X- _ O
an -X- _ O
auxiliary -X- _ O
semantic -X- _ O
alignment -X- _ O
loss -X- _ O
that -X- _ O
encourages -X- _ O
appropriate -X- _ O
character -X- _ O
tokens -X- _ O
to -X- _ O
appear -X- _ O
in -X- _ O
the -X- _ O
final -X- _ O
visual -X- _ O
tokens -X- _ O
. -X- _ O

To -X- _ O
the -X- _ O
best -X- _ O
of -X- _ O
our -X- _ O
knowledge -X- _ O
, -X- _ O
all -X- _ O
previous -X- _ O
works -X- _ O
in -X- _ O
story -X- _ O
visualization -X- _ O
employ -X- _ O
GAN -X- _ O
- -X- _ O
based -X- _ O
( -X- _ O
Goodfellow -X- _ O
et -X- _ O
al -X- _ O
. -X- _ O
, -X- _ O
2014 -X- _ O
) -X- _ O
methods -X- _ O
, -X- _ O
which -X- _ O
are -X- _ O
shown -X- _ O
to -X- _ O
be -X- _ O
unstable -X- _ O
( -X- _ O
Kodali -X- _ O
et -X- _ O
al -X- _ O
. -X- _ O
, -X- _ O
2017 -X- _ O
; -X- _ O
Thanh -X- _ O
- -X- _ O
Tung -X- _ O
et -X- _ O
al -X- _ O
. -X- _ O
, -X- _ O
2018 -X- _ O
) -X- _ O
. -X- _ O
Figure -X- _ O
1 -X- _ O
shows -X- _ O
that -X- _ O
the -X- _ O
images -X- _ O
generated -X- _ O
by -X- _ O
VQ -X- _ B-MethodName
- -X- _ I-MethodName
VAE -X- _ I-MethodName
- -X- _ I-MethodName
LM -X- _ I-MethodName
are -X- _ O
clearer -X- _ O
than -X- _ O
those -X- _ O
by -X- _ O
previous -X- _ O
GAN -X- _ O
- -X- _ O
based -X- _ O
models -X- _ O
such -X- _ O
as -X- _ O
CP -X- _ B-MethodName
- -X- _ I-MethodName
CSV -X- _ I-MethodName
( -X- _ O
Song -X- _ O
et -X- _ O
al -X- _ O
. -X- _ O
, -X- _ O
2020 -X- _ O
) -X- _ O
and -X- _ O
VLC -X- _ O
, -X- _ O
suggesting -X- _ O
the -X- _ O
instability -X- _ O
of -X- _ O
GAN -X- _ O
- -X- _ O
based -X- _ O
models -X- _ O
. -X- _ O
On -X- _ O
the -X- _ O
other -X- _ O
hand -X- _ O
, -X- _ O
VQ -X- _ B-MethodName
- -X- _ I-MethodName
VAE -X- _ I-MethodName
- -X- _ I-MethodName
LM -X- _ I-MethodName
architecture -X- _ O
has -X- _ O
been -X- _ O
shown -X- _ O
to -X- _ O
stabilize -X- _ O
the -X- _ O
training -X- _ O
( -X- _ O
Van -X- _ O
Den -X- _ O
Oord -X- _ O
et -X- _ O
al -X- _ O
. -X- _ O
, -X- _ O
2017 -X- _ O
) -X- _ O
, -X- _ O
leading -X- _ O
to -X- _ O
better -X- _ O
image -X- _ O
quality -X- _ O
( -X- _ O
the -X- _ O
third -X- _ O
row -X- _ O
in -X- _ O
Figure -X- _ O
1 -X- _ O
) -X- _ O
. -X- _ O
Finally -X- _ O
, -X- _ O
our -X- _ O
proposed -X- _ O
twostage -X- _ O
visual -X- _ O
planning -X- _ O
model -X- _ O
( -X- _ O
VP -X- _ B-MethodName
- -X- _ I-MethodName
CSV -X- _ I-MethodName
) -X- _ O
can -X- _ O
further -X- _ O
improve -X- _ O
VQ -X- _ B-MethodName
- -X- _ I-MethodName
VAE -X- _ I-MethodName
- -X- _ I-MethodName
LM -X- _ I-MethodName
, -X- _ O
which -X- _ O
produces -X- _ O
the -X- _ O
best -X- _ O
quality -X- _ O
images -X- _ O
in -X- _ O
Figure -X- _ O
1 -X- _ O
. -X- _ O

Beyond -X- _ O
this -X- _ O
example -X- _ O
, -X- _ O
we -X- _ O
conduct -X- _ O
extensive -X- _ O
experiments -X- _ O
to -X- _ O
show -X- _ O
that -X- _ O
our -X- _ O
proposed -X- _ O
two -X- _ O
- -X- _ O
stage -X- _ O
visual -X- _ O
token -X- _ O
plan -X- _ O
and -X- _ O
the -X- _ O
semantic -X- _ O
alignment -X- _ O
method -X- _ O
perform -X- _ O
better -X- _ O
on -X- _ O
character -X- _ O
preservation -X- _ O
compared -X- _ O
with -X- _ O
various -X- _ O
baseline -X- _ O
models -X- _ O
, -X- _ O
which -X- _ O
in -X- _ O
general -X- _ O
contribute -X- _ O
to -X- _ O
the -X- _ O
improved -X- _ O
story -X- _ B-TaskName
visualization -X- _ I-TaskName
quality -X- _ O
. -X- _ O
We -X- _ O
summarize -X- _ O
our -X- _ O
contributions -X- _ O
below -X- _ O
, -X- _ O

• -X- _ O
We -X- _ O
adopt -X- _ O
the -X- _ O
VQ -X- _ B-MethodName
- -X- _ I-MethodName
VAE -X- _ I-MethodName
- -X- _ I-MethodName
LM -X- _ I-MethodName
architecture -X- _ O
as -X- _ O
our -X- _ O
baselines -X- _ O
for -X- _ O
the -X- _ O
story -X- _ O
visualization -X- _ O
task -X- _ O
, -X- _ O
which -X- _ O
achieve -X- _ O
better -X- _ O
results -X- _ O
than -X- _ O
previous -X- _ O
GAN -X- _ O
- -X- _ O
based -X- _ O
models -X- _ O
. -X- _ O
• -X- _ O
Our -X- _ O
key -X- _ O
contribution -X- _ O
is -X- _ O
to -X- _ O
develop -X- _ O
VQ -X- _ B-MethodName
- -X- _ I-MethodName
VAE -X- _ I-MethodName
- -X- _ I-MethodName
LM -X- _ I-MethodName
with -X- _ O
visual -X- _ O
token -X- _ O
planning -X- _ O
and -X- _ O
alignment -X- _ O
to -X- _ O
improve -X- _ O
the -X- _ O
performance -X- _ O
of -X- _ O
character -X- _ O
preservation -X- _ O
and -X- _ O
visual -X- _ O
quality -X- _ O
. -X- _ O
• -X- _ O
Extensive -X- _ O
experiments -X- _ O
, -X- _ O
evaluations -X- _ O
and -X- _ O
analysis -X- _ O
show -X- _ O
that -X- _ O
our -X- _ O
models -X- _ O
outperform -X- _ O
all -X- _ O
baseline -X- _ O
systems -X- _ O
by -X- _ O
a -X- _ O
large -X- _ O
margin -X- _ O
, -X- _ O
demonstrating -X- _ O
the -X- _ O
efficacy -X- _ O
of -X- _ O
our -X- _ O
proposed -X- _ O
method -X- _ O
. -X- _ O

In -X- _ O
the -X- _ O
field -X- _ O
of -X- _ O
image -X- _ O
generation -X- _ O
, -X- _ O
Generative -X- _ O
Adversarial -X- _ O
Nets -X- _ O
( -X- _ O
GAN -X- _ O
) -X- _ O
( -X- _ O
Goodfellow -X- _ O
et -X- _ O
al -X- _ O
. -X- _ O
, -X- _ O
2014 -X- _ O
) -X- _ O
, -X- _ O
Variational -X- _ O
Autoencoders -X- _ O
( -X- _ O
VAE -X- _ O
) -X- _ O
( -X- _ O
Kingma -X- _ O
and -X- _ O
Welling -X- _ O
, -X- _ O
2014 -X- _ O
) -X- _ O
and -X- _ O
their -X- _ O
variants -X- _ O
Mirza -X- _ O
and -X- _ O
Osindero -X- _ O
, -X- _ O
2014 -X- _ O
; -X- _ O
Sohn -X- _ O
et -X- _ O
al -X- _ O
. -X- _ O
, -X- _ O
2015 -X- _ O
) -X- _ O
have -X- _ O
been -X- _ O
studied -X- _ O
. -X- _ O
Text -X- _ O
- -X- _ O
to -X- _ O
- -X- _ O
image -X- _ O
generation -X- _ O
includes -X- _ O
text -X- _ O
conditions -X- _ O
into -X- _ O
these -X- _ O
models -X- _ O
. -X- _ O
StackGAN -X- _ O
( -X- _ O
Zhang -X- _ O
et -X- _ O
al -X- _ O
. -X- _ O
, -X- _ O
2017 -X- _ O
) -X- _ O
proposes -X- _ O
a -X- _ O
sketch -X- _ O
- -X- _ O
refinement -X- _ O
process -X- _ O
that -X- _ O
first -X- _ O
sketches -X- _ O
the -X- _ O
primitive -X- _ O
shape -X- _ O
and -X- _ O
colors -X- _ O
before -X- _ O
finalizing -X- _ O
the -X- _ O
details -X- _ O
. -X- _ O
AttnGAN -X- _ O
( -X- _ O
Xu -X- _ O
et -X- _ O
al -X- _ O
. -X- _ O
, -X- _ O
2018b -X- _ O
) -X- _ O
allows -X- _ O
attention -X- _ O
- -X- _ O
driven -X- _ O
, -X- _ O
multi -X- _ O
- -X- _ O
stage -X- _ O
refinements -X- _ O
of -X- _ O
fine -X- _ O
- -X- _ O
grained -X- _ O
text -X- _ O
- -X- _ O
to -X- _ O
- -X- _ O
image -X- _ O
generation -X- _ O
to -X- _ O
improve -X- _ O
the -X- _ O
image -X- _ O
quality -X- _ O
. -X- _ O
MirrorGAN -X- _ O
( -X- _ O
Qiao -X- _ O
et -X- _ O
al -X- _ O
. -X- _ O
, -X- _ O
2019 -X- _ O
) -X- _ O
further -X- _ O
enhances -X- _ O
the -X- _ O
semantic -X- _ O
consistency -X- _ O
between -X- _ O
the -X- _ O
text -X- _ O
description -X- _ O
and -X- _ O
visual -X- _ O
content -X- _ O
by -X- _ O
leveraging -X- _ O
semantic -X- _ O
embedding -X- _ O
, -X- _ O
global -X- _ O
attention -X- _ O
, -X- _ O
and -X- _ O
semantic -X- _ O
alignment -X- _ O
modules -X- _ O
. -X- _ O
More -X- _ O
recently -X- _ O
, -X- _ O
VQ -X- _ O
- -X- _ O
VAE -X- _ O
with -X- _ O
transformer -X- _ O
( -X- _ O
VQ -X- _ B-MethodName
- -X- _ I-MethodName
VAE -X- _ I-MethodName
- -X- _ I-MethodName
LM -X- _ I-MethodName
) -X- _ O
structure -X- _ O
significantly -X- _ O
outperforms -X- _ O
GAN -X- _ O
- -X- _ O
based -X- _ O
methods -X- _ O
, -X- _ O
and -X- _ O
DALL -X- _ O
- -X- _ O
E -X- _ O
( -X- _ O
Ramesh -X- _ O
et -X- _ O
al -X- _ O
. -X- _ O
, -X- _ O
2021 -X- _ O
) -X- _ O
is -X- _ O
one -X- _ O
of -X- _ O
the -X- _ O
most -X- _ O
well -X- _ O
- -X- _ O
known -X- _ O
methods -X- _ O
that -X- _ O
use -X- _ O
this -X- _ O
structure -X- _ O
. -X- _ O

Li -X- _ O
et -X- _ O
al -X- _ O
. -X- _ O
( -X- _ O
2019 -X- _ O
) -X- _ O
is -X- _ O
one -X- _ O
of -X- _ O
the -X- _ O
earliest -X- _ O
works -X- _ O
to -X- _ O
propose -X- _ O
a -X- _ O
Sequential -X- _ O
Conditional -X- _ O
GAN -X- _ O
as -X- _ O
a -X- _ O
method -X- _ O
for -X- _ O
story -X- _ O
visualization -X- _ O
. -X- _ O
They -X- _ O
encode -X- _ O
the -X- _ O
story -X- _ O
and -X- _ O
decode -X- _ O
the -X- _ O
images -X- _ O
using -X- _ O
a -X- _ O
sequential -X- _ O
model -X- _ O
, -X- _ O
combining -X- _ O
image -X- _ O
and -X- _ O
story -X- _ O
discriminators -X- _ O
for -X- _ O
adversarial -X- _ O
learning -X- _ O
. -X- _ O
extends -X- _ O
the -X- _ O
GAN -X- _ O
structure -X- _ O
by -X- _ O
including -X- _ O
a -X- _ O
dual -X- _ O
learning -X- _ O
framework -X- _ O
that -X- _ O
uses -X- _ O
video -X- _ O
captioning -X- _ O
to -X- _ O
reinforce -X- _ O
the -X- _ O
semantic -X- _ O
alignment -X- _ O
between -X- _ O
the -X- _ O
story -X- _ O
and -X- _ O
generated -X- _ O
images -X- _ O
. -X- _ O
Based -X- _ O
on -X- _ O
this -X- _ O
new -X- _ O
framework -X- _ O
, -X- _ O
improves -X- _ O
the -X- _ O
generation -X- _ O
quality -X- _ O
by -X- _ O
incorporating -X- _ O
constituency -X- _ O
parse -X- _ O
trees -X- _ O
, -X- _ O
commonsense -X- _ O
knowledge -X- _ O
, -X- _ O
and -X- _ O
visual -X- _ O
structure -X- _ O
via -X- _ O
bounding -X- _ O
boxes -X- _ O
and -X- _ O
dense -X- _ O
captioning -X- _ O
. -X- _ O
To -X- _ O
improve -X- _ O
the -X- _ O
global -X- _ O
consistency -X- _ O
across -X- _ O
dynamic -X- _ O
scenes -X- _ O
and -X- _ O
characters -X- _ O
in -X- _ O
the -X- _ O
story -X- _ O
flow -X- _ O
, -X- _ O
Zeng -X- _ O
et -X- _ O
al -X- _ O
. -X- _ O
( -X- _ O
2019 -X- _ O
) -X- _ O
enhances -X- _ O
the -X- _ O
sentence -X- _ O
- -X- _ O
to -X- _ O
- -X- _ O
image -X- _ O
and -X- _ O
word -X- _ O
- -X- _ O
to -X- _ O
- -X- _ O
image -X- _ O
- -X- _ O
patch -X- _ O
alignment -X- _ O
by -X- _ O
proposing -X- _ O
an -X- _ O
aligned -X- _ O
sentence -X- _ O
encoder -X- _ O
and -X- _ O
attentional -X- _ O
word -X- _ O
encoder -X- _ O
. -X- _ O
With -X- _ O
similar -X- _ O
motivation -X- _ O
, -X- _ O
includes -X- _ O
dilated -X- _ O
convolution -X- _ O
in -X- _ O
the -X- _ O
discriminators -X- _ O
to -X- _ O
expand -X- _ O
the -X- _ O
receptive -X- _ O
field -X- _ O
and -X- _ O
weighted -X- _ O
activation -X- _ O
degree -X- _ O
to -X- _ O
provide -X- _ O
a -X- _ O
robust -X- _ O
evaluation -X- _ O
between -X- _ O
images -X- _ O
and -X- _ O
stories -X- _ O
. -X- _ O

To -X- _ O
preserve -X- _ O
character -X- _ O
information -X- _ O
, -X- _ O
CP -X- _ B-MethodName
- -X- _ I-MethodName
CSV -X- _ I-MethodName
( -X- _ O
Song -X- _ O
et -X- _ O
al -X- _ O
. -X- _ O
, -X- _ O
2020 -X- _ O
) -X- _ O
adapts -X- _ O
a -X- _ O
GAN -X- _ O
- -X- _ O
based -X- _ O
model -X- _ O
with -X- _ O
figure -X- _ O
- -X- _ O
background -X- _ O
segmentation -X- _ O
that -X- _ O
creates -X- _ O
masks -X- _ O
to -X- _ O
preserve -X- _ O
characters -X- _ O
and -X- _ O
improve -X- _ O
story -X- _ O
consistency -X- _ O
. -X- _ O
Our -X- _ O
work -X- _ O
differs -X- _ O
from -X- _ O
it -X- _ O
by -X- _ O
proposing -X- _ O
a -X- _ O
two -X- _ O
- -X- _ O
stage -X- _ O
visual -X- _ O
planning -X- _ O
model -X- _ O
enhanced -X- _ O
by -X- _ O
character -X- _ O
- -X- _ O
token -X- _ O
alignments -X- _ O
that -X- _ O
can -X- _ O
be -X- _ O
easily -X- _ O
incorporated -X- _ O
into -X- _ O
the -X- _ O
state -X- _ O
- -X- _ O
of -X- _ O
- -X- _ O
the -X- _ O
- -X- _ O
art -X- _ O
VQ -X- _ B-MethodName
- -X- _ I-MethodName
VAE -X- _ I-MethodName
- -X- _ I-MethodName
LM -X- _ I-MethodName
architecture -X- _ O
. -X- _ O

Vector -X- _ O
Quantised -X- _ O
- -X- _ O
Variational -X- _ O
AutoEncoder -X- _ O
( -X- _ O
VQ -X- _ O
- -X- _ O
VAE -X- _ O
) -X- _ O
( -X- _ O
Van -X- _ O
Den -X- _ O
Oord -X- _ O
et -X- _ O
al -X- _ O
. -X- _ O
, -X- _ O
2017 -X- _ O
) -X- _ O
encodes -X- _ O
images -X- _ O
into -X- _ O
latent -X- _ O
discrete -X- _ O
codes -X- _ O
instead -X- _ O
of -X- _ O
continuous -X- _ O
variables -X- _ O
as -X- _ O
in -X- _ O
VAEs -X- _ O
( -X- _ O
Kingma -X- _ O
and -X- _ O
Welling -X- _ O
, -X- _ O
2014 -X- _ O
) -X- _ O
, -X- _ O
which -X- _ O
helps -X- _ O
alleviate -X- _ O
the -X- _ O
" -X- _ O
posterior -X- _ O
collapse -X- _ O
" -X- _ O
issue -X- _ O
in -X- _ O
VAEs -X- _ O
whose -X- _ O
continuous -X- _ O
latent -X- _ O
variables -X- _ O
tend -X- _ O
to -X- _ O
be -X- _ O
ignored -X- _ O
by -X- _ O
strong -X- _ O
autoregressive -X- _ O
decoder -X- _ O
. -X- _ O

Denote -X- _ O
the -X- _ O
input -X- _ O
image -X- _ O
as -X- _ O
x -X- _ O
and -X- _ O
the -X- _ O
latent -X- _ O
variable -X- _ O
as -X- _ O
z -X- _ O
, -X- _ O
and -X- _ O
both -X- _ O
the -X- _ O
prior -X- _ O
p -X- _ O
( -X- _ O
z -X- _ O
) -X- _ O
and -X- _ O
the -X- _ O
posterior -X- _ O
q -X- _ O
( -X- _ O
z|x -X- _ O
) -X- _ O
in -X- _ O
VQ -X- _ O
- -X- _ O
VAE -X- _ O
follow -X- _ O
categorical -X- _ O
distributions -X- _ O
. -X- _ O
Assuming -X- _ O
there -X- _ O
are -X- _ O
K -X- _ O
quantized -X- _ O
entries -X- _ O
, -X- _ O
each -X- _ O
z -X- _ O
k -X- _ O
, -X- _ O
k -X- _ O
∈ -X- _ O
{ -X- _ O
1 -X- _ O
... -X- _ O
K -X- _ O
} -X- _ O
is -X- _ O
associated -X- _ O
with -X- _ O
a -X- _ O
trainable -X- _ O
embedding -X- _ O
vector -X- _ O
e -X- _ O
k -X- _ O
. -X- _ O
The -X- _ O
encoder -X- _ O
maps -X- _ O
the -X- _ O
input -X- _ O
to -X- _ O
a -X- _ O
vector -X- _ O
z -X- _ O
e -X- _ O
( -X- _ O
x -X- _ O
) -X- _ O
that -X- _ O
derives -X- _ O
the -X- _ O
posterior -X- _ O
distribution -X- _ O
: -X- _ O

Intuitively -X- _ O
, -X- _ O
the -X- _ O
nearest -X- _ O
embedding -X- _ O
vector -X- _ O
, -X- _ O
ê -X- _ O
k -X- _ O
, -X- _ O
to -X- _ O
z -X- _ O
e -X- _ O
( -X- _ O
x -X- _ O
) -X- _ O
, -X- _ O
is -X- _ O
used -X- _ O
as -X- _ O
the -X- _ O
latent -X- _ O
representation -X- _ O
z. -X- _ O
The -X- _ O
decoder -X- _ O
then -X- _ O
takes -X- _ O
as -X- _ O
input -X- _ O
theê -X- _ O
k -X- _ O
to -X- _ O
approximate -X- _ O
the -X- _ O
distribution -X- _ O
p -X- _ O
( -X- _ O
x|z -X- _ O
) -X- _ O
over -X- _ O
the -X- _ O
data -X- _ O
. -X- _ O
The -X- _ O
training -X- _ O
objective -X- _ O
of -X- _ O
VQ -X- _ O
- -X- _ O
VAE -X- _ O
is -X- _ O
: -X- _ O

The -X- _ O
above -X- _ O
objective -X- _ O
consists -X- _ O
of -X- _ O
: -X- _ O
( -X- _ O
1 -X- _ O
) -X- _ O
A -X- _ O
reconstruction -X- _ O
loss -X- _ O
L -X- _ O
recon -X- _ O
that -X- _ O
encourages -X- _ O
the -X- _ O
model -X- _ O
to -X- _ O
learn -X- _ O
good -X- _ O
representations -X- _ O
that -X- _ O
accurately -X- _ O
reconstruct -X- _ O
the -X- _ O
original -X- _ O
input -X- _ O
image -X- _ O
x. -X- _ O
( -X- _ O
2 -X- _ O
) -X- _ O
A -X- _ O
codebook -X- _ O
loss -X- _ O
L -X- _ O
codebook -X- _ O
that -X- _ O
minimizes -X- _ O
the -X- _ O
distance -X- _ O
between -X- _ O
codebook -X- _ O
embeddings -X- _ O
( -X- _ O
e -X- _ O
k -X- _ O
) -X- _ O
and -X- _ O
the -X- _ O
corresponding -X- _ O
encoder -X- _ O
outputs -X- _ O
z -X- _ O
e -X- _ O
( -X- _ O
x -X- _ O
) -X- _ O
. -X- _ O
( -X- _ O
3 -X- _ O
) -X- _ O
A -X- _ O
commitment -X- _ O
loss -X- _ O
L -X- _ O
commit -X- _ O
( -X- _ O
usually -X- _ O
weighted -X- _ O
by -X- _ O
a -X- _ O
hyperparameter -X- _ O
β -X- _ O
) -X- _ O
which -X- _ O
prevents -X- _ O
the -X- _ O
encoder -X- _ O
outputs -X- _ O
from -X- _ O
fluctuating -X- _ O
too -X- _ O
much -X- _ O
under -X- _ O
different -X- _ O
code -X- _ O
vectors -X- _ O
. -X- _ O

To -X- _ O
extend -X- _ O
the -X- _ O
standard -X- _ O
VQ -X- _ O
- -X- _ O
VAE -X- _ O
, -X- _ O
which -X- _ O
originally -X- _ O
takes -X- _ O
inputs -X- _ O
and -X- _ O
outputs -X- _ O
of -X- _ O
the -X- _ O
same -X- _ O
modality -X- _ O
, -X- _ O
to -X- _ O
handle -X- _ O
multimodal -X- _ O
inputs -X- _ O
and -X- _ O
outputs -X- _ O
such -X- _ O
as -X- _ O
textto -X- _ O
- -X- _ O
image -X- _ O
generations -X- _ O
, -X- _ O
the -X- _ O
key -X- _ O
idea -X- _ O
is -X- _ O
to -X- _ O
augment -X- _ O
the -X- _ O
VAE -X- _ O
architecture -X- _ O
with -X- _ O
a -X- _ O
transformer -X- _ O
- -X- _ O
based -X- _ O
language -X- _ O
model -X- _ O
( -X- _ O
LM -X- _ O
) -X- _ O
. -X- _ O
Denote -X- _ O
the -X- _ O
textual -X- _ O
inputs -X- _ O
as -X- _ O
y -X- _ O
, -X- _ O
the -X- _ O
text -X- _ O
- -X- _ O
to -X- _ O
- -X- _ O
image -X- _ O
generative -X- _ O
process -X- _ O
can -X- _ O
be -X- _ O
decomposed -X- _ O
into -X- _ O
p -X- _ O
( -X- _ O
x|y -X- _ O
) -X- _ O
= -X- _ O
p -X- _ O
( -X- _ O
x|z -X- _ O
) -X- _ O
p -X- _ O
( -X- _ O
z|y -X- _ O
) -X- _ O
. -X- _ O
The -X- _ O
LM -X- _ O
( -X- _ O
p -X- _ O
( -X- _ O
z|y -X- _ O
) -X- _ O
) -X- _ O
generates -X- _ O
latent -X- _ O
codes -X- _ O
z -X- _ O
conditioned -X- _ O
on -X- _ O
y -X- _ O
, -X- _ O
which -X- _ O
can -X- _ O
be -X- _ O
directly -X- _ O
plugged -X- _ O
into -X- _ O
the -X- _ O
decoder -X- _ O
of -X- _ O
VQ -X- _ O
- -X- _ O
VAE -X- _ O
to -X- _ O
reconstruct -X- _ O
the -X- _ O
output -X- _ O
image -X- _ O
. -X- _ O
In -X- _ O
the -X- _ O
existing -X- _ O
VQ -X- _ B-MethodName
- -X- _ I-MethodName
VAE -X- _ I-MethodName
- -X- _ I-MethodName
LM -X- _ I-MethodName
architectures -X- _ O
such -X- _ O
as -X- _ O
Yan -X- _ O
et -X- _ O
al -X- _ O
. -X- _ O
Based -X- _ O
on -X- _ O
the -X- _ O
corresponded -X- _ O
sentence -X- _ O
( -X- _ O
s -X- _ O
) -X- _ O
, -X- _ O
we -X- _ O
can -X- _ O
get -X- _ O
the -X- _ O
characters -X- _ O
" -X- _ O
Poby -X- _ O
" -X- _ O
, -X- _ O
" -X- _ O
Crong -X- _ O
" -X- _ O
, -X- _ O
" -X- _ O
Pororo -X- _ O
" -X- _ O
and -X- _ O
" -X- _ O
Eddy -X- _ O
" -X- _ O
that -X- _ O
are -X- _ O
involved -X- _ O
in -X- _ O
the -X- _ O
image -X- _ O
. -X- _ O
We -X- _ O
then -X- _ O
apply -X- _ O
Grad -X- _ O
- -X- _ O
CAM -X- _ O
on -X- _ O
a -X- _ O
pretrained -X- _ O
ResNet -X- _ O
by -X- _ O
specifying -X- _ O
each -X- _ O
character -X- _ O
and -X- _ O
obtaining -X- _ O
a -X- _ O
heatmap -X- _ O
for -X- _ O
each -X- _ O
character -X- _ O
. -X- _ O
Combining -X- _ O
these -X- _ O
heatmaps -X- _ O
, -X- _ O
we -X- _ O
can -X- _ O
obtain -X- _ O
an -X- _ O
overall -X- _ O
heatmap -X- _ O
that -X- _ O
distinguishes -X- _ O
the -X- _ O
character -X- _ O
and -X- _ O
background -X- _ O
regions -X- _ O
. -X- _ O
We -X- _ O
mask -X- _ O
the -X- _ O
background -X- _ O
tokens -X- _ O
and -X- _ O
leave -X- _ O
the -X- _ O
rest -X- _ O
character -X- _ O
visual -X- _ O
tokens -X- _ O
as -X- _ O
targets -X- _ O
in -X- _ O
our -X- _ O
proposed -X- _ O
visual -X- _ O
planning -X- _ O
methods -X- _ O
. -X- _ O
( -X- _ O
b -X- _ O
) -X- _ O
and -X- _ O
( -X- _ O
c -X- _ O
) -X- _ O
depict -X- _ O
the -X- _ O
two -X- _ O
- -X- _ O
stage -X- _ O
generation -X- _ O
, -X- _ O
where -X- _ O
( -X- _ O
b -X- _ O
) -X- _ O
learns -X- _ O
to -X- _ O
generate -X- _ O
character -X- _ O
visual -X- _ O
tokens -X- _ O
which -X- _ O
is -X- _ O
generated -X- _ O
from -X- _ O
( -X- _ O
a -X- _ O
) -X- _ O
, -X- _ O
and -X- _ O
then -X- _ O
( -X- _ O
c -X- _ O
) -X- _ O
completes -X- _ O
the -X- _ O
visual -X- _ O
tokens -X- _ O
. -X- _ O

In -X- _ O
order -X- _ O
to -X- _ O
exploit -X- _ O
the -X- _ O
trained -X- _ O
VQ -X- _ O
- -X- _ O
VAE -X- _ O
decoder -X- _ O
, -X- _ O
the -X- _ O
output -X- _ O
space -X- _ O
of -X- _ O
the -X- _ O
LM -X- _ O
needs -X- _ O
to -X- _ O
be -X- _ O
bridged -X- _ O
to -X- _ O
the -X- _ O
input -X- _ O
space -X- _ O
of -X- _ O
the -X- _ O
decoder -X- _ O
, -X- _ O
i.e. -X- _ O
we -X- _ O
require -X- _ O
the -X- _ O
LM -X- _ O
to -X- _ O
be -X- _ O
finetuned -X- _ O
to -X- _ O
produce -X- _ O
plausible -X- _ O
visual -X- _ O
tokens -X- _ O
. -X- _ O
As -X- _ O
shown -X- _ O
in -X- _ O
the -X- _ O
upper -X- _ O
half -X- _ O
of -X- _ O
Figure -X- _ O
2 -X- _ O
, -X- _ O
the -X- _ O
visual -X- _ O
tokens -X- _ O
are -X- _ O
quantized -X- _ O
latent -X- _ O
codes -X- _ O
encoded -X- _ O
from -X- _ O
the -X- _ O
target -X- _ O
image -X- _ O
sequence -X- _ O
. -X- _ O
They -X- _ O
are -X- _ O
then -X- _ O
flattened -X- _ O
and -X- _ O
concatenated -X- _ O
into -X- _ O
one -X- _ O
long -X- _ O
token -X- _ O
sequence -X- _ O
. -X- _ O
The -X- _ O
LM -X- _ O
( -X- _ O
Figure -X- _ O
2 -X- _ O
lower -X- _ O
half -X- _ O
) -X- _ O
takes -X- _ O
these -X- _ O
visual -X- _ O
tokens -X- _ O
as -X- _ O
the -X- _ O
training -X- _ O
targets -X- _ O
for -X- _ O
encoding -X- _ O
input -X- _ O
stories -X- _ O
. -X- _ O
We -X- _ O
follow -X- _ O
the -X- _ O
existing -X- _ O
work -X- _ O
( -X- _ O
Yan -X- _ O
et -X- _ O
al -X- _ O
. -X- _ O
, -X- _ O
2021 -X- _ O
; -X- _ O
Ramesh -X- _ O
et -X- _ O
al -X- _ O
. -X- _ O
, -X- _ O
2021 -X- _ O
) -X- _ O
to -X- _ O
train -X- _ O
VQ -X- _ O
- -X- _ O
VAE -X- _ O
and -X- _ O
LM -X- _ O
independently -X- _ O
; -X- _ O
however -X- _ O
, -X- _ O
both -X- _ O
components -X- _ O
are -X- _ O
trained -X- _ O
from -X- _ O
scratch -X- _ O
to -X- _ O
accommodate -X- _ O
the -X- _ O
targeted -X- _ O
animation -X- _ O
domain -X- _ O
in -X- _ O
this -X- _ O
work -X- _ O
. -X- _ O

The -X- _ O
proposed -X- _ O
VP -X- _ B-MethodName
- -X- _ I-MethodName
CSV -X- _ I-MethodName
framework -X- _ O
is -X- _ O
illustrated -X- _ O
in -X- _ O
Figure -X- _ O
3 -X- _ O
. -X- _ O
In -X- _ O
order -X- _ O
to -X- _ O
exploit -X- _ O
character -X- _ O
- -X- _ O
centric -X- _ O
inductive -X- _ O
biases -X- _ O
to -X- _ O
guide -X- _ O
a -X- _ O
more -X- _ O
consistent -X- _ O
story -X- _ B-TaskName
visualization -X- _ I-TaskName
, -X- _ O
we -X- _ O
decompose -X- _ O
the -X- _ O
text -X- _ O
- -X- _ O
to -X- _ O
- -X- _ O
visual -X- _ O
- -X- _ O
token -X- _ O
generation -X- _ O
( -X- _ O
Section -X- _ O
3.2 -X- _ O
) -X- _ O
into -X- _ O
a -X- _ O
two -X- _ O
- -X- _ O
stage -X- _ O
framework -X- _ O
comprising -X- _ O
: -X- _ O
( -X- _ O
1 -X- _ O
) -X- _ O
a -X- _ O
plan -X- _ O
module -X- _ O
( -X- _ O
Figure -X- _ O
3b -X- _ O
) -X- _ O
that -X- _ O
performs -X- _ O
character -X- _ O
- -X- _ O
level -X- _ O
planning -X- _ O
by -X- _ O
focusing -X- _ O
on -X- _ O
generating -X- _ O
visual -X- _ O
tokens -X- _ O
for -X- _ O
character -X- _ O
regions -X- _ O
, -X- _ O
while -X- _ O
non -X- _ O
- -X- _ O
character -X- _ O
regions -X- _ O
are -X- _ O
masked -X- _ O
- -X- _ O
out -X- _ O
, -X- _ O
given -X- _ O
the -X- _ O
input -X- _ O
story -X- _ O
, -X- _ O
and -X- _ O
( -X- _ O
2 -X- _ O
) -X- _ O
a -X- _ O
completion -X- _ O
module -X- _ O
( -X- _ O
Figure -X- _ O
3c -X- _ O
) -X- _ O
which -X- _ O
conditions -X- _ O
on -X- _ O
both -X- _ O
the -X- _ O
input -X- _ O
story -X- _ O
and -X- _ O
the -X- _ O
outputs -X- _ O
from -X- _ O
( -X- _ O
1 -X- _ O
) -X- _ O
to -X- _ O
produce -X- _ O
the -X- _ O
complete -X- _ O
visual -X- _ O
tokens -X- _ O
as -X- _ O
the -X- _ O
input -X- _ O
to -X- _ O
the -X- _ O
VQ -X- _ O
- -X- _ O
VAE -X- _ O
decoder -X- _ O
. -X- _ O

Given -X- _ O
a -X- _ O
story -X- _ O
s -X- _ O
which -X- _ O
consists -X- _ O
of -X- _ O
a -X- _ O
sequence -X- _ O
of -X- _ O
short -X- _ O
paragraphs -X- _ O
: -X- _ O
s -X- _ O
= -X- _ O
{ -X- _ O
s -X- _ O
1 -X- _ O
, -X- _ O
s -X- _ O
2 -X- _ O
, -X- _ O
... -X- _ O
, -X- _ O
s -X- _ O
n -X- _ O
} -X- _ O
. -X- _ O
Each -X- _ O
paragraph -X- _ O
( -X- _ O
one -X- _ O
or -X- _ O
a -X- _ O
few -X- _ O
sentences -X- _ O
) -X- _ O
corresponds -X- _ O
to -X- _ O
an -X- _ O
image -X- _ O
in -X- _ O
the -X- _ O
sequence -X- _ O
. -X- _ O
The -X- _ O
goal -X- _ O
of -X- _ O
story -X- _ O
visualization -X- _ O
is -X- _ O
to -X- _ O
generate -X- _ O
a -X- _ O
sequence -X- _ O
of -X- _ O
images -X- _ O
x -X- _ O
= -X- _ O
{ -X- _ O
x -X- _ O
1 -X- _ O
, -X- _ O
x -X- _ O
2 -X- _ O
, -X- _ O
... -X- _ O
, -X- _ O
x -X- _ O
n -X- _ O
} -X- _ O
conditioned -X- _ O
on -X- _ O
the -X- _ O
story -X- _ O
s -X- _ O
. -X- _ O

] -X- _ O
to -X- _ O
perform -X- _ O
sequence -X- _ O
generation -X- _ O
. -X- _ O
For -X- _ O
visual -X- _ O
tokens -X- _ O
z -X- _ O
i -X- _ O
in -X- _ O
the -X- _ O
i -X- _ O
- -X- _ O
th -X- _ O
image -X- _ O
, -X- _ O
we -X- _ O
use -X- _ O
r -X- _ O
i -X- _ O
∈ -X- _ O
( -X- _ O
p -X- _ O
× -X- _ O
p -X- _ O
) -X- _ O
to -X- _ O
denote -X- _ O
the -X- _ O
tokens -X- _ O
within -X- _ O
the -X- _ O
regions -X- _ O
containing -X- _ O
story -X- _ O
characters -X- _ O
, -X- _ O
while -X- _ O
tokens -X- _ O
in -X- _ O
non -X- _ O
- -X- _ O
character -X- _ O
regions -X- _ O
will -X- _ O
be -X- _ O
replaced -X- _ O
with -X- _ O
a -X- _ O
special -X- _ O
masking -X- _ O
token -X- _ O
[ -X- _ O
MASK -X- _ O
] -X- _ O
as -X- _ O
the -X- _ O
target -X- _ O
of -X- _ O
our -X- _ O
planning -X- _ O
module -X- _ O
. -X- _ O
z -X- _ O
i -X- _ O
would -X- _ O
be -X- _ O
completely -X- _ O
masked -X- _ O
out -X- _ O
( -X- _ O
filled -X- _ O
with -X- _ O
all -X- _ O
[ -X- _ O
MASK -X- _ O
] -X- _ O
) -X- _ O
if -X- _ O
the -X- _ O
image -X- _ O
x -X- _ O
i -X- _ O
does -X- _ O
not -X- _ O
contain -X- _ O
any -X- _ O
characters -X- _ O
. -X- _ O

The -X- _ O
visual -X- _ O
planning -X- _ O
stage -X- _ O
focuses -X- _ O
on -X- _ O
generating -X- _ O
a -X- _ O
visually -X- _ O
and -X- _ O
story -X- _ O
- -X- _ O
wise -X- _ O
consistent -X- _ O
character -X- _ O
plan -X- _ O
to -X- _ O
determine -X- _ O
the -X- _ O
suitable -X- _ O
spatial -X- _ O
regions -X- _ O
in -X- _ O
each -X- _ O
image -X- _ O
frame -X- _ O
to -X- _ O
place -X- _ O
characters -X- _ O
before -X- _ O
filling -X- _ O
in -X- _ O
other -X- _ O
visual -X- _ O
details -X- _ O
. -X- _ O
Due -X- _ O
to -X- _ O
the -X- _ O
lack -X- _ O
of -X- _ O
annotations -X- _ O
for -X- _ O
character -X- _ O
regions -X- _ O
in -X- _ O
the -X- _ O
dataset -X- _ O
, -X- _ O
we -X- _ O
first -X- _ O
leverage -X- _ O
external -X- _ O
tools -X- _ O
to -X- _ O
extract -X- _ O
character -X- _ O
regions -X- _ O
during -X- _ O
data -X- _ O
pre -X- _ O
- -X- _ O
processing -X- _ O
. -X- _ O
Character -X- _ O
region -X- _ O
extraction -X- _ O
. -X- _ O
As -X- _ O
shown -X- _ O
in -X- _ O
Figure -X- _ O
3a -X- _ O
, -X- _ O
we -X- _ O
first -X- _ O
train -X- _ O
a -X- _ O
multi -X- _ O
- -X- _ O
label -X- _ O
classifer -X- _ O
that -X- _ O
is -X- _ O
able -X- _ O
to -X- _ O
identify -X- _ O
all -X- _ O
characters -X- _ O
in -X- _ O
text -X- _ O
inputs -X- _ O
. -X- _ O
We -X- _ O
then -X- _ O
utilize -X- _ O
Grad -X- _ O
- -X- _ O
CAM -X- _ O
( -X- _ O
Selvaraju -X- _ O
et -X- _ O
al -X- _ O
. -X- _ O
, -X- _ O
2017 -X- _ O
) -X- _ O
, -X- _ O
a -X- _ O
widely -X- _ O
- -X- _ O
used -X- _ O
technique -X- _ O
for -X- _ O
generating -X- _ O
class -X- _ O
- -X- _ O
specific -X- _ O
heatmaps -X- _ O
to -X- _ O
locate -X- _ O
highly -X- _ O
- -X- _ O
attended -X- _ O
regions -X- _ O
within -X- _ O
images -X- _ O
. -X- _ O
In -X- _ O
our -X- _ O
case -X- _ O
, -X- _ O
these -X- _ O
classes -X- _ O
refer -X- _ O
to -X- _ O
characters -X- _ O
, -X- _ O
so -X- _ O
Grad -X- _ O
- -X- _ O
CAM -X- _ O
can -X- _ O
help -X- _ O
us -X- _ O
find -X- _ O
the -X- _ O
character -X- _ O
regions -X- _ O
without -X- _ O
any -X- _ O
supervised -X- _ O
data -X- _ O
. -X- _ O
For -X- _ O
each -X- _ O
character -X- _ O
identified -X- _ O
by -X- _ O
the -X- _ O
multi -X- _ O
- -X- _ O
label -X- _ O
classifer -X- _ O
in -X- _ O
the -X- _ O
associated -X- _ O
sentence -X- _ O
( -X- _ O
s -X- _ O
) -X- _ O
of -X- _ O
an -X- _ O
image -X- _ O
, -X- _ O
Grad -X- _ O
- -X- _ O
CAM -X- _ O
produces -X- _ O
a -X- _ O
heatmap -X- _ O
highlighting -X- _ O
the -X- _ O
character -X- _ O
region -X- _ O
. -X- _ O
We -X- _ O
merge -X- _ O
these -X- _ O
heatmaps -X- _ O
into -X- _ O
one -X- _ O
that -X- _ O
represents -X- _ O
the -X- _ O
region -X- _ O
covering -X- _ O
all -X- _ O
existing -X- _ O
characters -X- _ O
. -X- _ O

More -X- _ O
specifically -X- _ O
, -X- _ O
we -X- _ O
first -X- _ O
train -X- _ O
a -X- _ O
CNN -X- _ O
character -X- _ O
classification -X- _ O
model -X- _ O
1 -X- _ O
with -X- _ O
multi -X- _ O
- -X- _ O
label -X- _ O
classification -X- _ O
loss -X- _ O
, -X- _ O
using -X- _ O
the -X- _ O
character -X- _ O
mentions -X- _ O
in -X- _ O
the -X- _ O
story -X- _ O
sentences -X- _ O
as -X- _ O
target -X- _ O
labels -X- _ O
. -X- _ O
As -X- _ O
exemplified -X- _ O
in -X- _ O
Figure -X- _ O
3a -X- _ O
, -X- _ O
we -X- _ O
obtain -X- _ O
four -X- _ O
independent -X- _ O
heatmaps -X- _ O
for -X- _ O
their -X- _ O
corresponding -X- _ O
characters -X- _ O
and -X- _ O
merge -X- _ O
them -X- _ O
into -X- _ O
a -X- _ O
single -X- _ O
one -X- _ O
. -X- _ O
A -X- _ O
visual -X- _ O
token -X- _ O
belongs -X- _ O
to -X- _ O
the -X- _ O
background -X- _ O
( -X- _ O
i.e. -X- _ O
the -X- _ O
blue -X- _ O
image -X- _ O
patches -X- _ O
) -X- _ O
if -X- _ O
none -X- _ O
of -X- _ O
the -X- _ O
above -X- _ O
character -X- _ O
heatmaps -X- _ O
attend -X- _ O
to -X- _ O
its -X- _ O
corresponding -X- _ O
image -X- _ O
region -X- _ O
. -X- _ O
Formally -X- _ O
, -X- _ O
the -X- _ O
masks -X- _ O
separating -X- _ O
the -X- _ O
character -X- _ O
and -X- _ O
non -X- _ O
- -X- _ O
character -X- _ O
visual -X- _ O
tokens -X- _ O
are -X- _ O
derived -X- _ O
using -X- _ O
the -X- _ O
following -X- _ O
formula -X- _ O
: -X- _ O

Character -X- _ O
token -X- _ O
planning -X- _ O
( -X- _ O
first -X- _ O
stage -X- _ O
) -X- _ O
. -X- _ O
We -X- _ O
adopt -X- _ O
a -X- _ O
GPT-2 -X- _ O
language -X- _ O
model -X- _ O
in -X- _ O
the -X- _ O
plan -X- _ O
module -X- _ O
to -X- _ O
produce -X- _ O
( -X- _ O
plan -X- _ O
) -X- _ O
the -X- _ O
character -X- _ O
visual -X- _ O
tokens -X- _ O
. -X- _ O
Specifically -X- _ O
, -X- _ O
conditioning -X- _ O
on -X- _ O
the -X- _ O
input -X- _ O
story -X- _ O
sentences -X- _ O
s -X- _ O
= -X- _ O
{ -X- _ O
s -X- _ O
1 -X- _ O
, -X- _ O
s -X- _ O
2 -X- _ O
, -X- _ O
... -X- _ O
, -X- _ O
s -X- _ O
n -X- _ O
} -X- _ O
, -X- _ O
the -X- _ O
model -X- _ O
learns -X- _ O
to -X- _ O
generate -X- _ O
the -X- _ O
planned -X- _ O
character -X- _ O
visual -X- _ O
tokens -X- _ O
r -X- _ O
= -X- _ O
{ -X- _ O
r -X- _ O
1 -X- _ O
, -X- _ O
r -X- _ O
2 -X- _ O
, -X- _ O
... -X- _ O
, -X- _ O
r -X- _ O
n -X- _ O
} -X- _ O
that -X- _ O
are -X- _ O
prepared -X- _ O
in -X- _ O
the -X- _ O
aforementioned -X- _ O
character -X- _ O
- -X- _ O
region -X- _ O
extraction -X- _ O
stage -X- _ O
. -X- _ O
Denote -X- _ O
θ -X- _ O
as -X- _ O
the -X- _ O
parameters -X- _ O
of -X- _ O
the -X- _ O
GPT-2 -X- _ O
model -X- _ O
, -X- _ O
per -X- _ O
sample -X- _ O
training -X- _ O
loss -X- _ O
can -X- _ O
be -X- _ O
computed -X- _ O
as -X- _ O
: -X- _ O

The -X- _ O
data -X- _ O
pre -X- _ O
- -X- _ O
processing -X- _ O
described -X- _ O
in -X- _ O
the -X- _ O
previous -X- _ O
section -X- _ O
enables -X- _ O
us -X- _ O
to -X- _ O
obtain -X- _ O
character -X- _ O
visual -X- _ O
tokens -X- _ O
in -X- _ O
the -X- _ O
training -X- _ O
data -X- _ O
. -X- _ O
With -X- _ O
that -X- _ O
, -X- _ O
we -X- _ O
can -X- _ O
compute -X- _ O
the -X- _ O
visual -X- _ O
token -X- _ O
distribution -X- _ O
for -X- _ O
each -X- _ O
character -X- _ O
. -X- _ O
It -X- _ O
can -X- _ O
be -X- _ O
observed -X- _ O
from -X- _ O
the -X- _ O
token -X- _ O
distribution -X- _ O
shown -X- _ O
in -X- _ O
Figure -X- _ O
4 -X- _ O
, -X- _ O
that -X- _ O
different -X- _ O
characters -X- _ O
tend -X- _ O
to -X- _ O
reflect -X- _ O
different -X- _ O
representative -X- _ O
token -X- _ O
IDs -X- _ O
. -X- _ O
Based -X- _ O
on -X- _ O
this -X- _ O
observation -X- _ O
, -X- _ O
a -X- _ O
straightforward -X- _ O
way -X- _ O
to -X- _ O
improve -X- _ O
the -X- _ O
model -X- _ O
's -X- _ O
character -X- _ O
preservation -X- _ O
is -X- _ O
to -X- _ O
increase -X- _ O
the -X- _ O
occurrence -X- _ O
probability -X- _ O
of -X- _ O
a -X- _ O
character -X- _ O
's -X- _ O
top -X- _ O
visual -X- _ O
tokens -X- _ O
if -X- _ O
it -X- _ O
is -X- _ O
mentioned -X- _ O
in -X- _ O
the -X- _ O
story -X- _ O
sentences -X- _ O
. -X- _ O
In -X- _ O
light -X- _ O
of -X- _ O
this -X- _ O
, -X- _ O
we -X- _ O
propose -X- _ O
to -X- _ O
use -X- _ O
a -X- _ O
semantic -X- _ O
loss -X- _ O
( -X- _ O
Xu -X- _ O
et -X- _ O
al -X- _ O
. -X- _ O
, -X- _ O
2018a -X- _ O
) -X- _ O
to -X- _ O
encourage -X- _ O
the -X- _ O
character -X- _ O
- -X- _ O
to -X- _ O
- -X- _ O
visualtoken -X- _ O
alignment -X- _ O
. -X- _ O

We -X- _ O
extract -X- _ O
the -X- _ O
top-10 -X- _ O
frequent -X- _ O
tokens -X- _ O
t -X- _ O
c -X- _ O
for -X- _ O
each -X- _ O
character -X- _ O
c -X- _ O
, -X- _ O
and -X- _ O
for -X- _ O
each -X- _ O
input -X- _ O
story -X- _ O
s -X- _ O
, -X- _ O
we -X- _ O
compose -X- _ O
a -X- _ O
token -X- _ O
set -X- _ O
T -X- _ O
= -X- _ O
c -X- _ O
t -X- _ O
c -X- _ O
, -X- _ O
in -X- _ O
which -X- _ O
the -X- _ O
character -X- _ O
c -X- _ O
is -X- _ O
mentioned -X- _ O
at -X- _ O
least -X- _ O
once -X- _ O
in -X- _ O
story -X- _ O
s. -X- _ O
We -X- _ O
denote -X- _ O
the -X- _ O
visual -X- _ O
tokens -X- _ O
extracted -X- _ O
from -X- _ O
their -X- _ O
corresponding -X- _ O
images -X- _ O
as -X- _ O
z -X- _ O
, -X- _ O
and -X- _ O
write -X- _ O
the -X- _ O
semantic -X- _ O
loss -X- _ O
as -X- _ O
: -X- _ O

where -X- _ O
Q -X- _ O
is -X- _ O
the -X- _ O
character -X- _ O
token -X- _ O
constraint -X- _ O
that -X- _ O
requires -X- _ O
the -X- _ O
character -X- _ O
tokens -X- _ O
in -X- _ O
T -X- _ O
to -X- _ O
appear -X- _ O
in -X- _ O
the -X- _ O
generated -X- _ O
visual -X- _ O
token -X- _ O
sequence -X- _ O
. -X- _ O
P -X- _ O
indicates -X- _ O
the -X- _ O
token -X- _ O
set -X- _ O
{ -X- _ O
z -X- _ O
j -X- _ O
∈ -X- _ O
T -X- _ O
| -X- _ O
z -X- _ O
j -X- _ O
∈ -X- _ O
z -X- _ O
} -X- _ O
; -X- _ O
N -X- _ O
denotes -X- _ O
the -X- _ O
token -X- _ O
set -X- _ O
{ -X- _ O
z -X- _ O
j -X- _ O
/ -X- _ O
∈ -X- _ O
T -X- _ O
| -X- _ O
z -X- _ O
j -X- _ O
∈ -X- _ O
z -X- _ O
} -X- _ O
, -X- _ O
and -X- _ O
p -X- _ O
j -X- _ O
is -X- _ O
the -X- _ O
predicted -X- _ O
probability -X- _ O
of -X- _ O
z -X- _ O
j -X- _ O
. -X- _ O
The -X- _ O
intuition -X- _ O
of -X- _ O
this -X- _ O
objective -X- _ O
is -X- _ O
that -X- _ O
if -X- _ O
all -X- _ O
( -X- _ O
identified -X- _ O
) -X- _ O
characters -X- _ O
' -X- _ O
top -X- _ O
visual -X- _ O
tokens -X- _ O
show -X- _ O
up -X- _ O
in -X- _ O
the -X- _ O
predicted -X- _ O
z -X- _ O
( -X- _ O
i.e. -X- _ O
z -X- _ O
|= -X- _ O
Q -X- _ O
) -X- _ O
, -X- _ O
we -X- _ O
further -X- _ O
increase -X- _ O
the -X- _ O
probability -X- _ O
of -X- _ O
tokens -X- _ O
in -X- _ O
P -X- _ O
, -X- _ O
while -X- _ O
penalizing -X- _ O
the -X- _ O
likelihood -X- _ O
of -X- _ O
generating -X- _ O
less -X- _ O
relevant -X- _ O
tokens -X- _ O
belonging -X- _ O
to -X- _ O
N -X- _ O
. -X- _ O

In -X- _ O
this -X- _ O
work -X- _ O
, -X- _ O
we -X- _ O
use -X- _ O
a -X- _ O
popular -X- _ O
story -X- _ O
visualization -X- _ O
dataset -X- _ O
, -X- _ O
Pororo -X- _ B-DatasetName
- -X- _ I-DatasetName
SV -X- _ I-DatasetName
to -X- _ O
train -X- _ O
and -X- _ O
evaluate -X- _ O
our -X- _ O
models -X- _ O
. -X- _ O
Each -X- _ O
story -X- _ O
in -X- _ O
Pororo -X- _ B-DatasetName
- -X- _ I-DatasetName
SV -X- _ I-DatasetName
contains -X- _ O
5 -X- _ O
short -X- _ O
paragraphs -X- _ O
( -X- _ O
a -X- _ O
paragraph -X- _ O
typically -X- _ O
consists -X- _ O
of -X- _ O
1 -X- _ O
- -X- _ O
2 -X- _ O
sentences -X- _ O
) -X- _ O
. -X- _ O
Each -X- _ O
short -X- _ O
paragraph -X- _ O
corresponds -X- _ O
to -X- _ O
one -X- _ O
image -X- _ O
in -X- _ O
the -X- _ O
target -X- _ O
image -X- _ O
sequence -X- _ O
. -X- _ O
The -X- _ O
dataset -X- _ O
contains -X- _ O
10,191 -X- _ O
, -X- _ O
2,334 -X- _ O
, -X- _ O
and -X- _ O
2,208 -X- _ O
samples -X- _ O
in -X- _ O
train -X- _ O
, -X- _ O
validation -X- _ O
, -X- _ O
and -X- _ O
test -X- _ O
split -X- _ O
. -X- _ O
The -X- _ O
validation -X- _ O
split -X- _ O
may -X- _ O
include -X- _ O
frames -X- _ O
in -X- _ O
the -X- _ O
training -X- _ O
split -X- _ O
, -X- _ O
while -X- _ O
the -X- _ O
test -X- _ O
split -X- _ O
contains -X- _ O
all -X- _ O
new -X- _ O
frames -X- _ O
unseen -X- _ O
from -X- _ O
the -X- _ O
training -X- _ O
data -X- _ O
. -X- _ O
To -X- _ O
better -X- _ O
demonstrate -X- _ O
the -X- _ O
visualization -X- _ O
performance -X- _ O
of -X- _ O
our -X- _ O
model -X- _ O
, -X- _ O
we -X- _ O
mainly -X- _ O
experiment -X- _ O
on -X- _ O
the -X- _ O
test -X- _ O
split -X- _ O
. -X- _ O
Besides -X- _ O
, -X- _ O
to -X- _ O
help -X- _ O
the -X- _ O
reader -X- _ O
understand -X- _ O
our -X- _ O
examples -X- _ O
, -X- _ O
we -X- _ O
show -X- _ O
the -X- _ O
main -X- _ O
characters -X- _ O
of -X- _ O
this -X- _ O
dataset -X- _ O
in -X- _ O
Figure -X- _ O
5 -X- _ O
. -X- _ O

Note -X- _ O
that -X- _ O
the -X- _ O
Pororo -X- _ B-DatasetName
- -X- _ I-DatasetName
SV -X- _ I-DatasetName
dataset -X- _ O
is -X- _ O
the -X- _ O
only -X- _ O
one -X- _ O
we -X- _ O
are -X- _ O
aware -X- _ O
of -X- _ O
that -X- _ O
has -X- _ O
been -X- _ O
studied -X- _ O
with -X- _ O
systematic -X- _ O
quantitative -X- _ O
evaluations -X- _ O
. -X- _ O
Another -X- _ O
notable -X- _ O
story -X- _ O
visualization -X- _ O
dataset -X- _ O
is -X- _ O
Flinstones -X- _ B-DatasetName
( -X- _ O
Gupta -X- _ O
et -X- _ O
al -X- _ O
. -X- _ O
, -X- _ O
2018 -X- _ O
) -X- _ O
, -X- _ O
however -X- _ O
, -X- _ O
there -X- _ O
is -X- _ O
not -X- _ O
established -X- _ O
automatic -X- _ O
evaluation -X- _ O
for -X- _ O
this -X- _ O
dataset -X- _ O
. -X- _ O
To -X- _ O
show -X- _ O
the -X- _ O
generalization -X- _ O
of -X- _ O
our -X- _ O
proposed -X- _ O
VP -X- _ B-MethodName
- -X- _ I-MethodName
CSV -X- _ I-MethodName
method -X- _ O
, -X- _ O
we -X- _ O
put -X- _ O
the -X- _ O
generation -X- _ O
example -X- _ O
of -X- _ O
our -X- _ O
model -X- _ O
trained -X- _ O
on -X- _ O
the -X- _ O
Flintstones -X- _ B-DatasetName
dataset -X- _ O
in -X- _ O
Appendix -X- _ O
Figure -X- _ O
11 -X- _ O
. -X- _ O

We -X- _ O
adopt -X- _ O
the -X- _ O
automatic -X- _ O
evaluation -X- _ O
metrics -X- _ O
following -X- _ O
existing -X- _ O
works -X- _ O
of -X- _ O
the -X- _ O
story -X- _ O
visualization -X- _ O
task -X- _ O
and -X- _ O
report -X- _ O
results -X- _ O
using -X- _ O
the -X- _ O
evaluation -X- _ O
script -X- _ O
provided -X- _ O
in -X- _ O
prior -X- _ O
work -X- _ O
. -X- _ O
2 -X- _ O
2 -X- _ O
https -X- _ O
: -X- _ O
/ -X- _ O
/ -X- _ O
github.com -X- _ O
/ -X- _ O
adymaharana -X- _ O
/ -X- _ O
VLCStoryGan -X- _ O
Character -X- _ B-MetricName
F1 -X- _ I-MetricName
score -X- _ O
measures -X- _ O
the -X- _ O
percentages -X- _ O
of -X- _ O
characters -X- _ O
obtained -X- _ O
from -X- _ O
the -X- _ O
generated -X- _ O
images -X- _ O
that -X- _ O
exactly -X- _ O
appear -X- _ O
in -X- _ O
the -X- _ O
story -X- _ O
inputs -X- _ O
. -X- _ O
A -X- _ O
pretrained -X- _ O
inception -X- _ O
v3 -X- _ O
model -X- _ O
( -X- _ O
Szegedy -X- _ O
et -X- _ O
al -X- _ O
. -X- _ O
, -X- _ O
2016 -X- _ O
) -X- _ O
is -X- _ O
finetuned -X- _ O
on -X- _ O
Pororo -X- _ B-DatasetName
- -X- _ I-DatasetName
SV -X- _ I-DatasetName
by -X- _ O
a -X- _ O
multi -X- _ O
- -X- _ O
label -X- _ O
classification -X- _ O
loss -X- _ O
and -X- _ O
can -X- _ O
predict -X- _ O
characters -X- _ O
in -X- _ O
test -X- _ O
images -X- _ O
. -X- _ O

Frame -X- _ B-MetricName
Accuracy -X- _ I-MetricName
( -X- _ O
Exact -X- _ O
Match -X- _ O
) -X- _ O
metric -X- _ O
measures -X- _ O
whether -X- _ O
all -X- _ O
characters -X- _ O
in -X- _ O
a -X- _ O
story -X- _ O
are -X- _ O
present -X- _ O
in -X- _ O
the -X- _ O
corresponding -X- _ O
images -X- _ O
using -X- _ O
the -X- _ O
same -X- _ O
model -X- _ O
as -X- _ O
in -X- _ O
the -X- _ O
Character -X- _ B-MetricName
F1 -X- _ I-MetricName
score -X- _ O
. -X- _ O
Character -X- _ B-MetricName
F1 -X- _ I-MetricName
score -X- _ O
calculates -X- _ O
the -X- _ O
proportion -X- _ O
of -X- _ O
characters -X- _ O
existing -X- _ O
in -X- _ O
a -X- _ O
story -X- _ O
, -X- _ O
while -X- _ O
Frame -X- _ B-MetricName
Accuracy -X- _ I-MetricName
calculates -X- _ O
the -X- _ O
percentage -X- _ O
of -X- _ O
samples -X- _ O
involving -X- _ O
all -X- _ O
characters -X- _ O
. -X- _ O

Frechet -X- _ B-MetricName
Inception -X- _ I-MetricName
Distance -X- _ I-MetricName
( -X- _ O
FID -X- _ B-MetricName
) -X- _ O
summarizes -X- _ O
how -X- _ O
similar -X- _ O
two -X- _ O
groups -X- _ O
are -X- _ O
in -X- _ O
terms -X- _ O
of -X- _ O
statistics -X- _ O
on -X- _ O
vision -X- _ O
features -X- _ O
of -X- _ O
the -X- _ O
raw -X- _ O
images -X- _ O
calculated -X- _ O
using -X- _ O
the -X- _ O
same -X- _ O
inception -X- _ O
v3 -X- _ O
model -X- _ O
. -X- _ O
Lower -X- _ O
scores -X- _ O
indicate -X- _ O
that -X- _ O
the -X- _ O
predicted -X- _ O
images -X- _ O
are -X- _ O
more -X- _ O
similar -X- _ O
to -X- _ O
the -X- _ O
ground -X- _ O
- -X- _ O
truth -X- _ O
images -X- _ O
. -X- _ O

Video -X- _ B-MetricName
Captioning -X- _ I-MetricName
Accuracy -X- _ I-MetricName
conducts -X- _ O
back -X- _ O
translation -X- _ O
( -X- _ O
i.e. -X- _ O
image -X- _ O
- -X- _ O
to -X- _ O
- -X- _ O
text -X- _ O
generation -X- _ O
) -X- _ O
to -X- _ O
measure -X- _ O
the -X- _ O
global -X- _ O
semantic -X- _ O
alignment -X- _ O
between -X- _ O
captions -X- _ O
and -X- _ O
generated -X- _ O
visualizations -X- _ O
. -X- _ O
This -X- _ O
metric -X- _ O
utilise -X- _ O
a -X- _ O
video -X- _ O
captioning -X- _ O
model -X- _ O
that -X- _ O
is -X- _ O
trained -X- _ O
with -X- _ O
the -X- _ O
Pororo -X- _ B-DatasetName
- -X- _ I-DatasetName
SV -X- _ I-DatasetName
dataset -X- _ O
to -X- _ O
generate -X- _ O
stories -X- _ O
based -X- _ O
on -X- _ O
the -X- _ O
image -X- _ O
sequences -X- _ O
. -X- _ O
It -X- _ O
reports -X- _ O
BLEU -X- _ B-MetricName
scores -X- _ O
between -X- _ O
the -X- _ O
predicted -X- _ O
caption -X- _ O
and -X- _ O
the -X- _ O
ground -X- _ O
truths -X- _ O
( -X- _ O
the -X- _ O
story -X- _ O
inputs -X- _ O
) -X- _ O
. -X- _ O
( -X- _ O
Xu -X- _ O
et -X- _ O
al -X- _ O
. -X- _ O
, -X- _ O
2018b -X- _ O
) -X- _ O
is -X- _ O
a -X- _ O
retrieval -X- _ O
- -X- _ O
based -X- _ O
metric -X- _ O
that -X- _ O
computes -X- _ O
the -X- _ O
probability -X- _ O
that -X- _ O
a -X- _ O
generated -X- _ O
image -X- _ O
sequence -X- _ O
has -X- _ O
the -X- _ O
highest -X- _ O
semantic -X- _ O
similarity -X- _ O
with -X- _ O
its -X- _ O
input -X- _ O
story -X- _ O
among -X- _ O
all -X- _ O
stories -X- _ O
in -X- _ O
the -X- _ O
test -X- _ O
data -X- _ O
. -X- _ O
a -X- _ O
Hierarchical -X- _ O
DAMSM -X- _ O
is -X- _ O
used -X- _ O
to -X- _ O
compute -X- _ O
cosine -X- _ O
similarity -X- _ O
and -X- _ O
rank -X- _ O
results -X- _ O
. -X- _ O

Visual -X- _ B-MetricName
Quality -X- _ I-MetricName
( -X- _ O
Visual -X- _ O
) -X- _ O
assess -X- _ O
the -X- _ O
overall -X- _ O
image -X- _ O
quality -X- _ O
of -X- _ O
a -X- _ O
generated -X- _ O
image -X- _ O
sequence -X- _ O
. -X- _ O
In -X- _ O
this -X- _ O
aspect -X- _ O
, -X- _ O
we -X- _ O
ask -X- _ O
workers -X- _ O
to -X- _ O
focus -X- _ O
on -X- _ O
the -X- _ O
image -X- _ O
quality -X- _ O
and -X- _ O
check -X- _ O
whether -X- _ O
the -X- _ O
objects -X- _ O
and -X- _ O
the -X- _ O
background -X- _ O
are -X- _ O
clear -X- _ O
. -X- _ O

Character -X- _ B-MetricName
Preservation -X- _ I-MetricName
( -X- _ O
Character -X- _ O
) -X- _ O
checks -X- _ O
the -X- _ O
occurrences -X- _ O
of -X- _ O
characters -X- _ O
. -X- _ O
In -X- _ O
this -X- _ O
aspect -X- _ O
, -X- _ O
workers -X- _ O
are -X- _ O
requested -X- _ O
to -X- _ O
focus -X- _ O
on -X- _ O
the -X- _ O
characters -X- _ O
mentioned -X- _ O
following -X- _ O
the -X- _ O
order -X- _ O
of -X- _ O
story -X- _ O
sentences -X- _ O
/ -X- _ O
paragraphs -X- _ O
, -X- _ O
and -X- _ O
judge -X- _ O
whether -X- _ O
these -X- _ O
characters -X- _ O
appear -X- _ O
in -X- _ O
the -X- _ O
image -X- _ O
sequences -X- _ O
. -X- _ O

For -X- _ O
VQ -X- _ O
- -X- _ O
VAE -X- _ O
training -X- _ O
, -X- _ O
all -X- _ O
image -X- _ O
data -X- _ O
are -X- _ O
scaled -X- _ O
to -X- _ O
64 -X- _ B-HyperparameterValue
× -X- _ I-HyperparameterValue
64 -X- _ I-HyperparameterValue
with -X- _ O
patch -X- _ B-HyperparameterName
size -X- _ I-HyperparameterName
= -X- _ O
8 -X- _ B-HyperparameterValue
, -X- _ O
resulting -X- _ O
in -X- _ O
a -X- _ O
total -X- _ O
visual -X- _ B-HyperparameterName
token -X- _ I-HyperparameterName
length -X- _ I-HyperparameterName
64 -X- _ O
/ -X- _ O
8 -X- _ O
× -X- _ O
64 -X- _ O
/ -X- _ O
8 -X- _ O
× -X- _ O
5 -X- _ O
= -X- _ O
320 -X- _ B-HyperparameterValue
per -X- _ O
image -X- _ O
sequence -X- _ O
. -X- _ O
The -X- _ O
number -X- _ B-HyperparameterName
of -X- _ I-HyperparameterName
visual -X- _ I-HyperparameterName
tokens -X- _ I-HyperparameterName
is -X- _ O
set -X- _ O
to -X- _ O
be -X- _ O
256 -X- _ B-HyperparameterValue
. -X- _ O
For -X- _ O
the -X- _ O
transformer -X- _ O
, -X- _ O
we -X- _ O
use -X- _ O
a -X- _ O
6 -X- _ O
- -X- _ O
layer -X- _ O
transformer -X- _ O
model -X- _ O
with -X- _ O
dimension -X- _ B-HyperparameterName
size -X- _ I-HyperparameterName
of -X- _ O
768 -X- _ B-HyperparameterValue
. -X- _ O
We -X- _ O
set -X- _ O
the -X- _ O
head -X- _ B-HyperparameterName
number -X- _ I-HyperparameterName
as -X- _ O
6 -X- _ B-HyperparameterValue
and -X- _ O
train -X- _ O
a -X- _ O
sparse -X- _ O
transformer -X- _ O
with -X- _ O
a -X- _ O
dropout -X- _ B-HyperparameterName
probability -X- _ O
of -X- _ O
0.1 -X- _ B-HyperparameterValue
. -X- _ O
Exact -X- _ O
architectural -X- _ O
details -X- _ O
and -X- _ O
hyperparameters -X- _ O
can -X- _ O
be -X- _ O
found -X- _ O
in -X- _ O
Appendix -X- _ O
A.5 -X- _ O
. -X- _ O

Our -X- _ O
experiments -X- _ O
and -X- _ O
analysis -X- _ O
seek -X- _ O
to -X- _ O
answer -X- _ O
these -X- _ O
questions -X- _ O
: -X- _ O
( -X- _ O
1 -X- _ O
Ablation -X- _ O
study -X- _ O
. -X- _ O
Table -X- _ O
1 -X- _ O
also -X- _ O
shows -X- _ O
ablation -X- _ O
studies -X- _ O
to -X- _ O
ensure -X- _ O
that -X- _ O
each -X- _ O
component -X- _ O
in -X- _ O
the -X- _ O
our -X- _ O
proposed -X- _ O
method -X- _ O
benefits -X- _ O
story -X- _ O
visualization -X- _ O
. -X- _ O
We -X- _ O
can -X- _ O
observe -X- _ O
that -X- _ O
visual -X- _ O
planning -X- _ O
and -X- _ O
token -X- _ O
- -X- _ O
level -X- _ O
character -X- _ O
alignment -X- _ O
each -X- _ O
improves -X- _ O
character -X- _ O
preservation -X- _ O
scores -X- _ O
( -X- _ O
i.e. -X- _ O
Character -X- _ B-MetricName
F1 -X- _ I-MetricName
, -X- _ O
Frame -X- _ B-MetricName
Accuracy -X- _ I-MetricName
) -X- _ O
, -X- _ O
resulting -X- _ O
in -X- _ O
better -X- _ O
semantic -X- _ O
alignment -X- _ O
between -X- _ O
generated -X- _ O
images -X- _ O
and -X- _ O
the -X- _ O
story -X- _ O
( -X- _ O
i.e. -X- _ O
BLEU2 -X- _ B-MetricName
/ -X- _ I-MetricName
3 -X- _ I-MetricName
, -X- _ O
R -X- _ B-MetricName
- -X- _ I-MetricName
Precision -X- _ I-MetricName
) -X- _ O
. -X- _ O

Combining -X- _ O
them -X- _ O
in -X- _ O
VP -X- _ B-MethodName
- -X- _ I-MethodName
CSV -X- _ I-MethodName
achieves -X- _ O
the -X- _ O
best -X- _ O
score -X- _ O
on -X- _ O
character -X- _ O
preservation -X- _ O
metrics -X- _ O
. -X- _ O
Human -X- _ O
evaluation -X- _ O
. -X- _ O
Since -X- _ O
automatic -X- _ O
metrics -X- _ O
can -X- _ O
be -X- _ O
insufficient -X- _ O
in -X- _ O
evaluating -X- _ O
the -X- _ O
story -X- _ O
visualization -X- _ O
quality -X- _ O
, -X- _ O
we -X- _ O
further -X- _ O
conduct -X- _ O
human -X- _ O
evaluations -X- _ O
by -X- _ O
asking -X- _ O
annotators -X- _ O
to -X- _ O
analyze -X- _ O
the -X- _ O
performance -X- _ O
of -X- _ O
the -X- _ O
story -X- _ B-TaskName
visualization -X- _ I-TaskName
models -X- _ O
. -X- _ O
We -X- _ O
hire -X- _ O
in -X- _ O
total -X- _ O
9 -X- _ O
Amazon -X- _ O
Mechanical -X- _ O
Turkers -X- _ O
who -X- _ O
succeed -X- _ O
in -X- _ O
our -X- _ O
previous -X- _ O
large -X- _ O
annotation -X- _ O
tasks -X- _ O
and -X- _ O
passed -X- _ O
the -X- _ O
additional -X- _ O
qualification -X- _ O
exam -X- _ O
for -X- _ O
story -X- _ O
visualization -X- _ O
. -X- _ O

In -X- _ O
total -X- _ O
, -X- _ O
we -X- _ O
collect -X- _ O
218 -X- _ O
sets -X- _ O
of -X- _ O
valid -X- _ O
annotations -X- _ O
story -X- _ O
visualization -X- _ O
results -X- _ O
. -X- _ O
By -X- _ O
comparing -X- _ O
models -X- _ O
provided -X- _ O
with -X- _ O
the -X- _ O
same -X- _ O
input -X- _ O
story -X- _ O
, -X- _ O
we -X- _ O
ask -X- _ O
annotators -X- _ O
to -X- _ O
rank -X- _ O
the -X- _ O
resulting -X- _ O
image -X- _ O
sequences -X- _ O
. -X- _ O
They -X- _ O
rank -X- _ B-MetricName
the -X- _ O
visualizations -X- _ O
on -X- _ O
a -X- _ O
scale -X- _ O
of -X- _ O
1 -X- _ B-MetricValue
to -X- _ O
3 -X- _ B-MetricValue
, -X- _ O
with -X- _ O
3 -X- _ B-MetricValue
indicating -X- _ O
the -X- _ O
best -X- _ O
and -X- _ O
1 -X- _ B-MetricValue
otherwise -X- _ O
. -X- _ O
Although -X- _ O
ties -X- _ O
are -X- _ O
allowed -X- _ O
, -X- _ O
annotators -X- _ O
are -X- _ O
encouraged -X- _ O
to -X- _ O
provide -X- _ O
unique -X- _ O
rankings -X- _ O
for -X- _ O
each -X- _ O
of -X- _ O
the -X- _ O
compared -X- _ O
image -X- _ O
sequences -X- _ O
. -X- _ O
We -X- _ O
show -X- _ O
the -X- _ O
detailed -X- _ O
instructions -X- _ O
and -X- _ O
the -X- _ O
user -X- _ O
interface -X- _ O
in -X- _ O
Appendix -X- _ O
A.6 -X- _ O
. -X- _ O

Table -X- _ O
2 -X- _ O
shows -X- _ O
the -X- _ O
results -X- _ O
of -X- _ O
human -X- _ O
evaluation -X- _ O
. -X- _ O
We -X- _ O
report -X- _ O
the -X- _ O
pairwise -X- _ B-MetricName
results -X- _ I-MetricName
and -X- _ O
run -X- _ O
the -X- _ O
sign -X- _ O
test -X- _ O
to -X- _ O
show -X- _ O
the -X- _ O
significant -X- _ O
difference -X- _ O
. -X- _ O
We -X- _ O
can -X- _ O
see -X- _ O
that -X- _ O
the -X- _ O
VQ -X- _ B-MethodName
- -X- _ I-MethodName
VAE -X- _ I-MethodName
- -X- _ I-MethodName
LM -X- _ I-MethodName
baseline -X- _ O
outperforms -X- _ O
the -X- _ O
previous -X- _ O
works -X- _ O
on -X- _ O
visual -X- _ O
quality -X- _ O
and -X- _ O
that -X- _ O
VP -X- _ B-MethodName
- -X- _ I-MethodName
CSV -X- _ I-MethodName
also -X- _ O
benefits -X- _ O
from -X- _ O
each -X- _ O
proposed -X- _ O
methods -X- _ O
-both -X- _ O
visual -X- _ O
planning -X- _ O
and -X- _ O
token -X- _ O
- -X- _ O
level -X- _ O
character -X- _ O
alignment -X- _ O
improves -X- _ O
the -X- _ O
performance -X- _ O
of -X- _ O
character -X- _ O
preservation -X- _ O
. -X- _ O

Analysis -X- _ O
on -X- _ O
visual -X- _ O
planning -X- _ O
. -X- _ O
We -X- _ O
conduct -X- _ O
an -X- _ O
indepth -X- _ O
study -X- _ O
to -X- _ O
analyze -X- _ O
the -X- _ O
performance -X- _ O
of -X- _ O
visual -X- _ O
planning -X- _ O
. -X- _ O
In -X- _ O
Figure -X- _ O
6 -X- _ O
, -X- _ O
the -X- _ O
first -X- _ O
row -X- _ O
shows -X- _ O
the -X- _ O
intermediate -X- _ O
image -X- _ O
results -X- _ O
with -X- _ O
the -X- _ O
background -X- _ O
masked -X- _ O
, -X- _ O
and -X- _ O
the -X- _ O
second -X- _ O
row -X- _ O
shows -X- _ O
the -X- _ O
final -X- _ O
im- -X- _ O
ages -X- _ O
. -X- _ O
We -X- _ O
observe -X- _ O
that -X- _ O
our -X- _ O
character -X- _ O
token -X- _ O
planning -X- _ O
model -X- _ O
successfully -X- _ O
output -X- _ O
character -X- _ O
- -X- _ O
related -X- _ O
tokens -X- _ O
in -X- _ O
most -X- _ O
of -X- _ O
the -X- _ O
cases -X- _ O
( -X- _ O
blue -X- _ O
boundary -X- _ O
) -X- _ O
. -X- _ O
This -X- _ O
aligns -X- _ O
with -X- _ O
our -X- _ O
expectation -X- _ O
that -X- _ O
our -X- _ O
character -X- _ O
- -X- _ O
token -X- _ O
plan -X- _ O
module -X- _ O
reinforces -X- _ O
the -X- _ O
system -X- _ O
's -X- _ O
attention -X- _ O
to -X- _ O
the -X- _ O
appropriate -X- _ O
characters -X- _ O
. -X- _ O
However -X- _ O
, -X- _ O
a -X- _ O
mistake -X- _ O
can -X- _ O
e -X- _ O
observed -X- _ O
( -X- _ O
red -X- _ O
boundary -X- _ O
) -X- _ O
where -X- _ O
the -X- _ O
visual -X- _ O
token -X- _ O
completion -X- _ O
model -X- _ O
predicts -X- _ O
a -X- _ O
character -X- _ O
based -X- _ O
on -X- _ O
nothing -X- _ O
( -X- _ O
masked -X- _ O
background -X- _ O
) -X- _ O
. -X- _ O
One -X- _ O
possible -X- _ O
explanation -X- _ O
could -X- _ O
be -X- _ O
the -X- _ O
discrepancy -X- _ O
resulting -X- _ O
from -X- _ O
our -X- _ O
two -X- _ O
- -X- _ O
stage -X- _ O
modules -X- _ O
being -X- _ O
separately -X- _ O
trained -X- _ O
. -X- _ O
In -X- _ O
addition -X- _ O
, -X- _ O
the -X- _ O
fifth -X- _ O
image -X- _ O
( -X- _ O
orange -X- _ O
boundary -X- _ O
) -X- _ O
reveals -X- _ O
an -X- _ O
example -X- _ O
of -X- _ O
low -X- _ O
- -X- _ O
quality -X- _ O
character -X- _ O
generation -X- _ O
, -X- _ O
which -X- _ O
suggests -X- _ O
future -X- _ O
work -X- _ O
to -X- _ O
boost -X- _ O
our -X- _ O
model -X- _ O
's -X- _ O
visualization -X- _ O
capacity -X- _ O
. -X- _ O

Analysis -X- _ O
on -X- _ O
character -X- _ O
alignment -X- _ O
. -X- _ O
Our -X- _ O
proposed -X- _ O
character -X- _ O
alignment -X- _ O
method -X- _ O
encourages -X- _ O
the -X- _ O
generated -X- _ O
visual -X- _ O
tokens -X- _ O
to -X- _ O
encompass -X- _ O
the -X- _ O
characterrelated -X- _ O
tokens -X- _ O
. -X- _ O
We -X- _ O
calculated -X- _ O
the -X- _ O
percentage -X- _ O
of -X- _ O
character -X- _ O
- -X- _ O
token -X- _ O
coverage -X- _ O
in -X- _ O
the -X- _ O
generated -X- _ O
visual -X- _ O
token -X- _ O
for -X- _ O
the -X- _ O
compared -X- _ O
models -X- _ O
. -X- _ O
Figure -X- _ O
7 -X- _ O
shows -X- _ O
that -X- _ O
our -X- _ O
proposed -X- _ O
VP -X- _ B-MethodName
- -X- _ I-MethodName
CSV -X- _ I-MethodName
model -X- _ O
with -X- _ O
character -X- _ O
alignment -X- _ O
can -X- _ O
achieve -X- _ O
the -X- _ O
highest -X- _ O
coverage -X- _ O
, -X- _ O
demonstrating -X- _ O
the -X- _ O
effectiveness -X- _ O
of -X- _ O
using -X- _ O
semantic -X- _ O
loss -X- _ O
to -X- _ O
preserve -X- _ O
characters -X- _ O
in -X- _ O
the -X- _ O
proposed -X- _ O
framework -X- _ O
. -X- _ O

In -X- _ O
this -X- _ O
work -X- _ O
, -X- _ O
we -X- _ O
propose -X- _ O
visual -X- _ O
planning -X- _ O
and -X- _ O
character -X- _ O
token -X- _ O
alignment -X- _ O
to -X- _ O
improve -X- _ O
character -X- _ O
preservation -X- _ O
and -X- _ O
visual -X- _ O
quality -X- _ O
. -X- _ O
Extensive -X- _ O
evaluation -X- _ O
results -X- _ O
show -X- _ O
that -X- _ O
our -X- _ O
VP -X- _ B-MethodName
- -X- _ I-MethodName
CSV -X- _ I-MethodName
model -X- _ O
outperforms -X- _ O
the -X- _ O
strong -X- _ O
baseline -X- _ O
models -X- _ O
by -X- _ O
a -X- _ O
large -X- _ O
margin -X- _ O
. -X- _ O
Future -X- _ O
research -X- _ O
in -X- _ O
story -X- _ O
visualization -X- _ O
can -X- _ O
aim -X- _ O
at -X- _ O
incorporating -X- _ O
events -X- _ O
that -X- _ O
include -X- _ O
not -X- _ O
only -X- _ O
characters -X- _ O
but -X- _ O
also -X- _ O
their -X- _ O
actions -X- _ O
and -X- _ O
relationships -X- _ O
with -X- _ O
one -X- _ O
another -X- _ O
, -X- _ O
which -X- _ O
furhter -X- _ O
challenge -X- _ O
machines -X- _ O
' -X- _ O
representation -X- _ O
capability -X- _ O
in -X- _ O
story -X- _ O
visualization -X- _ O
. -X- _ O

Our -X- _ O
VP -X- _ B-MethodName
- -X- _ I-MethodName
CSV -X- _ I-MethodName
significantly -X- _ O
improves -X- _ O
the -X- _ O
performance -X- _ O
in -X- _ O
story -X- _ B-TaskName
visualization -X- _ I-TaskName
, -X- _ O
though -X- _ O
there -X- _ O
are -X- _ O
still -X- _ O
some -X- _ O
limits -X- _ O
as -X- _ O
shown -X- _ O
in -X- _ O
Figure -X- _ O
8 -X- _ O
. -X- _ O
We -X- _ O
summarize -X- _ O
the -X- _ O
limitations -X- _ O
below -X- _ O
. -X- _ O
Multiple -X- _ O
- -X- _ O
character -X- _ O
errors -X- _ O
. -X- _ O
In -X- _ O
the -X- _ O
first -X- _ O
image -X- _ O
, -X- _ O
we -X- _ O
see -X- _ O
an -X- _ O
error -X- _ O
when -X- _ O
the -X- _ O
model -X- _ O
encounters -X- _ O
multiple -X- _ O
characters -X- _ O
. -X- _ O
With -X- _ O
more -X- _ O
characters -X- _ O
in -X- _ O
the -X- _ O
image -X- _ O
, -X- _ O
it -X- _ O
becomes -X- _ O
harder -X- _ O
to -X- _ O
generate -X- _ O
every -X- _ O
individual -X- _ O
in -X- _ O
the -X- _ O
image -X- _ O
. -X- _ O
In -X- _ O
the -X- _ O
fifth -X- _ O
image -X- _ O
, -X- _ O
Harry -X- _ O
and -X- _ O
Poby -X- _ O
are -X- _ O
mixed -X- _ O
, -X- _ O
resulting -X- _ O
in -X- _ O
poor -X- _ O
generation -X- _ O
quality -X- _ O
for -X- _ O
both -X- _ O
characters -X- _ O
. -X- _ O
Low -X- _ O
image -X- _ O
quality -X- _ O
. -X- _ O
In -X- _ O
the -X- _ O
second -X- _ O
image -X- _ O
, -X- _ O
Although -X- _ O
Poby -X- _ O
's -X- _ O
nose -X- _ O
is -X- _ O
obvious -X- _ O
, -X- _ O
the -X- _ O
rest -X- _ O
of -X- _ O
the -X- _ O
body -X- _ O
is -X- _ O
vague -X- _ O
. -X- _ O
Improving -X- _ O
overall -X- _ O
image -X- _ O
quality -X- _ O
is -X- _ O
certainly -X- _ O
a -X- _ O
future -X- _ O
research -X- _ O
direction -X- _ O
. -X- _ O
Handling -X- _ O
Events -X- _ O
. -X- _ O
In -X- _ O
generated -X- _ O
images -X- _ O
, -X- _ O
it -X- _ O
is -X- _ O
still -X- _ O
hard -X- _ O
to -X- _ O
see -X- _ O
the -X- _ O
clear -X- _ O
action -X- _ O
performed -X- _ O
by -X- _ O
each -X- _ O
character -X- _ O
. -X- _ O
For -X- _ O
example -X- _ O
, -X- _ O
even -X- _ O
though -X- _ O
" -X- _ O
Poby -X- _ O
" -X- _ O
is -X- _ O
visible -X- _ O
in -X- _ O
the -X- _ O
third -X- _ O
image -X- _ O
, -X- _ O
it -X- _ O
is -X- _ O
uncertain -X- _ O
if -X- _ O
he -X- _ O
is -X- _ O
smiling -X- _ O
or -X- _ O
walking -X- _ O
. -X- _ O
It -X- _ O
is -X- _ O
challenging -X- _ O
until -X- _ O
the -X- _ O
image -X- _ O
quality -X- _ O
is -X- _ O
good -X- _ O
enough -X- _ O
to -X- _ O
identify -X- _ O
the -X- _ O
event -X- _ O
, -X- _ O
so -X- _ O
improving -X- _ O
image -X- _ O
quality -X- _ O
could -X- _ O
help -X- _ O
identifying -X- _ O
events -X- _ O
in -X- _ O
the -X- _ O
future -X- _ O
research -X- _ O
. -X- _ O

In -X- _ O
this -X- _ O
paper -X- _ O
, -X- _ O
we -X- _ O
propose -X- _ O
using -X- _ O
VQ -X- _ B-MethodName
- -X- _ I-MethodName
VAE -X- _ I-MethodName
- -X- _ I-MethodName
LM -X- _ I-MethodName
and -X- _ O
adapting -X- _ O
its -X- _ O
Transformer -X- _ O
into -X- _ O
a -X- _ O
two -X- _ O
- -X- _ O
stage -X- _ O
model -X- _ O
. -X- _ O
We -X- _ O
encounter -X- _ O
two -X- _ O
train -X- _ O
- -X- _ O
test -X- _ O
discrepancy -X- _ O
issues -X- _ O
: -X- _ O
independent -X- _ O
training -X- _ O
of -X- _ O
VQ -X- _ O
- -X- _ O
VAE -X- _ O
and -X- _ O
Transformer -X- _ O
and -X- _ O
the -X- _ O
independent -X- _ O
training -X- _ O
of -X- _ O
two -X- _ O
stages -X- _ O
. -X- _ O
Due -X- _ O
to -X- _ O
the -X- _ O
extraordinarily -X- _ O
high -X- _ O
time -X- _ O
- -X- _ O
consuming -X- _ O
joint -X- _ O
training -X- _ O
of -X- _ O
these -X- _ O
models -X- _ O
, -X- _ O
we -X- _ O
place -X- _ O
them -X- _ O
into -X- _ O
our -X- _ O
future -X- _ O
works -X- _ O
. -X- _ O

We -X- _ O
scale -X- _ O
the -X- _ O
image -X- _ O
data -X- _ O
into -X- _ O
64×64 -X- _ O
as -X- _ O
the -X- _ O
same -X- _ O
as -X- _ O
previous -X- _ O
works -X- _ O
. -X- _ O
Our -X- _ O
VQ -X- _ O
- -X- _ O
VAE -X- _ O
is -X- _ O
pretrained -X- _ O
on -X- _ O
a -X- _ O
single -X- _ O
image -X- _ O
in -X- _ O
the -X- _ O
Pororo -X- _ O
training -X- _ O
dataset -X- _ O
. -X- _ O
Each -X- _ O
image -X- _ O
can -X- _ O
be -X- _ O
quantized -X- _ O
into -X- _ O
an -X- _ O
8×8 -X- _ O
visual -X- _ O
token -X- _ O
matrix -X- _ O
, -X- _ O
where -X- _ O
each -X- _ O
visual -X- _ O
token -X- _ O
represents -X- _ O
a -X- _ O
region -X- _ O
of -X- _ O
8×8 -X- _ O
pixels -X- _ O
. -X- _ O
We -X- _ O
use -X- _ O
one -X- _ O
NVIDIA -X- _ O
A100 -X- _ O
40 -X- _ O
GB -X- _ O
to -X- _ O
train -X- _ O
this -X- _ O
model -X- _ O
for -X- _ O
48 -X- _ O
hours -X- _ O
. -X- _ O
For -X- _ O
training -X- _ O
transformer -X- _ O
, -X- _ O
both -X- _ O
character -X- _ O
token -X- _ O
planning -X- _ O
and -X- _ O
visual -X- _ O
token -X- _ O
completion -X- _ O
models -X- _ O
use -X- _ O
a -X- _ O
6 -X- _ O
- -X- _ O
layer -X- _ O
transformer -X- _ O
model -X- _ O
with -X- _ O
dimension -X- _ B-HyperparameterName
size -X- _ I-HyperparameterName
of -X- _ O
768 -X- _ B-HyperparameterValue
. -X- _ O
We -X- _ O
set -X- _ O
the -X- _ O
head -X- _ B-HyperparameterName
number -X- _ I-HyperparameterName
as -X- _ O
6 -X- _ B-HyperparameterValue
and -X- _ O
train -X- _ O
Sparse -X- _ O
Transformers -X- _ O
with -X- _ O
local -X- _ O
and -X- _ O
strided -X- _ O
attention -X- _ O
across -X- _ O
space -X- _ O
- -X- _ O
time -X- _ O
with -X- _ O
a -X- _ O
dropout -X- _ B-HyperparameterName
probability -X- _ O
of -X- _ O
0.1 -X- _ B-HyperparameterValue
. -X- _ O
We -X- _ O
use -X- _ O
four -X- _ O
NVIDIA -X- _ O
A100 -X- _ O
40 -X- _ O
GB -X- _ O
to -X- _ O
train -X- _ O
each -X- _ O
model -X- _ O
for -X- _ O
12 -X- _ O
hours -X- _ O
. -X- _ O
The -X- _ O
implementations -X- _ O
of -X- _ O
the -X- _ O
transformer -X- _ O
- -X- _ O
based -X- _ O
models -X- _ O
are -X- _ O
extended -X- _ O
from -X- _ O
the -X- _ O
DALLE -X- _ O
- -X- _ O
python -X- _ O
code -X- _ O
3 -X- _ O
, -X- _ O
and -X- _ O
our -X- _ O
entire -X- _ O
code -X- _ O
- -X- _ O
base -X- _ O
is -X- _ O
implemented -X- _ O
in -X- _ O
PyTorch -X- _ O
4 -X- _ O
. -X- _ O
Please -X- _ O
note -X- _ O
that -X- _ O
all -X- _ O
the -X- _ O
models -X- _ O
in -X- _ O
this -X- _ O
paper -X- _ O
are -X- _ O
trained -X- _ O
from -X- _ O
scratch -X- _ O
. -X- _ O

We -X- _ O
tame -X- _ O
the -X- _ O
image -X- _ B-HyperparameterName
patch -X- _ I-HyperparameterName
size -X- _ I-HyperparameterName
in -X- _ O
[ -X- _ O
4,8,12,16 -X- _ B-HyperparameterValue
] -X- _ O
, -X- _ O
the -X- _ O
transformer -X- _ B-HyperparameterName
dimension -X- _ I-HyperparameterName
in -X- _ O
[ -X- _ O
512,768,1024 -X- _ B-HyperparameterValue
] -X- _ O
, -X- _ O
the -X- _ O
number -X- _ B-HyperparameterName
of -X- _ I-HyperparameterName
visual -X- _ I-HyperparameterName
tokens -X- _ I-HyperparameterName
in -X- _ O
[ -X- _ O
64,128,256,512 -X- _ B-HyperparameterValue
] -X- _ O
, -X- _ O
and -X- _ O
choose -X- _ O
the -X- _ O
hyperparameters -X- _ O
with -X- _ O
the -X- _ O
best -X- _ O
score -X- _ O
on -X- _ O
FID -X- _ B-MetricName
( -X- _ O
i.e. -X- _ O
image -X- _ O
quality -X- _ O
) -X- _ O
. -X- _ O

We -X- _ O
show -X- _ O
another -X- _ O
two -X- _ O
examples -X- _ O
of -X- _ O
the -X- _ O
results -X- _ O
generated -X- _ O
by -X- _ O
different -X- _ O
methods -X- _ O
. -X- _ O
In -X- _ O
Figure -X- _ O
9 -X- _ O
, -X- _ O
we -X- _ O
observe -X- _ O
that -X- _ O
the -X- _ O
image -X- _ O
sequence -X- _ O
generated -X- _ O
by -X- _ O
our -X- _ O
VP -X- _ B-MethodName
- -X- _ I-MethodName
CSV -X- _ I-MethodName
precisely -X- _ O
matches -X- _ O
the -X- _ O
given -X- _ O
story -X- _ O
. -X- _ O
The -X- _ O
characters -X- _ O
are -X- _ O
likewise -X- _ O
compatible -X- _ O
with -X- _ O
the -X- _ O
gold -X- _ O
image -X- _ O
sequence -X- _ O
; -X- _ O
however -X- _ O
, -X- _ O
the -X- _ O
characters -X- _ O
are -X- _ O
unclear -X- _ O
in -X- _ O
the -X- _ O
second -X- _ O
image -X- _ O
. -X- _ O
In -X- _ O
Figure -X- _ O
10 -X- _ O
, -X- _ O
compared -X- _ O
with -X- _ O
baseline -X- _ O
model -X- _ O
VQ -X- _ B-MethodName
- -X- _ I-MethodName
VAE -X- _ I-MethodName
- -X- _ I-MethodName
LM -X- _ I-MethodName
, -X- _ O
VP -X- _ B-MethodName
- -X- _ I-MethodName
CSV -X- _ I-MethodName
generates -X- _ O
better -X- _ O
' -X- _ O
Pororo -X- _ O
" -X- _ O
and -X- _ O
" -X- _ O
Crong -X- _ O
" -X- _ O
. -X- _ O
Besides -X- _ O
, -X- _ O
the -X- _ O
results -X- _ O
of -X- _ O
GAN -X- _ O
- -X- _ O
based -X- _ O
approaches -X- _ O
( -X- _ O
i.e. -X- _ O
VLC -X- _ O
and -X- _ O
CP -X- _ B-MethodName
- -X- _ I-MethodName
CSV -X- _ I-MethodName
) -X- _ O
are -X- _ O
exceedingly -X- _ O
imprecise -X- _ O
, -X- _ O
making -X- _ O
it -X- _ O
almost -X- _ O
impossible -X- _ O
to -X- _ O
distinguish -X- _ O
the -X- _ O
characters -X- _ O
in -X- _ O
the -X- _ O
image -X- _ O
sequence -X- _ O
. -X- _ O

on -X- _ O
Flintstones -X- _ B-DatasetName
dataset -X- _ O
. -X- _ O
Flint -X- _ O
- -X- _ O
stonesSV -X- _ O
) -X- _ O
is -X- _ O
another -X- _ O
story -X- _ O
visualization -X- _ O
dataset -X- _ O
that -X- _ O
is -X- _ O
derived -X- _ O
by -X- _ O
Flintstones -X- _ B-DatasetName
dataset -X- _ O
( -X- _ O
Gupta -X- _ O
et -X- _ O
al -X- _ O
. -X- _ O
, -X- _ O
2018 -X- _ O
) -X- _ O
. -X- _ O
To -X- _ O
show -X- _ O
the -X- _ O
generalization -X- _ O
of -X- _ O
our -X- _ O
proposed -X- _ O
VP -X- _ B-MethodName
- -X- _ I-MethodName
CSV -X- _ I-MethodName
method -X- _ O
, -X- _ O
we -X- _ O
provide -X- _ O
an -X- _ O
example -X- _ O
on -X- _ O
Flintstones -X- _ B-DatasetName
dataset -X- _ O
in -X- _ O
Figure -X- _ O
11 -X- _ O
. -X- _ O
We -X- _ O
can -X- _ O
observe -X- _ O
that -X- _ O
compared -X- _ O
with -X- _ O
VQ -X- _ B-MethodName
- -X- _ I-MethodName
VAE -X- _ I-MethodName
- -X- _ I-MethodName
LM -X- _ I-MethodName
, -X- _ O
our -X- _ O
proposed -X- _ O
method -X- _ O
provides -X- _ O
higher -X- _ O
character -X- _ O
quality -X- _ O
. -X- _ O

In -X- _ O
this -X- _ O
section -X- _ O
, -X- _ O
we -X- _ O
discuss -X- _ O
the -X- _ O
limitations -X- _ O
of -X- _ O
the -X- _ O
Pororo -X- _ B-DatasetName
- -X- _ I-DatasetName
SV -X- _ I-DatasetName
dataset -X- _ O
. -X- _ O
Figure -X- _ O
13 -X- _ O
and -X- _ O
Figure -X- _ O
14 -X- _ O
show -X- _ O
bad -X- _ O
training -X- _ O
samples -X- _ O
in -X- _ O
the -X- _ O
Pororo -X- _ O
- -X- _ O
SV -X- _ O
dataset -X- _ O
. -X- _ O
Figure -X- _ O
13 -X- _ O
shows -X- _ O
serious -X- _ O
repetition -X- _ O
issues -X- _ O
( -X- _ O
in -X- _ O
red -X- _ O
) -X- _ O
in -X- _ O
some -X- _ O
of -X- _ O
the -X- _ O
input -X- _ O
stories -X- _ O
. -X- _ O
Obviously -X- _ O
, -X- _ O
concatenati -X- _ O

CFSum -X- _ B-MethodName
: -X- _ O
A -X- _ O
Coarse -X- _ O
- -X- _ O
to -X- _ O
- -X- _ O
Fine -X- _ O
Contribution -X- _ O
Network -X- _ O
for -X- _ O
Multimodal -X- _ B-TaskName
Summarization -X- _ I-TaskName

Multimodal -X- _ B-TaskName
summarization -X- _ I-TaskName
usually -X- _ O
suffers -X- _ O
from -X- _ O
the -X- _ O
problem -X- _ O
that -X- _ O
the -X- _ O
contribution -X- _ O
of -X- _ O
the -X- _ O
visual -X- _ O
modality -X- _ O
is -X- _ O
unclear -X- _ O
. -X- _ O
Existing -X- _ O
multimodal -X- _ B-TaskName
summarization -X- _ I-TaskName
approaches -X- _ O
focus -X- _ O
on -X- _ O
designing -X- _ O
the -X- _ O
fusion -X- _ O
methods -X- _ O
of -X- _ O
different -X- _ O
modalities -X- _ O
, -X- _ O
while -X- _ O
ignoring -X- _ O
the -X- _ O
adaptive -X- _ O
conditions -X- _ O
under -X- _ O
which -X- _ O
visual -X- _ O
modalities -X- _ O
are -X- _ O
useful -X- _ O
. -X- _ O
Therefore -X- _ O
, -X- _ O
we -X- _ O
propose -X- _ O
a -X- _ O
novel -X- _ O
Coarse -X- _ O
- -X- _ O
to -X- _ O
- -X- _ O
Fine -X- _ O
contribution -X- _ O
network -X- _ O
for -X- _ O
multimodal -X- _ B-TaskName
Summarization -X- _ I-TaskName
( -X- _ O
CFSum -X- _ B-MethodName
) -X- _ O
to -X- _ O
consider -X- _ O
different -X- _ O
contributions -X- _ O
of -X- _ O
images -X- _ O
for -X- _ O
summarization -X- _ O
. -X- _ O
First -X- _ O
, -X- _ O
to -X- _ O
eliminate -X- _ O
the -X- _ O
interference -X- _ O
of -X- _ O
useless -X- _ O
images -X- _ O
, -X- _ O
we -X- _ O
propose -X- _ O
a -X- _ O
pre -X- _ O
- -X- _ O
filter -X- _ O
module -X- _ O
to -X- _ O
abandon -X- _ O
useless -X- _ O
images -X- _ O
. -X- _ O
Second -X- _ O
, -X- _ O
to -X- _ O
make -X- _ O
accurate -X- _ O
use -X- _ O
of -X- _ O
useful -X- _ O
images -X- _ O
, -X- _ O
we -X- _ O
propose -X- _ O
two -X- _ O
levels -X- _ O
of -X- _ O
visual -X- _ O
complement -X- _ O
modules -X- _ O
, -X- _ O
word -X- _ O
level -X- _ O
and -X- _ O
phrase -X- _ O
level -X- _ O
. -X- _ O
Specifically -X- _ O
, -X- _ O
image -X- _ O
contributions -X- _ O
are -X- _ O
calculated -X- _ O
and -X- _ O
are -X- _ O
adopted -X- _ O
to -X- _ O
guide -X- _ O
the -X- _ O
attention -X- _ O
of -X- _ O
both -X- _ O
textual -X- _ O
and -X- _ O
visual -X- _ O
modalities -X- _ O
. -X- _ O
Experimental -X- _ O
results -X- _ O
have -X- _ O
shown -X- _ O
that -X- _ O
CFSum -X- _ B-MethodName
significantly -X- _ O
outperforms -X- _ O
multiple -X- _ O
strong -X- _ O
baselines -X- _ O
on -X- _ O
the -X- _ O
standard -X- _ O
benchmark -X- _ O
. -X- _ O
Furthermore -X- _ O
, -X- _ O
the -X- _ O
analysis -X- _ O
verifies -X- _ O
that -X- _ O
useful -X- _ O
images -X- _ O
can -X- _ O
even -X- _ O
help -X- _ O
generate -X- _ O
nonvisual -X- _ O
words -X- _ O
which -X- _ O
are -X- _ O
implicitly -X- _ O
represented -X- _ O
in -X- _ O
the -X- _ O
image -X- _ O
1 -X- _ O
. -X- _ O

Introduction -X- _ O

With -X- _ O
the -X- _ O
information -X- _ O
explosion -X- _ O
, -X- _ O
the -X- _ O
internet -X- _ O
is -X- _ O
flooded -X- _ O
with -X- _ O
various -X- _ O
multimodal -X- _ O
information -X- _ O
. -X- _ O
Multimodal -X- _ B-MethodName
summarization -X- _ I-MethodName
( -X- _ O
MMS -X- _ B-MethodName
) -X- _ O
can -X- _ O
help -X- _ O
generate -X- _ O
more -X- _ O
abundant -X- _ O
and -X- _ O
comprehensive -X- _ O
summary -X- _ O
information -X- _ O
than -X- _ O
unimodal -X- _ O
based -X- _ O
on -X- _ O
extra -X- _ O
visual -X- _ O
information -X- _ O
. -X- _ O
Existing -X- _ O
studies -X- _ O
on -X- _ O
multimodal -X- _ B-MethodName
summarization -X- _ I-MethodName
include -X- _ O
multimodal -X- _ O
sentence -X- _ O
summarization -X- _ O
( -X- _ O
Li -X- _ O
et -X- _ O
al -X- _ O
. -X- _ O
, -X- _ O
2018b -X- _ O
) -X- _ O
, -X- _ O
multimodal -X- _ B-MethodName
summarization -X- _ I-MethodName
with -X- _ O

Figure -X- _ O
1 -X- _ O
: -X- _ O
Experiments -X- _ O
on -X- _ O
existing -X- _ O
mainstream -X- _ O
multimodal -X- _ B-MethodName
summarization -X- _ I-MethodName
models -X- _ O
. -X- _ O
The -X- _ O
performance -X- _ O
is -X- _ O
not -X- _ O
affected -X- _ O
by -X- _ O
masking -X- _ O
images -X- _ O
. -X- _ O
" -X- _ O
Concat -X- _ O
" -X- _ O
is -X- _ O
the -X- _ O
concatenate -X- _ O
fusion -X- _ O
method -X- _ O
, -X- _ O
and -X- _ O
" -X- _ O
Attn -X- _ O
" -X- _ O
is -X- _ O
the -X- _ O
attention -X- _ O
- -X- _ O
based -X- _ O
fusion -X- _ O
method -X- _ O
. -X- _ O

In -X- _ O
this -X- _ O
paper -X- _ O
, -X- _ O
we -X- _ O
focus -X- _ O
on -X- _ O
the -X- _ O
task -X- _ O
that -X- _ O
generating -X- _ O
a -X- _ O
text -X- _ O
summary -X- _ O
based -X- _ O
on -X- _ O
the -X- _ O
input -X- _ O
of -X- _ O
a -X- _ O
text -X- _ O
and -X- _ O
an -X- _ O
image -X- _ O
. -X- _ O
It -X- _ O
has -X- _ O
been -X- _ O
proved -X- _ O
that -X- _ O
integrating -X- _ O
multimodal -X- _ O
data -X- _ O
can -X- _ O
help -X- _ O
improve -X- _ O
the -X- _ O
quality -X- _ O
of -X- _ O
the -X- _ O
summary -X- _ O
( -X- _ O
Li -X- _ O
et -X- _ O
al -X- _ O
. -X- _ O
, -X- _ O
2018b -X- _ O
; -X- _ O
Jangra -X- _ O
et -X- _ O
al -X- _ O
. -X- _ O
, -X- _ O
2020 -X- _ O
; -X- _ O
Palaskar -X- _ O
et -X- _ O
al -X- _ O
. -X- _ O
, -X- _ O
2019 -X- _ O
; -X- _ O
Yu -X- _ O
et -X- _ O
al -X- _ O
. -X- _ O
, -X- _ O
2021 -X- _ O
) -X- _ O
. -X- _ O

However -X- _ O
, -X- _ O
it -X- _ O
is -X- _ O
unclear -X- _ O
whether -X- _ O
the -X- _ O
visual -X- _ O
modality -X- _ O
can -X- _ O
indeed -X- _ O
benefit -X- _ O
the -X- _ O
process -X- _ O
of -X- _ O
summarization -X- _ O
. -X- _ O
Thus -X- _ O
, -X- _ O
we -X- _ O
conduct -X- _ O
an -X- _ O
experiment -X- _ O
to -X- _ O
explore -X- _ O
the -X- _ O
influence -X- _ O
of -X- _ O
masking -X- _ O
images -X- _ O
on -X- _ O
the -X- _ O
summary -X- _ O
. -X- _ O
As -X- _ O
shown -X- _ O
in -X- _ O
Figure -X- _ O
1 -X- _ O
, -X- _ O
the -X- _ O
solid -X- _ O
lines -X- _ O
mean -X- _ O
the -X- _ O
performance -X- _ O
of -X- _ O
summary -X- _ O
generated -X- _ O
by -X- _ O
masking -X- _ O
portions -X- _ O
of -X- _ O
images -X- _ O
, -X- _ O
and -X- _ O
the -X- _ O
dashed -X- _ O
lines -X- _ O
indicate -X- _ O
the -X- _ O
origin -X- _ O
performance -X- _ O
. -X- _ O
It -X- _ O
can -X- _ O
be -X- _ O
observed -X- _ O
that -X- _ O
the -X- _ O
dashed -X- _ O
and -X- _ O
the -X- _ O
solid -X- _ O
lines -X- _ O
roughly -X- _ O
coincide -X- _ O
, -X- _ O
which -X- _ O
indicates -X- _ O
that -X- _ O
masking -X- _ O
images -X- _ O
do -X- _ O
not -X- _ O
affect -X- _ O
the -X- _ O
performance -X- _ O
of -X- _ O
the -X- _ O
multimodal -X- _ O
model -X- _ O
. -X- _ O
Some -X- _ O
masking -X- _ O
rates -X- _ O
can -X- _ O
even -X- _ O
raise -X- _ O
the -X- _ O
ROUGE-1 -X- _ B-MetricName
value -X- _ O
of -X- _ O
the -X- _ O
summary -X- _ O
. -X- _ O
It -X- _ O
indicates -X- _ O
that -X- _ O
existing -X- _ O
models -X- _ O
do -X- _ O
not -X- _ O
make -X- _ O
effective -X- _ O
use -X- _ O
of -X- _ O
image -X- _ O
information -X- _ O
for -X- _ O
the -X- _ O
summary -X- _ O
. -X- _ O

Existing -X- _ O
approaches -X- _ O
have -X- _ O
two -X- _ O
major -X- _ O
problems -X- _ O
. -X- _ O
First -X- _ O
, -X- _ O
existing -X- _ O
studies -X- _ O
focus -X- _ O
on -X- _ O
multimodal -X- _ O
fusion -X- _ O
, -X- _ O
such -X- _ O
as -X- _ O
concatenate -X- _ O
, -X- _ O
attention -X- _ O
- -X- _ O
based -X- _ O
, -X- _ O
and -X- _ O
gatebased -X- _ O
fusion -X- _ O
( -X- _ O
referring -X- _ O
to -X- _ O
Related -X- _ O
Work -X- _ O
) -X- _ O
. -X- _ O
However -X- _ O
, -X- _ O
they -X- _ O
ignore -X- _ O
the -X- _ O
adaptive -X- _ O
conditions -X- _ O
under -X- _ O
which -X- _ O
visual -X- _ O
modalities -X- _ O
are -X- _ O
helpful -X- _ O
. -X- _ O
Thus -X- _ O
they -X- _ O
are -X- _ O
poor -X- _ O
at -X- _ O
extracting -X- _ O
useful -X- _ O
visual -X- _ O
information -X- _ O
. -X- _ O
Furthermore -X- _ O
, -X- _ O
all -X- _ O
fusion -X- _ O
methods -X- _ O
do -X- _ O
not -X- _ O
explicitly -X- _ O
model -X- _ O
the -X- _ O
image -X- _ O
complementarity -X- _ O
for -X- _ O
the -X- _ O
summary -X- _ O
. -X- _ O
Especially -X- _ O
for -X- _ O
the -X- _ O
attention -X- _ O
- -X- _ O
based -X- _ O
method -X- _ O
, -X- _ O
the -X- _ O
inter -X- _ O
- -X- _ O
attention -X- _ O
is -X- _ O
not -X- _ O
accurate -X- _ O
enough -X- _ O
, -X- _ O
which -X- _ O
leads -X- _ O
to -X- _ O
inefficient -X- _ O
use -X- _ O
of -X- _ O
the -X- _ O
image -X- _ O
. -X- _ O
Second -X- _ O
, -X- _ O
in -X- _ O
many -X- _ O
samples -X- _ O
, -X- _ O
the -X- _ O
image -X- _ O
may -X- _ O
introduce -X- _ O
noise -X- _ O
, -X- _ O
while -X- _ O
existing -X- _ O
fusion -X- _ O
methods -X- _ O
assume -X- _ O
that -X- _ O
all -X- _ O
images -X- _ O
are -X- _ O
helpful -X- _ O
for -X- _ O
the -X- _ O
summary -X- _ O
without -X- _ O
considering -X- _ O
the -X- _ O
interference -X- _ O
of -X- _ O
useless -X- _ O
images -X- _ O
. -X- _ O
As -X- _ O
analyzed -X- _ O
above -X- _ O
, -X- _ O
we -X- _ O
believe -X- _ O
that -X- _ O
: -X- _ O
1 -X- _ O
) -X- _ O
It -X- _ O
is -X- _ O
essential -X- _ O
to -X- _ O
eliminate -X- _ O
the -X- _ O
influence -X- _ O
of -X- _ O
the -X- _ O
useless -X- _ O
image -X- _ O
. -X- _ O
2 -X- _ O
) -X- _ O
The -X- _ O
contributions -X- _ O
of -X- _ O
the -X- _ O
image -X- _ O
to -X- _ O
the -X- _ O
summary -X- _ O
need -X- _ O
to -X- _ O
be -X- _ O
clarified -X- _ O
. -X- _ O
In -X- _ O
particular -X- _ O
, -X- _ O
it -X- _ O
is -X- _ O
necessary -X- _ O
to -X- _ O
consider -X- _ O
the -X- _ O
complementarity -X- _ O
of -X- _ O
visual -X- _ O
information -X- _ O
relative -X- _ O
to -X- _ O
textual -X- _ O
information -X- _ O
. -X- _ O

Although -X- _ O
we -X- _ O
notice -X- _ O
the -X- _ O
lack -X- _ O
of -X- _ O
image -X- _ O
contributions -X- _ O
, -X- _ O
it -X- _ O
is -X- _ O
difficult -X- _ O
to -X- _ O
detach -X- _ O
various -X- _ O
roles -X- _ O
of -X- _ O
images -X- _ O
from -X- _ O
a -X- _ O
single -X- _ O
fusion -X- _ O
layer -X- _ O
. -X- _ O
Thus -X- _ O
, -X- _ O
in -X- _ O
this -X- _ O
work -X- _ O
, -X- _ O
we -X- _ O
propose -X- _ O
a -X- _ O
novel -X- _ O
Coarse -X- _ O
- -X- _ O
to -X- _ O
- -X- _ O
Fine -X- _ O
contribution -X- _ O
network -X- _ O
for -X- _ O
multimodal -X- _ B-TaskName
Summarization -X- _ I-TaskName
( -X- _ O
CFSum -X- _ B-MethodName
) -X- _ O
to -X- _ O
extract -X- _ O
the -X- _ O
role -X- _ O
of -X- _ O
the -X- _ O
image -X- _ O
at -X- _ O
different -X- _ O
stages -X- _ O
. -X- _ O
First -X- _ O
, -X- _ O
we -X- _ O
apply -X- _ O
a -X- _ O
pre -X- _ O
- -X- _ O
filter -X- _ O
module -X- _ O
to -X- _ O
abandon -X- _ O
useless -X- _ O
images -X- _ O
. -X- _ O
It -X- _ O
coarsely -X- _ O
obtains -X- _ O
helpful -X- _ O
images -X- _ O
for -X- _ O
the -X- _ O
summary -X- _ O
. -X- _ O
Specifically -X- _ O
, -X- _ O
the -X- _ O
consistency -X- _ O
of -X- _ O
content -X- _ O
between -X- _ O
image -X- _ O
and -X- _ O
text -X- _ O
is -X- _ O
calculated -X- _ O
. -X- _ O
If -X- _ O
the -X- _ O
consistency -X- _ O
is -X- _ O
low -X- _ O
, -X- _ O
the -X- _ O
image -X- _ O
will -X- _ O
be -X- _ O
masked -X- _ O
in -X- _ O
subsequent -X- _ O
encoding -X- _ O
. -X- _ O
Second -X- _ O
, -X- _ O
when -X- _ O
the -X- _ O
image -X- _ O
is -X- _ O
coarsely -X- _ O
useful -X- _ O
, -X- _ O
the -X- _ O
complement -X- _ O
module -X- _ O
is -X- _ O
employed -X- _ O
to -X- _ O
finely -X- _ O
guide -X- _ O
the -X- _ O
fusion -X- _ O
of -X- _ O
text -X- _ O
with -X- _ O
the -X- _ O
image -X- _ O
. -X- _ O
To -X- _ O
consider -X- _ O
image -X- _ O
contributions -X- _ O
for -X- _ O
text -X- _ O
with -X- _ O
different -X- _ O
granularities -X- _ O
, -X- _ O
the -X- _ O
complement -X- _ O
module -X- _ O
consists -X- _ O
of -X- _ O
two -X- _ O
levels -X- _ O
, -X- _ O
word -X- _ O
level -X- _ O
and -X- _ O
phrase -X- _ O
level -X- _ O
. -X- _ O
For -X- _ O
the -X- _ O
word -X- _ O
level -X- _ O
complement -X- _ O
module -X- _ O
, -X- _ O
to -X- _ O
obtain -X- _ O
the -X- _ O
image -X- _ O
complementarity -X- _ O
over -X- _ O
the -X- _ O
text -X- _ O
, -X- _ O
the -X- _ O
difference -X- _ O
between -X- _ O
bi -X- _ O
- -X- _ O
modal -X- _ O
and -X- _ O
uni -X- _ O
- -X- _ O
modal -X- _ O
inputs -X- _ O
is -X- _ O
measured -X- _ O
through -X- _ O
a -X- _ O
classification -X- _ O
task -X- _ O
. -X- _ O
Then -X- _ O
we -X- _ O
add -X- _ O
a -X- _ O
loss -X- _ O
to -X- _ O
guide -X- _ O
the -X- _ O
attention -X- _ O
between -X- _ O
words -X- _ O
and -X- _ O
the -X- _ O
image -X- _ O
. -X- _ O
For -X- _ O
the -X- _ O
phrase -X- _ O
level -X- _ O
complement -X- _ O
module -X- _ O
, -X- _ O
similar -X- _ O
to -X- _ O
the -X- _ O
word -X- _ O
level -X- _ O
, -X- _ O
the -X- _ O
image -X- _ O
complementarity -X- _ O
on -X- _ O
phrases -X- _ O
is -X- _ O
acquired -X- _ O
to -X- _ O
guide -X- _ O
the -X- _ O
attention -X- _ O
between -X- _ O
phrases -X- _ O
and -X- _ O
the -X- _ O
image -X- _ O
. -X- _ O
Through -X- _ O
these -X- _ O
modules -X- _ O
, -X- _ O
the -X- _ O
model -X- _ O
can -X- _ O
acquire -X- _ O
more -X- _ O
explicit -X- _ O
image -X- _ O
contributions -X- _ O
and -X- _ O
provide -X- _ O
better -X- _ O
multimodal -X- _ O
encoding -X- _ O
for -X- _ O
summary -X- _ O
generation -X- _ O
. -X- _ O

( -X- _ O
1 -X- _ O
) -X- _ O
We -X- _ O
propose -X- _ O
a -X- _ O
Coarse -X- _ O
- -X- _ O
to -X- _ O
- -X- _ O
Fine -X- _ O
contribution -X- _ O
network -X- _ O
for -X- _ O
multimodal -X- _ B-TaskName
Summarization -X- _ I-TaskName
( -X- _ O
CFSum -X- _ B-MethodName
) -X- _ O
to -X- _ O
model -X- _ O
different -X- _ O
contributions -X- _ O
of -X- _ O
images -X- _ O
for -X- _ O
summarization -X- _ O
. -X- _ O

( -X- _ O
2 -X- _ O
) -X- _ O
We -X- _ O
innovatively -X- _ O
design -X- _ O
a -X- _ O
pre -X- _ O
- -X- _ O
filter -X- _ O
module -X- _ O
to -X- _ O
coarsely -X- _ O
reduce -X- _ O
the -X- _ O
interference -X- _ O
of -X- _ O
the -X- _ O
useless -X- _ O
images -X- _ O
and -X- _ O
develop -X- _ O
two -X- _ O
visual -X- _ O
complement -X- _ O
modules -X- _ O
to -X- _ O
finely -X- _ O
obtain -X- _ O
image -X- _ O
complementarity -X- _ O
over -X- _ O
the -X- _ O
summary -X- _ O
. -X- _ O

( -X- _ O
3 -X- _ O
) -X- _ O
Experimental -X- _ O
results -X- _ O
show -X- _ O
that -X- _ O
our -X- _ O
model -X- _ O
outperforms -X- _ O
strong -X- _ O
baselines -X- _ O
. -X- _ O
Besides -X- _ O
, -X- _ O
extensive -X- _ O
analysis -X- _ O
proves -X- _ O
that -X- _ O
useful -X- _ O
image -X- _ O
even -X- _ O
contributes -X- _ O
to -X- _ O
non -X- _ O
- -X- _ O
visual -X- _ O
words -X- _ O
which -X- _ O
are -X- _ O
implicitly -X- _ O
represented -X- _ O
in -X- _ O
the -X- _ O
image -X- _ O
. -X- _ O

Multimodal -X- _ B-TaskName
Summarization -X- _ I-TaskName
Tasks -X- _ O
. -X- _ O
In -X- _ O
the -X- _ O
field -X- _ O
of -X- _ O
multimodal -X- _ B-TaskName
summarization -X- _ I-TaskName
, -X- _ O
there -X- _ O
are -X- _ O
usually -X- _ O
three -X- _ O
steps -X- _ O
. -X- _ O
First -X- _ O
, -X- _ O
different -X- _ O
feature -X- _ O
extractor -X- _ O
modules -X- _ O
are -X- _ O
adopted -X- _ O
to -X- _ O
extract -X- _ O
the -X- _ O
features -X- _ O
of -X- _ O
the -X- _ O
text -X- _ O
and -X- _ O
the -X- _ O
image -X- _ O
, -X- _ O
respectively -X- _ O
. -X- _ O
Second -X- _ O
, -X- _ O
the -X- _ O
different -X- _ O
features -X- _ O
are -X- _ O
fused -X- _ O
at -X- _ O
the -X- _ O
fusion -X- _ O
layer -X- _ O
. -X- _ O
Finally -X- _ O
, -X- _ O
the -X- _ O
fused -X- _ O
context -X- _ O
features -X- _ O
are -X- _ O
fed -X- _ O
into -X- _ O
the -X- _ O
text -X- _ O
decoder -X- _ O
to -X- _ O
generate -X- _ O
a -X- _ O
summary -X- _ O
. -X- _ O
Existing -X- _ O
studies -X- _ O
focus -X- _ O
on -X- _ O
multimodal -X- _ O
fusion -X- _ O
. -X- _ O
Specifically -X- _ O
, -X- _ O
the -X- _ O
fusion -X- _ O
methods -X- _ O
consist -X- _ O
of -X- _ O
concatenate -X- _ O
, -X- _ O
attention -X- _ O
- -X- _ O
based -X- _ O
, -X- _ O
and -X- _ O
gate -X- _ O
- -X- _ O
based -X- _ O
. -X- _ O
The -X- _ O
concatenate -X- _ O
fusion -X- _ O
directly -X- _ O
concatenates -X- _ O
multimodal -X- _ O
features -X- _ O
into -X- _ O
a -X- _ O
fusion -X- _ O
context -X- _ O
( -X- _ O
Li -X- _ O
et -X- _ O
al -X- _ O
. -X- _ O
, -X- _ O
2018b -X- _ O
( -X- _ O
Li -X- _ O
et -X- _ O
al -X- _ O
. -X- _ O
, -X- _ O
, -X- _ O
2020a -X- _ O
. -X- _ O
It -X- _ O
can -X- _ O
fully -X- _ O
extract -X- _ O
highlevel -X- _ O
features -X- _ O
of -X- _ O
different -X- _ O
modalities -X- _ O
, -X- _ O
but -X- _ O
there -X- _ O
is -X- _ O
a -X- _ O
large -X- _ O
gap -X- _ O
between -X- _ O
high -X- _ O
- -X- _ O
dimensional -X- _ O
spaces -X- _ O
. -X- _ O
The -X- _ O
attention -X- _ O
- -X- _ O
based -X- _ O
methods -X- _ O
fuse -X- _ O
all -X- _ O
multimodal -X- _ O
features -X- _ O
with -X- _ O
attention -X- _ O
mechanism -X- _ O
( -X- _ O
Atri -X- _ O
et -X- _ O
al -X- _ O
. -X- _ O
, -X- _ O
2021 -X- _ O
; -X- _ O
Palaskar -X- _ O
et -X- _ O
al -X- _ O
. -X- _ O
, -X- _ O
2019 -X- _ O
; -X- _ O
Kitada -X- _ O
et -X- _ O
al -X- _ O
. -X- _ O
, -X- _ O
2022 -X- _ O
) -X- _ O
, -X- _ O
which -X- _ O
can -X- _ O
get -X- _ O
the -X- _ O
correlations -X- _ O
between -X- _ O
each -X- _ O
unit -X- _ O
of -X- _ O
text -X- _ O
and -X- _ O
image -X- _ O
. -X- _ O
Gate -X- _ O
- -X- _ O
based -X- _ O
methods -X- _ O
take -X- _ O
text -X- _ O
as -X- _ O
the -X- _ O
central -X- _ O
modality -X- _ O
( -X- _ O
Jangra -X- _ O
et -X- _ O
al -X- _ O
. -X- _ O
, -X- _ O
2021 -X- _ O
) -X- _ O
and -X- _ O
exploit -X- _ O
images -X- _ O
to -X- _ O
help -X- _ O
focus -X- _ O
on -X- _ O
the -X- _ O
core -X- _ O
information -X- _ O
Li -X- _ O
et -X- _ O
al -X- _ O
. -X- _ O
, -X- _ O
2020b -X- _ O
) -X- _ O
. -X- _ O
In -X- _ O
summary -X- _ O
, -X- _ O
( -X- _ O
1 -X- _ O
) -X- _ O
all -X- _ O
fusion -X- _ O
methods -X- _ O
do -X- _ O
not -X- _ O
explicitly -X- _ O
model -X- _ O
the -X- _ O
image -X- _ O
complementarity -X- _ O
for -X- _ O
the -X- _ O
summary -X- _ O
, -X- _ O
which -X- _ O
leads -X- _ O
to -X- _ O
inefficient -X- _ O
use -X- _ O
of -X- _ O
the -X- _ O
image -X- _ O
. -X- _ O
( -X- _ O
2 -X- _ O
) -X- _ O
concatenate -X- _ O
and -X- _ O
attention -X- _ O
- -X- _ O
based -X- _ O
can -X- _ O
not -X- _ O
eliminate -X- _ O
the -X- _ O
influence -X- _ O
of -X- _ O
useless -X- _ O
images -X- _ O
in -X- _ O
the -X- _ O
fusion -X- _ O
layer -X- _ O
. -X- _ O

Cross -X- _ O
- -X- _ O
modal -X- _ O
tasks -X- _ O
. -X- _ O
Some -X- _ O
studies -X- _ O
have -X- _ O
noted -X- _ O
the -X- _ O
contributions -X- _ O
of -X- _ O
modalities -X- _ O
and -X- _ O
explored -X- _ O
the -X- _ O
crossmodal -X- _ O
influence -X- _ O
in -X- _ O
other -X- _ O
multimodal -X- _ O
tasks -X- _ O
. -X- _ O
Zeng -X- _ O
et -X- _ O
al -X- _ O
. -X- _ O
( -X- _ O
2021 -X- _ O
) -X- _ O
propose -X- _ O
loss -X- _ O
modulation -X- _ O
to -X- _ O
explore -X- _ O
the -X- _ O
contribution -X- _ O
of -X- _ O
individual -X- _ O
modalities -X- _ O
and -X- _ O
devise -X- _ O
a -X- _ O
modality -X- _ O
filter -X- _ O
to -X- _ O
reduce -X- _ O
modality -X- _ O
noise -X- _ O
, -X- _ O
which -X- _ O
con- -X- _ O
3 -X- _ O
Proposed -X- _ O
Methods -X- _ O

As -X- _ O
depicted -X- _ O
in -X- _ O
Figure -X- _ O
2 -X- _ O
, -X- _ O
the -X- _ O
CFSum -X- _ B-MethodName
takes -X- _ I-MethodName
bimodal -X- _ O
and -X- _ O
uni -X- _ O
- -X- _ O
modal -X- _ O
streams -X- _ O
as -X- _ O
input -X- _ O
parallelly -X- _ O
. -X- _ O
It -X- _ O
builds -X- _ O
coarse -X- _ O
and -X- _ O
fine -X- _ O
image -X- _ O
contributions -X- _ O
with -X- _ O
three -X- _ O
modules -X- _ O
( -X- _ O
Coarse -X- _ O
- -X- _ O
to -X- _ O
- -X- _ O
Fine -X- _ O
Structure -X- _ O
) -X- _ O
. -X- _ O
First -X- _ O
, -X- _ O
the -X- _ O
pre -X- _ O
- -X- _ O
filter -X- _ O
module -X- _ O
coarsely -X- _ O
filters -X- _ O
the -X- _ O
images -X- _ O
inconsistent -X- _ O
with -X- _ O
texts -X- _ O
( -X- _ O
Pre -X- _ O
- -X- _ O
filter -X- _ O
Module -X- _ O
) -X- _ O
. -X- _ O
Second -X- _ O
, -X- _ O
two -X- _ O
levels -X- _ O
of -X- _ O
visual -X- _ O
complement -X- _ O
modules -X- _ O
consisting -X- _ O
of -X- _ O
word -X- _ O
level -X- _ O
( -X- _ O
Word -X- _ O
- -X- _ O
level -X- _ O
Complement -X- _ O
) -X- _ O
and -X- _ O
phrase -X- _ O
level -X- _ O
( -X- _ O
Phrase -X- _ O
- -X- _ O
level -X- _ O
Complement -X- _ O
) -X- _ O
make -X- _ O
accurate -X- _ O
use -X- _ O
of -X- _ O
useful -X- _ O
images -X- _ O
. -X- _ O

We -X- _ O
build -X- _ O
our -X- _ O
model -X- _ O
based -X- _ O
on -X- _ O
the -X- _ O
multimodal -X- _ O
transformer -X- _ O
UNITER -X- _ O
( -X- _ O
Chen -X- _ O
et -X- _ O
al -X- _ O
. -X- _ O
, -X- _ O
2020 -X- _ O
) -X- _ O
and -X- _ O
GRU -X- _ O
( -X- _ O
Chung -X- _ O
et -X- _ O
al -X- _ O
. -X- _ O
, -X- _ O
2014 -X- _ O
) -X- _ O
encoder -X- _ O
- -X- _ O
decoder -X- _ O
architectures -X- _ O
. -X- _ O
We -X- _ O
refer -X- _ O
the -X- _ O
model -X- _ O
to -X- _ O
UniG. -X- _ O
As -X- _ O
shown -X- _ O
in -X- _ O
Figure -X- _ O
2 -X- _ O
( -X- _ O
a -X- _ O
) -X- _ O
, -X- _ O
in -X- _ O
order -X- _ O
to -X- _ O
evaluate -X- _ O
the -X- _ O
complementarity -X- _ O
of -X- _ O
different -X- _ O
modalities -X- _ O
, -X- _ O
the -X- _ O
bi -X- _ O
- -X- _ O
modal -X- _ O
and -X- _ O
uni -X- _ O
- -X- _ O
modal -X- _ O
inputs -X- _ O
are -X- _ O
operated -X- _ O
parallelly -X- _ O
with -X- _ O
the -X- _ O
same -X- _ O
encoder -X- _ O
. -X- _ O
The -X- _ O
two -X- _ O
parallel -X- _ O
streams -X- _ O
can -X- _ O
catch -X- _ O
the -X- _ O
gain -X- _ O
of -X- _ O
the -X- _ O
image -X- _ O
. -X- _ O
Additionally -X- _ O
, -X- _ O
we -X- _ O
generate -X- _ O
a -X- _ O
summary -X- _ O
relying -X- _ O
on -X- _ O
bi -X- _ O
- -X- _ O
modal -X- _ O
encoding -X- _ O
. -X- _ O
Uni -X- _ O
- -X- _ O
modal -X- _ O
encoding -X- _ O
assists -X- _ O
in -X- _ O
measuring -X- _ O
various -X- _ O
contributions -X- _ O
and -X- _ O
guiding -X- _ O
the -X- _ O
bi -X- _ O
- -X- _ O
modal -X- _ O
encoding -X- _ O
. -X- _ O

Specifically -X- _ O
, -X- _ O
the -X- _ O
multimodal -X- _ O
encoder -X- _ O
consists -X- _ O
of -X- _ O
L -X- _ B-HyperparameterName
= -X- _ O
12 -X- _ B-HyperparameterValue
multimodal -X- _ O
transformer -X- _ B-HyperparameterName
layers -X- _ I-HyperparameterName
. -X- _ O
We -X- _ O
serve -X- _ O
the -X- _ O
L -X- _ B-HyperparameterName
layers -X- _ O
as -X- _ O
a -X- _ O
hierarchical -X- _ O
structure -X- _ O
and -X- _ O
divide -X- _ O
L -X- _ B-HyperparameterName
layers -X- _ O
into -X- _ O
three -X- _ O
parts -X- _ O
as -X- _ O
shown -X- _ O
in -X- _ O
Figure -X- _ O
2 -X- _ O
( -X- _ O
a -X- _ O
) -X- _ O
. -X- _ O
L -X- _ O
f -X- _ O
, -X- _ O
L -X- _ O
w -X- _ O
, -X- _ O
L -X- _ O
p -X- _ O
mark -X- _ O
as -X- _ O
the -X- _ O
starting -X- _ O
layer -X- _ O
of -X- _ O
the -X- _ O
prefilter -X- _ O
, -X- _ O
the -X- _ O
word -X- _ O
- -X- _ O
level -X- _ O
complement -X- _ O
, -X- _ O
and -X- _ O
the -X- _ O
phraselevel -X- _ O
complement -X- _ O
modules -X- _ O
, -X- _ O
respectively -X- _ O
. -X- _ O
Existing -X- _ O
studies -X- _ O
assume -X- _ O
all -X- _ O
images -X- _ O
benefit -X- _ O
summary -X- _ O
generation -X- _ O
or -X- _ O
input -X- _ O
text -X- _ O
encoding -X- _ O
, -X- _ O
resulting -X- _ O
in -X- _ O
damage -X- _ O
from -X- _ O
unnecessary -X- _ O
images -X- _ O
. -X- _ O
The -X- _ O
pre -X- _ O
- -X- _ O
filter -X- _ O
module -X- _ O
is -X- _ O
utilized -X- _ O
to -X- _ O
eliminate -X- _ O
the -X- _ O
interference -X- _ O
of -X- _ O
misleading -X- _ O
images -X- _ O
in -X- _ O
advance -X- _ O
. -X- _ O
Next -X- _ O
, -X- _ O
the -X- _ O
word -X- _ O
- -X- _ O
level -X- _ O
complement -X- _ O
module -X- _ O
is -X- _ O
developed -X- _ O
to -X- _ O
model -X- _ O
the -X- _ O
gain -X- _ O
of -X- _ O
the -X- _ O
image -X- _ O
on -X- _ O
input -X- _ O
words -X- _ O
for -X- _ O
the -X- _ O
summary -X- _ O
. -X- _ O
Then -X- _ O
the -X- _ O
image -X- _ O
gain -X- _ O
guides -X- _ O
the -X- _ O
subsequent -X- _ O
attention -X- _ O
between -X- _ O
words -X- _ O
and -X- _ O
the -X- _ O
image -X- _ O
. -X- _ O
Finally -X- _ O
, -X- _ O
similar -X- _ O
to -X- _ O
the -X- _ O
word -X- _ O
level -X- _ O
, -X- _ O
the -X- _ O
phrase -X- _ O
- -X- _ O
level -X- _ O
complement -X- _ O
module -X- _ O
concentrates -X- _ O
on -X- _ O
phrases -X- _ O
at -X- _ O
higher -X- _ O
layers -X- _ O
. -X- _ O
Each -X- _ O
component -X- _ O
will -X- _ O
be -X- _ O
elaborated -X- _ O
in -X- _ O
the -X- _ O
following -X- _ O
subsections -X- _ O
. -X- _ O

The -X- _ O
bi -X- _ O
- -X- _ O
modal -X- _ O
and -X- _ O
uni -X- _ O
- -X- _ O
modal -X- _ O
features -X- _ O
from -X- _ O
the -X- _ O
i -X- _ O
th -X- _ O
layer -X- _ O
are -X- _ O
encoded -X- _ O
as -X- _ O
m -X- _ O
i -X- _ O
∈ -X- _ O
R -X- _ O
C×H -X- _ O
, -X- _ O
u -X- _ O
i -X- _ O
∈ -X- _ O
R -X- _ O
T -X- _ O
×H -X- _ O
, -X- _ O
where -X- _ O
i -X- _ O
∈ -X- _ O
[ -X- _ O
1 -X- _ O
, -X- _ O
L -X- _ O
] -X- _ O
, -X- _ O
and -X- _ O
C -X- _ O
, -X- _ O
T -X- _ O
denote -X- _ O
the -X- _ O
lengths -X- _ O
of -X- _ O
bimodal -X- _ O
and -X- _ O
uni -X- _ O
- -X- _ O
modal -X- _ O
tokens -X- _ O
. -X- _ O
H -X- _ O
denotes -X- _ O
the -X- _ O
hidden -X- _ O
dimension -X- _ O
. -X- _ O
The -X- _ O
bi -X- _ O
- -X- _ O
modal -X- _ O
self -X- _ O
- -X- _ O
attention -X- _ O
matrix -X- _ O
in -X- _ O
the -X- _ O
i -X- _ O
th -X- _ O
layer -X- _ O
is -X- _ O
A -X- _ O
i -X- _ O
= -X- _ O
( -X- _ O
a -X- _ O
i -X- _ O
r -X- _ O
, -X- _ O
s -X- _ O
) -X- _ O
∈ -X- _ O
R -X- _ O
C×C -X- _ O
. -X- _ O
The -X- _ O
pre -X- _ O
- -X- _ O
filter -X- _ O
module -X- _ O
aims -X- _ O
at -X- _ O
filtering -X- _ O
images -X- _ O
that -X- _ O
are -X- _ O
unnecessary -X- _ O
to -X- _ O
the -X- _ O
summary -X- _ O
. -X- _ O
As -X- _ O
shown -X- _ O
in -X- _ O
Figure -X- _ O
2 -X- _ O
( -X- _ O
a -X- _ O
) -X- _ O
, -X- _ O
given -X- _ O
two -X- _ O
encoded -X- _ O
features -X- _ O
m -X- _ O
L -X- _ O
f -X- _ O
and -X- _ O
u -X- _ O
L -X- _ O
f -X- _ O
from -X- _ O
the -X- _ O
L -X- _ O
th -X- _ O
f -X- _ O
layer -X- _ O
, -X- _ O
the -X- _ O
goal -X- _ O
of -X- _ O
the -X- _ O
filtering -X- _ O
module -X- _ O
is -X- _ O
to -X- _ O
select -X- _ O
those -X- _ O
useless -X- _ O
images -X- _ O
and -X- _ O
guide -X- _ O
the -X- _ O
self -X- _ O
- -X- _ O
attention -X- _ O
of -X- _ O
all -X- _ O
subsequent -X- _ O
layers -X- _ O
. -X- _ O
We -X- _ O
believe -X- _ O
that -X- _ O
if -X- _ O
the -X- _ O
bi -X- _ O
- -X- _ O
modal -X- _ O
feature -X- _ O
has -X- _ O
low -X- _ O
consistency -X- _ O
with -X- _ O
the -X- _ O
uni -X- _ O
- -X- _ O
modal -X- _ O
feature -X- _ O
, -X- _ O
the -X- _ O
image -X- _ O
may -X- _ O
introduce -X- _ O
interferential -X- _ O
information -X- _ O
. -X- _ O
Specifically -X- _ O
, -X- _ O
we -X- _ O
first -X- _ O
calculate -X- _ O
the -X- _ O
consistency -X- _ O
∆ -X- _ O
C -X- _ O
between -X- _ O
unimodal -X- _ O
feature -X- _ O
u -X- _ O
L -X- _ O
f -X- _ O
and -X- _ O
bi -X- _ O
- -X- _ O
modal -X- _ O
feature -X- _ O
m -X- _ O
L -X- _ O
f -X- _ O
as -X- _ O
follows -X- _ O
: -X- _ O

By -X- _ O
correcting -X- _ O
the -X- _ O
attention -X- _ O
matrix -X- _ O
, -X- _ O
the -X- _ O
image -X- _ O
with -X- _ O
a -X- _ O
large -X- _ O
deviation -X- _ O
in -X- _ O
content -X- _ O
is -X- _ O
cropped -X- _ O
out -X- _ O
. -X- _ O
In -X- _ O
other -X- _ O
words -X- _ O
, -X- _ O
the -X- _ O
multimodal -X- _ O
inconsistency -X- _ O
features -X- _ O
degenerate -X- _ O
into -X- _ O
text -X- _ O
- -X- _ O
only -X- _ O
features -X- _ O
through -X- _ O
this -X- _ O
process -X- _ O
. -X- _ O
The -X- _ O
simple -X- _ O
method -X- _ O
has -X- _ O
been -X- _ O
shown -X- _ O
to -X- _ O
be -X- _ O
effective -X- _ O
in -X- _ O
our -X- _ O
experiments -X- _ O
. -X- _ O

Image -X- _ O
gain -X- _ O
measurement -X- _ O
. -X- _ O
Intuitively -X- _ O
, -X- _ O
the -X- _ O
text -X- _ O
tokens -X- _ O
should -X- _ O
concern -X- _ O
the -X- _ O
image -X- _ O
which -X- _ O
is -X- _ O
helpful -X- _ O
for -X- _ O
the -X- _ O
summary -X- _ O
. -X- _ O
In -X- _ O
previous -X- _ O
attention -X- _ O
- -X- _ O
based -X- _ O
studies -X- _ O
, -X- _ O
inter -X- _ O
- -X- _ O
modality -X- _ O
correlation -X- _ O
can -X- _ O
be -X- _ O
modeled -X- _ O
as -X- _ O
softmax -X- _ O
( -X- _ O
QK -X- _ O
√ -X- _ O
D -X- _ O
) -X- _ O
V -X- _ O
. -X- _ O
Q -X- _ O
, -X- _ O
K -X- _ O
, -X- _ O
V -X- _ O
are -X- _ O
the -X- _ O
projected -X- _ O
features -X- _ O
from -X- _ O
the -X- _ O
bi -X- _ O
- -X- _ O
modal -X- _ O
input -X- _ O
. -X- _ O
However -X- _ O
, -X- _ O
it -X- _ O
does -X- _ O
not -X- _ O
explicitly -X- _ O
model -X- _ O
the -X- _ O
image -X- _ O
complementarity -X- _ O
for -X- _ O
the -X- _ O
summary -X- _ O
, -X- _ O
which -X- _ O
leads -X- _ O
to -X- _ O
inefficient -X- _ O
use -X- _ O
of -X- _ O
the -X- _ O
image -X- _ O
. -X- _ O

Following -X- _ O
the -X- _ O
motivation -X- _ O
above -X- _ O
, -X- _ O
we -X- _ O
hope -X- _ O
to -X- _ O
calculate -X- _ O
the -X- _ O
image -X- _ O
gain -X- _ O
on -X- _ O
the -X- _ O
summary -X- _ O
with -X- _ O
mutual -X- _ O
information -X- _ O
. -X- _ O
In -X- _ O
other -X- _ O
words -X- _ O
, -X- _ O
we -X- _ O
want -X- _ O
to -X- _ O
measure -X- _ O
whether -X- _ O
generating -X- _ O
summaries -X- _ O
based -X- _ O
on -X- _ O
bi -X- _ O
- -X- _ O
modal -X- _ O
feature -X- _ O
m -X- _ O
L -X- _ O
is -X- _ O
more -X- _ O
deterministic -X- _ O
than -X- _ O
generating -X- _ O
summaries -X- _ O
based -X- _ O
on -X- _ O
uni -X- _ O
- -X- _ O
modal -X- _ O
feature -X- _ O
u -X- _ O
L -X- _ O
. -X- _ O
Thus -X- _ O
, -X- _ O
we -X- _ O
expect -X- _ O
to -X- _ O
calculate -X- _ O
the -X- _ O
image -X- _ O
gain -X- _ O
on -X- _ O
the -X- _ O
k -X- _ O
- -X- _ O
th -X- _ O
word -X- _ O
of -X- _ O
the -X- _ O
reference -X- _ O
summary -X- _ O
: -X- _ O

However -X- _ O
, -X- _ O
we -X- _ O
intend -X- _ O
to -X- _ O
obtain -X- _ O
GI -X- _ O
k -X- _ O
before -X- _ O
generating -X- _ O
summary -X- _ O
S -X- _ O
and -X- _ O
encoding -X- _ O
m -X- _ O
L -X- _ O
. -X- _ O
Thus -X- _ O
GI -X- _ O
can -X- _ O
be -X- _ O
beneficial -X- _ O
for -X- _ O
generating -X- _ O
S -X- _ O
and -X- _ O
encoding -X- _ O
m -X- _ O
L -X- _ O
. -X- _ O
To -X- _ O
this -X- _ O
end -X- _ O
, -X- _ O
we -X- _ O
define -X- _ O
Copy -X- _ O
Classification -X- _ O
task -X- _ O
Y -X- _ O
to -X- _ O
approximate -X- _ O
the -X- _ O
summary -X- _ O
task -X- _ O
S -X- _ O
: -X- _ O
for -X- _ O
each -X- _ O
input -X- _ O
text -X- _ O
token -X- _ O
t -X- _ O
j -X- _ O
, -X- _ O
the -X- _ O
target -X- _ O
is -X- _ O
to -X- _ O
binary -X- _ O
categorize -X- _ O
whether -X- _ O
it -X- _ O
appears -X- _ O
in -X- _ O
the -X- _ O
reference -X- _ O
summary -X- _ O
. -X- _ O
If -X- _ O
the -X- _ O
token -X- _ O
appears -X- _ O
in -X- _ O
the -X- _ O
reference -X- _ O
summary -X- _ O
, -X- _ O
it -X- _ O
is -X- _ O
classified -X- _ O
asŷ -X- _ O
j -X- _ O
= -X- _ O
1 -X- _ O
; -X- _ O
otherwise -X- _ O
, -X- _ O
ŷ -X- _ O
j -X- _ O
= -X- _ O
0 -X- _ O
. -X- _ O
Next -X- _ O
, -X- _ O
the -X- _ O
GI -X- _ O
j -X- _ O
is -X- _ O
given -X- _ O
by -X- _ O
: -X- _ O

where -X- _ O
u -X- _ O
Lw -X- _ O
, -X- _ O
m -X- _ O
Lw -X- _ O
denote -X- _ O
the -X- _ O
uni -X- _ O
- -X- _ O
modal -X- _ O
and -X- _ O
the -X- _ O
bimodal -X- _ O
feature -X- _ O
acquired -X- _ O
by -X- _ O
L -X- _ O
th -X- _ O
w -X- _ O
layer -X- _ O
. -X- _ O
Finally -X- _ O
, -X- _ O
we -X- _ O
measure -X- _ O
the -X- _ O
gain -X- _ O
that -X- _ O
the -X- _ O
image -X- _ O
brings -X- _ O
to -X- _ O
predict -X- _ O
whether -X- _ O
a -X- _ O
word -X- _ O
appears -X- _ O
correctly -X- _ O
in -X- _ O
the -X- _ O
summary -X- _ O
as -X- _ O
follows -X- _ O
: -X- _ O

Image -X- _ O
gain -X- _ O
application -X- _ O
. -X- _ O
We -X- _ O
introduce -X- _ O
divergence -X- _ O
loss -X- _ O
to -X- _ O
restrain -X- _ O
that -X- _ O
the -X- _ O
image -X- _ O
with -X- _ O
greater -X- _ O
gain -X- _ O
should -X- _ O
receive -X- _ O
more -X- _ O
textual -X- _ O
attention -X- _ O
. -X- _ O
In -X- _ O
successive -X- _ O
i -X- _ O
th -X- _ O
i∈ -X- _ O
[ -X- _ O
Lw+1 -X- _ O
, -X- _ O
Lw+3 -X- _ O
] -X- _ O
layer -X- _ O
, -X- _ O
the -X- _ O
average -X- _ O
interattention -X- _ O
between -X- _ O
each -X- _ O
text -X- _ O
token -X- _ O
t -X- _ O
j -X- _ O
and -X- _ O
the -X- _ O
image -X- _ O
is -X- _ O
: -X- _ O

Image -X- _ O
gain -X- _ O
measurement -X- _ O
. -X- _ O
Different -X- _ O
from -X- _ O
copy -X- _ O
classification -X- _ O
task -X- _ O
at -X- _ O
the -X- _ O
word -X- _ O
level -X- _ O
, -X- _ O
we -X- _ O
define -X- _ O
Copy -X- _ O
Scorer -X- _ O
task -X- _ O
to -X- _ O
measure -X- _ O
the -X- _ O
image -X- _ O
gain -X- _ O
on -X- _ O
phrases -X- _ O
: -X- _ O
We -X- _ O
obtain -X- _ O
phrases -X- _ O
{ -X- _ O
p -X- _ O
1 -X- _ O
, -X- _ O
... -X- _ O
, -X- _ O
p -X- _ O
k -X- _ O
... -X- _ O
} -X- _ O
from -X- _ O
the -X- _ O
text -X- _ O
with -X- _ O
StandfordNLP -X- _ O
2 -X- _ O
. -X- _ O
{ -X- _ O
l -X- _ O
1 -X- _ O
, -X- _ O
... -X- _ O
, -X- _ O
l -X- _ O
k -X- _ O
... -X- _ O
} -X- _ O
is -X- _ O
the -X- _ O
number -X- _ O
of -X- _ O
words -X- _ O
in -X- _ O
the -X- _ O
phrases -X- _ O
. -X- _ O
The -X- _ O
task -X- _ O
targets -X- _ O
scoring -X- _ O
the -X- _ O
proportion -X- _ O
of -X- _ O
words -X- _ O
that -X- _ O
appear -X- _ O
in -X- _ O
both -X- _ O
the -X- _ O
phrase -X- _ O
and -X- _ O
the -X- _ O
reference -X- _ O
summary -X- _ O
: -X- _ O

We -X- _ O
experiment -X- _ O
with -X- _ O
the -X- _ O
multimodal -X- _ B-DatasetName
sentence -X- _ I-DatasetName
summarization -X- _ I-DatasetName
dataset -X- _ I-DatasetName
3 -X- _ O
( -X- _ O
Li -X- _ O
et -X- _ O
al -X- _ O
. -X- _ O
, -X- _ O
2018a -X- _ O
66,000 -X- _ O
samples -X- _ O
in -X- _ O
total -X- _ O
. -X- _ O
And -X- _ O
each -X- _ O
sample -X- _ O
is -X- _ O
a -X- _ O
triplet -X- _ O
of -X- _ O
< -X- _ O
sentence -X- _ O
, -X- _ O
image -X- _ O
, -X- _ O
summary -X- _ O
> -X- _ O
. -X- _ O
Some -X- _ O
statistical -X- _ O
information -X- _ O
is -X- _ O
shown -X- _ O
in -X- _ O
Table -X- _ O
1 -X- _ O
. -X- _ O
Appendix -X- _ O
D -X- _ O
gives -X- _ O
the -X- _ O
categories -X- _ O
of -X- _ O
test -X- _ O
images -X- _ O
. -X- _ O
We -X- _ O
set -X- _ O
both -X- _ O
the -X- _ O
text -X- _ B-HyperparameterName
embedding -X- _ I-HyperparameterName
dimension -X- _ I-HyperparameterName
and -X- _ O
hidden -X- _ B-HyperparameterName
dimension -X- _ I-HyperparameterName
as -X- _ O
768 -X- _ B-HyperparameterValue
. -X- _ O
We -X- _ O
apply -X- _ O
" -X- _ O
bert -X- _ O
- -X- _ O
baseuncased -X- _ O
" -X- _ O
( -X- _ O
Devlin -X- _ O
et -X- _ O
al -X- _ O
. -X- _ O
, -X- _ O
2019 -X- _ O
) -X- _ O
vocabulary -X- _ O
with -X- _ O
28,996 -X- _ O
tokens -X- _ O
. -X- _ O
The -X- _ O
dropout -X- _ B-HyperparameterName
( -X- _ O
Srivastava -X- _ O
et -X- _ O
al -X- _ O
. -X- _ O
, -X- _ O
2014 -X- _ O
) -X- _ O
rate -X- _ O
is -X- _ O
set -X- _ O
to -X- _ O
0.1 -X- _ B-HyperparameterValue
. -X- _ O
Besides -X- _ O
, -X- _ O
the -X- _ O
batch -X- _ B-HyperparameterName
size -X- _ I-HyperparameterName
is -X- _ O
set -X- _ O
to -X- _ O
8 -X- _ B-HyperparameterValue
. -X- _ O
For -X- _ O
texts -X- _ O
, -X- _ O
we -X- _ O
use -X- _ O
the -X- _ O
max -X- _ B-HyperparameterName
text -X- _ I-HyperparameterName
encoding -X- _ I-HyperparameterName
length -X- _ I-HyperparameterName
of -X- _ O
60 -X- _ B-HyperparameterValue
, -X- _ O
and -X- _ O
the -X- _ O
minimum -X- _ B-HyperparameterName
text -X- _ I-HyperparameterName
decoding -X- _ I-HyperparameterName
length -X- _ I-HyperparameterName
is -X- _ O
8 -X- _ B-HyperparameterValue
. -X- _ O
For -X- _ O
images -X- _ O
, -X- _ O
the -X- _ O
object -X- _ O
detection -X- _ O
tool -X- _ O
BUTD -X- _ O
( -X- _ O
Anderson -X- _ O
et -X- _ O
al -X- _ O
. -X- _ O
, -X- _ O
2018 -X- _ O
) -X- _ O
is -X- _ O
applied -X- _ O
to -X- _ O
extract -X- _ O
the -X- _ O
image -X- _ O
feature -X- _ O
, -X- _ O
with -X- _ O
the -X- _ O
maximum -X- _ B-HyperparameterName
boxes -X- _ I-HyperparameterName
as -X- _ O
36 -X- _ B-HyperparameterValue
. -X- _ O
We -X- _ O
use -X- _ O
the -X- _ O
Adam -X- _ B-HyperparameterValue
( -X- _ O
Kingma -X- _ O
and -X- _ O
Ba -X- _ O
, -X- _ O
2014 -X- _ O
) -X- _ O
optimizer -X- _ B-HyperparameterName
and -X- _ O
set -X- _ O
the -X- _ O
learning -X- _ B-HyperparameterName
rate -X- _ I-HyperparameterName
as -X- _ O
5e -X- _ B-HyperparameterValue
− -X- _ I-HyperparameterValue
05 -X- _ I-HyperparameterValue
, -X- _ O
momentum -X- _ B-HyperparameterName
parameters -X- _ O
as -X- _ O
β -X- _ B-HyperparameterName
1 -X- _ I-HyperparameterName
= -X- _ O
0.9 -X- _ B-HyperparameterValue
, -X- _ O
β -X- _ B-HyperparameterName
2 -X- _ I-HyperparameterName
= -X- _ O
0.98 -X- _ B-HyperparameterValue
. -X- _ O
The -X- _ O
model -X- _ O
is -X- _ O
initially -X- _ O
trained -X- _ O
with -X- _ O
the -X- _ O
summary -X- _ O
generation -X- _ O
loss -X- _ O
for -X- _ O
35 -X- _ B-HyperparameterValue
epochs -X- _ B-HyperparameterName
. -X- _ O
To -X- _ O
obtain -X- _ O
our -X- _ O
final -X- _ O
model -X- _ O
, -X- _ O
we -X- _ O
train -X- _ O
for -X- _ O
a -X- _ O
further -X- _ O
15 -X- _ B-HyperparameterValue
epochs -X- _ B-HyperparameterName
with -X- _ O
the -X- _ O
hierarchical -X- _ O
framework -X- _ O
. -X- _ O
In -X- _ O
the -X- _ O
test -X- _ O
phase -X- _ O
, -X- _ O
we -X- _ O
employ -X- _ O
beam -X- _ O
search -X- _ O
and -X- _ O
set -X- _ O
the -X- _ O
beam -X- _ B-HyperparameterName
size -X- _ I-HyperparameterName
as -X- _ O
4 -X- _ B-HyperparameterValue
to -X- _ O
generate -X- _ O
the -X- _ O
summary -X- _ O
. -X- _ O
The -X- _ O
parameter -X- _ O
α -X- _ B-HyperparameterName
in -X- _ O
the -X- _ O
pre -X- _ O
- -X- _ O
filter -X- _ O
module -X- _ O
is -X- _ O
set -X- _ O
as -X- _ O
α -X- _ B-HyperparameterName
= -X- _ O
0.65 -X- _ B-HyperparameterValue
. -X- _ O

Our -X- _ O
methods -X- _ O
are -X- _ O
reported -X- _ O
with -X- _ O
six -X- _ O
automatic -X- _ O
metrics -X- _ O
, -X- _ O
including -X- _ O
ROUGE-1 -X- _ B-MetricName
, -X- _ O
ROUGE-2 -X- _ B-MetricName
, -X- _ O
ROUGE -X- _ B-MetricName
- -X- _ I-MetricName
L -X- _ I-MetricName
( -X- _ O
Lin -X- _ O
and -X- _ O
Hovy -X- _ O
, -X- _ O
2002 -X- _ O
) -X- _ O
, -X- _ O
BLEU -X- _ B-MetricName
( -X- _ O
Papineni -X- _ O
et -X- _ O
al -X- _ O
. -X- _ O
, -X- _ O
2002 -X- _ O
) -X- _ O
, -X- _ O
BERTScore -X- _ B-MetricName
, -X- _ O
and -X- _ O
MoverScore -X- _ B-MetricName
( -X- _ O
Zhao -X- _ O
et -X- _ O
al -X- _ O
. -X- _ O
, -X- _ O
2019 -X- _ O
) -X- _ O
. -X- _ O
More -X- _ O
details -X- _ O
of -X- _ O
evaluation -X- _ O
scripts -X- _ O
are -X- _ O
given -X- _ O
in -X- _ O
Appendix -X- _ O
A -X- _ O
. -X- _ O

Comparisons -X- _ O
with -X- _ O
Baselines -X- _ O
. -X- _ O
We -X- _ O
compare -X- _ O
our -X- _ O
work -X- _ O
with -X- _ O
our -X- _ O
baselines -X- _ O
and -X- _ O
other -X- _ O
work -X- _ O
on -X- _ O
the -X- _ O
multimodal -X- _ B-DatasetName
sentence -X- _ I-DatasetName
summarization -X- _ I-DatasetName
dataset -X- _ I-DatasetName
. -X- _ O
Table -X- _ O
2 -X- _ O
shows -X- _ O
the -X- _ O
results -X- _ O
of -X- _ O
different -X- _ O
models -X- _ O
. -X- _ O
The -X- _ O
results -X- _ O
show -X- _ O
that -X- _ O
UniG -X- _ B-MethodName
performs -X- _ O
comparably -X- _ O
with -X- _ O
UniG -X- _ B-MethodName
( -X- _ I-MethodName
T -X- _ I-MethodName
) -X- _ I-MethodName
. -X- _ O
CFSums -X- _ B-MethodName
build -X- _ O
on -X- _ O
UniG -X- _ O
, -X- _ O
and -X- _ O
introduces -X- _ O
coarse -X- _ O
- -X- _ O
to -X- _ O
- -X- _ O
fine -X- _ O
contribution -X- _ O
network -X- _ O
. -X- _ O
" -X- _ O
F -X- _ O
" -X- _ O
, -X- _ O
" -X- _ O
W -X- _ O
" -X- _ O
, -X- _ O
and -X- _ O
" -X- _ O
P -X- _ O
" -X- _ O
represent -X- _ O
the -X- _ O
pre -X- _ O
- -X- _ O
filter -X- _ O
, -X- _ O
the -X- _ O
word -X- _ O
- -X- _ O
level -X- _ O
complement -X- _ O
, -X- _ O
and -X- _ O
the -X- _ O
phrase -X- _ O
- -X- _ O
level -X- _ O
complement -X- _ O
modules -X- _ O
contained -X- _ O
in -X- _ O
the -X- _ O
CFSum -X- _ O
. -X- _ O
The -X- _ O
footnote -X- _ O
is -X- _ O
the -X- _ O
location -X- _ O
of -X- _ O
the -X- _ O
corresponding -X- _ O
module -X- _ O
. -X- _ O
For -X- _ O
example -X- _ O
, -X- _ O
CFSum -X- _ B-MethodName
- -X- _ O
F -X- _ O
3 -X- _ O
contains -X- _ O
a -X- _ O
pre -X- _ O
- -X- _ O
filter -X- _ O
module -X- _ O
with -X- _ O
L -X- _ O
f -X- _ O
= -X- _ O
3 -X- _ O
. -X- _ O
Generally -X- _ O
, -X- _ O
our -X- _ O
methods -X- _ O
CFSums -X- _ B-MethodName
outperform -X- _ O
the -X- _ O
baselines -X- _ O
UniG -X- _ B-MethodName
( -X- _ I-MethodName
T -X- _ I-MethodName
) -X- _ I-MethodName
and -X- _ O
UniG. -X- _ B-MethodName
The -X- _ O
best -X- _ O
methods -X- _ O
is -X- _ O
CFSum -X- _ B-MethodName
- -X- _ O
F -X- _ O
3 -X- _ O
W -X- _ O
6 -X- _ O
P -X- _ O
9 -X- _ O
. -X- _ O
And -X- _ O
it -X- _ O
achieves -X- _ O
1.64 -X- _ B-MetricValue
higher -X- _ O
points -X- _ O
on -X- _ O
ROUGE-1 -X- _ B-MetricName
than -X- _ O
UniG. -X- _ B-MethodName
We -X- _ O
also -X- _ O
conduct -X- _ O
ablation -X- _ O
experiments -X- _ O
by -X- _ O
applying -X- _ O
one -X- _ O
or -X- _ O
two -X- _ O
kinds -X- _ O
of -X- _ O
contributions -X- _ O
. -X- _ O
The -X- _ O
results -X- _ O
demonstrate -X- _ O
that -X- _ O
each -X- _ O
image -X- _ O
contribution -X- _ O
benefits -X- _ O
the -X- _ O
model -X- _ O
. -X- _ O
In -X- _ O
addition -X- _ O
, -X- _ O
combining -X- _ O
all -X- _ O
image -X- _ O
contributions -X- _ O
brings -X- _ O
greater -X- _ O
gains -X- _ O
than -X- _ O
a -X- _ O
single -X- _ O
contribution -X- _ O
. -X- _ O
Therefore -X- _ O
, -X- _ O
it -X- _ O
can -X- _ O
be -X- _ O
concluded -X- _ O
that -X- _ O
different -X- _ O
contributions -X- _ O
are -X- _ O
complementary -X- _ O
to -X- _ O
the -X- _ O
summary -X- _ O
. -X- _ O
Besides -X- _ O
, -X- _ O
we -X- _ O
conduct -X- _ O
ablation -X- _ O
studies -X- _ O
by -X- _ O
placing -X- _ O
the -X- _ O
pre -X- _ O
- -X- _ O
filter -X- _ O
module -X- _ O
at -X- _ O
the -X- _ O
beginning -X- _ O
( -X- _ O
L -X- _ O
f -X- _ O
= -X- _ O
3 -X- _ O
) -X- _ O
or -X- _ O
the -X- _ O
end -X- _ O
of -X- _ O
the -X- _ O
hierarchical -X- _ O
layers -X- _ O
( -X- _ O
L -X- _ O
f -X- _ O
= -X- _ O
9 -X- _ O
) -X- _ O
. -X- _ O
In -X- _ O
comparison -X- _ O
, -X- _ O
placing -X- _ O
the -X- _ O
pre -X- _ O
- -X- _ O
filter -X- _ O
module -X- _ O
at -X- _ O
the -X- _ O
beginning -X- _ O
( -X- _ O
CFSum -X- _ B-MethodName
- -X- _ O
F -X- _ O
3 -X- _ O
W -X- _ O
6 -X- _ O
P -X- _ O
9 -X- _ O
) -X- _ O
yields -X- _ O
better -X- _ O
performance -X- _ O
. -X- _ O

We -X- _ O
randomly -X- _ O
select -X- _ O
50 -X- _ O
samples -X- _ O
from -X- _ O
the -X- _ O
test -X- _ O
dataset -X- _ O
and -X- _ O
invite -X- _ O
three -X- _ O
postgraduates -X- _ O
to -X- _ O
score -X- _ O
1 -X- _ B-MetricValue
- -X- _ I-MetricValue
5 -X- _ I-MetricValue
for -X- _ O
the -X- _ O
summary -X- _ B-MetricName
quality -X- _ I-MetricName
. -X- _ O
The -X- _ O
evaluation -X- _ O
metrics -X- _ O
include -X- _ O
informativeness -X- _ O
, -X- _ O
fluency -X- _ O
, -X- _ O
and -X- _ O
non -X- _ O
- -X- _ O
redundancy -X- _ O
. -X- _ O

( -X- _ O
1 -X- _ O
) -X- _ O
Informativeness -X- _ B-MetricName
: -X- _ O
Does -X- _ O
the -X- _ O
system -X- _ O
summary -X- _ O
contain -X- _ O
comprehensive -X- _ O
reference -X- _ O
content -X- _ O
? -X- _ O
( -X- _ O
2 -X- _ O
) -X- _ O
Fluency -X- _ B-MetricName
: -X- _ O
Is -X- _ O
the -X- _ O
system -X- _ O
summary -X- _ O
grammatically -X- _ O
correct -X- _ O
and -X- _ O
readable -X- _ O
? -X- _ O
( -X- _ O
3 -X- _ O
) -X- _ O
Non -X- _ B-MetricName
- -X- _ I-MetricName
Redundancy -X- _ I-MetricName
: -X- _ O
Does -X- _ O
the -X- _ O
system -X- _ O
summary -X- _ O
not -X- _ O
have -X- _ O
redundant -X- _ O
or -X- _ O
incorrect -X- _ O
information -X- _ O
relative -X- _ O
to -X- _ O
the -X- _ O
reference -X- _ O
summary -X- _ O
? -X- _ O
Table -X- _ O
3 -X- _ O
shows -X- _ O
the -X- _ O
human -X- _ O
evaluation -X- _ O
results -X- _ O
. -X- _ O
We -X- _ O
run -X- _ O
the -X- _ O
inter -X- _ O
- -X- _ O
annotator -X- _ O
agreement -X- _ O
study -X- _ O
on -X- _ O
three -X- _ O
volunteers -X- _ O
' -X- _ O
scores -X- _ O
and -X- _ O
achieve -X- _ O
reasonable -X- _ O
scores -X- _ O
, -X- _ O
0.47 -X- _ B-MetricValue
, -X- _ O
0.39 -X- _ B-MetricValue
, -X- _ O
and -X- _ O
0.43 -X- _ B-MetricValue
on -X- _ O
informativeness -X- _ B-MetricName
, -X- _ O
fluency -X- _ B-MetricName
, -X- _ O
and -X- _ O
non -X- _ B-MetricName
- -X- _ I-MetricName
redundancy -X- _ I-MetricName
, -X- _ O
respectively -X- _ O
. -X- _ O
The -X- _ O
results -X- _ O
show -X- _ O
that -X- _ O
our -X- _ O
method -X- _ O
CFSum -X- _ B-MethodName
- -X- _ O
F -X- _ O
3 -X- _ O
W -X- _ O
6 -X- _ O
S -X- _ O
9 -X- _ O
achieves -X- _ O
the -X- _ O
best -X- _ O
performance -X- _ O
on -X- _ O
all -X- _ O
three -X- _ O
aspects -X- _ O
over -X- _ O
UniG -X- _ B-MethodName
( -X- _ I-MethodName
T -X- _ I-MethodName
) -X- _ I-MethodName
and -X- _ O
UniG -X- _ B-MethodName
baselines -X- _ O
. -X- _ O
Thus -X- _ O
we -X- _ O
conclude -X- _ O
that -X- _ O
our -X- _ O
method -X- _ O
is -X- _ O
also -X- _ O
effective -X- _ O
through -X- _ O
human -X- _ O
evaluation -X- _ O
. -X- _ O

In -X- _ O
other -X- _ O
multimodal -X- _ O
tasks -X- _ O
such -X- _ O
as -X- _ O
image -X- _ O
captioning -X- _ O
and -X- _ O
multimodal -X- _ O
translation -X- _ O
, -X- _ O
their -X- _ O
models -X- _ O
learn -X- _ O
to -X- _ O
attend -X- _ O
to -X- _ O
the -X- _ O
image -X- _ O
more -X- _ O
for -X- _ O
visual -X- _ O
words -X- _ O
like -X- _ O
" -X- _ O
red -X- _ O
" -X- _ O
, -X- _ O
" -X- _ O
rose -X- _ O
" -X- _ O
and -X- _ O
" -X- _ O
woman -X- _ O
" -X- _ O
( -X- _ O
Lu -X- _ O
et -X- _ O
al -X- _ O
. -X- _ O
, -X- _ O
2017 -X- _ O
; -X- _ O
Calixto -X- _ O
et -X- _ O
al -X- _ O
. -X- _ O
, -X- _ O
2017 -X- _ O
) -X- _ O
. -X- _ O
Since -X- _ O
our -X- _ O
proposed -X- _ O
complement -X- _ O
modules -X- _ O
aim -X- _ O
at -X- _ O
extracting -X- _ O
complementary -X- _ O
information -X- _ O
relative -X- _ O
to -X- _ O
textual -X- _ O
modality -X- _ O
, -X- _ O
we -X- _ O
want -X- _ O
to -X- _ O
know -X- _ O
which -X- _ O
word -X- _ O
or -X- _ O
phrase -X- _ O
the -X- _ O
image -X- _ O
provides -X- _ O
gains -X- _ O
on -X- _ O
. -X- _ O
As -X- _ O
shown -X- _ O
in -X- _ O
Figure -X- _ O
3 -X- _ O
, -X- _ O
we -X- _ O
visualize -X- _ O
the -X- _ O
complement -X- _ O
gain -X- _ O
value -X- _ O
for -X- _ O
the -X- _ O
input -X- _ O
words -X- _ O
. -X- _ O
We -X- _ O
manually -X- _ O
align -X- _ O
the -X- _ O
reference -X- _ O
summary -X- _ O
and -X- _ O
the -X- _ O
input -X- _ O
text -X- _ O
. -X- _ O
The -X- _ O
word -X- _ O
highlighted -X- _ O
with -X- _ O
a -X- _ O
red -X- _ O
box -X- _ O
indicates -X- _ O
that -X- _ O
it -X- _ O
appears -X- _ O
in -X- _ O
the -X- _ O
reference -X- _ O
summary -X- _ O
generatively -X- _ O
5 -X- _ O
or -X- _ O
extractively -X- _ O
. -X- _ O

First -X- _ O
, -X- _ O
we -X- _ O
find -X- _ O
that -X- _ O
words -X- _ O
with -X- _ O
positive -X- _ O
image -X- _ O
gain -X- _ O
can -X- _ O
basically -X- _ O
cover -X- _ O
the -X- _ O
reference -X- _ O
summary -X- _ O
information -X- _ O
. -X- _ O
It -X- _ O
proves -X- _ O
that -X- _ O
our -X- _ O
calculated -X- _ O
gain -X- _ O
helps -X- _ O
in -X- _ O
generating -X- _ O
the -X- _ O
target -X- _ O
summary -X- _ O
words -X- _ O
. -X- _ O
Second -X- _ O
, -X- _ O
it -X- _ O
can -X- _ O
be -X- _ O
observed -X- _ O
that -X- _ O
different -X- _ O
complement -X- _ O
modules -X- _ O
bring -X- _ O
positive -X- _ O
gains -X- _ O
in -X- _ O
different -X- _ O
areas -X- _ O
, -X- _ O
which -X- _ O
means -X- _ O
different -X- _ O
levels -X- _ O
of -X- _ O
complement -X- _ O
modules -X- _ O
are -X- _ O
complementary -X- _ O
. -X- _ O
It -X- _ O
further -X- _ O
explains -X- _ O
that -X- _ O
multiple -X- _ O
contributions -X- _ O
are -X- _ O
better -X- _ O
than -X- _ O
a -X- _ O
single -X- _ O
contribution -X- _ O
in -X- _ O
the -X- _ O
experimental -X- _ O
results -X- _ O
. -X- _ O
At -X- _ O
last -X- _ O
, -X- _ O
it -X- _ O
is -X- _ O
worth -X- _ O
noting -X- _ O
that -X- _ O
some -X- _ O
words -X- _ O
are -X- _ O
gained -X- _ O
from -X- _ O
the -X- _ O
image -X- _ O
but -X- _ O
are -X- _ O
not -X- _ O
visible -X- _ O
in -X- _ O
the -X- _ O
image -X- _ O
, -X- _ O
i.e. -X- _ O
, -X- _ O
" -X- _ O
relatives -X- _ O
" -X- _ O
and -X- _ O
" -X- _ O
victims -X- _ O
" -X- _ O
. -X- _ O
Therefore -X- _ O
, -X- _ O
we -X- _ O
believe -X- _ O
the -X- _ O
image -X- _ O
brings -X- _ O
gain -X- _ O
in -X- _ O
both -X- _ O
visible -X- _ O
and -X- _ O
invisible -X- _ O
words -X- _ O
. -X- _ O
We -X- _ O
explain -X- _ O
further -X- _ O
in -X- _ O
Gainable -X- _ O
Images -X- _ O
. -X- _ O

Since -X- _ O
we -X- _ O
believe -X- _ O
that -X- _ O
images -X- _ O
should -X- _ O
provide -X- _ O
meaningful -X- _ O
contributions -X- _ O
instead -X- _ O
of -X- _ O
robustness -X- _ O
enhancements -X- _ O
in -X- _ O
multimodal -X- _ B-TaskName
summarization -X- _ I-TaskName
, -X- _ O
we -X- _ O
wonder -X- _ O
whether -X- _ O
unpaired -X- _ O
multimodal -X- _ O
data -X- _ O
may -X- _ O
affect -X- _ O
the -X- _ O
performance -X- _ O
of -X- _ O
our -X- _ O
model -X- _ O
. -X- _ O
Therefore -X- _ O
, -X- _ O
we -X- _ O
try -X- _ O
generating -X- _ O
the -X- _ O
summary -X- _ O
based -X- _ O
on -X- _ O
the -X- _ O
unpaired -X- _ O
image -X- _ O
and -X- _ O
text -X- _ O
. -X- _ O

We -X- _ O
exchange -X- _ O
20 -X- _ O
pairs -X- _ O
from -X- _ O
100 -X- _ O
pairs -X- _ O
of -X- _ O
test -X- _ O
samples -X- _ O
. -X- _ O
And -X- _ O
we -X- _ O
conduct -X- _ O
experiments -X- _ O
with -X- _ O
different -X- _ O
sampling -X- _ O
for -X- _ O
three -X- _ O
times -X- _ O
. -X- _ O
The -X- _ O
mean -X- _ O
and -X- _ O
standard -X- _ O
deviation -X- _ O
reports -X- _ O
as -X- _ O
Table -X- _ O
4 -X- _ O
. -X- _ O
" -X- _ O
Paired -X- _ O
" -X- _ O
represents -X- _ O
ROUGE-1 -X- _ B-MetricName
on -X- _ O
test -X- _ O
set -X- _ O
, -X- _ O
" -X- _ O
Unpaired -X- _ O
" -X- _ O
represents -X- _ O
ROUGE-1 -X- _ B-MetricName
on -X- _ O
the -X- _ O
unpaired -X- _ O
set -X- _ O
. -X- _ O
" -X- _ O
CFSum -X- _ B-MethodName
( -X- _ O
filter -X- _ O
- -X- _ O
off -X- _ O
) -X- _ O
" -X- _ O
represents -X- _ O
turning -X- _ O
down -X- _ O
the -X- _ O
pre -X- _ O
- -X- _ O
filter -X- _ O
mechanism -X- _ O
. -X- _ O
The -X- _ O
results -X- _ O
show -X- _ O
different -X- _ O
trends -X- _ O
in -X- _ O
the -X- _ O
two -X- _ O
models -X- _ O
. -X- _ O
For -X- _ O
UniG -X- _ B-MethodName
, -X- _ O
unpaired -X- _ O
multi -X- _ O
- -X- _ O
modalities -X- _ O
do -X- _ O
not -X- _ O
affect -X- _ O
the -X- _ O
performance -X- _ O
. -X- _ O
We -X- _ O
guess -X- _ O
UniG -X- _ B-MethodName
does -X- _ I-MethodName
not -X- _ O
exploit -X- _ O
meaningful -X- _ O
image -X- _ O
information -X- _ O
while -X- _ O
relying -X- _ O
only -X- _ O
on -X- _ O
text -X- _ O
to -X- _ O
generate -X- _ O
the -X- _ O
summary -X- _ O
. -X- _ O
In -X- _ O
contrast -X- _ O
, -X- _ O
CFSum -X- _ B-MethodName
hurt -X- _ O
more -X- _ O
severely -X- _ O
from -X- _ O
unpairing -X- _ O
. -X- _ O
The -X- _ O
difference -X- _ O
exists -X- _ O
because -X- _ O
CFSum -X- _ B-MethodName
depends -X- _ O
on -X- _ O
the -X- _ O
image -X- _ O
and -X- _ O
text -X- _ O
. -X- _ O
Thus -X- _ O
, -X- _ O
the -X- _ O
unpaired -X- _ O
image -X- _ O
would -X- _ O
reduce -X- _ O
the -X- _ O
correct -X- _ O
information -X- _ O
that -X- _ O
CFSum -X- _ B-MethodName
gets -X- _ O
. -X- _ O
However -X- _ O
, -X- _ O
CFSum -X- _ B-MethodName
still -X- _ O
performs -X- _ O
better -X- _ O
than -X- _ O
UniG -X- _ B-MethodName
, -X- _ I-MethodName
proving -X- _ O
that -X- _ O
it -X- _ O
is -X- _ O
fault -X- _ O
- -X- _ O
tolerant -X- _ O
. -X- _ O
Furthermore -X- _ O
, -X- _ O
CF -X- _ B-MethodName
- -X- _ I-MethodName
Sum -X- _ I-MethodName
( -X- _ O
filter -X- _ O
- -X- _ O
off -X- _ O
) -X- _ O
significantly -X- _ O
suffers -X- _ O
from -X- _ O
unpaired -X- _ O
data -X- _ O
, -X- _ O
showing -X- _ O
that -X- _ O
pre -X- _ O
- -X- _ O
filter -X- _ O
can -X- _ O
eliminate -X- _ O
useless -X- _ O
images -X- _ O
. -X- _ O

One -X- _ O
of -X- _ O
the -X- _ O
most -X- _ O
important -X- _ O
hyperparameters -X- _ O
in -X- _ O
CF -X- _ B-MethodName
- -X- _ I-MethodName
Sum -X- _ I-MethodName
is -X- _ O
the -X- _ O
location -X- _ O
of -X- _ O
different -X- _ O
contribution -X- _ O
modules -X- _ O
. -X- _ O
Because -X- _ O
the -X- _ O
three -X- _ O
modules -X- _ O
' -X- _ O
order -X- _ O
in -X- _ O
the -X- _ O
network -X- _ O
is -X- _ O
fixed -X- _ O
, -X- _ O
we -X- _ O
change -X- _ O
their -X- _ O
absolute -X- _ O
position -X- _ O
in -X- _ O
the -X- _ O
encoder -X- _ O
layers -X- _ O
and -X- _ O
report -X- _ O
the -X- _ O
corresponding -X- _ O
performance -X- _ O
in -X- _ O
Figure -X- _ O
5 -X- _ O
. -X- _ O
w -X- _ B-HyperparameterName
denotes -X- _ O
the -X- _ O
number -X- _ O
of -X- _ O
layers -X- _ O
between -X- _ O
two -X- _ O
modules -X- _ O
, -X- _ O
and -X- _ O
the -X- _ O
X -X- _ O
axis -X- _ O
denotes -X- _ O
the -X- _ O
starting -X- _ O
layer -X- _ O
of -X- _ O
the -X- _ O
pre -X- _ O
- -X- _ O
filter -X- _ O
module -X- _ O
. -X- _ O

The -X- _ O
results -X- _ O
show -X- _ O
that -X- _ O
the -X- _ O
different -X- _ O
layer -X- _ O
settings -X- _ O
achieve -X- _ O
comparable -X- _ O
performance -X- _ O
. -X- _ O
It -X- _ O
is -X- _ O
noticeable -X- _ O
that -X- _ O
w -X- _ B-HyperparameterName
= -X- _ O
2 -X- _ B-HyperparameterValue
weakens -X- _ O
the -X- _ O
model -X- _ O
. -X- _ O
This -X- _ O
is -X- _ O
due -X- _ O
to -X- _ O
the -X- _ O
fact -X- _ O
that -X- _ O
the -X- _ O
network -X- _ O
with -X- _ O
small -X- _ O
w -X- _ O
loses -X- _ O
the -X- _ O
advantage -X- _ O
of -X- _ O
a -X- _ O
hierarchical -X- _ O
structure -X- _ O
in -X- _ O
the -X- _ O
encoder -X- _ O
. -X- _ O

We -X- _ O
select -X- _ O
three -X- _ O
gained -X- _ O
words -X- _ O
and -X- _ O
corresponding -X- _ O
gainable -X- _ O
images -X- _ O
to -X- _ O
show -X- _ O
in -X- _ O
Figure -X- _ O
4 -X- _ O
. -X- _ O
Consistent -X- _ O
with -X- _ O
our -X- _ O
perception -X- _ O
, -X- _ O
images -X- _ O
bring -X- _ O
gains -X- _ O
on -X- _ O
visual -X- _ O
words -X- _ O
, -X- _ O
such -X- _ O
as -X- _ O
" -X- _ O
earthquake -X- _ O
" -X- _ O
. -X- _ O
More -X- _ O
importantly -X- _ O
, -X- _ O
they -X- _ O
bring -X- _ O
gains -X- _ O
on -X- _ O
non -X- _ O
- -X- _ O
visual -X- _ O
words -X- _ O
such -X- _ O
as -X- _ O
" -X- _ O
celebrate -X- _ O
" -X- _ O
and -X- _ O
" -X- _ O
victims -X- _ O
" -X- _ O
. -X- _ O
For -X- _ O
example -X- _ O
, -X- _ O
" -X- _ O
celebrate -X- _ O
" -X- _ O
may -X- _ O
be -X- _ O
used -X- _ O
in -X- _ O
competitions -X- _ O
, -X- _ O
events -X- _ O
, -X- _ O
and -X- _ O
diplomacy -X- _ O
as -X- _ O
shown -X- _ O
in -X- _ O
Figure -X- _ O
4 -X- _ O
. -X- _ O
Multimodal -X- _ O
tasks -X- _ O
such -X- _ O
as -X- _ O
image -X- _ O
captioning -X- _ O
or -X- _ O
multimodal -X- _ O
question -X- _ O
answering -X- _ O
focus -X- _ O
on -X- _ O
establishing -X- _ O
associations -X- _ O
between -X- _ O
visual -X- _ O
words -X- _ O
and -X- _ O
images -X- _ O
. -X- _ O
However -X- _ O
, -X- _ O
multimodal -X- _ B-TaskName
summarization -X- _ I-TaskName
also -X- _ O
needs -X- _ O
to -X- _ O
pay -X- _ O
attention -X- _ O
to -X- _ O
the -X- _ O
associations -X- _ O
between -X- _ O
non -X- _ O
- -X- _ O
visual -X- _ O
words -X- _ O
and -X- _ O
images -X- _ O
. -X- _ O

Based -X- _ O
on -X- _ O
the -X- _ O
observation -X- _ O
that -X- _ O
existing -X- _ O
multimodal -X- _ O
summary -X- _ O
models -X- _ O
do -X- _ O
not -X- _ O
take -X- _ O
full -X- _ O
advantage -X- _ O
of -X- _ O
useful -X- _ O
image -X- _ O
information -X- _ O
, -X- _ O
this -X- _ O
paper -X- _ O
focuses -X- _ O
on -X- _ O
modeling -X- _ O
different -X- _ O
contributions -X- _ O
of -X- _ O
images -X- _ O
for -X- _ O
summarization -X- _ O
. -X- _ O
Therefore -X- _ O
, -X- _ O
we -X- _ O
propose -X- _ O
a -X- _ O
novel -X- _ O
framework -X- _ O
CFSum -X- _ B-MethodName
consisting -X- _ O
of -X- _ O
pre -X- _ O
- -X- _ O
filter -X- _ O
, -X- _ O
word -X- _ O
- -X- _ O
level -X- _ O
complement -X- _ O
, -X- _ O
and -X- _ O
phrase -X- _ O
- -X- _ O
level -X- _ O
complement -X- _ O
modules -X- _ O
. -X- _ O
The -X- _ O
pre -X- _ O
- -X- _ O
filter -X- _ O
coarsely -X- _ O
eliminates -X- _ O
the -X- _ O
impact -X- _ O
of -X- _ O
useless -X- _ O
images -X- _ O
. -X- _ O
The -X- _ O
two -X- _ O
- -X- _ O
level -X- _ O
visual -X- _ O
complement -X- _ O
modules -X- _ O
measure -X- _ O
different -X- _ O
aspects -X- _ O
of -X- _ O
image -X- _ O
gains -X- _ O
and -X- _ O
guide -X- _ O
the -X- _ O
fusion -X- _ O
of -X- _ O
different -X- _ O
modalities -X- _ O
. -X- _ O
Experimental -X- _ O
results -X- _ O
have -X- _ O
shown -X- _ O
that -X- _ O
CFSum -X- _ B-MethodName
can -X- _ O
significantly -X- _ O
improve -X- _ O
the -X- _ O
summary -X- _ O
. -X- _ O
More -X- _ O
importantly -X- _ O
, -X- _ O
the -X- _ O
complement -X- _ O
modules -X- _ O
make -X- _ O
images -X- _ O
contribute -X- _ O
to -X- _ O
visual -X- _ O
words -X- _ O
and -X- _ O
non -X- _ O
- -X- _ O
visual -X- _ O
words -X- _ O
. -X- _ O

Since -X- _ O
our -X- _ O
method -X- _ O
constructs -X- _ O
on -X- _ O
the -X- _ O
multimodal -X- _ O
transformer -X- _ O
, -X- _ O
it -X- _ O
can -X- _ O
not -X- _ O
be -X- _ O
migrated -X- _ O
to -X- _ O
the -X- _ O
dualstream -X- _ O
model -X- _ O
. -X- _ O
Experiment -X- _ O
results -X- _ O
show -X- _ O
that -X- _ O
CF -X- _ B-MethodName
- -X- _ I-MethodName
Sum -X- _ I-MethodName
can -X- _ O
achieve -X- _ O
comparable -X- _ O
performance -X- _ O
with -X- _ O
strong -X- _ O
baselines -X- _ O
. -X- _ O
But -X- _ O
it -X- _ O
still -X- _ O
can -X- _ O
not -X- _ O
surpass -X- _ O
the -X- _ O
SOTA -X- _ O
of -X- _ O
some -X- _ O
dual -X- _ O
- -X- _ O
stream -X- _ O
large -X- _ O
models -X- _ O
. -X- _ O

Here -X- _ O
, -X- _ O
we -X- _ O
will -X- _ O
introduce -X- _ O
some -X- _ O
detailed -X- _ O
settings -X- _ O
for -X- _ O
our -X- _ O
experiments -X- _ O
. -X- _ O
All -X- _ O
methods -X- _ O
are -X- _ O
run -X- _ O
on -X- _ O
NVIDIA -X- _ O
GeForce -X- _ O
RTX -X- _ O
3090 -X- _ O
. -X- _ O
UniG -X- _ B-MethodName
has -X- _ O
139 -X- _ O
M -X- _ O
parameters -X- _ O
. -X- _ O
When -X- _ O
the -X- _ O
batch -X- _ B-HyperparameterName
size -X- _ I-HyperparameterName
is -X- _ O
8 -X- _ B-HyperparameterValue
, -X- _ O
it -X- _ O
takes -X- _ O
20 -X- _ O
hours -X- _ O
to -X- _ O
train -X- _ O
for -X- _ O
50 -X- _ O
epochs -X- _ O
with -X- _ O
a -X- _ O
single -X- _ O
GPU -X- _ O
. -X- _ O
We -X- _ O
also -X- _ O
provide -X- _ O
evaluation -X- _ O
scripts -X- _ O
for -X- _ O
reproduction -X- _ O
. -X- _ O
For -X- _ O
ROUGE -X- _ B-MetricName
score -X- _ O
, -X- _ O
we -X- _ O
use -X- _ O
file2rouge -X- _ O
6 -X- _ O
with -X- _ O
default -X- _ O
settings -X- _ O
. -X- _ O
For -X- _ O
BERTScore -X- _ B-MetricName
7 -X- _ O
, -X- _ O
we -X- _ O
use -X- _ O
the -X- _ O
official -X- _ O
API -X- _ O
. -X- _ O
It -X- _ O
exploits -X- _ O
the -X- _ O
pre -X- _ O
- -X- _ O
trained -X- _ O
contextual -X- _ O
embeddings -X- _ O
from -X- _ O
BERT -X- _ O
to -X- _ O
calculate -X- _ O
the -X- _ O
similarity -X- _ O
between -X- _ O
the -X- _ O
hypothesis -X- _ O
sentences -X- _ O
and -X- _ O
the -X- _ O
reference -X- _ O
sentences -X- _ O
. -X- _ O
For -X- _ O
MoverScore -X- _ B-MetricName
, -X- _ O
we -X- _ O
use -X- _ O
mover -X- _ O
- -X- _ O
score_v2 -X- _ O
8 -X- _ O
, -X- _ O
which -X- _ O
leverages -X- _ O
BERT -X- _ O
and -X- _ O
Earth -X- _ O
Mover -X- _ O
Distance -X- _ O
to -X- _ O
measure -X- _ O
the -X- _ O
similarity -X- _ O
. -X- _ O

The -X- _ O
line -X- _ O
charts -X- _ O
also -X- _ O
show -X- _ O
that -X- _ O
CFSum -X- _ B-MethodName
is -X- _ O
superior -X- _ O
to -X- _ O
UniG -X- _ B-MethodName
in -X- _ O
all -X- _ O
categories -X- _ O
. -X- _ O
Therefore -X- _ O
there -X- _ O
is -X- _ O
no -X- _ O
category -X- _ O
bias -X- _ O
in -X- _ O
our -X- _ O
method -X- _ O
. -X- _ O

( -X- _ O
2 -X- _ O
) -X- _ O
the -X- _ O
attention -X- _ O
matrix -X- _ O
from -X- _ O
the -X- _ O
11 -X- _ O
th -X- _ O
encoder -X- _ O
layer -X- _ O
of -X- _ O
CFSum -X- _ B-MethodName
- -X- _ O
F -X- _ O
3 -X- _ O
W -X- _ O
6 -X- _ O
S -X- _ O
9 -X- _ O
, -X- _ O
whose -X- _ O
layer -X- _ O
is -X- _ O
under -X- _ O
the -X- _ O
phrase -X- _ O
- -X- _ O
level -X- _ O
guidance -X- _ O
. -X- _ O
The -X- _ O
attention -X- _ O
matrix -X- _ O
is -X- _ O
renormalized -X- _ O
after -X- _ O
removing -X- _ O
[ -X- _ O
CLS -X- _ O
] -X- _ O
and -X- _ O
[ -X- _ O
SEP -X- _ O
] -X- _ O
. -X- _ O
They -X- _ O
are -X- _ O
shown -X- _ O
in -X- _ O
Figure -X- _ O
7 -X- _ O
and -X- _ O
Figure -X- _ O
8 -X- _ O
. -X- _ O
From -X- _ O
the -X- _ O
attention -X- _ O
under -X- _ O
the -X- _ O
word -X- _ O
- -X- _ O
level -X- _ O
guidance -X- _ O
, -X- _ O
we -X- _ O
can -X- _ O
observe -X- _ O
that -X- _ O
some -X- _ O
input -X- _ O
words -X- _ O
which -X- _ O
generatively -X- _ O
or -X- _ O
extractively -X- _ O
occur -X- _ O
in -X- _ O
the -X- _ O
reference -X- _ O
summary -X- _ O
will -X- _ O
attend -X- _ O
to -X- _ O
the -X- _ O
image -X- _ O
, -X- _ O
such -X- _ O
as -X- _ O
" -X- _ O
crash -X- _ O
" -X- _ O
and -X- _ O
" -X- _ O
relatives -X- _ O
" -X- _ O
. -X- _ O
From -X- _ O
the -X- _ O
attention -X- _ O
under -X- _ O
the -X- _ O
phrase -X- _ O
- -X- _ O
level -X- _ O
guidance -X- _ O
, -X- _ O
we -X- _ O
can -X- _ O
observe -X- _ O
that -X- _ O
some -X- _ O
input -X- _ O
phrases -X- _ O
which -X- _ O
generatively -X- _ O
or -X- _ O
extractively -X- _ O
occur -X- _ O
in -X- _ O
the -X- _ O
reference -X- _ O
summary -X- _ O
attend -X- _ O
to -X- _ O
the -X- _ O
image -X- _ O
more -X- _ O
. -X- _ O
Above -X- _ O
all -X- _ O
, -X- _ O
it -X- _ O
also -X- _ O
proves -X- _ O
that -X- _ O
two -X- _ O
visual -X- _ O
complement -X- _ O
modules -X- _ O
succeed -X- _ O
in -X- _ O
providing -X- _ O
better -X- _ O
encoding -X- _ O
to -X- _ O
generate -X- _ O
summaries -X- _ O
. -X- _ O

CogTaskonomy -X- _ B-MethodName
: -X- _ O
Cognitively -X- _ B-MethodName
Inspired -X- _ I-MethodName
Task -X- _ I-MethodName
Taxonomy -X- _ I-MethodName
Is -X- _ O
Beneficial -X- _ O
to -X- _ O
Transfer -X- _ O
Learning -X- _ O
in -X- _ O
NLP -X- _ O

Is -X- _ O
there -X- _ O
a -X- _ O
principle -X- _ O
to -X- _ O
guide -X- _ O
transfer -X- _ O
learning -X- _ O
across -X- _ O
tasks -X- _ O
in -X- _ O
natural -X- _ O
language -X- _ O
processing -X- _ O
( -X- _ O
NLP -X- _ O
) -X- _ O
? -X- _ O
Taxonomy -X- _ O
( -X- _ O
Zamir -X- _ O
et -X- _ O
al -X- _ O
. -X- _ O
, -X- _ O
2018 -X- _ O
) -X- _ O
finds -X- _ O
that -X- _ O
a -X- _ O
structure -X- _ O
exists -X- _ O
among -X- _ O
visual -X- _ O
tasks -X- _ O
, -X- _ O
as -X- _ O
a -X- _ O
principle -X- _ O
underlying -X- _ O
transfer -X- _ O
learning -X- _ O
for -X- _ O
them -X- _ O
. -X- _ O
In -X- _ O
this -X- _ O
paper -X- _ O
, -X- _ O
we -X- _ O
propose -X- _ O
a -X- _ O
cognitively -X- _ O
inspired -X- _ O
framework -X- _ O
, -X- _ O
CogTaskonomy -X- _ B-MethodName
, -X- _ O
to -X- _ O
learn -X- _ O
taxonomy -X- _ B-TaskName
for -X- _ I-TaskName
NLP -X- _ I-TaskName
tasks -X- _ I-TaskName
. -X- _ O
The -X- _ O
framework -X- _ O
consists -X- _ O
of -X- _ O
Cognitive -X- _ B-MethodName
Representation -X- _ I-MethodName
Analytics -X- _ I-MethodName
( -X- _ O
CRA -X- _ B-MethodName
) -X- _ O
and -X- _ O
Cognitive -X- _ B-MethodName
- -X- _ I-MethodName
Neural -X- _ I-MethodName
Mapping -X- _ I-MethodName
( -X- _ O
CNM -X- _ B-MethodName
) -X- _ O
. -X- _ O
The -X- _ O
former -X- _ O
employs -X- _ O
Representational -X- _ O
Similarity -X- _ O
Analysis -X- _ O
, -X- _ O
which -X- _ O
is -X- _ O
commonly -X- _ O
used -X- _ O
in -X- _ O
computational -X- _ O
neuroscience -X- _ O
to -X- _ O
find -X- _ O
a -X- _ O
correlation -X- _ O
between -X- _ O
brainactivity -X- _ O
measurement -X- _ O
and -X- _ O
computational -X- _ O
modeling -X- _ O
, -X- _ O
to -X- _ O
estimate -X- _ O
task -X- _ O
similarity -X- _ O
with -X- _ O
taskspecific -X- _ O
sentence -X- _ O
representations -X- _ O
. -X- _ O
The -X- _ O
latter -X- _ O
learns -X- _ O
to -X- _ O
detect -X- _ O
task -X- _ O
relations -X- _ O
by -X- _ O
projecting -X- _ O
neural -X- _ O
representations -X- _ O
from -X- _ O
NLP -X- _ O
models -X- _ O
to -X- _ O
cognitive -X- _ O
signals -X- _ O
( -X- _ O
i.e. -X- _ O
, -X- _ O
fMRI -X- _ O
voxels -X- _ O
) -X- _ O
. -X- _ O
Experiments -X- _ O
on -X- _ O
12 -X- _ O
NLP -X- _ O
tasks -X- _ O
, -X- _ O
where -X- _ O
BERT -X- _ O
/ -X- _ O
TinyBERT -X- _ O
are -X- _ O
used -X- _ O
as -X- _ O
the -X- _ O
underlying -X- _ O
models -X- _ O
for -X- _ O
transfer -X- _ O
learning -X- _ O
, -X- _ O
demonstrate -X- _ O
that -X- _ O
the -X- _ O
proposed -X- _ O
Cog -X- _ B-MethodName
- -X- _ I-MethodName
Taskonomy -X- _ I-MethodName
is -X- _ O
able -X- _ O
to -X- _ O
guide -X- _ O
transfer -X- _ O
learning -X- _ O
, -X- _ O
achieving -X- _ O
performance -X- _ O
competitive -X- _ O
to -X- _ O
the -X- _ O
Analytic -X- _ O
Hierarchy -X- _ O
Process -X- _ O
( -X- _ O
Saaty -X- _ O
, -X- _ O
1987 -X- _ O
) -X- _ O
used -X- _ O
in -X- _ O
visual -X- _ O
Taskonomy -X- _ O
( -X- _ O
Zamir -X- _ O
et -X- _ O
al -X- _ O
. -X- _ O
, -X- _ O
2018 -X- _ O
but -X- _ O
without -X- _ O
requiring -X- _ O
exhaustive -X- _ O
pairwise -X- _ O
O -X- _ O
( -X- _ O
m -X- _ O
2 -X- _ O
) -X- _ O
task -X- _ O
transferring -X- _ O
. -X- _ O
Analyses -X- _ O
further -X- _ O
discover -X- _ O
that -X- _ O
CNM -X- _ O
is -X- _ O
capable -X- _ O
of -X- _ O
learning -X- _ O
modelagnostic -X- _ O
task -X- _ B-TaskName
taxonomy -X- _ I-TaskName
. -X- _ O
The -X- _ O
source -X- _ O
code -X- _ O
is -X- _ O
available -X- _ O
at -X- _ O
https -X- _ O
: -X- _ O
/ -X- _ O
/ -X- _ O
github.com -X- _ O
/ -X- _ O
tjunlp -X- _ O
- -X- _ O
lab -X- _ O
/ -X- _ O
CogTaskonomy.git -X- _ O
. -X- _ O

Introduction -X- _ O

Transfer -X- _ O
learning -X- _ O
( -X- _ O
TL -X- _ O
) -X- _ O
has -X- _ O
attracted -X- _ O
extensive -X- _ O
research -X- _ O
interests -X- _ O
in -X- _ O
natural -X- _ O
language -X- _ O
processing -X- _ O
with -X- _ O
a -X- _ O
wide -X- _ O
range -X- _ O
of -X- _ O
forms -X- _ O
, -X- _ O
e.g. -X- _ O
, -X- _ O
TL -X- _ O
from -X- _ O
pretrained -X- _ O
language -X- _ O
models -X- _ O
( -X- _ O
PLM -X- _ O
) -X- _ O
to -X- _ O
downstream -X- _ O
tasks -X- _ O
Radford -X- _ O
et -X- _ O
al -X- _ O
. -X- _ O
, -X- _ O
2018 -X- _ O
) -X- _ O
, -X- _ O
from -X- _ O
a -X- _ O
task -X- _ O
with -X- _ O
rich -X- _ O
labeled -X- _ O
data -X- _ O
to -X- _ O
a -X- _ O
task -X- _ O
with -X- _ O
low -X- _ O
resource -X- _ O
† -X- _ O
Equal -X- _ O
contribution -X- _ O
. -X- _ O

* -X- _ O
Corresponding -X- _ O
author -X- _ O
. -X- _ O
( -X- _ O
Chu -X- _ O
and -X- _ O
Wang -X- _ O
, -X- _ O
2018 -X- _ O
; -X- _ O
Yu -X- _ O
et -X- _ O
al -X- _ O
. -X- _ O
, -X- _ O
2021 -X- _ O
) -X- _ O
, -X- _ O
from -X- _ O
highresource -X- _ O
languages -X- _ O
to -X- _ O
low -X- _ O
- -X- _ O
resource -X- _ O
languages -X- _ O
( -X- _ O
Gu -X- _ O
et -X- _ O
al -X- _ O
. -X- _ O
, -X- _ O
2018 -X- _ O
; -X- _ O
Ko -X- _ O
et -X- _ O
al -X- _ O
. -X- _ O
, -X- _ O
2021 -X- _ O
) -X- _ O
, -X- _ O
etc -X- _ O
. -X- _ O
1 -X- _ O
A -X- _ O
high -X- _ O
- -X- _ O
level -X- _ O
concept -X- _ O
or -X- _ O
question -X- _ O
on -X- _ O
cross -X- _ O
- -X- _ O
task -X- _ O
transfer -X- _ O
learning -X- _ O
is -X- _ O
how -X- _ O
these -X- _ O
involved -X- _ O
tasks -X- _ O
are -X- _ O
related -X- _ O
to -X- _ O
each -X- _ O
other -X- _ O
. -X- _ O
Is -X- _ O
sentiment -X- _ O
analysis -X- _ O
related -X- _ O
to -X- _ O
paraphrasing -X- _ O
? -X- _ O
Is -X- _ O
textual -X- _ O
entailment -X- _ O
more -X- _ O
related -X- _ O
to -X- _ O
question -X- _ O
answering -X- _ O
than -X- _ O
named -X- _ O
entity -X- _ O
recognition -X- _ O
? -X- _ O
All -X- _ O
these -X- _ O
sub -X- _ O
- -X- _ O
questions -X- _ O
resolve -X- _ O
themselves -X- _ O
into -X- _ O
whether -X- _ O
a -X- _ O
structure -X- _ O
exists -X- _ O
among -X- _ O
NLP -X- _ O
tasks -X- _ O
. -X- _ O
Such -X- _ O
task -X- _ O
taxonomy -X- _ O
is -X- _ O
of -X- _ O
notable -X- _ O
values -X- _ O
to -X- _ O
transfer -X- _ O
learning -X- _ O
in -X- _ O
NLP -X- _ O
in -X- _ O
that -X- _ O
it -X- _ O
has -X- _ O
the -X- _ O
potential -X- _ O
to -X- _ O
guide -X- _ O
TL -X- _ O
and -X- _ O
reduce -X- _ O
redundancies -X- _ O
across -X- _ O
tasks -X- _ O
( -X- _ O
Zamir -X- _ O
et -X- _ O
al -X- _ O
. -X- _ O
, -X- _ O
2018 -X- _ O
) -X- _ O
. -X- _ O

In -X- _ O
this -X- _ O
paper -X- _ O
, -X- _ O
partially -X- _ O
inspired -X- _ O
by -X- _ O
the -X- _ O
task -X- _ O
taxonomy -X- _ O
in -X- _ O
visual -X- _ O
tasks -X- _ O
( -X- _ O
Zamir -X- _ O
et -X- _ O
al -X- _ O
. -X- _ O
, -X- _ O
2018 -X- _ O
) -X- _ O
, -X- _ O
we -X- _ O
study -X- _ O
the -X- _ O
hierarchical -X- _ O
task -X- _ O
structure -X- _ O
for -X- _ O
NLP -X- _ O
tasks -X- _ O
. -X- _ O
But -X- _ O
significantly -X- _ O
different -X- _ O
from -X- _ O
the -X- _ O
visual -X- _ O
Taskonomy -X- _ O
( -X- _ O
Zamir -X- _ O
et -X- _ O
al -X- _ O
. -X- _ O
, -X- _ O
2018 -X- _ O
) -X- _ O
, -X- _ O
we -X- _ O
construct -X- _ O
NLP -X- _ O
taskonomy -X- _ O
from -X- _ O
a -X- _ O
cognitively -X- _ O
inspired -X- _ O
perspective -X- _ O
. -X- _ O

Cognitively -X- _ O
inspired -X- _ O
NLP -X- _ O
is -X- _ O
the -X- _ O
intersection -X- _ O
of -X- _ O
NLP -X- _ O
and -X- _ O
cognitive -X- _ O
neuroscience -X- _ O
that -X- _ O
aims -X- _ O
at -X- _ O
uncovering -X- _ O
cognitive -X- _ O
processes -X- _ O
in -X- _ O
the -X- _ O
brain -X- _ O
, -X- _ O
including -X- _ O
cognition -X- _ O
in -X- _ O
language -X- _ O
comprehension -X- _ O
. -X- _ O
With -X- _ O
the -X- _ O
increasing -X- _ O
availability -X- _ O
of -X- _ O
cognitively -X- _ O
annotated -X- _ O
data -X- _ O
, -X- _ O
on -X- _ O
the -X- _ O
one -X- _ O
hand -X- _ O
, -X- _ O
cognitive -X- _ O
processing -X- _ O
signals -X- _ O
( -X- _ O
e.g. -X- _ O
, -X- _ O
eye -X- _ O
- -X- _ O
tracking -X- _ O
, -X- _ O
EEG -X- _ O
, -X- _ O
fMRI -X- _ O
) -X- _ O
have -X- _ O
been -X- _ O
explored -X- _ O
to -X- _ O
enhance -X- _ O
neural -X- _ O
models -X- _ O
for -X- _ O
a -X- _ O
wide -X- _ O
range -X- _ O
of -X- _ O
NLP -X- _ O
tasks -X- _ O
( -X- _ O
Barrett -X- _ O
and -X- _ O
Søgaard -X- _ O
, -X- _ O
2015 -X- _ O
; -X- _ O
Bingel -X- _ O
et -X- _ O
al -X- _ O
. -X- _ O
, -X- _ O
2016 -X- _ O
; -X- _ O
Hollenstein -X- _ O
et -X- _ O
al -X- _ O
. -X- _ O
, -X- _ O
2019a -X- _ O
) -X- _ O
. -X- _ O
On -X- _ O
the -X- _ O
other -X- _ O
hand -X- _ O
, -X- _ O
representations -X- _ O
learned -X- _ O
in -X- _ O
NLP -X- _ O
models -X- _ O
are -X- _ O
used -X- _ O
to -X- _ O
predict -X- _ O
brain -X- _ O
activation -X- _ O
patterns -X- _ O
recorded -X- _ O
in -X- _ O
cognitive -X- _ O
processing -X- _ O
data -X- _ O
( -X- _ O
Mitchell -X- _ O
et -X- _ O
al -X- _ O
. -X- _ O
, -X- _ O
2008 -X- _ O
; -X- _ O
Pereira -X- _ O
et -X- _ O
al -X- _ O
. -X- _ O
, -X- _ O
2018 -X- _ O
; -X- _ O
Hale -X- _ O
et -X- _ O
al -X- _ O
. -X- _ O
, -X- _ O
2018 -X- _ O
; -X- _ O
Hollenstein -X- _ O
et -X- _ O
al -X- _ O
. -X- _ O
, -X- _ O
2019b -X- _ O
) -X- _ O
. -X- _ O
These -X- _ O
studies -X- _ O
on -X- _ O
the -X- _ O
bidirectional -X- _ O
association -X- _ O
between -X- _ O
the -X- _ O
two -X- _ O
areas -X- _ O
demonstrate -X- _ O
that -X- _ O
information -X- _ O
underlying -X- _ O
cognitive -X- _ O
processing -X- _ O
data -X- _ O
is -X- _ O
closely -X- _ O
related -X- _ O
to -X- _ O
tasks -X- _ O
and -X- _ O
representations -X- _ O
in -X- _ O
NLP -X- _ O
. -X- _ O
Hence -X- _ O
we -X- _ O
want -X- _ O
to -X- _ O
know -X- _ O
whether -X- _ O
it -X- _ O
is -X- _ O
feasible -X- _ O
to -X- _ O
isolate -X- _ O
task -X- _ O
repre- -X- _ O
Pretrained -X- _ O
language -X- _ O
models -X- _ O
are -X- _ O
fine -X- _ O
- -X- _ O
tuned -X- _ O
on -X- _ O
downstream -X- _ O
tasks -X- _ O
to -X- _ O
obtain -X- _ O
task -X- _ O
- -X- _ O
specific -X- _ O
sentence -X- _ O
representations -X- _ O
, -X- _ O
which -X- _ O
are -X- _ O
then -X- _ O
fed -X- _ O
into -X- _ O
CRA -X- _ B-MethodName
, -X- _ O
CNM -X- _ B-MethodName
for -X- _ O
estimating -X- _ O
task -X- _ O
similarity -X- _ O
. -X- _ O
We -X- _ O
can -X- _ O
obtain -X- _ O
the -X- _ O
most -X- _ O
similar -X- _ O
task -X- _ O
for -X- _ O
each -X- _ O
target -X- _ O
task -X- _ O
by -X- _ O
the -X- _ O
corresponding -X- _ O
task -X- _ O
similarity -X- _ O
estimation -X- _ O
method -X- _ O
and -X- _ O
rank -X- _ O
it -X- _ O
according -X- _ O
to -X- _ O
the -X- _ O
oracle -X- _ O
task -X- _ O
ranking -X- _ O
obtained -X- _ O
according -X- _ O
to -X- _ O
transfer -X- _ O
learning -X- _ O
performance -X- _ O
. -X- _ O
R -X- _ O
is -X- _ O
the -X- _ O
task -X- _ O
ranking -X- _ O
score -X- _ O
which -X- _ O
is -X- _ O
averaged -X- _ O
over -X- _ O
all -X- _ O
target -X- _ O
tasks -X- _ O
. -X- _ O
sentations -X- _ O
from -X- _ O
cognitive -X- _ O
processing -X- _ O
data -X- _ O
and -X- _ O
use -X- _ O
them -X- _ O
to -X- _ O
learn -X- _ O
task -X- _ O
taxonomy -X- _ O
in -X- _ O
NLP -X- _ O
. -X- _ O

To -X- _ O
examine -X- _ O
this -X- _ O
hypothesis -X- _ O
, -X- _ O
we -X- _ O
propose -X- _ O
CogTaskonomy -X- _ B-MethodName
, -X- _ O
a -X- _ O
Cognitively -X- _ O
Inspired -X- _ O
Task -X- _ O
Taxonomy -X- _ O
framework -X- _ O
, -X- _ O
as -X- _ O
illustrated -X- _ O
in -X- _ O
Figure -X- _ O
1 -X- _ O
, -X- _ O
to -X- _ O
learn -X- _ O
a -X- _ O
task -X- _ O
structure -X- _ O
for -X- _ O
NLP -X- _ O
tasks -X- _ O
. -X- _ O
CogTaskonomy -X- _ O
consists -X- _ O
of -X- _ O
two -X- _ O
main -X- _ O
cognitively -X- _ O
inspired -X- _ O
components -X- _ O
: -X- _ O
Cognitive -X- _ B-MethodName
Representation -X- _ I-MethodName
Analytics -X- _ I-MethodName
( -X- _ O
CRA -X- _ B-MethodName
) -X- _ O
and -X- _ O
Cognitive -X- _ B-MethodName
- -X- _ I-MethodName
Neural -X- _ I-MethodName
Mapping -X- _ I-MethodName
( -X- _ O
CNM -X- _ B-MethodName
) -X- _ O
. -X- _ O
CRA -X- _ B-MethodName
extracts -X- _ O
task -X- _ O
representations -X- _ O
from -X- _ O
NLP -X- _ O
models -X- _ O
and -X- _ O
employs -X- _ O
Representational -X- _ O
Similarity -X- _ O
Analysis -X- _ O
( -X- _ O
RSA -X- _ O
) -X- _ O
( -X- _ O
Kriegeskorte -X- _ O
et -X- _ O
al -X- _ O
. -X- _ O
, -X- _ O
2008 -X- _ O
) -X- _ O
, -X- _ O
which -X- _ O
is -X- _ O
commonly -X- _ O
used -X- _ O
to -X- _ O
measure -X- _ O
the -X- _ O
correlation -X- _ O
between -X- _ O
brain -X- _ O
activity -X- _ O
and -X- _ O
computational -X- _ O
model -X- _ O
, -X- _ O
to -X- _ O
estimate -X- _ O
NLP -X- _ O
task -X- _ O
similarity -X- _ O
. -X- _ O
CNM -X- _ B-MethodName
trains -X- _ O
fully -X- _ O
connected -X- _ O
neural -X- _ O
networks -X- _ O
to -X- _ O
build -X- _ O
the -X- _ O
mapping -X- _ O
from -X- _ O
sentence -X- _ O
representations -X- _ O
of -X- _ O
pretrained -X- _ O
models -X- _ O
finetuned -X- _ O
on -X- _ O
specific -X- _ O
tasks -X- _ O
to -X- _ O
fMRI -X- _ O
signals -X- _ O
recorded -X- _ O
when -X- _ O
human -X- _ O
subjects -X- _ O
read -X- _ O
those -X- _ O
sentences -X- _ O
. -X- _ O
It -X- _ O
then -X- _ O
uses -X- _ O
mapping -X- _ O
correlation -X- _ O
coefficients -X- _ O
as -X- _ O
task -X- _ O
representations -X- _ O
to -X- _ O
compute -X- _ O
task -X- _ O
similarity -X- _ O
. -X- _ O

Both -X- _ O
methods -X- _ O
require -X- _ O
sentence -X- _ O
representations -X- _ O
to -X- _ O
compute -X- _ O
task -X- _ O
representations -X- _ O
. -X- _ O
We -X- _ O
use -X- _ O
pretrained -X- _ O
language -X- _ O
models -X- _ O
fine -X- _ O
- -X- _ O
tuned -X- _ O
on -X- _ O
specific -X- _ O
tasks -X- _ O
, -X- _ O
particularly -X- _ O
BERT -X- _ O
and -X- _ O
TinyBERT -X- _ O
( -X- _ O
Jiao -X- _ O
et -X- _ O
al -X- _ O
. -X- _ O
, -X- _ O
2020 -X- _ O
) -X- _ O
, -X- _ O
to -X- _ O
obtain -X- _ O
sentence -X- _ O
representations -X- _ O
. -X- _ O

We -X- _ O
compare -X- _ O
the -X- _ O
proposed -X- _ O
CogTaskonomy -X- _ B-MethodName
against -X- _ O
the -X- _ O
Analytic -X- _ B-MethodName
Hierarchy -X- _ I-MethodName
Process -X- _ I-MethodName
( -X- _ O
AHP -X- _ B-MethodName
) -X- _ O
used -X- _ O
in -X- _ O
Taskonomy -X- _ O
( -X- _ O
Zamir -X- _ O
et -X- _ O
al -X- _ O
. -X- _ O
, -X- _ O
2018 -X- _ O
) -X- _ O
. -X- _ O
We -X- _ O
guide -X- _ O
TL -X- _ O
across -X- _ O
tasks -X- _ O
with -X- _ O
the -X- _ O
learned -X- _ O
task -X- _ O
structure -X- _ O
and -X- _ O
evaluate -X- _ O
the -X- _ O
effectiveness -X- _ O
of -X- _ O
these -X- _ O
methods -X- _ O
by -X- _ O
estimating -X- _ O
TL -X- _ O
performance -X- _ O
from -X- _ O
various -X- _ O
source -X- _ O
to -X- _ O
target -X- _ O
tasks -X- _ O
. -X- _ O

Related -X- _ O
Work -X- _ O

Our -X- _ O
work -X- _ O
is -X- _ O
related -X- _ O
to -X- _ O
cognitively -X- _ O
inspired -X- _ O
NLP -X- _ O
and -X- _ O
a -X- _ O
variety -X- _ O
of -X- _ O
learning -X- _ O
formalisms -X- _ O
that -X- _ O
involve -X- _ O
knowledge -X- _ O
transfer -X- _ O
across -X- _ O
different -X- _ O
tasks -X- _ O
. -X- _ O
We -X- _ O
briefly -X- _ O
review -X- _ O
these -X- _ O
topics -X- _ O
within -X- _ O
the -X- _ O
scope -X- _ O
of -X- _ O
NLP -X- _ O
and -X- _ O
the -X- _ O
constraint -X- _ O
of -X- _ O
space -X- _ O
. -X- _ O

Cognitively -X- _ O
Inspired -X- _ O
NLP -X- _ O

Using -X- _ O
NLP -X- _ O
Representations -X- _ O
for -X- _ O
Brain -X- _ O
Activity -X- _ O
Prediction -X- _ O
Since -X- _ O
the -X- _ O
pioneering -X- _ O
work -X- _ O
( -X- _ O
Mitchell -X- _ O
et -X- _ O
al -X- _ O
. -X- _ O
, -X- _ O
2008 -X- _ O
) -X- _ O
, -X- _ O
connecting -X- _ O
statistical -X- _ O
NLP -X- _ O
representations -X- _ O
with -X- _ O
cognition -X- _ O
has -X- _ O
attracted -X- _ O
widespread -X- _ O
at -X- _ O
- -X- _ O
tention -X- _ O
. -X- _ O
Chang -X- _ O
et -X- _ O
al -X- _ O
. -X- _ O
( -X- _ O
2009 -X- _ O
) -X- _ O
explore -X- _ O
adjective -X- _ O
- -X- _ O
noun -X- _ O
composition -X- _ O
in -X- _ O
fMRI -X- _ O
based -X- _ O
on -X- _ O
co -X- _ O
- -X- _ O
occurrence -X- _ O
statistics -X- _ O
. -X- _ O
Huth -X- _ O
et -X- _ O
al -X- _ O
. -X- _ O
( -X- _ O
2016 -X- _ O
) -X- _ O
use -X- _ O
distributed -X- _ O
word -X- _ O
representations -X- _ O
to -X- _ O
map -X- _ O
fMRI -X- _ O
data -X- _ O
to -X- _ O
activated -X- _ O
brain -X- _ O
regions -X- _ O
, -X- _ O
revealing -X- _ O
a -X- _ O
semantic -X- _ O
map -X- _ O
of -X- _ O
how -X- _ O
words -X- _ O
are -X- _ O
distributed -X- _ O
in -X- _ O
the -X- _ O
human -X- _ O
cerebral -X- _ O
cortex -X- _ O
. -X- _ O
A -X- _ O
great -X- _ O
deal -X- _ O
of -X- _ O
research -X- _ O
( -X- _ O
Murphy -X- _ O
et -X- _ O
al -X- _ O
. -X- _ O
, -X- _ O
2012 -X- _ O
; -X- _ O
Anderson -X- _ O
et -X- _ O
al -X- _ O
. -X- _ O
, -X- _ O
2016 -X- _ O
; -X- _ O
Søgaard -X- _ O
, -X- _ O
2016 -X- _ O
; -X- _ O
Bulat -X- _ O
et -X- _ O
al -X- _ O
. -X- _ O
, -X- _ O
2017 -X- _ O
) -X- _ O
has -X- _ O
been -X- _ O
devoted -X- _ O
to -X- _ O
word -X- _ O
decoding -X- _ O
. -X- _ O
Pereira -X- _ O
et -X- _ O
al -X- _ O
. -X- _ O
( -X- _ O
2018 -X- _ O
) -X- _ O
extend -X- _ O
brain -X- _ O
decoding -X- _ O
to -X- _ O
sentence -X- _ O
stimuli -X- _ O
, -X- _ O
suggesting -X- _ O
that -X- _ O
neural -X- _ O
network -X- _ O
language -X- _ O
models -X- _ O
can -X- _ O
be -X- _ O
used -X- _ O
to -X- _ O
interpret -X- _ O
sentences -X- _ O
in -X- _ O
a -X- _ O
long -X- _ O
- -X- _ O
term -X- _ O
context -X- _ O
. -X- _ O
Ren -X- _ O
and -X- _ O
Xiong -X- _ O
( -X- _ O
2022 -X- _ O
) -X- _ O
( -X- _ O
Barrett -X- _ O
and -X- _ O
Søgaard -X- _ O
, -X- _ O
2015 -X- _ O
; -X- _ O
Bingel -X- _ O
et -X- _ O
al -X- _ O
. -X- _ O
, -X- _ O
2016 -X- _ O
; -X- _ O
Gauthier -X- _ O
and -X- _ O
Levy -X- _ O
, -X- _ O
2019 -X- _ O
; -X- _ O
Ren -X- _ O
and -X- _ O
Xiong -X- _ O
, -X- _ O
2021 -X- _ O
) -X- _ O
, -X- _ O
just -X- _ O
to -X- _ O
name -X- _ O
a -X- _ O
few -X- _ O
. -X- _ O

Learning -X- _ O
across -X- _ O
Tasks -X- _ O

A -X- _ O
very -X- _ O
important -X- _ O
trend -X- _ O
in -X- _ O
recent -X- _ O
NLP -X- _ O
is -X- _ O
that -X- _ O
models -X- _ O
, -X- _ O
algorithms -X- _ O
, -X- _ O
and -X- _ O
solutions -X- _ O
are -X- _ O
not -X- _ O
developed -X- _ O
for -X- _ O
only -X- _ O
a -X- _ O
single -X- _ O
task -X- _ O
, -X- _ O
but -X- _ O
for -X- _ O
multiple -X- _ O
tasks -X- _ O
or -X- _ O
across -X- _ O
tasks -X- _ O
Radford -X- _ O
et -X- _ O
al -X- _ O
. -X- _ O
, -X- _ O
2018 -X- _ O
; -X- _ O
McCann -X- _ O
et -X- _ O
al -X- _ O
. -X- _ O
, -X- _ O
2018 -X- _ O
; -X- _ O
Worsham -X- _ O
and -X- _ O
Kalita -X- _ O
, -X- _ O
2020 -X- _ O
Multi -X- _ O
- -X- _ O
task -X- _ O
Learning -X- _ O
is -X- _ O
to -X- _ O
jointly -X- _ O
train -X- _ O
all -X- _ O
tasks -X- _ O
of -X- _ O
interests -X- _ O
with -X- _ O
task -X- _ O
linkages -X- _ O
, -X- _ O
e.g. -X- _ O
, -X- _ O
in -X- _ O
the -X- _ O
form -X- _ O
of -X- _ O
regularization -X- _ O
or -X- _ O
sharing -X- _ O
parameters -X- _ O
across -X- _ O
tasks -X- _ O
( -X- _ O
Collobert -X- _ O
et -X- _ O
al -X- _ O
. -X- _ O
, -X- _ O
2011 -X- _ O
) -X- _ O
. -X- _ O
It -X- _ O
is -X- _ O
important -X- _ O
in -X- _ O
multitask -X- _ O
learning -X- _ O
to -X- _ O
find -X- _ O
related -X- _ O
tasks -X- _ O
for -X- _ O
target -X- _ O
tasks -X- _ O
as -X- _ O
auxiliary -X- _ O
tasks -X- _ O
( -X- _ O
Ruder -X- _ O
, -X- _ O
2017 -X- _ O
) -X- _ O
. -X- _ O

Transfer -X- _ O
Learning -X- _ O
targets -X- _ O
at -X- _ O
transferring -X- _ O
knowledge -X- _ O
from -X- _ O
a -X- _ O
source -X- _ O
task -X- _ O
to -X- _ O
a -X- _ O
target -X- _ O
task -X- _ O
. -X- _ O
According -X- _ O
to -X- _ O
the -X- _ O
task -X- _ O
and -X- _ O
domain -X- _ O
difference -X- _ O
in -X- _ O
the -X- _ O
source -X- _ O
and -X- _ O
target -X- _ O
, -X- _ O
TL -X- _ O
is -X- _ O
divided -X- _ O
into -X- _ O
transductive -X- _ O
TL -X- _ O
( -X- _ O
same -X- _ O
task -X- _ O
, -X- _ O
different -X- _ O
domain -X- _ O
, -X- _ O
a.k.a -X- _ O
. -X- _ O
domain -X- _ O
adaptation -X- _ O
) -X- _ O
, -X- _ O
inductive -X- _ O
TL -X- _ O
( -X- _ O
same -X- _ O
domain -X- _ O
, -X- _ O
different -X- _ O
task -X- _ O
) -X- _ O
and -X- _ O
unsupervised -X- _ O
TL -X- _ O
( -X- _ O
both -X- _ O
different -X- _ O
) -X- _ O
( -X- _ O
Eaton -X- _ O
and -X- _ O
des -X- _ O
- -X- _ O
Jardins -X- _ O
, -X- _ O
2011 -X- _ O
; -X- _ O
Ghifary -X- _ O
et -X- _ O
al -X- _ O
. -X- _ O
, -X- _ O
2014 -X- _ O
; -X- _ O
Yuan -X- _ O
and -X- _ O
Wen -X- _ O
, -X- _ O
2021 -X- _ O
) -X- _ O
. -X- _ O
If -X- _ O
the -X- _ O
source -X- _ O
and -X- _ O
target -X- _ O
are -X- _ O
dissimilar -X- _ O
, -X- _ O
negative -X- _ O
transfer -X- _ O
may -X- _ O
hurt -X- _ O
TL -X- _ O
( -X- _ O
Niu -X- _ O
et -X- _ O
al -X- _ O
. -X- _ O
, -X- _ O
2020 -X- _ O
) -X- _ O
. -X- _ O

Meta -X- _ O
Learning -X- _ O
aims -X- _ O
to -X- _ O
gain -X- _ O
experience -X- _ O
over -X- _ O
a -X- _ O
set -X- _ O
of -X- _ O
related -X- _ O
tasks -X- _ O
for -X- _ O
improving -X- _ O
the -X- _ O
learning -X- _ O
algorithm -X- _ O
itself -X- _ O
( -X- _ O
Hospedales -X- _ O
et -X- _ O
al -X- _ O
. -X- _ O
, -X- _ O
2020 -X- _ O
) -X- _ O
. -X- _ O
Existing -X- _ O
meta -X- _ O
learning -X- _ O
methods -X- _ O
implicitly -X- _ O
assume -X- _ O
that -X- _ O
tasks -X- _ O
are -X- _ O
similar -X- _ O
to -X- _ O
each -X- _ O
other -X- _ O
, -X- _ O
but -X- _ O
it -X- _ O
is -X- _ O
often -X- _ O
unclear -X- _ O
how -X- _ O
to -X- _ O
quantify -X- _ O
task -X- _ O
similarities -X- _ O
and -X- _ O
their -X- _ O
roles -X- _ O
in -X- _ O
learning -X- _ O
( -X- _ O
Venkitaraman -X- _ O
and -X- _ O
Wahlberg -X- _ O
, -X- _ O
2020 -X- _ O
) -X- _ O
. -X- _ O

Lifelong -X- _ O
Learning -X- _ O
is -X- _ O
to -X- _ O
learn -X- _ O
continuously -X- _ O
and -X- _ O
accumulate -X- _ O
knowledge -X- _ O
along -X- _ O
a -X- _ O
sequence -X- _ O
of -X- _ O
tasks -X- _ O
and -X- _ O
uses -X- _ O
it -X- _ O
for -X- _ O
future -X- _ O
learning -X- _ O
( -X- _ O
Chen -X- _ O
and -X- _ O
Liu -X- _ O
, -X- _ O
2018 -X- _ O
) -X- _ O
. -X- _ O

The -X- _ O
system -X- _ O
is -X- _ O
tuned -X- _ O
to -X- _ O
be -X- _ O
able -X- _ O
to -X- _ O
select -X- _ O
the -X- _ O
most -X- _ O
related -X- _ O
prior -X- _ O
knowledge -X- _ O
to -X- _ O
bias -X- _ O
the -X- _ O
learning -X- _ O
towards -X- _ O
a -X- _ O
new -X- _ O
task -X- _ O
favourably -X- _ O
( -X- _ O
Silver -X- _ O
et -X- _ O
al -X- _ O
. -X- _ O
, -X- _ O
2013 -X- _ O
) -X- _ O
. -X- _ O

Learning -X- _ O
Task -X- _ O
Relations -X- _ O

As -X- _ O
task -X- _ O
relatedness -X- _ O
is -X- _ O
important -X- _ O
for -X- _ O
cross -X- _ O
- -X- _ O
task -X- _ O
learning -X- _ O
formalisms -X- _ O
mentioned -X- _ O
in -X- _ O
Section -X- _ O
2.2 -X- _ O
, -X- _ O
efforts -X- _ O
have -X- _ O
also -X- _ O
been -X- _ O
made -X- _ O
to -X- _ O
learn -X- _ O
task -X- _ O
relations -X- _ O
. -X- _ O
Crawshaw -X- _ O
( -X- _ O
2020 -X- _ O
) -X- _ O
groups -X- _ O
previous -X- _ O
methods -X- _ O
on -X- _ O
task -X- _ O
relationship -X- _ O
learning -X- _ O
into -X- _ O
three -X- _ O
categories -X- _ O
. -X- _ O
The -X- _ O
first -X- _ O
is -X- _ O
task -X- _ O
grouping -X- _ O
or -X- _ O
clustering -X- _ O
, -X- _ O
which -X- _ O
divides -X- _ O
a -X- _ O
set -X- _ O
of -X- _ O
tasks -X- _ O
into -X- _ O
clusters -X- _ O
so -X- _ O
that -X- _ O
tasks -X- _ O
in -X- _ O
the -X- _ O
same -X- _ O
cluster -X- _ O
can -X- _ O
be -X- _ O
jointly -X- _ O
trained -X- _ O
( -X- _ O
Bingel -X- _ O
and -X- _ O
Søgaard -X- _ O
, -X- _ O
2017 -X- _ O
; -X- _ O
Standley -X- _ O
et -X- _ O
al -X- _ O
. -X- _ O
, -X- _ O
2019 -X- _ O
) -X- _ O
. -X- _ O
The -X- _ O
second -X- _ O
is -X- _ O
learning -X- _ O
transfer -X- _ O
relationships -X- _ O
, -X- _ O
which -X- _ O
analyzes -X- _ O
whether -X- _ O
transfer -X- _ O
between -X- _ O
tasks -X- _ O
is -X- _ O
beneficial -X- _ O
to -X- _ O
learning -X- _ O
, -X- _ O
regardless -X- _ O
of -X- _ O
whether -X- _ O
tasks -X- _ O
are -X- _ O
related -X- _ O
or -X- _ O
not -X- _ O
( -X- _ O
Zamir -X- _ O
et -X- _ O
al -X- _ O
. -X- _ O
, -X- _ O
2018 -X- _ O
; -X- _ O
Dwivedi -X- _ O
and -X- _ O
Roig -X- _ O
, -X- _ O
2019 -X- _ O
; -X- _ O
Song -X- _ O
et -X- _ O
al -X- _ O
. -X- _ O
, -X- _ O
2019 -X- _ O
) -X- _ O
. -X- _ O
The -X- _ O
third -X- _ O
is -X- _ O
task -X- _ O
embedding -X- _ O
, -X- _ O
which -X- _ O
learns -X- _ O
a -X- _ O
specific -X- _ O
representation -X- _ O
space -X- _ O
for -X- _ O
tasks -X- _ O
( -X- _ O
James -X- _ O
et -X- _ O
al -X- _ O
. -X- _ O
, -X- _ O
2018 -X- _ O
; -X- _ O
Lan -X- _ O
et -X- _ O
al -X- _ O
. -X- _ O
, -X- _ O
2019 -X- _ O
) -X- _ O
. -X- _ O

Our -X- _ O
research -X- _ O
can -X- _ O
be -X- _ O
considered -X- _ O
as -X- _ O
a -X- _ O
mix -X- _ O
of -X- _ O
these -X- _ O
categories -X- _ O
. -X- _ O
CNM -X- _ B-MethodName
learns -X- _ O
cognition -X- _ O
- -X- _ O
based -X- _ O
task -X- _ O
representations -X- _ O
while -X- _ O
both -X- _ O
CNM -X- _ B-MethodName
and -X- _ O
CRA -X- _ B-MethodName
learn -X- _ O
task -X- _ O
relations -X- _ O
aiming -X- _ O
at -X- _ O
transfer -X- _ O
learning -X- _ O
. -X- _ O
Additionally -X- _ O
, -X- _ O
significantly -X- _ O
different -X- _ O
from -X- _ O
previous -X- _ O
studies -X- _ O
, -X- _ O
we -X- _ O
learn -X- _ O
task -X- _ O
structures -X- _ O
from -X- _ O
a -X- _ O
cognitive -X- _ O
perspective -X- _ O
3 -X- _ O
, -X- _ O
which -X- _ O
is -X- _ O
expected -X- _ O
to -X- _ O
estimate -X- _ O
task -X- _ O
relatedness -X- _ O
in -X- _ O
a -X- _ O
cognitively -X- _ O
tuned -X- _ O
space -X- _ O
. -X- _ O
As -X- _ O
will -X- _ O
be -X- _ O
demonstrated -X- _ O
below -X- _ O
, -X- _ O
our -X- _ O
cognitively -X- _ O
motivated -X- _ O
methods -X- _ O
incur -X- _ O
a -X- _ O
low -X- _ O
computation -X- _ O
cost -X- _ O
and -X- _ O
exhibit -X- _ O
generalization -X- _ O
across -X- _ O
underlying -X- _ O
models -X- _ O
to -X- _ O
some -X- _ O
extend -X- _ O
. -X- _ O

CogTaskonomy -X- _ B-MethodName

Figure -X- _ O
1 -X- _ O
illustrates -X- _ O
the -X- _ O
basic -X- _ O
framework -X- _ O
of -X- _ O
Cog -X- _ B-MethodName
- -X- _ I-MethodName
Taskonomy -X- _ I-MethodName
. -X- _ O
First -X- _ O
, -X- _ O
we -X- _ O
obtain -X- _ O
task -X- _ O
- -X- _ O
specific -X- _ O
sentence -X- _ O
representations -X- _ O
of -X- _ O
text -X- _ O
stimuli -X- _ O
from -X- _ O
cognitive -X- _ O
data -X- _ O
by -X- _ O
feeding -X- _ O
them -X- _ O
into -X- _ O
fine -X- _ O
- -X- _ O
tuned -X- _ O
or -X- _ O
distilled -X- _ O
pretrained -X- _ O
language -X- _ O
models -X- _ O
on -X- _ O
12 -X- _ O
downstream -X- _ O
tasks -X- _ O
( -X- _ O
Section -X- _ O
3.1 -X- _ O
) -X- _ O
. -X- _ O
Subsequently -X- _ O
, -X- _ O
task -X- _ O
- -X- _ O
specific -X- _ O
representations -X- _ O
are -X- _ O
fed -X- _ O
into -X- _ O
two -X- _ O
cognitively -X- _ O
inspired -X- _ O
components -X- _ O
, -X- _ O
cognitive -X- _ O
representation -X- _ O
analytics -X- _ O
( -X- _ O
Section -X- _ O
3.2 -X- _ O
) -X- _ O
and -X- _ O
cognitive -X- _ B-MethodName
- -X- _ I-MethodName
neural -X- _ I-MethodName
mapping -X- _ I-MethodName
( -X- _ O
Section -X- _ O
3.3 -X- _ O
) -X- _ O
, -X- _ O
for -X- _ O
estimating -X- _ O
task -X- _ O
similarity -X- _ O
and -X- _ O
inducing -X- _ O
task -X- _ O
taxonomy -X- _ O
. -X- _ O

Task -X- _ O
- -X- _ O
Specific -X- _ O
Sentence -X- _ O
Representations -X- _ O

Fine -X- _ O
- -X- _ O
tuning -X- _ O
a -X- _ O
pretrained -X- _ O
language -X- _ O
model -X- _ O
for -X- _ O
an -X- _ O
end -X- _ O
task -X- _ O
is -X- _ O
a -X- _ O
widely -X- _ O
used -X- _ O
strategy -X- _ O
for -X- _ O
quickly -X- _ O
and -X- _ O
efficiently -X- _ O
building -X- _ O
a -X- _ O
model -X- _ O
for -X- _ O
that -X- _ O
task -X- _ O
with -X- _ O
limited -X- _ O
labeled -X- _ O
data -X- _ O
. -X- _ O
Zhou -X- _ O
and -X- _ O
Srikumar -X- _ O
( -X- _ O
2021 -X- _ O
) -X- _ O
find -X- _ O
that -X- _ O
fine -X- _ O
- -X- _ O
tuning -X- _ O
reconfigures -X- _ O
underlying -X- _ O
semantic -X- _ O
space -X- _ O
to -X- _ O
adjust -X- _ O
pretrained -X- _ O
representations -X- _ O
to -X- _ O
downstream -X- _ O
tasks -X- _ O
. -X- _ O
In -X- _ O
view -X- _ O
of -X- _ O
this -X- _ O
, -X- _ O
we -X- _ O
take -X- _ O
sentence -X- _ O
- -X- _ O
level -X- _ O
textual -X- _ O
stimuli -X- _ O
of -X- _ O
cognitive -X- _ O
data -X- _ O
as -X- _ O
input -X- _ O
data -X- _ O
for -X- _ O
a -X- _ O
specific -X- _ O
fine -X- _ O
- -X- _ O
tuned -X- _ O
model -X- _ O
to -X- _ O
obtain -X- _ O
representations -X- _ O
that -X- _ O
contain -X- _ O
information -X- _ O
specific -X- _ O
to -X- _ O
that -X- _ O
task -X- _ O
. -X- _ O
4 -X- _ O
Additionally -X- _ O
, -X- _ O
Cheng -X- _ O
et -X- _ O
al -X- _ O
. -X- _ O
( -X- _ O
2020 -X- _ O
) -X- _ O
suggest -X- _ O
that -X- _ O
knowledge -X- _ O
distillation -X- _ O
( -X- _ O
KD -X- _ O
) -X- _ O
helps -X- _ O
models -X- _ O
to -X- _ O
be -X- _ O
more -X- _ O
focused -X- _ O
on -X- _ O
task -X- _ O
- -X- _ O
relevant -X- _ O
concepts -X- _ O
. -X- _ O
Therefore -X- _ O
, -X- _ O
without -X- _ O
loss -X- _ O
of -X- _ O
generality -X- _ O
, -X- _ O
we -X- _ O
use -X- _ O
BERT -X- _ O
and -X- _ O
TinyBERT -X- _ O
( -X- _ O
performing -X- _ O
KD -X- _ O
) -X- _ O
to -X- _ O
obtain -X- _ O
task -X- _ O
- -X- _ O
specific -X- _ O
sentence -X- _ O
representations -X- _ O
. -X- _ O

BERT -X- _ O
Following -X- _ O
, -X- _ O
we -X- _ O
prepend -X- _ O
a -X- _ O
special -X- _ O
classification -X- _ O
token -X- _ O
[ -X- _ O
CLS -X- _ O
] -X- _ O
to -X- _ O
each -X- _ O
input -X- _ O
sentence -X- _ O
in -X- _ O
order -X- _ O
to -X- _ O
extract -X- _ O
the -X- _ O
contextualized -X- _ O
representation -X- _ O
of -X- _ O
the -X- _ O
corresponding -X- _ O
sentence -X- _ O
. -X- _ O
Merchant -X- _ O
et -X- _ O
al -X- _ O
. -X- _ O
( -X- _ O
2020 -X- _ O
) -X- _ O
find -X- _ O
that -X- _ O
fine -X- _ O
- -X- _ O
tuning -X- _ O
primarily -X- _ O
affects -X- _ O
top -X- _ O
layers -X- _ O
of -X- _ O
BERT -X- _ O
. -X- _ O
Hence -X- _ O
, -X- _ O
we -X- _ O
take -X- _ O
the -X- _ O
hidden -X- _ O
state -X- _ O
of -X- _ O
the -X- _ O
prepended -X- _ O
token -X- _ O
of -X- _ O
each -X- _ O
sequence -X- _ O
in -X- _ O
the -X- _ O
last -X- _ O
layer -X- _ O
as -X- _ O
the -X- _ O
sentence -X- _ O
representation -X- _ O
. -X- _ O

TinyBERT -X- _ O
TinyBERT -X- _ O
( -X- _ O
Jiao -X- _ O
et -X- _ O
al -X- _ O
. -X- _ O
, -X- _ O
2020 -X- _ O
) -X- _ O
performs -X- _ O
knowledge -X- _ O
distillation -X- _ O
at -X- _ O
both -X- _ O
the -X- _ O
pretraining -X- _ O
and -X- _ O
fine -X- _ O
- -X- _ O
tuning -X- _ O
stage -X- _ O
. -X- _ O
By -X- _ O
leveraging -X- _ O
KD -X- _ O
, -X- _ O
Tiny -X- _ O
- -X- _ O
BERT -X- _ O
learns -X- _ O
to -X- _ O
transfer -X- _ O
knowledge -X- _ O
encoded -X- _ O
in -X- _ O
the -X- _ O
large -X- _ O
teacher -X- _ O
BERT -X- _ O
to -X- _ O
itself -X- _ O
. -X- _ O
As -X- _ O
a -X- _ O
result -X- _ O
, -X- _ O
TinyBERT -X- _ O
can -X- _ O
capture -X- _ O
both -X- _ O
general -X- _ O
and -X- _ O
task -X- _ O
- -X- _ O
specific -X- _ O
knowledge -X- _ O
. -X- _ O
Similarly -X- _ O
, -X- _ O
we -X- _ O
use -X- _ O
the -X- _ O
hidden -X- _ O
state -X- _ O
of -X- _ O
[ -X- _ O
CLS -X- _ O
] -X- _ O
token -X- _ O
in -X- _ O
the -X- _ O
last -X- _ O
layer -X- _ O
as -X- _ O
the -X- _ O
contextualized -X- _ O
representation -X- _ O
for -X- _ O
a -X- _ O
given -X- _ O
sentence -X- _ O
. -X- _ O

Cognitive -X- _ B-MethodName
Representation -X- _ I-MethodName
Analytics -X- _ I-MethodName

With -X- _ O
task -X- _ O
- -X- _ O
specific -X- _ O
representations -X- _ O
learned -X- _ O
by -X- _ O
feeding -X- _ O
text -X- _ O
stimuli -X- _ O
of -X- _ O
cognitive -X- _ O
data -X- _ O
into -X- _ O
a -X- _ O
fine -X- _ O
- -X- _ O
tuned -X- _ O
model -X- _ O
, -X- _ O
we -X- _ O
can -X- _ O
estimate -X- _ O
pairwise -X- _ O
task -X- _ O
similarity -X- _ O
for -X- _ O
any -X- _ O
two -X- _ O
tasks -X- _ O
in -X- _ O
a -X- _ O
given -X- _ O
task -X- _ O
list -X- _ O
T -X- _ O
= -X- _ O
{ -X- _ O
t -X- _ O
1 -X- _ O
, -X- _ O
t -X- _ O
2 -X- _ O
, -X- _ O
... -X- _ O
, -X- _ O
t -X- _ O
m -X- _ O
} -X- _ O
. -X- _ O
The -X- _ O
first -X- _ O
cognitively -X- _ O
inspired -X- _ O
method -X- _ O
is -X- _ O
the -X- _ O
cognitive -X- _ B-MethodName
representation -X- _ I-MethodName
analytics -X- _ I-MethodName
that -X- _ O
adapts -X- _ O
a -X- _ O
common -X- _ O
method -X- _ O
in -X- _ O
computational -X- _ O
neuroscience -X- _ O
to -X- _ O
our -X- _ O
scenario -X- _ O
. -X- _ O
We -X- _ O
first -X- _ O
briefly -X- _ O
introduce -X- _ O
the -X- _ O
common -X- _ O
method -X- _ O
, -X- _ O
representational -X- _ O
similarity -X- _ O
analysis -X- _ O
, -X- _ O
and -X- _ O
then -X- _ O
elaborate -X- _ O
the -X- _ O
adaptation -X- _ O
. -X- _ O

Representational -X- _ O
Similarity -X- _ O
Analysis -X- _ O
is -X- _ O
widely -X- _ O
applied -X- _ O
in -X- _ O
cognitive -X- _ O
neuroscience -X- _ O
, -X- _ O
which -X- _ O
can -X- _ O
not -X- _ O
only -X- _ O
realize -X- _ O
cross -X- _ O
- -X- _ O
modal -X- _ O
cognitive -X- _ O
data -X- _ O
comparison -X- _ O
but -X- _ O
also -X- _ O
quantitatively -X- _ O
relate -X- _ O
brain -X- _ O
activity -X- _ O
measurements -X- _ O
to -X- _ O
computational -X- _ O
models -X- _ O
. -X- _ O
It -X- _ O
first -X- _ O
calculates -X- _ O
a -X- _ O
representation -X- _ O
dissimilarity -X- _ O
matrix -X- _ O
( -X- _ O
RDM -X- _ O
) -X- _ O
of -X- _ O
different -X- _ O
modal -X- _ O
data -X- _ O
, -X- _ O
and -X- _ O
then -X- _ O
estimates -X- _ O
the -X- _ O
correlation -X- _ O
between -X- _ O
RDMs -X- _ O
. -X- _ O
In -X- _ O
this -X- _ O
way -X- _ O
, -X- _ O
it -X- _ O
successfully -X- _ O
captures -X- _ O
cross -X- _ O
- -X- _ O
modal -X- _ O
data -X- _ O
relationships -X- _ O
( -X- _ O
Kriegeskorte -X- _ O
et -X- _ O
al -X- _ O
. -X- _ O
, -X- _ O
2008 -X- _ O
) -X- _ O
. -X- _ O
RSA -X- _ O
can -X- _ O
be -X- _ O
also -X- _ O
applied -X- _ O
for -X- _ O
the -X- _ O
comparison -X- _ O
between -X- _ O
computational -X- _ O
models -X- _ O
and -X- _ O
cognitive -X- _ O
data -X- _ O
. -X- _ O
The -X- _ O
RDM -X- _ O
of -X- _ O
a -X- _ O
computational -X- _ O
model -X- _ O
is -X- _ O
obtained -X- _ O
by -X- _ O
comparing -X- _ O
the -X- _ O
dissimilarity -X- _ O
of -X- _ O
data -X- _ O
representations -X- _ O
obtained -X- _ O
from -X- _ O
the -X- _ O
computational -X- _ O
model -X- _ O
in -X- _ O
pairs -X- _ O
. -X- _ O
It -X- _ O
is -X- _ O
then -X- _ O
compared -X- _ O
with -X- _ O
the -X- _ O
RDM -X- _ O
of -X- _ O
brain -X- _ O
activity -X- _ O
measurements -X- _ O
. -X- _ O
5 -X- _ O
We -X- _ O
take -X- _ O
all -X- _ O
sentence -X- _ O
representations -X- _ O
R -X- _ O
i -X- _ O
generated -X- _ O
by -X- _ O
a -X- _ O
task -X- _ O
- -X- _ O
specific -X- _ O
model -X- _ O
PLM -X- _ O
FT -X- _ O
i -X- _ O
( -X- _ O
a -X- _ O
pretrained -X- _ O
language -X- _ O
model -X- _ O
( -X- _ O
either -X- _ O
BERT -X- _ O
or -X- _ O
TinyBERT -X- _ O
) -X- _ O
finetuned -X- _ O
on -X- _ O
the -X- _ O
ith -X- _ O
task -X- _ O
) -X- _ O
as -X- _ O
the -X- _ O
base -X- _ O
to -X- _ O
simulate -X- _ O
cognitive -X- _ O
representations -X- _ O
required -X- _ O
by -X- _ O
RSA -X- _ O
. -X- _ O
For -X- _ O
each -X- _ O
pair -X- _ O
of -X- _ O
sentence -X- _ O
representations -X- _ O
( -X- _ O
R -X- _ O
ij -X- _ O
, -X- _ O
R -X- _ O
ij -X- _ O
′ -X- _ O
) -X- _ O
for -X- _ O
the -X- _ O
jth -X- _ O
and -X- _ O
j -X- _ O
′ -X- _ O
th -X- _ O
sentence -X- _ O
of -X- _ O
the -X- _ O
ith -X- _ O
task -X- _ O
, -X- _ O
we -X- _ O
compute -X- _ O
a -X- _ O
dissimilarity -X- _ O
score -X- _ O
in -X- _ O
three -X- _ O
metrics -X- _ O
( -X- _ O
e -X- _ O
) -X- _ O
: -X- _ O
Euclidean -X- _ O
distance -X- _ O
( -X- _ O
euclidean -X- _ O
) -X- _ O
, -X- _ O
Canberra -X- _ O
distance -X- _ O
( -X- _ O
canberra -X- _ O
) -X- _ O
and -X- _ O
Pearson -X- _ O
correlation -X- _ O
coefficient -X- _ O
( -X- _ O
ρ -X- _ O
) -X- _ O
. -X- _ O
Among -X- _ O
them -X- _ O
, -X- _ O
the -X- _ O
first -X- _ O
two -X- _ O
distance -X- _ O
metrics -X- _ O
can -X- _ O
naturally -X- _ O
represent -X- _ O
dissimilarity -X- _ O
( -X- _ O
Dis -X- _ O
) -X- _ O
, -X- _ O
while -X- _ O
the -X- _ O
last -X- _ O
ρ -X- _ O
needs -X- _ O
to -X- _ O
be -X- _ O
converted -X- _ O
to -X- _ O
1 -X- _ O
− -X- _ O
ρ -X- _ O
to -X- _ O
indicate -X- _ O
dissimilarity -X- _ O
, -X- _ O
as -X- _ O
follows -X- _ O
: -X- _ O

Dis -X- _ O
i -X- _ O
jj -X- _ O
′ -X- _ O
= -X- _ O
e -X- _ O
( -X- _ O
R -X- _ O
ij -X- _ O
, -X- _ O
R -X- _ O
ij -X- _ O
′ -X- _ O
) -X- _ O
e -X- _ O
is -X- _ O
not -X- _ O
ρ -X- _ O
1 -X- _ O
− -X- _ O
e -X- _ O
( -X- _ O
R -X- _ O
ij -X- _ O
, -X- _ O
R -X- _ O
ij -X- _ O
′ -X- _ O
) -X- _ O
e -X- _ O
is -X- _ O
ρ -X- _ O
( -X- _ O
1 -X- _ O
) -X- _ O

RDM -X- _ O
for -X- _ O
the -X- _ O
ith -X- _ O
task -X- _ O
consists -X- _ O
of -X- _ O
the -X- _ O
dissimilarity -X- _ O
scores -X- _ O
of -X- _ O
all -X- _ O
sentence -X- _ O
pairs -X- _ O
. -X- _ O
We -X- _ O
formulate -X- _ O
it -X- _ O
as -X- _ O
follows -X- _ O
: -X- _ O

RDM -X- _ O
i -X- _ O
= -X- _ O
[ -X- _ O
Dis -X- _ O
i -X- _ O
12 -X- _ O
, -X- _ O
Dis -X- _ O
i -X- _ O
13 -X- _ O
, -X- _ O
. -X- _ O
. -X- _ O
. -X- _ O
, -X- _ O
Dis -X- _ O
i -X- _ O
1n -X- _ O
, -X- _ O
. -X- _ O
. -X- _ O
. -X- _ O
Dis -X- _ O
i -X- _ O
jj -X- _ O
′ -X- _ O
, -X- _ O
. -X- _ O
. -X- _ O
. -X- _ O
, -X- _ O
Dis -X- _ O
i -X- _ O
( -X- _ O
n−1 -X- _ O
) -X- _ O
n -X- _ O
] -X- _ O
, -X- _ O
j -X- _ O
̸ -X- _ O
= -X- _ O
j -X- _ O
′ -X- _ O
( -X- _ O
2 -X- _ O
) -X- _ O

where -X- _ O
n -X- _ O
is -X- _ O
the -X- _ O
number -X- _ O
of -X- _ O
sentences -X- _ O
. -X- _ O
RDMs -X- _ O
computed -X- _ O
in -X- _ O
this -X- _ O
way -X- _ O
are -X- _ O
then -X- _ O
used -X- _ O
for -X- _ O
estimating -X- _ O
similarity -X- _ O
between -X- _ O
NLP -X- _ O
tasks -X- _ O
. -X- _ O
The -X- _ O
pairwise -X- _ O
similarity -X- _ O
Sim -X- _ O
ii -X- _ O
′ -X- _ O
of -X- _ O
the -X- _ O
ith -X- _ O
and -X- _ O
i -X- _ O
′ -X- _ O
th -X- _ O
task -X- _ O
is -X- _ O
computed -X- _ O
as -X- _ O
follows -X- _ O
: -X- _ O

Sim -X- _ O
ii -X- _ O
′ -X- _ O
= -X- _ O
Similarity -X- _ O
( -X- _ O
RDM -X- _ O
⊺ -X- _ O
i -X- _ O
• -X- _ O
RDM -X- _ O
i -X- _ O
′ -X- _ O
) -X- _ O

( -X- _ O
3 -X- _ O
) -X- _ O
Similarity -X- _ O
( -X- _ O
• -X- _ O
) -X- _ O
is -X- _ O
a -X- _ O
similarity -X- _ O
function -X- _ O
, -X- _ O
which -X- _ O
can -X- _ O
be -X- _ O
Spearman -X- _ O
rank -X- _ O
correlation -X- _ O
( -X- _ O
r -X- _ O
s -X- _ O
) -X- _ O
, -X- _ O
ρ -X- _ O
and -X- _ O
cosine -X- _ O
( -X- _ O
cos -X- _ O
, -X- _ O
by -X- _ O
default -X- _ O
) -X- _ O
. -X- _ O

In -X- _ O
summary -X- _ O
, -X- _ O
we -X- _ O
calculate -X- _ O
the -X- _ O
similarity -X- _ O
between -X- _ O
each -X- _ O
RDM -X- _ O
pair -X- _ O
and -X- _ O
finally -X- _ O
obtain -X- _ O
a -X- _ O
similarity -X- _ O
matrix -X- _ O
for -X- _ O
a -X- _ O
set -X- _ O
of -X- _ O
tasks -X- _ O
, -X- _ O
as -X- _ O
shown -X- _ O
in -X- _ O
Figure -X- _ O
2 -X- _ O
. -X- _ O

Cognitive -X- _ B-MethodName
- -X- _ I-MethodName
Neural -X- _ I-MethodName
Mapping -X- _ I-MethodName

The -X- _ O
idea -X- _ O
behind -X- _ O
cognitive -X- _ O
- -X- _ O
neural -X- _ O
mapping -X- _ O
is -X- _ O
to -X- _ O
project -X- _ O
sentence -X- _ O
representations -X- _ O
of -X- _ O
NLP -X- _ O
models -X- _ O
fine -X- _ O
- -X- _ O
tuned -X- _ O
in -X- _ O
a -X- _ O
specific -X- _ O
task -X- _ O
to -X- _ O
cognitive -X- _ O
signals -X- _ O
( -X- _ O
i.e. -X- _ O
, -X- _ O
fMRI -X- _ O
voxels -X- _ O
in -X- _ O
this -X- _ O
paper -X- _ O
) -X- _ O
recorded -X- _ O
when -X- _ O
humans -X- _ O
read -X- _ O
those -X- _ O
sentences -X- _ O
with -X- _ O
a -X- _ O
neural -X- _ O
network -X- _ O
. -X- _ O
The -X- _ O
connections -X- _ O
between -X- _ O
the -X- _ O
specific -X- _ O
task -X- _ O
and -X- _ O
cognitive -X- _ O
signals -X- _ O
learned -X- _ O
in -X- _ O
this -X- _ O
way -X- _ O
could -X- _ O
be -X- _ O
transformed -X- _ O
into -X- _ O
cognitively -X- _ O
inspired -X- _ O
task -X- _ O
representations -X- _ O
for -X- _ O
further -X- _ O
task -X- _ O
similarity -X- _ O
estimation -X- _ O
. -X- _ O
The -X- _ O
mapping -X- _ O
can -X- _ O
be -X- _ O
considered -X- _ O
as -X- _ O
a -X- _ O
way -X- _ O
to -X- _ O
isolate -X- _ O
brain -X- _ O
activity -X- _ O
related -X- _ O
to -X- _ O
the -X- _ O
specific -X- _ O
task -X- _ O
from -X- _ O
fMRI -X- _ O
cognitive -X- _ O
signals -X- _ O
. -X- _ O
Particularly -X- _ O
, -X- _ O
for -X- _ O
the -X- _ O
ith -X- _ O
task -X- _ O
and -X- _ O
sth -X- _ O
subject -X- _ O
, -X- _ O
we -X- _ O
use -X- _ O
a -X- _ O
fully -X- _ O
connected -X- _ O
3 -X- _ O
- -X- _ O
layer -X- _ O
feed -X- _ O
- -X- _ O
forward -X- _ O
neural -X- _ O
network -X- _ O
to -X- _ O
project -X- _ O
sentence -X- _ O
representation -X- _ O
R -X- _ O
ij -X- _ O
specific -X- _ O
to -X- _ O
this -X- _ O
task -X- _ O
to -X- _ O
fMRI -X- _ O
y -X- _ O
is -X- _ O
j -X- _ O
of -X- _ O
the -X- _ O
sth -X- _ O
subject -X- _ O
reading -X- _ O
the -X- _ O
jth -X- _ O
sentence -X- _ O
as -X- _ O
follows -X- _ O
: -X- _ O

y -X- _ O
is -X- _ O
j -X- _ O
= -X- _ O
W -X- _ O
i -X- _ O
2 -X- _ O
( -X- _ O
ReLU -X- _ O
( -X- _ O
W -X- _ O
i -X- _ O
1 -X- _ O
( -X- _ O
R -X- _ O
ij -X- _ O
) -X- _ O
) -X- _ O
( -X- _ O
4 -X- _ O
) -X- _ O

To -X- _ O
optimize -X- _ O
the -X- _ O
mapping -X- _ O
model -X- _ O
, -X- _ O
we -X- _ O
use -X- _ O
the -X- _ O
mean -X- _ O
squared -X- _ O
error -X- _ O
( -X- _ O
MSE -X- _ O
) -X- _ O
as -X- _ O
loss -X- _ O
function -X- _ O
. -X- _ O
5 -X- _ O
- -X- _ O
fold -X- _ O
cross -X- _ O
- -X- _ O
validation -X- _ O
is -X- _ O
performed -X- _ O
for -X- _ O
each -X- _ O
mapping -X- _ O
model -X- _ O
. -X- _ O
Before -X- _ O
training -X- _ O
, -X- _ O
grid -X- _ O
search -X- _ O
is -X- _ O
conducted -X- _ O
, -X- _ O
and -X- _ O
the -X- _ O
optimal -X- _ O
number -X- _ O
of -X- _ O
hidden -X- _ O
layer -X- _ O
units -X- _ O
in -X- _ O
the -X- _ O
mapping -X- _ O
network -X- _ O
is -X- _ O
obtained -X- _ O
by -X- _ O
three -X- _ O
times -X- _ O
of -X- _ O
cross -X- _ O
- -X- _ O
validation -X- _ O
on -X- _ O
the -X- _ O
verification -X- _ O
set -X- _ O
accounting -X- _ O
for -X- _ O
20 -X- _ O
% -X- _ O
training -X- _ O
data -X- _ O
. -X- _ O

Each -X- _ O
mapping -X- _ O
is -X- _ O
run -X- _ O
5 -X- _ O
times -X- _ O
. -X- _ O
We -X- _ O
average -X- _ O
models -X- _ O
over -X- _ O
all -X- _ O
subjects -X- _ O
and -X- _ O
5 -X- _ O
runs -X- _ O
and -X- _ O
then -X- _ O
evaluate -X- _ O
mapping -X- _ O
model -X- _ O
performance -X- _ O
in -X- _ O
all -X- _ O
voxels -X- _ O
. -X- _ O
Particularly -X- _ O
, -X- _ O
we -X- _ O
compute -X- _ O
the -X- _ O
cognitively -X- _ O
inspired -X- _ O
task -X- _ O
representation -X- _ O
CogR -X- _ O
i -X- _ O
for -X- _ O
the -X- _ O
ith -X- _ O
task -X- _ O
, -X- _ O
which -X- _ O
consists -X- _ O
of -X- _ O
the -X- _ O
correlation -X- _ O
coefficients -X- _ O
on -X- _ O
all -X- _ O
voxels -X- _ O
between -X- _ O
predicted -X- _ O
values -X- _ O
and -X- _ O
ground -X- _ O
- -X- _ O
truth -X- _ O
values -X- _ O
, -X- _ O
defined -X- _ O
as -X- _ O
follows -X- _ O
: -X- _ O

CogR -X- _ O

i -X- _ O
= -X- _ O
[ -X- _ O
c -X- _ O
( -X- _ O
ŷ -X- _ O
i -X- _ O
0 -X- _ O
, -X- _ O
y -X- _ O
0 -X- _ O
) -X- _ O
, -X- _ O
. -X- _ O
. -X- _ O
. -X- _ O
, -X- _ O
c -X- _ O
( -X- _ O
ŷ -X- _ O
i -X- _ O
k -X- _ O
, -X- _ O
y -X- _ O
k -X- _ O
) -X- _ O
, -X- _ O
. -X- _ O
. -X- _ O
. -X- _ O
, -X- _ O
c -X- _ O
( -X- _ O
ŷ -X- _ O
i -X- _ O
v -X- _ O
, -X- _ O
y -X- _ O
v -X- _ O
) -X- _ O
] -X- _ O
, -X- _ O
0 -X- _ O
≤ -X- _ O
k -X- _ O
≤ -X- _ O
v -X- _ O
( -X- _ O
5 -X- _ O
) -X- _ O

whereŷ -X- _ O
i -X- _ O
k -X- _ O
is -X- _ O
a -X- _ O
vector -X- _ O
of -X- _ O
all -X- _ O
predicted -X- _ O
values -X- _ O
for -X- _ O
the -X- _ O
kth -X- _ O
voxel -X- _ O
from -X- _ O
all -X- _ O
input -X- _ O
sentences -X- _ O
by -X- _ O
the -X- _ O
mapping -X- _ O
model -X- _ O
tuned -X- _ O
for -X- _ O
the -X- _ O
ith -X- _ O
task -X- _ O
, -X- _ O
y -X- _ O
k -X- _ O
is -X- _ O
a -X- _ O
vector -X- _ O
of -X- _ O
the -X- _ O
ground -X- _ O
- -X- _ O
truth -X- _ O
values -X- _ O
for -X- _ O
the -X- _ O
kth -X- _ O
voxel -X- _ O
from -X- _ O
all -X- _ O
sentence -X- _ O
- -X- _ O
level -X- _ O
signals -X- _ O
of -X- _ O
text -X- _ O
stimuli -X- _ O
in -X- _ O
fMRI -X- _ O
data -X- _ O
, -X- _ O
v -X- _ O
is -X- _ O
the -X- _ O
number -X- _ O
of -X- _ O
voxels -X- _ O
used -X- _ O
, -X- _ O
and -X- _ O
c -X- _ O
( -X- _ O
• -X- _ O
) -X- _ O
is -X- _ O
a -X- _ O
function -X- _ O
for -X- _ O
comparing -X- _ O
two -X- _ O
input -X- _ O
vectors -X- _ O
. -X- _ O
We -X- _ O
instantiate -X- _ O
c -X- _ O
in -X- _ O
two -X- _ O
functions -X- _ O
: -X- _ O
the -X- _ O
coefficient -X- _ O
of -X- _ O
determination -X- _ O
( -X- _ O
R -X- _ O
2 -X- _ O
) -X- _ O
and -X- _ O
ρ -X- _ O
. -X- _ O
6 -X- _ O
We -X- _ O
then -X- _ O
use -X- _ O
cosine -X- _ O
similarity -X- _ O
to -X- _ O
calculate -X- _ O
pairwise -X- _ O
task -X- _ O
similarity -X- _ O
as -X- _ O
follows -X- _ O
: -X- _ O

Sim -X- _ O
ii -X- _ O
′ -X- _ O
= -X- _ O
cos -X- _ O
( -X- _ O
CogR -X- _ O
⊺ -X- _ O
i -X- _ O
• -X- _ O
CogR -X- _ O
i -X- _ O
′ -X- _ O
) -X- _ O
( -X- _ O
6 -X- _ O
) -X- _ O

Experiments -X- _ O

We -X- _ O
conducted -X- _ O
experiments -X- _ O
with -X- _ O
widely -X- _ O
- -X- _ O
used -X- _ O
NLP -X- _ O
benchmark -X- _ O
datasets -X- _ O
and -X- _ O
cognitive -X- _ O
data -X- _ O
to -X- _ O
evaluate -X- _ O
the -X- _ O
effectiveness -X- _ O
of -X- _ O
CogTaskonomy -X- _ B-MethodName
. -X- _ O

Cognitive -X- _ O
Dataset -X- _ O

The -X- _ O
brain -X- _ B-DatasetName
fMRI -X- _ I-DatasetName
dataset -X- _ O
in -X- _ O
our -X- _ O
experiments -X- _ O
is -X- _ O
from -X- _ O
Pereira -X- _ O
et -X- _ O
al -X- _ O
. -X- _ O
( -X- _ O
2018 -X- _ O
) -X- _ O
, -X- _ O
which -X- _ O
is -X- _ O
recorded -X- _ O
on -X- _ O
a -X- _ O
wholebody -X- _ O
3 -X- _ O
- -X- _ O
Tesla -X- _ O
Siemens -X- _ O
Trio -X- _ O
scanner -X- _ O
with -X- _ O
a -X- _ O
32channel -X- _ O
head -X- _ O
coil -X- _ O
by -X- _ O
showing -X- _ O
627 -X- _ O
natural -X- _ O
language -X- _ O
sentences -X- _ O
to -X- _ O
5 -X- _ O
adult -X- _ O
subjects -X- _ O
. -X- _ O
7 -X- _ O
Since -X- _ O
voxels -X- _ O
were -X- _ O
randomly -X- _ O
selected -X- _ O
, -X- _ O
Z -X- _ O
- -X- _ O
Score -X- _ O
standardization -X- _ O
was -X- _ O
carried -X- _ O
out -X- _ O
for -X- _ O
voxels -X- _ O
obtained -X- _ O
from -X- _ O
different -X- _ O
stimuli -X- _ O
at -X- _ O
each -X- _ O
location -X- _ O
on -X- _ O
the -X- _ O
basis -X- _ O
of -X- _ O
the -X- _ O
original -X- _ O
data -X- _ O
set -X- _ O
to -X- _ O
avoid -X- _ O
the -X- _ O
influence -X- _ O
of -X- _ O
outliers -X- _ O
. -X- _ O
Subjects -X- _ O
are -X- _ O
asked -X- _ O
to -X- _ O
read -X- _ O
each -X- _ O
encyclopedic -X- _ O
statement -X- _ O
carefully -X- _ O
, -X- _ O
while -X- _ O
the -X- _ O
fMRI -X- _ O
scanner -X- _ O
records -X- _ O
brain -X- _ O
signals -X- _ O
at -X- _ O
this -X- _ O
point -X- _ O
. -X- _ O
As -X- _ O
a -X- _ O
result -X- _ O
, -X- _ O
each -X- _ O
fMRI -X- _ O
scan -X- _ O
covers -X- _ O
multiple -X- _ O
words -X- _ O
at -X- _ O
a -X- _ O
time -X- _ O
, -X- _ O
subject -X- _ O
to -X- _ O
continuous -X- _ O
stimulation -X- _ O
. -X- _ O
Each -X- _ O
fMRI -X- _ O
recording -X- _ O
contains -X- _ O
a -X- _ O
number -X- _ O
of -X- _ O
voxels -X- _ O
. -X- _ O
We -X- _ O
flattened -X- _ O
3d -X- _ O
fMRI -X- _ O
images -X- _ O
into -X- _ O
1d -X- _ O
vectors -X- _ O
. -X- _ O
v -X- _ O
voxels -X- _ O
were -X- _ O
randomly -X- _ O
selected -X- _ O
, -X- _ O
yielding -X- _ O
matrices -X- _ O
I -X- _ O
s -X- _ O
∈ -X- _ O
R -X- _ O
627×v -X- _ O
for -X- _ O
each -X- _ O
subject -X- _ O
s -X- _ O
. -X- _ O

Tasks -X- _ O

We -X- _ O
selected -X- _ O
8 -X- _ O
NLP -X- _ O
tasks -X- _ O
from -X- _ O
the -X- _ O
GLUE -X- _ O
benchmark -X- _ O
, -X- _ O
including -X- _ O
CoLA -X- _ B-TaskName
, -X- _ O
MNLI -X- _ B-TaskName
, -X- _ O
MRPC -X- _ B-TaskName
, -X- _ O
QNLI -X- _ B-TaskName
, -X- _ O
QQP -X- _ B-TaskName
, -X- _ O
RTE -X- _ B-TaskName
, -X- _ O
SST-2 -X- _ B-TaskName
, -X- _ O
STS -X- _ B-TaskName
- -X- _ I-TaskName
B. -X- _ I-TaskName
These -X- _ O
tasks -X- _ O
are -X- _ O
considered -X- _ O
important -X- _ O
for -X- _ O
generalizable -X- _ O
natural -X- _ O
language -X- _ O
understanding -X- _ O
, -X- _ O
exhibiting -X- _ O
diversity -X- _ O
in -X- _ O
domains -X- _ O
, -X- _ O
dataset -X- _ O
sizes -X- _ O
, -X- _ O
and -X- _ O
difficulties -X- _ O
. -X- _ O
To -X- _ O
cover -X- _ O
the -X- _ O
spectrum -X- _ O
of -X- _ O
NLP -X- _ O
tasks -X- _ O
as -X- _ O
much -X- _ O
as -X- _ O
possible -X- _ O
, -X- _ O
we -X- _ O
also -X- _ O
included -X- _ O
Extractive -X- _ B-TaskName
Question -X- _ I-TaskName
Answering -X- _ I-TaskName
( -X- _ O
QA -X- _ B-TaskName
) -X- _ O
, -X- _ O
Relation -X- _ B-TaskName
Extraction -X- _ I-TaskName
( -X- _ O
RE -X- _ B-TaskName
) -X- _ O
, -X- _ O
Named -X- _ B-TaskName
Entity -X- _ I-TaskName
Recognition -X- _ I-TaskName
( -X- _ O
NER -X- _ B-TaskName
) -X- _ O
, -X- _ O
and -X- _ O
Passage -X- _ B-TaskName
Reranking -X- _ I-TaskName
( -X- _ O
PR -X- _ B-TaskName
) -X- _ O
. -X- _ O
The -X- _ O
datasets -X- _ O
of -X- _ O
these -X- _ O
four -X- _ O
tasks -X- _ O
are -X- _ O
SQuAD -X- _ B-DatasetName
2.0 -X- _ I-DatasetName
( -X- _ O
Rajpurkar -X- _ O
et -X- _ O
al -X- _ O
. -X- _ O
, -X- _ O
2018 -X- _ O
) -X- _ O
, -X- _ O
Semeval-2010 -X- _ B-DatasetName
task -X- _ I-DatasetName
8 -X- _ I-DatasetName
( -X- _ O
Hendrickx -X- _ O
et -X- _ O
al -X- _ O
. -X- _ O
, -X- _ O
2010 -X- _ O
) -X- _ O
, -X- _ O
CoNLL -X- _ B-DatasetName
2003 -X- _ I-DatasetName
( -X- _ I-DatasetName
Sang -X- _ O
and -X- _ O
Meulder -X- _ O
, -X- _ O
2003 -X- _ O
, -X- _ O
MS -X- _ B-DatasetName
MARCO -X- _ I-DatasetName
( -X- _ O
Nguyen -X- _ O
et -X- _ O
al -X- _ O
. -X- _ O
, -X- _ O
2016 -X- _ O
; -X- _ O
Craswell -X- _ O
et -X- _ O
al -X- _ O
. -X- _ O
, -X- _ O
2020 -X- _ O
) -X- _ O
, -X- _ O
respectively -X- _ O
. -X- _ O

Baselines -X- _ O
and -X- _ O
Settings -X- _ O

We -X- _ O
mainly -X- _ O
used -X- _ O
two -X- _ O
methods -X- _ O
as -X- _ O
our -X- _ O
baselines -X- _ O
, -X- _ O
including -X- _ O
Direct -X- _ B-MethodName
Similarity -X- _ I-MethodName
Estimation -X- _ I-MethodName
( -X- _ O
DSE -X- _ B-MethodName
) -X- _ O
, -X- _ O
Analytic -X- _ B-MethodName
Hierarchy -X- _ I-MethodName
Process -X- _ I-MethodName
( -X- _ O
AHP -X- _ B-MethodName
) -X- _ O
( -X- _ O
Zamir -X- _ O
et -X- _ O
al -X- _ O
. -X- _ O
, -X- _ O
2018 -X- _ O
) -X- _ O
. -X- _ O
Detailed -X- _ O
experimental -X- _ O
settings -X- _ O
are -X- _ O
shown -X- _ O
in -X- _ O
Appendix -X- _ O
A.2 -X- _ O
. -X- _ O

Direct -X- _ B-MethodName
Similarity -X- _ I-MethodName
Estimation -X- _ I-MethodName
( -X- _ O
DSE -X- _ B-MethodName
) -X- _ O

A -X- _ O
straightforward -X- _ O
way -X- _ O
to -X- _ O
estimate -X- _ O
pairwise -X- _ O
task -X- _ O
similarity -X- _ O
is -X- _ O
to -X- _ O
calculate -X- _ O
sentence -X- _ O
- -X- _ O
level -X- _ O
similarities -X- _ O
based -X- _ O
on -X- _ O
task -X- _ O
- -X- _ O
specific -X- _ O
sentence -X- _ O
representations -X- _ O
and -X- _ O
then -X- _ O
average -X- _ O
them -X- _ O
. -X- _ O
Concretely -X- _ O
, -X- _ O
let -X- _ O
R -X- _ O
ij -X- _ O
be -X- _ O
the -X- _ O
task -X- _ O
- -X- _ O
specific -X- _ O
representation -X- _ O
for -X- _ O
the -X- _ O
jth -X- _ O
sentence -X- _ O
in -X- _ O
the -X- _ O
ith -X- _ O
task -X- _ O
. -X- _ O

The -X- _ O
task -X- _ O
similarity -X- _ O
Sim -X- _ O
ii -X- _ O
′ -X- _ O
for -X- _ O
a -X- _ O
task -X- _ O
pair -X- _ O
( -X- _ O
i -X- _ O
, -X- _ O
i -X- _ O
′ -X- _ O
) -X- _ O
is -X- _ O
computed -X- _ O
as -X- _ O
follows -X- _ O
: -X- _ O

R -X- _ O
ij -X- _ O
= -X- _ O
PLM -X- _ O
FT -X- _ O
i -X- _ O
( -X- _ O
x -X- _ O
j -X- _ O
) -X- _ O
( -X- _ O
7 -X- _ O

) -X- _ O

Sim -X- _ O
ii -X- _ O
′ -X- _ O
= -X- _ O
j -X- _ O
Similarity -X- _ O
( -X- _ O
R -X- _ O
⊺ -X- _ O
ij -X- _ O
• -X- _ O
R -X- _ O
i -X- _ O
′ -X- _ O
j -X- _ O
) -X- _ O
n -X- _ O
( -X- _ O
8 -X- _ O

) -X- _ O

ipated -X- _ O
in -X- _ O
experiments -X- _ O
2 -X- _ O
and -X- _ O
3 -X- _ O
were -X- _ O
chosen -X- _ O
in -X- _ O
this -X- _ O
paper -X- _ O
. -X- _ O

where -X- _ O
PLM -X- _ O
FT -X- _ O
i -X- _ O
is -X- _ O
the -X- _ O
pretrained -X- _ O
language -X- _ O
model -X- _ O
fine -X- _ O
- -X- _ O
tuned -X- _ O
on -X- _ O
the -X- _ O
ith -X- _ O
task -X- _ O
. -X- _ O
PLM -X- _ O
can -X- _ O
be -X- _ O
instantiated -X- _ O
as -X- _ O
TinyBERT -X- _ O
or -X- _ O
BERT -X- _ O
. -X- _ O

Analytic -X- _ B-MethodName
Hierarchy -X- _ I-MethodName
Process -X- _ I-MethodName
( -X- _ O
AHP -X- _ B-MethodName
) -X- _ O

The -X- _ O
main -X- _ O
idea -X- _ O
is -X- _ O
to -X- _ O
construct -X- _ O
a -X- _ O
matrix -X- _ O
W -X- _ O
t -X- _ O
for -X- _ O
each -X- _ O
target -X- _ O
task -X- _ O
t -X- _ O
, -X- _ O
where -X- _ O
the -X- _ O
element -X- _ O
at -X- _ O
( -X- _ O
i -X- _ O
, -X- _ O
i -X- _ O
′ -X- _ O
) -X- _ O
in -X- _ O
the -X- _ O
matrix -X- _ O
shows -X- _ O
how -X- _ O
many -X- _ O
times -X- _ O
the -X- _ O
ith -X- _ O
source -X- _ O
task -X- _ O
is -X- _ O
better -X- _ O
than -X- _ O
i -X- _ O
′ -X- _ O
th -X- _ O
source -X- _ O
task -X- _ O
in -X- _ O
terms -X- _ O
of -X- _ O
the -X- _ O
transferability -X- _ O
to -X- _ O
the -X- _ O
target -X- _ O
task -X- _ O
on -X- _ O
a -X- _ O
held -X- _ O
- -X- _ O
out -X- _ O
set -X- _ O
. -X- _ O
The -X- _ O
principal -X- _ O
eigenvector -X- _ O
of -X- _ O
W -X- _ O
t -X- _ O
is -X- _ O
then -X- _ O
taken -X- _ O
as -X- _ O
the -X- _ O
task -X- _ O
representation -X- _ O
for -X- _ O
the -X- _ O
corresponding -X- _ O
task -X- _ O
, -X- _ O
and -X- _ O
all -X- _ O
task -X- _ O
representations -X- _ O
are -X- _ O
stacked -X- _ O
up -X- _ O
to -X- _ O
obtain -X- _ O
an -X- _ O
affinity -X- _ O
matrix -X- _ O
. -X- _ O
8 -X- _ O
The -X- _ O
affinity -X- _ O
matrix -X- _ O
is -X- _ O
then -X- _ O
viewed -X- _ O
as -X- _ O
the -X- _ O
task -X- _ O
similarity -X- _ O
matrix -X- _ O
. -X- _ O

Evaluation -X- _ O
Metric -X- _ O

Task -X- _ O
Transferring -X- _ O
To -X- _ O
assess -X- _ O
the -X- _ O
similarity -X- _ O
between -X- _ O
tasks -X- _ O
, -X- _ O
all -X- _ O
models -X- _ O
fine -X- _ O
- -X- _ O
tuned -X- _ O
on -X- _ O
non -X- _ O
- -X- _ O
target -X- _ O
tasks -X- _ O
will -X- _ O
be -X- _ O
used -X- _ O
as -X- _ O
source -X- _ O
models -X- _ O
, -X- _ O
and -X- _ O
continue -X- _ O
to -X- _ O
be -X- _ O
fine -X- _ O
- -X- _ O
tuned -X- _ O
in -X- _ O
the -X- _ O
same -X- _ O
way -X- _ O
to -X- _ O
transfer -X- _ O
on -X- _ O
the -X- _ O
target -X- _ O
task -X- _ O
. -X- _ O
In -X- _ O
task -X- _ O
transferring -X- _ O
, -X- _ O
all -X- _ O
parameters -X- _ O
of -X- _ O
source -X- _ O
models -X- _ O
are -X- _ O
fine -X- _ O
- -X- _ O
tuned -X- _ O
( -X- _ O
i.e. -X- _ O
, -X- _ O
not -X- _ O
fixed -X- _ O
) -X- _ O
. -X- _ O
We -X- _ O
used -X- _ O
the -X- _ O
same -X- _ O
learning -X- _ O
rate -X- _ O
and -X- _ O
a -X- _ O
number -X- _ O
of -X- _ O
training -X- _ O
steps -X- _ O
for -X- _ O
all -X- _ O
task -X- _ O
transferring -X- _ O
. -X- _ O
This -X- _ O
allows -X- _ O
a -X- _ O
fair -X- _ O
comparison -X- _ O
between -X- _ O
different -X- _ O
source -X- _ O
tasks -X- _ O
. -X- _ O

Oracle -X- _ O
Task -X- _ O
Ranking -X- _ O
The -X- _ O
final -X- _ O
similarity -X- _ O
ranking -X- _ O
of -X- _ O
source -X- _ O
tasks -X- _ O
to -X- _ O
a -X- _ O
given -X- _ O
target -X- _ O
task -X- _ O
is -X- _ O
based -X- _ O
on -X- _ O
the -X- _ O
results -X- _ O
obtained -X- _ O
from -X- _ O
the -X- _ O
task -X- _ O
transferring -X- _ O
experiments -X- _ O
. -X- _ O
Generally -X- _ O
speaking -X- _ O
, -X- _ O
the -X- _ O
better -X- _ O
the -X- _ O
source -X- _ O
- -X- _ O
to -X- _ O
- -X- _ O
target -X- _ O
transfer -X- _ O
performance -X- _ O
is -X- _ O
, -X- _ O
the -X- _ O
more -X- _ O
similar -X- _ O
the -X- _ O
two -X- _ O
tasks -X- _ O
are -X- _ O
, -X- _ O
since -X- _ O
the -X- _ O
essence -X- _ O
of -X- _ O
TL -X- _ O
is -X- _ O
to -X- _ O
apply -X- _ O
knowledge -X- _ O
learned -X- _ O
in -X- _ O
the -X- _ O
source -X- _ O
task -X- _ O
to -X- _ O
the -X- _ O
target -X- _ O
task -X- _ O
. -X- _ O
Based -X- _ O
on -X- _ O
this -X- _ O
concept -X- _ O
, -X- _ O
we -X- _ O
rank -X- _ O
tasks -X- _ O
in -X- _ O
terms -X- _ O
of -X- _ O
transfer -X- _ O
learning -X- _ O
performance -X- _ O
, -X- _ O
for -X- _ O
more -X- _ O
details -X- _ O
please -X- _ O
see -X- _ O
Appendix -X- _ O
A.3 -X- _ O
. -X- _ O

Task -X- _ B-MetricName
Ranking -X- _ I-MetricName
Score -X- _ I-MetricName
Based -X- _ O
on -X- _ O
similarity -X- _ O
results -X- _ O
computed -X- _ O
by -X- _ O
each -X- _ O
task -X- _ O
estimation -X- _ O
method -X- _ O
, -X- _ O
we -X- _ O
can -X- _ O
obtain -X- _ O
the -X- _ O
most -X- _ O
similar -X- _ O
task -X- _ O
for -X- _ O
each -X- _ O
target -X- _ O
task -X- _ O
. -X- _ O
We -X- _ O
then -X- _ O
check -X- _ O
the -X- _ O
ranking -X- _ O
position -X- _ O
of -X- _ O
the -X- _ O
most -X- _ O
similar -X- _ O
task -X- _ O
in -X- _ O
the -X- _ O
oracle -X- _ O
task -X- _ O
ranking -X- _ O
. -X- _ O
We -X- _ O
average -X- _ O
ranking -X- _ O
positions -X- _ O
of -X- _ O
all -X- _ O
target -X- _ O
tasks -X- _ O
as -X- _ O
the -X- _ O
final -X- _ O
task -X- _ O
ranking -X- _ O
score -X- _ O
for -X- _ O
the -X- _ O
corresponding -X- _ O
task -X- _ O
estimation -X- _ O
method -X- _ O
. -X- _ O
Note -X- _ O
that -X- _ O
we -X- _ O
exclude -X- _ O
the -X- _ O
transfer -X- _ O
to -X- _ O
the -X- _ O
target -X- _ O
task -X- _ O
itself -X- _ O
in -X- _ O
computing -X- _ O
task -X- _ O
ranking -X- _ O
scores -X- _ O
. -X- _ O
9 -X- _ O

Method -X- _ O


Main -X- _ O
Results -X- _ O

Task -X- _ B-MetricName
ranking -X- _ I-MetricName
scores -X- _ I-MetricName
( -X- _ O
using -X- _ O
the -X- _ O
ranking -X- _ O
of -X- _ O
task -X- _ O
transferring -X- _ O
as -X- _ O
the -X- _ O
oracle -X- _ O
ranking -X- _ O
) -X- _ O
of -X- _ O
different -X- _ O
task -X- _ O
similarity -X- _ O
estimation -X- _ O
methods -X- _ O
are -X- _ O
shown -X- _ O
in -X- _ O
Table -X- _ O
1 -X- _ O
. -X- _ O

From -X- _ O
these -X- _ O
results -X- _ O
, -X- _ O
we -X- _ O
have -X- _ O
the -X- _ O
following -X- _ O
observations -X- _ O
: -X- _ O

• -X- _ O
Both -X- _ O
CRA -X- _ B-MethodName
and -X- _ O
CNM -X- _ B-MethodName
are -X- _ O
better -X- _ O
than -X- _ O
random -X- _ O
ranking -X- _ O
and -X- _ O
DSE -X- _ B-MethodName
, -X- _ O
suggesting -X- _ O
that -X- _ O
cognitively -X- _ O
inspired -X- _ O
task -X- _ O
similarity -X- _ O
estimation -X- _ O
is -X- _ O
able -X- _ O
to -X- _ O
capture -X- _ O
relations -X- _ O
of -X- _ O
NLP -X- _ O
tasks -X- _ O
. -X- _ O
• -X- _ O
When -X- _ O
TinyBERT -X- _ O
is -X- _ O
used -X- _ O
, -X- _ O
DSE -X- _ B-MethodName
is -X- _ O
even -X- _ O
worse -X- _ O
than -X- _ O
random -X- _ O
ranking -X- _ O
. -X- _ O
This -X- _ O
suggests -X- _ O
that -X- _ O
simply -X- _ O
using -X- _ O
task -X- _ O
- -X- _ O
specific -X- _ O
sentence -X- _ O
representations -X- _ O
can -X- _ O
not -X- _ O
well -X- _ O
detect -X- _ O
task -X- _ O
relations -X- _ O
and -X- _ O
distinguish -X- _ O
different -X- _ O
tasks -X- _ O
. -X- _ O
• -X- _ O
TinyBERT -X- _ O
performs -X- _ O
better -X- _ O
than -X- _ O
BERT -X- _ O
across -X- _ O
three -X- _ O
task -X- _ O
estimation -X- _ O
methods -X- _ O
( -X- _ O
i.e. -X- _ O
, -X- _ O
CRA -X- _ B-MethodName
, -X- _ O
CNM -X- _ B-MethodName
and -X- _ O
AHP -X- _ B-MethodName
) -X- _ O
although -X- _ O
the -X- _ O
number -X- _ O
of -X- _ O
parameters -X- _ O
in -X- _ O
the -X- _ O
former -X- _ O
is -X- _ O
only -X- _ O
half -X- _ O
of -X- _ O
that -X- _ O
in -X- _ O
the -X- _ O
latter -X- _ O
. -X- _ O
We -X- _ O
conjecture -X- _ O
that -X- _ O
TinyBERT -X- _ O
uses -X- _ O
knowledge -X- _ O
distillation -X- _ O
, -X- _ O
making -X- _ O
sentence -X- _ O
representations -X- _ O
more -X- _ O
relevant -X- _ O
to -X- _ O
individual -X- _ O
tasks -X- _ O
and -X- _ O
hence -X- _ O
resulting -X- _ O
in -X- _ O
better -X- _ O
task -X- _ O
similarity -X- _ O
estimation -X- _ O
. -X- _ O
• -X- _ O
We -X- _ O
can -X- _ O
also -X- _ O
combine -X- _ O
CRA -X- _ B-MethodName
and -X- _ O
CNM -X- _ B-MethodName
( -X- _ O
CRA+ -X- _ B-MethodName
CNM -X- _ B-MethodName
) -X- _ O
by -X- _ O
averaging -X- _ O
task -X- _ O
similarity -X- _ O
scores -X- _ O
estimated -X- _ O
by -X- _ O
them -X- _ O
. -X- _ O
Such -X- _ O
combination -X- _ O
is -X- _ O
better -X- _ O
than -X- _ O
both -X- _ O
methods -X- _ O
alone -X- _ O
. -X- _ O
Although -X- _ O
AHP -X- _ B-MethodName
is -X- _ O
better -X- _ O
than -X- _ O
our -X- _ O
methods -X- _ O
, -X- _ O
it -X- _ O
directly -X- _ O
uses -X- _ O
the -X- _ O
results -X- _ O
of -X- _ O
transfer -X- _ O
learning -X- _ O
to -X- _ O
measure -X- _ O
similarities -X- _ O
between -X- _ O
different -X- _ O
tasks -X- _ O
, -X- _ O
which -X- _ O
is -X- _ O
very -X- _ O
time -X- _ O
- -X- _ O
consuming -X- _ O
. -X- _ O
if -X- _ O
we -X- _ O
have -X- _ O
m -X- _ O
tasks -X- _ O
, -X- _ O
we -X- _ O
have -X- _ O
similarity -X- _ O
method -X- _ O
would -X- _ O
yield -X- _ O
a -X- _ O
task -X- _ B-MetricName
ranking -X- _ I-MetricName
score -X- _ I-MetricName
of -X- _ O
1 -X- _ B-MetricValue
on -X- _ O
each -X- _ O
target -X- _ O
task -X- _ O
. -X- _ O
A -X- _ O
random -X- _ O
method -X- _ O
would -X- _ O
yield -X- _ O
a -X- _ O
ranking -X- _ O
score -X- _ O
of -X- _ O
0.5 -X- _ O
( -X- _ O
1 -X- _ O
+ -X- _ O
11 -X- _ O
) -X- _ O
= -X- _ O
6 -X- _ B-MetricValue
in -X- _ O
our -X- _ O
experiments -X- _ O
theoretically -X- _ O
. -X- _ O
We -X- _ O
have -X- _ O
also -X- _ O
conducted -X- _ O
random -X- _ O
sampling -X- _ O
5000 -X- _ O
times -X- _ O
on -X- _ O
TinyBERT -X- _ O
and -X- _ O
BERT -X- _ O
, -X- _ O
and -X- _ O
obtained -X- _ O
mean -X- _ O
task -X- _ O
ranking -X- _ O
scores -X- _ O
of -X- _ O
6.05 -X- _ B-MetricValue
and -X- _ O
6.04 -X- _ B-MetricValue
respectively -X- _ O
. -X- _ O
Hence -X- _ O
, -X- _ O
we -X- _ O
take -X- _ O
the -X- _ O
6 -X- _ B-MetricValue
as -X- _ O
the -X- _ O
task -X- _ B-MetricName
ranking -X- _ I-MetricName
score -X- _ I-MetricName
for -X- _ O
random -X- _ O
ranking -X- _ O
. -X- _ O
to -X- _ O
perform -X- _ O
O -X- _ O
( -X- _ O
m -X- _ O
2 -X- _ O
) -X- _ O
transfer -X- _ O
learning -X- _ O
to -X- _ O
obtain -X- _ O
the -X- _ O
task -X- _ O
similarity -X- _ O
matrix -X- _ O
across -X- _ O
all -X- _ O
task -X- _ O
pairs -X- _ O
. -X- _ O
In -X- _ O
contrast -X- _ O
, -X- _ O
our -X- _ O
methods -X- _ O
do -X- _ O
not -X- _ O
require -X- _ O
any -X- _ O
costly -X- _ O
transfer -X- _ O
learning -X- _ O
between -X- _ O
tasks -X- _ O
. -X- _ O
It -X- _ O
is -X- _ O
hence -X- _ O
easier -X- _ O
to -X- _ O
perform -X- _ O
and -X- _ O
able -X- _ O
to -X- _ O
guide -X- _ O
transfer -X- _ O
learning -X- _ O
across -X- _ O
tasks -X- _ O
. -X- _ O
We -X- _ O
further -X- _ O
evaluated -X- _ O
the -X- _ O
actual -X- _ O
transfer -X- _ O
learning -X- _ O
performance -X- _ O
of -X- _ O
each -X- _ O
target -X- _ O
task -X- _ O
from -X- _ O
the -X- _ O
most -X- _ O
similar -X- _ O
source -X- _ O
task -X- _ O
according -X- _ O
to -X- _ O
different -X- _ O
task -X- _ O
similarity -X- _ O
estimation -X- _ O
methods -X- _ O
. -X- _ O
Results -X- _ O
are -X- _ O
shown -X- _ O
in -X- _ O
Appendix -X- _ O
A.4 -X- _ O
, -X- _ O
which -X- _ O
further -X- _ O
validate -X- _ O
the -X- _ O
effectiveness -X- _ O
of -X- _ O
our -X- _ O
methods -X- _ O
and -X- _ O
show -X- _ O
that -X- _ O
CRA+CNM -X- _ B-MethodName
is -X- _ O
very -X- _ O
close -X- _ O
to -X- _ O
that -X- _ O
of -X- _ O
AHP -X- _ B-MethodName
. -X- _ O
In -X- _ O
later -X- _ O
experiments -X- _ O
and -X- _ O
analyses -X- _ O
, -X- _ O
we -X- _ O
will -X- _ O
show -X- _ O
more -X- _ O
advantages -X- _ O
of -X- _ O
our -X- _ O
methods -X- _ O
over -X- _ O
AHP -X- _ B-MethodName
. -X- _ O

Evaluating -X- _ O
CRA -X- _ B-MethodName
with -X- _ O
Different -X- _ O
Dissimilarity -X- _ O
/ -X- _ O
Similarity -X- _ O
Measurement -X- _ O
Combinations -X- _ O

CRA -X- _ B-MethodName
adopts -X- _ O
RSA -X- _ O
to -X- _ O
transform -X- _ O
the -X- _ O
dissimilarity -X- _ O
of -X- _ O
task -X- _ O
- -X- _ O
specific -X- _ O
sentence -X- _ O
representations -X- _ O
into -X- _ O
the -X- _ O
similarity -X- _ O
of -X- _ O
tasks -X- _ O
. -X- _ O
We -X- _ O
have -X- _ O
different -X- _ O
options -X- _ O
for -X- _ O
dissimilarity -X- _ O
measurement -X- _ O
( -X- _ O
e.g. -X- _ O
, -X- _ O
euclidean -X- _ O
, -X- _ O
canberra -X- _ O
) -X- _ O
in -X- _ O
sentences -X- _ O
and -X- _ O
for -X- _ O
similarity -X- _ O
measurement -X- _ O
( -X- _ O
e.g. -X- _ O
, -X- _ O
cos -X- _ O
, -X- _ O
ρ -X- _ O
) -X- _ O
in -X- _ O
tasks -X- _ O
. -X- _ O
Hence -X- _ O
we -X- _ O
want -X- _ O
to -X- _ O
know -X- _ O
the -X- _ O
impact -X- _ O
of -X- _ O
the -X- _ O
combinations -X- _ O
of -X- _ O
different -X- _ O
measurements -X- _ O
in -X- _ O
sentence -X- _ O
dissimilarity -X- _ O
and -X- _ O
task -X- _ O
similarity -X- _ O
on -X- _ O
final -X- _ O
performance -X- _ O
. -X- _ O
Results -X- _ O
are -X- _ O
provided -X- _ O
in -X- _ O
Table -X- _ O
2 -X- _ O
. -X- _ O
Again -X- _ O
, -X- _ O
we -X- _ O
have -X- _ O
several -X- _ O
interesting -X- _ O
observations -X- _ O
. -X- _ O
First -X- _ O
, -X- _ O
with -X- _ O
different -X- _ O
combinations -X- _ O
of -X- _ O
these -X- _ O
measurements -X- _ O
, -X- _ O
our -X- _ O
CRA -X- _ B-MethodName
significantly -X- _ O
outperforms -X- _ O
random -X- _ O
ranking -X- _ O
in -X- _ O
almost -X- _ O
all -X- _ O
cases -X- _ O
. -X- _ O
This -X- _ O
suggests -X- _ O
that -X- _ O
RSA -X- _ O
is -X- _ O
able -X- _ O
to -X- _ O
be -X- _ O
adapted -X- _ O
to -X- _ O
NLP -X- _ O
task -X- _ O
structure -X- _ O
detection -X- _ O
. -X- _ O
Second -X- _ O
, -X- _ O
in -X- _ O
comparison -X- _ O
to -X- _ O
the -X- _ O
combination -X- _ O
of -X- _ O
ρ -X- _ O
and -X- _ O
r -X- _ O
s -X- _ O
in -X- _ O
the -X- _ O
original -X- _ O
RSA -X- _ O
( -X- _ O
Kriegeskorte -X- _ O
et -X- _ O
al -X- _ O
. -X- _ O
, -X- _ O
2008 -X- _ O
) -X- _ O
, -X- _ O
in -X- _ O
our -X- _ O
case -X- _ O
, -X- _ O
the -X- _ O
combination -X- _ O
of -X- _ O
ρ -X- _ O
and -X- _ O
cos -X- _ O
is -X- _ O
better -X- _ O
than -X- _ O
other -X- _ O
combinations -X- _ O
in -X- _ O
the -X- _ O
majority -X- _ O
of -X- _ O
cases -X- _ O
. -X- _ O
Third -X- _ O
, -X- _ O
TinyBERT -X- _ O
is -X- _ O
more -X- _ O
robust -X- _ O
to -X- _ O
these -X- _ O
different -X- _ O
combinations -X- _ O
than -X- _ O
BERT -X- _ O
. -X- _ O

Evaluating -X- _ O
CNM -X- _ B-MethodName
with -X- _ O
Different -X- _ O
PLMs -X- _ O
and -X- _ O
Numbers -X- _ O
of -X- _ O
Voxels -X- _ O

Since -X- _ O
CNM -X- _ B-MethodName
bridges -X- _ O
pretrained -X- _ O
language -X- _ O
models -X- _ O
on -X- _ O
the -X- _ O
input -X- _ O
side -X- _ O
and -X- _ O
voxels -X- _ O
in -X- _ O
fMRI -X- _ O
images -X- _ O
on -X- _ O
the -X- _ O
output -X- _ O
side -X- _ O
, -X- _ O
we -X- _ O
further -X- _ O
evaluated -X- _ O
CNM -X- _ B-MethodName
by -X- _ O
varying -X- _ O
the -X- _ O
selection -X- _ O
of -X- _ O
PLMs -X- _ O
( -X- _ O
either -X- _ O
BERT -X- _ O
or -X- _ O
TinyBERT -X- _ O
) -X- _ O
and -X- _ O
the -X- _ O
numbers -X- _ O
of -X- _ O
voxels -X- _ O
. -X- _ O
Results -X- _ O
are -X- _ O
displayed -X- _ O
in -X- _ O
Figure -X- _ O
3 -X- _ O
. -X- _ O
It -X- _ O
is -X- _ O
interesting -X- _ O
to -X- _ O
find -X- _ O
that -X- _ O
with -X- _ O
a -X- _ O
small -X- _ O
number -X- _ O
of -X- _ O
cognitive -X- _ O
signals -X- _ O
( -X- _ O
voxels -X- _ O
) -X- _ O
, -X- _ O
TinyBERT -X- _ O
for -X- _ O
CNM -X- _ B-MethodName
can -X- _ O
achieve -X- _ O
a -X- _ O
good -X- _ O
task -X- _ O
ranking -X- _ O
score -X- _ O
. -X- _ O
By -X- _ O
contrast -X- _ O
, -X- _ O
without -X- _ O
sufficient -X- _ O
cognitive -X- _ O
signals -X- _ O
, -X- _ O
BERT -X- _ O
for -X- _ O
CNM -X- _ B-MethodName
fails -X- _ O
in -X- _ O
task -X- _ O
similarity -X- _ O
estimation -X- _ O
, -X- _ O
obtaining -X- _ O
a -X- _ O
task -X- _ O
ranking -X- _ O
score -X- _ O
worse -X- _ O
than -X- _ O
random -X- _ O
ranking -X- _ O
. -X- _ O
This -X- _ O
is -X- _ O
consistent -X- _ O
with -X- _ O
our -X- _ O
previous -X- _ O
finding -X- _ O
in -X- _ O
the -X- _ O
main -X- _ O
results -X- _ O
that -X- _ O
TinyBERT -X- _ O
( -X- _ O
with -X- _ O
KD -X- _ O
) -X- _ O
captures -X- _ O
more -X- _ O
task -X- _ O
- -X- _ O
relevant -X- _ O
knowledge -X- _ O
than -X- _ O
BERT -X- _ O
for -X- _ O
task -X- _ O
relation -X- _ O
detection -X- _ O
. -X- _ O

Analysis -X- _ O


CNM -X- _ B-MethodName
: -X- _ O
Voxel -X- _ B-TaskName
Prediction -X- _ I-TaskName
Evaluation -X- _ O

We -X- _ O
conducted -X- _ O
experiments -X- _ O
to -X- _ O
take -X- _ O
a -X- _ O
deep -X- _ O
look -X- _ O
into -X- _ O
the -X- _ O
feed -X- _ O
- -X- _ O
forward -X- _ O
neural -X- _ O
mapping -X- _ O
model -X- _ O
in -X- _ O
CNM -X- _ O
. -X- _ O
The -X- _ O
number -X- _ O
of -X- _ O
voxels -X- _ O
was -X- _ O
set -X- _ O
to -X- _ O
30K. -X- _ O
Pretrained -X- _ O
Language -X- _ O
Models -X- _ O
We -X- _ O
compared -X- _ O
the -X- _ O
prediction -X- _ O
performance -X- _ O
( -X- _ O
measured -X- _ O
by -X- _ O
MSE -X- _ B-MetricValue
between -X- _ O
predicted -X- _ O
results -X- _ O
and -X- _ O
ground -X- _ O
- -X- _ O
truth -X- _ O
voxels -X- _ O
) -X- _ O
across -X- _ O
different -X- _ O
tasks -X- _ O
using -X- _ O
BERT -X- _ O
vs. -X- _ O
Tiny -X- _ O
- -X- _ O
BERT -X- _ O
as -X- _ O
the -X- _ O
pretrained -X- _ O
language -X- _ O
model -X- _ O
to -X- _ O
obtain -X- _ O
task -X- _ O
- -X- _ O
specific -X- _ O
sentence -X- _ O
representations -X- _ O
. -X- _ O
Results -X- _ O
are -X- _ O
shown -X- _ O
in -X- _ O
Figure -X- _ O
4 -X- _ O
( -X- _ O
a -X- _ O
) -X- _ O
. -X- _ O
We -X- _ O
can -X- _ O
clearly -X- _ O
see -X- _ O
that -X- _ O
both -X- _ O
BERT -X- _ O
and -X- _ O
TinyBERT -X- _ O
are -X- _ O
better -X- _ O
than -X- _ O
the -X- _ O
random -X- _ O
baseline -X- _ O
across -X- _ O
all -X- _ O
tasks -X- _ O
. -X- _ O
And -X- _ O
TinyBERT -X- _ O
is -X- _ O
better -X- _ O
than -X- _ O
BERT -X- _ O
on -X- _ O
all -X- _ O
tasks -X- _ O
, -X- _ O
which -X- _ O
resonates -X- _ O
with -X- _ O
the -X- _ O
main -X- _ O
results -X- _ O
shown -X- _ O
in -X- _ O
Section -X- _ O
4.5 -X- _ O
. -X- _ O

Subjects -X- _ O
We -X- _ O
analyzed -X- _ O
prediction -X- _ O
performance -X- _ O
across -X- _ O
different -X- _ O
subjects -X- _ O
, -X- _ O
as -X- _ O
shown -X- _ O
in -X- _ O
Figure -X- _ O
4 -X- _ O
( -X- _ O
b -X- _ O
) -X- _ O
. -X- _ O
Although -X- _ O
the -X- _ O
prediction -X- _ O
performance -X- _ O
varies -X- _ O
across -X- _ O
different -X- _ O
tasks -X- _ O
, -X- _ O
the -X- _ O
shapes -X- _ O
of -X- _ O
the -X- _ O
prediction -X- _ O
perfor- -X- _ O
mance -X- _ O
curve -X- _ O
over -X- _ O
12 -X- _ O
tasks -X- _ O
for -X- _ O
different -X- _ O
subjects -X- _ O
are -X- _ O
similar -X- _ O
to -X- _ O
each -X- _ O
other -X- _ O
, -X- _ O
indicating -X- _ O
that -X- _ O
similar -X- _ O
brain -X- _ O
activities -X- _ O
are -X- _ O
activated -X- _ O
for -X- _ O
these -X- _ O
tasks -X- _ O
across -X- _ O
different -X- _ O
subjects -X- _ O
. -X- _ O

Analysis -X- _ O
on -X- _ O
the -X- _ O
Generality -X- _ O
of -X- _ O
Task -X- _ O
Similarity -X- _ O
Estimation -X- _ O
to -X- _ O
Underlying -X- _ O
PLMs -X- _ O

Models -X- _ O
underlying -X- _ O
our -X- _ O
cross -X- _ O
- -X- _ O
task -X- _ O
transfer -X- _ O
learning -X- _ O
are -X- _ O
different -X- _ O
pretrained -X- _ O
language -X- _ O
models -X- _ O
, -X- _ O
which -X- _ O
is -X- _ O
a -X- _ O
widely -X- _ O
acknowledged -X- _ O
practice -X- _ O
for -X- _ O
transfer -X- _ O
learning -X- _ O
in -X- _ O
NLP -X- _ O
. -X- _ O
We -X- _ O
therefore -X- _ O
want -X- _ O
to -X- _ O
investigate -X- _ O
how -X- _ O
general -X- _ O
our -X- _ O
task -X- _ O
similarity -X- _ O
estimation -X- _ O
methods -X- _ O
( -X- _ O
e.g. -X- _ O
, -X- _ O
CNM -X- _ O
, -X- _ O
CRA -X- _ O
, -X- _ O
AHP -X- _ O
) -X- _ O
are -X- _ O
to -X- _ O
the -X- _ O
underlying -X- _ O
models -X- _ O
. -X- _ O
This -X- _ O
is -X- _ O
important -X- _ O
as -X- _ O
we -X- _ O
want -X- _ O
to -X- _ O
find -X- _ O
a -X- _ O
task -X- _ O
taxonomy -X- _ O
method -X- _ O
that -X- _ O
is -X- _ O
not -X- _ O
sensitive -X- _ O
to -X- _ O
underlying -X- _ O
models -X- _ O
. -X- _ O
That -X- _ O
is -X- _ O
, -X- _ O
the -X- _ O
learned -X- _ O
task -X- _ O
taxonomy -X- _ O
can -X- _ O
be -X- _ O
used -X- _ O
to -X- _ O
guide -X- _ O
transfer -X- _ O
learning -X- _ O
for -X- _ O
any -X- _ O
model -X- _ O
. -X- _ O
For -X- _ O
this -X- _ O
, -X- _ O
we -X- _ O
first -X- _ O
computed -X- _ O
the -X- _ O
Pearson -X- _ B-MetricName
correlation -X- _ I-MetricName
coefficient -X- _ I-MetricName
( -X- _ O
ρ -X- _ O
) -X- _ O
and -X- _ O
the -X- _ O
Spearman -X- _ B-MetricName
rank -X- _ I-MetricName
correlation -X- _ I-MetricName
( -X- _ O
r -X- _ O
s -X- _ O
) -X- _ O
between -X- _ O
task -X- _ O
similarities -X- _ O
obtained -X- _ O
with -X- _ O
TinyBERT -X- _ O
and -X- _ O
those -X- _ O
with -X- _ O
BERT -X- _ O
using -X- _ O
the -X- _ O
same -X- _ O
similarity -X- _ O
estimation -X- _ O
method -X- _ O
. -X- _ O
The -X- _ O
correlation -X- _ O
coefficients -X- _ O
between -X- _ O
BERT -X- _ O
- -X- _ O
based -X- _ O
and -X- _ O
TinyBERT -X- _ O
- -X- _ O
based -X- _ O
task -X- _ O
similarity -X- _ O
matrices -X- _ O
obtained -X- _ O
by -X- _ O
the -X- _ O
CRA -X- _ B-MethodName
, -X- _ O
CNM -X- _ B-MethodName
and -X- _ O
AHP -X- _ B-MethodName
are -X- _ O
( -X- _ O
ρ -X- _ O
= -X- _ O
0.23 -X- _ B-MetricValue
, -X- _ O
r -X- _ O
s -X- _ O
= -X- _ O
0.11 -X- _ B-MetricValue
) -X- _ O
, -X- _ O
( -X- _ O
ρ -X- _ O
= -X- _ O
0.85 -X- _ B-MetricValue
, -X- _ O
r -X- _ O
s -X- _ O
= -X- _ O
0.76 -X- _ B-MetricValue
) -X- _ O
and -X- _ O
( -X- _ O
ρ -X- _ O
= -X- _ O
0.36 -X- _ B-MetricValue
, -X- _ O
r -X- _ O
s -X- _ O
= -X- _ O
0.34 -X- _ B-MetricValue
) -X- _ O
respectively -X- _ O
. -X- _ O
Both -X- _ O
AHP -X- _ B-MethodName
and -X- _ O
CRA -X- _ B-MethodName
show -X- _ O
pool -X- _ O
correlations -X- _ O
between -X- _ O
task -X- _ O
similarity -X- _ O
matrices -X- _ O
using -X- _ O
BERT -X- _ O
and -X- _ O
TinyBERT -X- _ O
. -X- _ O
On -X- _ O
the -X- _ O
contrary -X- _ O
, -X- _ O
CNM -X- _ B-MethodName
is -X- _ O
very -X- _ O
robust -X- _ O
to -X- _ O
the -X- _ O
variations -X- _ O
of -X- _ O
underlying -X- _ O
models -X- _ O
. -X- _ O
We -X- _ O
speculate -X- _ O
that -X- _ O
both -X- _ O
CRA -X- _ B-MethodName
and -X- _ O
AHP -X- _ B-MethodName
capture -X- _ O
task -X- _ O
relations -X- _ O
specific -X- _ O
to -X- _ O
underlying -X- _ O
models -X- _ O
while -X- _ O
CNM -X- _ B-MethodName
could -X- _ O
remove -X- _ O
such -X- _ O
bias -X- _ O
by -X- _ O
building -X- _ O
the -X- _ O
task -X- _ O
taxonomy -X- _ O
based -X- _ O
on -X- _ O
the -X- _ O
cognitive -X- _ O
data -X- _ O
. -X- _ O
In -X- _ O
other -X- _ O
words -X- _ O
, -X- _ O
CNM -X- _ B-MethodName
is -X- _ O
able -X- _ O
to -X- _ O
detect -X- _ O
model -X- _ O
- -X- _ O
agnostic -X- _ O
task -X- _ O
relations -X- _ O
, -X- _ O
yet -X- _ O
another -X- _ O
desirable -X- _ O
advantage -X- _ O
over -X- _ O
AHP -X- _ B-MethodName
with -X- _ O
exhaustive -X- _ O
computation -X- _ O
cost -X- _ O
. -X- _ O

To -X- _ O
further -X- _ O
examine -X- _ O
this -X- _ O
hypothesis -X- _ O
, -X- _ O
we -X- _ O
used -X- _ O
the -X- _ O
task -X- _ O
ranking -X- _ O
estimated -X- _ O
with -X- _ O
another -X- _ O
underlying -X- _ O
PLM -X- _ O
x -X- _ O
to -X- _ O
guide -X- _ O
transfer -X- _ O
learning -X- _ O
with -X- _ O
an -X- _ O
underlying -X- _ O
PLM -X- _ O
y. -X- _ O
In -X- _ O
our -X- _ O
work -X- _ O
, -X- _ O
this -X- _ O
would -X- _ O
be -X- _ O
using -X- _ O
TinyBERT -X- _ O
to -X- _ O
guide -X- _ O
BERT -X- _ O
( -X- _ O
TB -X- _ O
→ -X- _ O
B -X- _ O
) -X- _ O
or -X- _ O
vice -X- _ O
versa -X- _ O
. -X- _ O
For -X- _ O
each -X- _ O
target -X- _ O
task -X- _ O
, -X- _ O
we -X- _ O
used -X- _ O
the -X- _ O
top -X- _ O
k -X- _ O
source -X- _ O
tasks -X- _ O
according -X- _ O
to -X- _ O
the -X- _ O
task -X- _ O
ranking -X- _ O
with -X- _ O
the -X- _ O
guiding -X- _ O
PLM -X- _ O
x -X- _ O
for -X- _ O
transfer -X- _ O
learning -X- _ O
with -X- _ O
the -X- _ O
PLM -X- _ O
y. -X- _ O
The -X- _ O
results -X- _ O
were -X- _ O
compared -X- _ O
to -X- _ O
the -X- _ O
actual -X- _ O
performance -X- _ O
of -X- _ O
transfer -X- _ O
learning -X- _ O
to -X- _ O
the -X- _ O
target -X- _ O
task -X- _ O
from -X- _ O
the -X- _ O
top -X- _ O
6 -X- _ O
source -X- _ O
tasks -X- _ O
according -X- _ O
to -X- _ O
the -X- _ O
task -X- _ O
ranking -X- _ O
with -X- _ O
the -X- _ O
PLM -X- _ O
y -X- _ O
itself -X- _ O
. -X- _ O
The -X- _ O
probability -X- _ O
of -X- _ O
the -X- _ O
top -X- _ O
k -X- _ O
source -X- _ O
tasks -X- _ O
occurring -X- _ O
in -X- _ O
the -X- _ O
real -X- _ O
top -X- _ O
6 -X- _ O
tasks -X- _ O
shows -X- _ O
how -X- _ O
much -X- _ O
transferability -X- _ O
learned -X- _ O
with -X- _ O
the -X- _ O
PLM -X- _ O
x -X- _ O
can -X- _ O
be -X- _ O
used -X- _ O
for -X- _ O
the -X- _ O
PLM -X- _ O
y. -X- _ O
Results -X- _ O
are -X- _ O
shown -X- _ O
in -X- _ O
Table -X- _ O
3 -X- _ O
, -X- _ O
which -X- _ O
again -X- _ O
suggests -X- _ O
the -X- _ O
superiority -X- _ O
of -X- _ O
CNM -X- _ B-MethodName
over -X- _ O
AHP -X- _ B-MethodName
. -X- _ O

We -X- _ O
further -X- _ O
analyzed -X- _ O
the -X- _ O
generality -X- _ O
of -X- _ O
CNM -X- _ B-MethodName
to -X- _ O
different -X- _ O
subjects -X- _ O
of -X- _ O
cognitive -X- _ O
data -X- _ O
used -X- _ O
in -X- _ O
CNM -X- _ B-MethodName
, -X- _ O
which -X- _ O
can -X- _ O
be -X- _ O
found -X- _ O
in -X- _ O
Appendix -X- _ O
A.5 -X- _ O
. -X- _ O
The -X- _ O
experimental -X- _ O
results -X- _ O
show -X- _ O
that -X- _ O
the -X- _ O
CNM -X- _ B-MethodName
is -X- _ O
also -X- _ O
robust -X- _ O
to -X- _ O
different -X- _ O
subjects -X- _ O
. -X- _ O

Taxonomy -X- _ O
Tree -X- _ O
of -X- _ O
12 -X- _ O
NLP -X- _ O
Tasks -X- _ O

We -X- _ O
visualize -X- _ O
all -X- _ O
pairwise -X- _ O
task -X- _ O
similarities -X- _ O
for -X- _ O
12 -X- _ O
tasks -X- _ O
learned -X- _ O
by -X- _ O
CNM -X- _ B-MethodName
( -X- _ O
averaged -X- _ O
over -X- _ O
5 -X- _ O
subjects -X- _ O
) -X- _ O
as -X- _ O
a -X- _ O
heatmap -X- _ O
, -X- _ O
shown -X- _ O
in -X- _ O
Figure -X- _ O
5 -X- _ O
( -X- _ O
a -X- _ O
) -X- _ O
. -X- _ O
It -X- _ O
is -X- _ O
clear -X- _ O
to -X- _ O
see -X- _ O
from -X- _ O
the -X- _ O
heatmap -X- _ O
that -X- _ O
6 -X- _ O
GLUE -X- _ B-TaskName
tasks -X- _ O
( -X- _ O
i.e. -X- _ O
, -X- _ O
CoLA -X- _ B-TaskName
, -X- _ O
QNLI -X- _ B-TaskName
, -X- _ O
RTE -X- _ B-TaskName
, -X- _ O
MNLI -X- _ B-TaskName
, -X- _ O
SST-2 -X- _ B-TaskName
, -X- _ O
and -X- _ O
MRPC -X- _ B-TaskName
) -X- _ O
form -X- _ O
a -X- _ O
cluster -X- _ O
. -X- _ O
These -X- _ O
tasks -X- _ O
are -X- _ O
all -X- _ O
related -X- _ O
to -X- _ O
sentence -X- _ O
understanding -X- _ O
. -X- _ O
We -X- _ O
further -X- _ O
perform -X- _ O
hierarchical -X- _ O
clustering -X- _ O
over -X- _ O
the -X- _ O
12 -X- _ O
tasks -X- _ O
according -X- _ O
to -X- _ O
their -X- _ O
similarities -X- _ O
to -X- _ O
create -X- _ O
a -X- _ O
taxonomy -X- _ O
tree -X- _ O
, -X- _ O
which -X- _ O
is -X- _ O
illustrated -X- _ O
in -X- _ O
Figure -X- _ O
5 -X- _ O
( -X- _ O
b -X- _ O
) -X- _ O
. -X- _ O

Conclusions -X- _ O

In -X- _ O
this -X- _ O
paper -X- _ O
, -X- _ O
we -X- _ O
have -X- _ O
presented -X- _ O
a -X- _ O
cognitively -X- _ O
inspired -X- _ O
framework -X- _ O
, -X- _ O
termed -X- _ O
CogTaxonomy -X- _ B-MethodName
, -X- _ O
to -X- _ O
learn -X- _ O
relation -X- _ O
and -X- _ O
structure -X- _ O
for -X- _ O
NLP -X- _ O
tasks -X- _ O
. -X- _ O
Experiments -X- _ O
demonstrate -X- _ O
that -X- _ O
the -X- _ O
task -X- _ O
taxonomy -X- _ O
detected -X- _ O
by -X- _ O
CogTaxonomy -X- _ O
can -X- _ O
be -X- _ O
used -X- _ O
to -X- _ O
guide -X- _ O
transfer -X- _ O
learning -X- _ O
across -X- _ O
12 -X- _ O
different -X- _ O
NLP -X- _ O
tasks -X- _ O
. -X- _ O
Both -X- _ O
CRA -X- _ B-MethodName
and -X- _ O
CNM -X- _ B-MethodName
, -X- _ O
the -X- _ O
two -X- _ O
essential -X- _ O
components -X- _ O
of -X- _ O
CogTaxonomy -X- _ B-MethodName
, -X- _ O
do -X- _ O
not -X- _ O
require -X- _ O
exhaustive -X- _ O
transfer -X- _ O
learning -X- _ O
across -X- _ O
all -X- _ O
source -X- _ O
- -X- _ O
target -X- _ O
task -X- _ O
pairs -X- _ O
. -X- _ O
The -X- _ O
former -X- _ O
is -X- _ O
robust -X- _ O
to -X- _ O
different -X- _ O
combinations -X- _ O
of -X- _ O
dissimilarity -X- _ O
/ -X- _ O
similarity -X- _ O
measurements -X- _ O
. -X- _ O
The -X- _ O
latter -X- _ O
resorts -X- _ O
to -X- _ O
cognitive -X- _ O
signals -X- _ O
to -X- _ O
learn -X- _ O
model -X- _ O
- -X- _ O
agnostic -X- _ O
task -X- _ O
relations -X- _ O
. -X- _ O

A -X- _ O
Appendix -X- _ O


A.1 -X- _ O
Correlation -X- _ O
Selection -X- _ O
in -X- _ O
Cognitive -X- _ B-MethodName
- -X- _ I-MethodName
Neural -X- _ I-MethodName
Mapping -X- _ I-MethodName

We -X- _ O
have -X- _ O
different -X- _ O
options -X- _ O
for -X- _ O
the -X- _ O
calculation -X- _ O
of -X- _ O
CogR -X- _ O
( -X- _ O
e.g. -X- _ O
, -X- _ O
R -X- _ O
2 -X- _ O
and -X- _ O
ρ -X- _ O
) -X- _ O
. -X- _ O
Therefore -X- _ O
, -X- _ O
we -X- _ O
computed -X- _ O
task -X- _ O
ranking -X- _ O
scores -X- _ O
with -X- _ O
different -X- _ O
options -X- _ O
for -X- _ O
CNM -X- _ B-MethodName
with -X- _ O
BERT -X- _ O
and -X- _ O
TinyBERT -X- _ O
. -X- _ O
Results -X- _ O
are -X- _ O
shown -X- _ O
in -X- _ O
Figure -X- _ O
6 -X- _ O
. -X- _ O
We -X- _ O
find -X- _ O
that -X- _ O
R -X- _ O
2 -X- _ O
is -X- _ O
better -X- _ O
than -X- _ O
ρ -X- _ O
in -X- _ O
almost -X- _ O
all -X- _ O
cases -X- _ O
. -X- _ O

A.2 -X- _ O
Experimental -X- _ O
Settings -X- _ O

Fine -X- _ O
- -X- _ O
tuning -X- _ O
and -X- _ O
Transferring -X- _ O
For -X- _ O
most -X- _ O
tasks -X- _ O
, -X- _ O
we -X- _ O
fine -X- _ O
- -X- _ O
tuned -X- _ O
BERT -X- _ O
to -X- _ O
obtain -X- _ O
task -X- _ O
- -X- _ O
specific -X- _ O
representations -X- _ O
, -X- _ O
with -X- _ O
the -X- _ O
exception -X- _ O
of -X- _ O
RE -X- _ B-TaskName
and -X- _ O
PR -X- _ B-TaskName
. -X- _ O
REDN -X- _ O
( -X- _ O
Li -X- _ O
and -X- _ O
Tian -X- _ O
, -X- _ O
2020 -X- _ O
) -X- _ O
was -X- _ O
used -X- _ O
for -X- _ O
RE -X- _ O
tasks -X- _ O
, -X- _ O
and -X- _ O
Cross -X- _ O
- -X- _ O
Encoder -X- _ O
( -X- _ O
Reimers -X- _ O
and -X- _ O
Gurevych -X- _ O
, -X- _ O
2019 -X- _ O
) -X- _ O
was -X- _ O
used -X- _ O
for -X- _ O
PR -X- _ O
. -X- _ O
Table -X- _ O
4 -X- _ O
shows -X- _ O
the -X- _ O
hyperparameters -X- _ O
and -X- _ O
configuration -X- _ O
for -X- _ O
task -X- _ O
training -X- _ O
in -X- _ O
our -X- _ O
experiments -X- _ O
. -X- _ O

For -X- _ O
source -X- _ O
- -X- _ O
to -X- _ O
- -X- _ O
target -X- _ O
task -X- _ O
transfer -X- _ O
learning -X- _ O
, -X- _ O
all -X- _ O
source -X- _ O
models -X- _ O
were -X- _ O
fine -X- _ O
- -X- _ O
tuned -X- _ O
on -X- _ O
the -X- _ O
target -X- _ O
task -X- _ O
dataset -X- _ O
with -X- _ O
the -X- _ O
same -X- _ O
settings -X- _ O
as -X- _ O
the -X- _ O
target -X- _ O
model -X- _ O
. -X- _ O
Knowledge -X- _ O
Distillation -X- _ O
Since -X- _ O
TinyBERT -X- _ O
has -X- _ O
officially -X- _ O
released -X- _ O
models -X- _ O
distilled -X- _ O
on -X- _ O
GLUE -X- _ O
, -X- _ O
we -X- _ O
directly -X- _ O
used -X- _ O
them -X- _ O
on -X- _ O
our -X- _ O
8 -X- _ O
GLUE -X- _ O
tasks -X- _ O
. -X- _ O
For -X- _ O
the -X- _ O
PR -X- _ B-TaskName
task -X- _ O
, -X- _ O
we -X- _ O
used -X- _ O
the -X- _ O
open -X- _ O
- -X- _ O
source -X- _ O
model -X- _ O
( -X- _ O
Reimers -X- _ O
and -X- _ O
Gurevych -X- _ O
, -X- _ O
2019 -X- _ O
) -X- _ O
with -X- _ O
the -X- _ O
same -X- _ O
TinyBERT -X- _ O
ar- -X- _ O
chitecture -X- _ O
directly -X- _ O
. -X- _ O
For -X- _ O
NER -X- _ B-TaskName
, -X- _ O
QA -X- _ B-TaskName
, -X- _ O
and -X- _ O
RE -X- _ B-TaskName
tasks -X- _ O
, -X- _ O
we -X- _ O
adopted -X- _ O
the -X- _ O
above -X- _ O
fine -X- _ O
- -X- _ O
tuned -X- _ O
models -X- _ O
as -X- _ O
the -X- _ O
teacher -X- _ O
model -X- _ O
and -X- _ O
used -X- _ O
the -X- _ O
open -X- _ O
- -X- _ O
source -X- _ O
General -X- _ O
TinyBERT -X- _ O
for -X- _ O
task -X- _ O
- -X- _ O
specific -X- _ O
distillation -X- _ O
, -X- _ O
following -X- _ O
the -X- _ O
recommended -X- _ O
practice -X- _ O
of -X- _ O
TinyBERT -X- _ O
( -X- _ O
Jiao -X- _ O
et -X- _ O
al -X- _ O
. -X- _ O
, -X- _ O
2020 -X- _ O
) -X- _ O
. -X- _ O
The -X- _ O
number -X- _ O
of -X- _ O
epochs -X- _ O
in -X- _ O
the -X- _ O
task -X- _ O
- -X- _ O
specific -X- _ O
distillation -X- _ O
phase -X- _ O
is -X- _ O
shown -X- _ O
in -X- _ O
Table -X- _ O
5 -X- _ O
, -X- _ O
and -X- _ O
the -X- _ O
settings -X- _ O
of -X- _ O
other -X- _ O
parameters -X- _ O
are -X- _ O
consistent -X- _ O
with -X- _ O
finetuning -X- _ O
. -X- _ O
In -X- _ O
CoNLL -X- _ O
2003 -X- _ O
( -X- _ O
Sang -X- _ O
andMeulder -X- _ O
, -X- _ O
2003 -X- _ O
) -X- _ O
, -X- _ O
we -X- _ O
also -X- _ O
carried -X- _ O
out -X- _ O
data -X- _ O
augmentation -X- _ O
according -X- _ O
to -X- _ O
the -X- _ O
method -X- _ O
proposed -X- _ O
by -X- _ O
TinyBERT -X- _ O
( -X- _ O
Jiao -X- _ O
et -X- _ O
al -X- _ O
. -X- _ O
, -X- _ O
2020 -X- _ O
) -X- _ O
, -X- _ O
while -X- _ O
no -X- _ O
data -X- _ O
augmentation -X- _ O
was -X- _ O
performed -X- _ O
on -X- _ O
other -X- _ O
datasets -X- _ O
. -X- _ O

A.3 -X- _ O
Oracle -X- _ O
Task -X- _ O
Ranking -X- _ O

Evaluation -X- _ O
Metrics -X- _ O
for -X- _ O
12 -X- _ O
Tasks -X- _ O
Among -X- _ O
the -X- _ O
8 -X- _ O
GLUE -X- _ O
tasks -X- _ O
, -X- _ O
Matthews -X- _ B-MetricName
correlation -X- _ I-MetricName
was -X- _ O
used -X- _ O
in -X- _ O
the -X- _ O
CoLA -X- _ B-TaskName
task -X- _ O
, -X- _ O
Spearman -X- _ B-MetricName
correlation -X- _ I-MetricName
coefficient -X- _ I-MetricName
was -X- _ O
used -X- _ O
in -X- _ O
the -X- _ O
STS -X- _ B-TaskName
- -X- _ I-TaskName
B -X- _ I-TaskName
task -X- _ O
. -X- _ O
For -X- _ O
the -X- _ O
passage -X- _ B-TaskName
reranking -X- _ I-TaskName
task -X- _ O
, -X- _ O
NDCG -X- _ B-MetricName
@ -X- _ I-MetricName
10 -X- _ I-MetricName
was -X- _ O
used -X- _ O
. -X- _ O
All -X- _ O
other -X- _ O
tasks -X- _ O
used -X- _ O
F -X- _ B-MetricName
1 -X- _ I-MetricName
score -X- _ O
as -X- _ O
the -X- _ O
evaluation -X- _ O
metric -X- _ O
. -X- _ O

Pairwise -X- _ O
Transfer -X- _ O
Learning -X- _ O
Results -X- _ O
and -X- _ O
Oracle -X- _ O

Ranking -X- _ O
We -X- _ O
obtain -X- _ O
pair -X- _ O
- -X- _ O
wise -X- _ O
transfer -X- _ O
learning -X- _ O
results -X- _ O
based -X- _ O
on -X- _ O
the -X- _ O
validation -X- _ O
set -X- _ O
of -X- _ O
each -X- _ O
task -X- _ O
except -X- _ O
the -X- _ O
NER -X- _ B-TaskName
task -X- _ O
of -X- _ O
which -X- _ O
the -X- _ O
test -X- _ O
set -X- _ O
is -X- _ O
publicly -X- _ O
available -X- _ O
. -X- _ O
The -X- _ O
results -X- _ O
with -X- _ O
BERT -X- _ O
and -X- _ O
TinyBERT -X- _ O
are -X- _ O
shown -X- _ O
in -X- _ O
the -X- _ O
Table -X- _ O
6 -X- _ O
and -X- _ O
Table -X- _ O
7 -X- _ O
respectively -X- _ O
. -X- _ O
Sorted -X- _ O
by -X- _ O
transfer -X- _ O
performance -X- _ O
, -X- _ O
the -X- _ O
oracle -X- _ O
ranking -X- _ O
of -X- _ O
each -X- _ O
source -X- _ O
task -X- _ O
to -X- _ O
a -X- _ O
target -X- _ O
task -X- _ O
is -X- _ O
marked -X- _ O
in -X- _ O
parentheses -X- _ O
. -X- _ O
9 -X- _ O
. -X- _ O
Similarly -X- _ O
, -X- _ O
CRA+CNM -X- _ B-MethodName
achieves -X- _ O
very -X- _ O
competitive -X- _ O
results -X- _ O
to -X- _ O
AHP -X- _ B-MethodName
in -X- _ O
TinyBERT -X- _ O
→ -X- _ O
BERT -X- _ O
and -X- _ O
even -X- _ O
better -X- _ O
results -X- _ O
than -X- _ O
AHP -X- _ B-MethodName
in -X- _ O
BERT -X- _ O
→ -X- _ O
Tiny -X- _ O
- -X- _ O
BERT -X- _ O
. -X- _ O

In -X- _ O
the -X- _ O
two -X- _ O
tables -X- _ O
, -X- _ O
we -X- _ O
calculate -X- _ O
the -X- _ O
average -X- _ O
transfer -X- _ O
learning -X- _ O
performance -X- _ O
over -X- _ O
12 -X- _ O
tasks -X- _ O
shown -X- _ O
in -X- _ O
the -X- _ O
last -X- _ O
column -X- _ O
of -X- _ O
the -X- _ O
two -X- _ O
tables -X- _ O
for -X- _ O
easy -X- _ O
compar- -X- _ O
Table -X- _ O
9 -X- _ O
: -X- _ O
Actual -X- _ O
target -X- _ O
task -X- _ O
performance -X- _ O
when -X- _ O
task -X- _ O
similarity -X- _ O
estimation -X- _ O
and -X- _ O
transfer -X- _ O
learning -X- _ O
use -X- _ O
different -X- _ O
underlying -X- _ O
PLMs -X- _ O
. -X- _ O
B -X- _ O
/ -X- _ O
TB -X- _ O
: -X- _ O
BERT -X- _ O
/ -X- _ O
TinyBERT -X- _ O
. -X- _ O
Type -X- _ O
( -X- _ O
x -X- _ O
→ -X- _ O
y -X- _ O
) -X- _ O
denotes -X- _ O
that -X- _ O
the -X- _ O
most -X- _ O
similar -X- _ O
source -X- _ O
task -X- _ O
selected -X- _ O
according -X- _ O
to -X- _ O
a -X- _ O
task -X- _ O
similarity -X- _ O
estimation -X- _ O
method -X- _ O
with -X- _ O
underlying -X- _ O
PLM -X- _ O
x -X- _ O
is -X- _ O
used -X- _ O
for -X- _ O
transfer -X- _ O
learning -X- _ O
to -X- _ O
a -X- _ O
target -X- _ O
task -X- _ O
with -X- _ O
underlying -X- _ O
PLM -X- _ O
y -X- _ O
. -X- _ O

ison -X- _ O
. -X- _ O
The -X- _ O
results -X- _ O
of -X- _ O
" -X- _ O
Random -X- _ O
" -X- _ O
in -X- _ O
the -X- _ O
two -X- _ O
tables -X- _ O
are -X- _ O
averaged -X- _ O
over -X- _ O
5000 -X- _ O
times -X- _ O
of -X- _ O
random -X- _ O
sampling -X- _ O
. -X- _ O
Specifically -X- _ O
, -X- _ O
each -X- _ O
round -X- _ O
of -X- _ O
random -X- _ O
sampling -X- _ O
selects -X- _ O
a -X- _ O
task -X- _ O
other -X- _ O
than -X- _ O
itself -X- _ O
for -X- _ O
each -X- _ O
target -X- _ O
task -X- _ O
as -X- _ O
the -X- _ O
source -X- _ O
task -X- _ O
for -X- _ O
transfer -X- _ O
learning -X- _ O
. -X- _ O

A.5 -X- _ O
Analysis -X- _ O
on -X- _ O
the -X- _ O
Generality -X- _ O
of -X- _ O
CNM -X- _ B-MethodName
across -X- _ O
Subjects -X- _ O

We -X- _ O
calculate -X- _ O
task -X- _ O
similarity -X- _ O
matrices -X- _ O
that -X- _ O
are -X- _ O
averaged -X- _ O
over -X- _ O
5 -X- _ O
subjects -X- _ O
in -X- _ O
CNM -X- _ B-MethodName
. -X- _ O
Are -X- _ O
results -X- _ O
for -X- _ O
individual -X- _ O
subjects -X- _ O
are -X- _ O
consistent -X- _ O
with -X- _ O
each -X- _ O
other -X- _ O
? -X- _ O
Hence -X- _ O
we -X- _ O
separately -X- _ O
calculated -X- _ O
task -X- _ O
similarity -X- _ O
matrices -X- _ O
for -X- _ O
each -X- _ O
subject -X- _ O
and -X- _ O
used -X- _ O
the -X- _ O
Spearman -X- _ B-MetricName
correlation -X- _ I-MetricName
coefficient -X- _ I-MetricName
to -X- _ O
measure -X- _ O
task -X- _ O
similarity -X- _ O
matrix -X- _ O
correlations -X- _ O
among -X- _ O
subjects -X- _ O
. -X- _ O
Results -X- _ O
are -X- _ O
shown -X- _ O
in -X- _ O
Figure -X- _ O
7 -X- _ O
, -X- _ O
which -X- _ O
indicates -X- _ O
high -X- _ O
correlations -X- _ O
among -X- _ O
subjects -X- _ O
. -X- _ O

Acknowledgments -X- _ O

The -X- _ O
present -X- _ O
research -X- _ O
was -X- _ O
supported -X- _ O
by -X- _ O
Zhejiang -X- _ O
Lab -X- _ O
( -X- _ O
No -X- _ O
. -X- _ O
2022KH0AB01 -X- _ O
) -X- _ O
and -X- _ O
the -X- _ O
Natural -X- _ O
Science -X- _ O
Foundation -X- _ O
of -X- _ O
Tianjin -X- _ O
( -X- _ O
No -X- _ O
. -X- _ O
19JCZDJC31400 -X- _ O
) -X- _ O
. -X- _ O
We -X- _ O
would -X- _ O
like -X- _ O
to -X- _ O
thank -X- _ O
the -X- _ O
anonymous -X- _ O
reviewers -X- _ O
for -X- _ O
their -X- _ O
insightful -X- _ O
comments -X- _ O