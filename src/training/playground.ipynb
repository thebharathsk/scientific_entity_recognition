{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load transformer model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "import spacy\n",
    "nlp_trf = spacy.load(\"en_core_web_trf\")\n",
    "\n",
    "nlp_bg = spacy.load(\"en_core_web_lg\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Pass text through model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "text = 'The goal of this workshop is to provide a common forum where people can discuss and compare novel ideas, models and tools for textual inference and paraphrasing. The workshop follows previous ACL workshops on these topics (the ACL workshop on \"Empirical Modeling of Semantic Equivalence and Entailment\", 2005, and the joint ACL-PASCAL workshop \"Textual Entailment and Paraphrasing\", 2007). This line of workshops goes in parallel with the RTE challenges, now organized by NIST, by promoting a deeper understanding of what are the scientific achievements and the new findings emerging in the field.'\n",
    "\n",
    "doc_trf = nlp_trf(text)\n",
    "doc_bg = nlp_bg(text)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Print Tokens"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "#############\n",
      "109 109\n",
      "True\n"
     ]
    }
   ],
   "source": [
    "list_trf = []\n",
    "list_bg = []\n",
    "\n",
    "#print tokens\n",
    "for token in doc_trf:\n",
    "    # print(token.text)\n",
    "    list_trf.append(token.text)\n",
    "\n",
    "print('#############')\n",
    "\n",
    "#print tokens\n",
    "for token in doc_bg:\n",
    "    # print(token.text)\n",
    "    list_bg.append(token.text)\n",
    "\n",
    "print(len(list_trf), len(list_bg))\n",
    "\n",
    "#check if the two lists are same\n",
    "print(list_trf == list_bg)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Print entities detected"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "eleven 96 102 CARDINAL\n",
      "80.5%(7.7% 173 183 PERCENT\n",
      "86.7%(4.6%absolute improvement),SQuADv1.1 question 234 284 PERCENT\n",
      "93.2(1.5 306 314 CARDINAL\n",
      "83.1 368 372 CARDINAL\n",
      "5.1 point 374 383 PERCENT\n"
     ]
    }
   ],
   "source": [
    "for ent in doc.ents:\n",
    "    print(ent.text, ent.start_char, ent.end_char, ent.label_)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "11711",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
